{"2025-07-25T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2507.19478v1","updated":"2025-07-25T17:59:26Z","published":"2025-07-25T17:59:26Z","title":"MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI\n  Agents","summary":"  We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI\nautomation agents across Windows, macOS, Linux, iOS, Android, and Web\nplatforms. It comprises four levels: GUI Content Understanding, Element\nGrounding, Task Automation, and Task Collaboration, covering essential skills\nfor GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)\nmetric to assess GUI agent execution efficiency in online automation scenarios.\nThrough MMBench-GUI, we identify accurate visual grounding as a critical\ndeterminant of overall task success, emphasizing the substantial benefits of\nmodular frameworks that integrate specialized grounding modules. Furthermore,\nto achieve reliable GUI automation, an agent requires strong task planning and\ncross-platform generalization abilities, with long-context memory, a broad\naction space, and long-term reasoning playing a critical role. More important,\ntask efficiency remains a critically underexplored dimension, and all models\nsuffer from substantial inefficiencies, with excessive redundant steps even\nwhen tasks are ultimately completed. The integration of precise localization,\neffective planning, and early stopping strategies is indispensable to enable\ntruly efficient and scalable GUI automation. Our benchmark code, evaluation\ndata, and running environment will be publicly available at\nhttps://github.com/open-compass/MMBench-GUI.\n","authors":["Xuehui Wang","Zhenyu Wu","JingJing Xie","Zichen Ding","Bowen Yang","Zehao Li","Zhaoyang Liu","Qingyun Li","Xuan Dong","Zhe Chen","Weiyun Wang","Xiangyu Zhao","Jixuan Chen","Haodong Duan","Tianbao Xie","Chenyu Yang","Shiqian Su","Yue Yu","Yuan Huang","Yiqian Liu","Xiao Zhang","Yanting Zhang","Xiangyu Yue","Weijie Su","Xizhou Zhu","Wei Shen","Jifeng Dai","Wenhai Wang"],"pdf_url":"https://arxiv.org/pdf/2507.19478v1.pdf","comment":"in progress"},{"id":"http://arxiv.org/abs/2507.19477v1","updated":"2025-07-25T17:59:13Z","published":"2025-07-25T17:59:13Z","title":"Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts","summary":"  Many recent papers have studied the development of superforecaster-level\nevent forecasting LLMs. While methodological problems with early studies cast\ndoubt on the use of LLMs for event forecasting, recent studies with improved\nevaluation methods have shown that state-of-the-art LLMs are gradually reaching\nsuperforecaster-level performance, and reinforcement learning has also been\nreported to improve future forecasting. Additionally, the unprecedented success\nof recent reasoning models and Deep Research-style models suggests that\ntechnology capable of greatly improving forecasting performance has been\ndeveloped. Therefore, based on these positive recent trends, we argue that the\ntime is ripe for research on large-scale training of superforecaster-level\nevent forecasting LLMs. We discuss two key research directions: training\nmethods and data acquisition. For training, we first introduce three\ndifficulties of LLM-based event forecasting training: noisiness-sparsity,\nknowledge cut-off, and simple reward structure problems. Then, we present\nrelated ideas to mitigate these problems: hypothetical event Bayesian networks,\nutilizing poorly-recalled and counterfactual events, and auxiliary reward\nsignals. For data, we propose aggressive use of market, public, and crawling\ndatasets to enable large-scale training and evaluation. Finally, we explain how\nthese technical advances could enable AI to provide predictive intelligence to\nsociety in broader areas. This position paper presents promising specific paths\nand considerations for getting closer to superforecaster-level AI technology,\naiming to call for researchers' interest in these directions.\n","authors":["Sang-Woo Lee","Sohee Yang","Donghyun Kwak","Noah Y. Siegel"],"pdf_url":"https://arxiv.org/pdf/2507.19477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06303v2","updated":"2025-07-25T17:55:30Z","published":"2024-08-12T17:15:02Z","title":"Long-Form Answers to Visual Questions from Blind and Low Vision People","summary":"  Vision language models can now generate long-form answers to questions about\nimages - long-form visual question answers (LFVQA). We contribute VizWiz-LF, a\ndataset of long-form answers to visual questions posed by blind and low vision\n(BLV) users. VizWiz-LF contains 4.2k long-form answers to 600 visual questions,\ncollected from human expert describers and six VQA models. We develop and\nannotate functional roles of sentences of LFVQA and demonstrate that long-form\nanswers contain information beyond the question answer such as explanations and\nsuggestions. We further conduct automatic and human evaluations with BLV and\nsighted people to evaluate long-form answers. BLV people perceive both\nhuman-written and generated long-form answers to be plausible, but generated\nanswers often hallucinate incorrect visual details, especially for unanswerable\nvisual questions (e.g., blurry or irrelevant images). To reduce hallucinations,\nwe evaluate the ability of VQA models to abstain from answering unanswerable\nquestions across multiple prompting strategies.\n","authors":["Mina Huh","Fangyuan Xu","Yi-Hao Peng","Chongyan Chen","Hansika Murugu","Danna Gurari","Eunsol Choi","Amy Pavel"],"pdf_url":"https://arxiv.org/pdf/2408.06303v2.pdf","comment":"COLM 2024 Oral Spotlight"},{"id":"http://arxiv.org/abs/2507.19470v1","updated":"2025-07-25T17:55:13Z","published":"2025-07-25T17:55:13Z","title":"Conversations Gone Awry, But Then? Evaluating Conversational Forecasting\n  Models","summary":"  We often rely on our intuition to anticipate the direction of a conversation.\nEndowing automated systems with similar foresight can enable them to assist\nhuman-human interactions. Recent work on developing models with this predictive\ncapacity has focused on the Conversations Gone Awry (CGA) task: forecasting\nwhether an ongoing conversation will derail. In this work, we revisit this task\nand introduce the first uniform evaluation framework, creating a benchmark that\nenables direct and reliable comparisons between different architectures. This\nallows us to present an up-to-date overview of the current progress in CGA\nmodels, in light of recent advancements in language modeling. Our framework\nalso introduces a novel metric that captures a model's ability to revise its\nforecast as the conversation progresses.\n","authors":["Son Quoc Tran","Tushaar Gangavarapu","Nicholas Chernogor","Jonathan P. Chang","Cristian Danescu-Niculescu-Mizil"],"pdf_url":"https://arxiv.org/pdf/2507.19470v1.pdf","comment":"Code and data available as part of ConvoKit:\n  https://convokit.cornell.edu"},{"id":"http://arxiv.org/abs/2505.03005v3","updated":"2025-07-25T17:46:09Z","published":"2025-05-05T20:03:28Z","title":"RADLADS: Rapid Attention Distillation to Linear Attention Decoders at\n  Scale","summary":"  We present Rapid Attention Distillation to Linear Attention Decoders at Scale\n(RADLADS), a protocol for rapidly converting softmax attention transformers\ninto linear attention decoder models, along with two new RWKV-variant\narchitectures, and models converted from popular Qwen2.5 open source models in\n7B, 32B, and 72B sizes. Our conversion process requires only 350-700M tokens,\nless than 0.005% of the token count used to train the original teacher models.\nConverting to our 72B linear attention model costs less than \\$2,000 USD at\ntoday's prices, yet quality at inference remains close to the original\ntransformer. These models achieve state-of-the-art downstream performance\nacross a set of standard benchmarks for linear attention models of their size.\nWe release all our models on HuggingFace under the Apache 2.0 license, with the\nexception of our 72B models which are also governed by the Qwen License\nAgreement.\n  Models at\nhttps://huggingface.co/collections/recursal/radlads-6818ee69e99e729ba8a87102\nTraining Code at https://github.com/recursal/RADLADS-paper\n","authors":["Daniel Goldstein","Eric Alcaide","Janna Lu","Eugene Cheah"],"pdf_url":"https://arxiv.org/pdf/2505.03005v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19457v1","updated":"2025-07-25T17:42:32Z","published":"2025-07-25T17:42:32Z","title":"GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning","summary":"  Large language models (LLMs) are increasingly adapted to downstream tasks via\nreinforcement learning (RL) methods like Group Relative Policy Optimization\n(GRPO), which often require thousands of rollouts to learn new tasks. We argue\nthat the interpretable nature of language can often provide a much richer\nlearning medium for LLMs, compared with policy gradients derived from sparse,\nscalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt\noptimizer that thoroughly incorporates natural language reflection to learn\nhigh-level rules from trial and error. Given any AI system containing one or\nmore LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool\ncalls, and tool outputs) and reflects on them in natural language to diagnose\nproblems, propose and test prompt updates, and combine complementary lessons\nfrom the Pareto frontier of its own attempts. As a result of GEPA's design, it\ncan often turn even just a few rollouts into a large quality gain. Across four\ntasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up\nto 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,\nMIPROv2, by over 10% across two LLMs, and demonstrates promising results as an\ninference-time search strategy for code optimization.\n","authors":["Lakshya A Agrawal","Shangyin Tan","Dilara Soylu","Noah Ziems","Rishi Khare","Krista Opsahl-Ong","Arnav Singhvi","Herumb Shandilya","Michael J Ryan","Meng Jiang","Christopher Potts","Koushik Sen","Alexandros G. Dimakis","Ion Stoica","Dan Klein","Matei Zaharia","Omar Khattab"],"pdf_url":"https://arxiv.org/pdf/2507.19457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08606v2","updated":"2025-07-25T16:55:43Z","published":"2025-02-12T17:52:47Z","title":"Distillation Scaling Laws","summary":"  We propose a distillation scaling law that estimates distilled model\nperformance based on a compute budget and its allocation between the student\nand teacher. Our findings mitigate the risks associated with large-scale\ndistillation by enabling compute-optimal allocation for both the teacher and\nstudent to maximize student performance. We provide compute-optimal\ndistillation recipes for two key scenarios: when a teacher already exists, and\nwhen a teacher needs training. In settings involving many students or an\nexisting teacher, distillation outperforms supervised learning up to a compute\nlevel that scales predictably with student size. Conversely, if only one\nstudent is to be distilled and a teacher also requires training, supervised\nlearning is generally preferable. Additionally, our large-scale study of\ndistillation increases our understanding of the process and helps inform\nexperimental design.\n","authors":["Dan Busbridge","Amitis Shidani","Floris Weers","Jason Ramapuram","Etai Littwin","Russ Webb"],"pdf_url":"https://arxiv.org/pdf/2502.08606v2.pdf","comment":"Version accepted to ICML 2025. 69 pages, 54 figures, 13 tables"},{"id":"http://arxiv.org/abs/2507.19419v1","updated":"2025-07-25T16:37:58Z","published":"2025-07-25T16:37:58Z","title":"TokenSmith: Streamlining Data Editing, Search, and Inspection for\n  Large-Scale Language Model Training and Interpretability","summary":"  Understanding the relationship between training data and model behavior\nduring pretraining is crucial, but existing workflows make this process\ncumbersome, fragmented, and often inaccessible to researchers. We present\nTokenSmith, an open-source library for interactive editing, inspection, and\nanalysis of datasets used in Megatron-style pretraining frameworks such as\nGPT-NeoX, Megatron, and NVIDIA NeMo. TokenSmith supports a wide range of\noperations including searching, viewing, ingesting, exporting, inspecting, and\nsampling data, all accessible through a simple user interface and a modular\nbackend. It also enables structured editing of pretraining data without\nrequiring changes to training code, simplifying dataset debugging, validation,\nand experimentation.\n  TokenSmith is designed as a plug and play addition to existing large language\nmodel pretraining workflows, thereby democratizing access to production-grade\ndataset tooling. TokenSmith is hosted on GitHub1, with accompanying\ndocumentation and tutorials. A demonstration video is also available on\nYouTube.\n","authors":["Mohammad Aflah Khan","Ameya Godbole","Johnny Tian-Zheng Wei","Ryan Wang","James Flemings","Krishna Gummadi","Willie Neiswanger","Robin Jia"],"pdf_url":"https://arxiv.org/pdf/2507.19419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19407v1","updated":"2025-07-25T16:15:00Z","published":"2025-07-25T16:15:00Z","title":"Towards Domain Specification of Embedding Models in Medicine","summary":"  Medical text embedding models are foundational to a wide array of healthcare\napplications, ranging from clinical decision support and biomedical information\nretrieval to medical question answering, yet they remain hampered by two\ncritical shortcomings. First, most models are trained on a narrow slice of\nmedical and biological data, beside not being up to date in terms of\nmethodology, making them ill suited to capture the diversity of terminology and\nsemantics encountered in practice. Second, existing evaluations are often\ninadequate: even widely used benchmarks fail to generalize across the full\nspectrum of real world medical tasks.\n  To address these gaps, we leverage MEDTE, a GTE model extensively fine-tuned\non diverse medical corpora through self-supervised contrastive learning across\nmultiple data sources, to deliver robust medical text embeddings.\n  Alongside this model, we propose a comprehensive benchmark suite of 51 tasks\nspanning classification, clustering, pair classification, and retrieval modeled\non the Massive Text Embedding Benchmark (MTEB) but tailored to the nuances of\nmedical text. Our results demonstrate that this combined approach not only\nestablishes a robust evaluation framework but also yields embeddings that\nconsistently outperform state of the art alternatives in different tasks.\n","authors":["Mohammad Khodadad","Ali Shiraee","Mahdi Astaraki","Hamidreza Mahyar"],"pdf_url":"https://arxiv.org/pdf/2507.19407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19396v1","updated":"2025-07-25T16:02:02Z","published":"2025-07-25T16:02:02Z","title":"Detection of Adverse Drug Events in Dutch clinical free text documents\n  using Transformer Models: benchmark study","summary":"  In this study, we set a benchmark for adverse drug event (ADE) detection in\nDutch clinical free text documents using several transformer models, clinical\nscenarios and fit-for-purpose performance measures. We trained a Bidirectional\nLong Short-Term Memory (Bi-LSTM) model and four transformer-based Dutch and/or\nmultilingual encoder models (BERTje, RobBERT, MedRoBERTa.nl, and NuNER) for the\ntasks of named entity recognition (NER) and relation classification (RC) using\n102 richly annotated Dutch ICU clinical progress notes. Anonymized free text\nclinical progress notes of patients admitted to intensive care unit (ICU) of\none academic hospital and discharge letters of patients admitted to Internal\nMedicine wards of two non-academic hospitals were reused. We evaluated our ADE\nRC models internally using gold standard (two-step task) and predicted entities\n(end-to-end task). In addition, all models were externally validated on\ndetecting ADEs at the document level. We report both micro- and macro-averaged\nF1 scores, given the imbalance of ADEs in the datasets. Although differences\nfor the ADE RC task between the models were small, MedRoBERTa.nl was the best\nperforming model with macro-averaged F1 score of 0.63 using gold standard and\n0.62 using predicted entities. The MedRoBERTa.nl models also performed the best\nin our external validation and achieved recall of between 0.67 to 0.74 using\npredicted entities, meaning between 67 to 74% of discharge letters with ADEs\nwere detected. Our benchmark study presents a robust and clinically meaningful\napproach for evaluating language models for ADE detection in clinical free text\ndocuments. Our study highlights the need to use appropriate performance\nmeasures fit for the task of ADE detection in clinical free-text documents and\nenvisioned future clinical use.\n","authors":["Rachel M. Murphy","Nishant Mishra","Nicolette F. de Keizer","Dave A. Dongelmans","Kitty J. Jager","Ameen Abu-Hanna","Joanna E. Klopotowska","Iacer Calixto"],"pdf_url":"https://arxiv.org/pdf/2507.19396v1.pdf","comment":"30 Pages, 5 Figures (Main Paper), 19 Pages, 2 Figures(Supplements).\n  Rachel M. Murphy and Nishant Mishra are shared first authors. Joanna E.\n  Klopotowska and Iacer Calixto are shared last authors"},{"id":"http://arxiv.org/abs/2507.19374v1","updated":"2025-07-25T15:25:17Z","published":"2025-07-25T15:25:17Z","title":"Data Augmentation for Spoken Grammatical Error Correction","summary":"  While there exist strong benchmark datasets for grammatical error correction\n(GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still\nunder-resourced. In this paper, we propose a fully automated method to generate\naudio-text pairs with grammatical errors and disfluencies. Moreover, we propose\na series of objective metrics that can be used to evaluate the generated data\nand choose the more suitable dataset for SGEC. The goal is to generate an\naugmented dataset that maintains the textual and acoustic characteristics of\nthe original data while providing new types of errors. This augmented dataset\nshould augment and enrich the original corpus without altering the language\nassessment scores of the second language (L2) learners. We evaluate the use of\nthe augmented corpus both for written GEC (the text part) and for SGEC (the\naudio-text pairs). Our experiments are conducted on the S\\&I Corpus, the first\npublicly available speech dataset with grammar error annotations.\n","authors":["Penny Karanasou","Mengjie Qian","Stefano Bannò","Mark J. F. Gales","Kate M. Knill"],"pdf_url":"https://arxiv.org/pdf/2507.19374v1.pdf","comment":"This work has been accepted by ISCA SLaTE 2025"},{"id":"http://arxiv.org/abs/2507.19362v1","updated":"2025-07-25T15:12:42Z","published":"2025-07-25T15:12:42Z","title":"LOTUS: A Leaderboard for Detailed Image Captioning from Quality to\n  Societal Bias and User Preferences","summary":"  Large Vision-Language Models (LVLMs) have transformed image captioning,\nshifting from concise captions to detailed descriptions. We introduce LOTUS, a\nleaderboard for evaluating detailed captions, addressing three main gaps in\nexisting evaluations: lack of standardized criteria, bias-aware assessments,\nand user preference considerations. LOTUS comprehensively evaluates various\naspects, including caption quality (e.g., alignment, descriptiveness), risks\n(\\eg, hallucination), and societal biases (e.g., gender bias) while enabling\npreference-oriented evaluations by tailoring criteria to diverse user\npreferences. Our analysis of recent LVLMs reveals no single model excels across\nall criteria, while correlations emerge between caption detail and bias risks.\nPreference-oriented evaluations demonstrate that optimal model selection\ndepends on user priorities.\n","authors":["Yusuke Hirota","Boyi Li","Ryo Hachiuma","Yueh-Hua Wu","Boris Ivanovic","Yuta Nakashima","Marco Pavone","Yejin Choi","Yu-Chiang Frank Wang","Chao-Han Huck Yang"],"pdf_url":"https://arxiv.org/pdf/2507.19362v1.pdf","comment":"Accepted to ACL 2025. Leaderboard:\n  huggingface.co/spaces/nvidia/lotus-vlm-bias-leaderboard"},{"id":"http://arxiv.org/abs/2507.19361v1","updated":"2025-07-25T15:12:06Z","published":"2025-07-25T15:12:06Z","title":"SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice\n  Understanding Large Language Models","summary":"  We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human\ncognition-inspired evaluation pipeline for voice understanding large language\nmodels, LLM Voice, designed to assess their voice understanding ability. Moving\nbeyond popular voice understanding metrics such as word error rate (WER), SIQ\nexamines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy:\n(1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e.,\nsimilarity of LLM's interpretations); and (3) Application (i.e., QA accuracy\nfor simulating downstream tasks). We demonstrate that SIQ not only quantifies\nvoice understanding abilities but also provides unified comparisons between\ncascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation\nerrors in existing benchmarks, and detects hallucinations in LLM Voice. Our\nframework represents a first-of-its-kind intelligence examination that bridges\ncognitive principles with voice-oriented benchmarks, while exposing overlooked\nchallenges in multi-modal training.\n","authors":["Zhen Wan","Chao-Han Huck Yang","Yahan Yu","Jinchuan Tian","Sheng Li","Ke Hu","Zhehuai Chen","Shinji Watanabe","Fei Cheng","Chenhui Chu","Sadao Kurohashi"],"pdf_url":"https://arxiv.org/pdf/2507.19361v1.pdf","comment":"Our Speech-IQ leaderboard will be hosted at\n  huggingface.co/spaces/nvidia/Speech-IQ-leaderboard. ACL 2025 main"},{"id":"http://arxiv.org/abs/2505.15670v4","updated":"2025-07-25T15:07:10Z","published":"2025-05-21T15:48:30Z","title":"SALM-Duplex: Efficient and Direct Duplex Modeling for Speech-to-Speech\n  Language Model","summary":"  Spoken dialogue is an intuitive form of human-computer interaction, yet\ncurrent speech language models often remain constrained to turn-based\nexchanges, lacking real-time adaptability such as user barge-in. We propose a\nnovel duplex speech to speech (S2S) architecture featuring continuous user\ninputs and codec agent outputs with channel fusion that directly models\nsimultaneous user and agent streams. Using a pretrained streaming encoder for\nuser input enables the first duplex S2S model without requiring speech\npretrain. Separate architectures for agent and user modeling facilitate codec\nfine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared\nto previous works. Experimental results show that the proposed model\noutperforms previous duplex models in reasoning, turn-taking, and barge-in\nabilities. The model requires significantly less speech data, as speech\npretrain is skipped, which markedly simplifies the process of building a duplex\nS2S model from any LLMs. Finally, it is the first openly available duplex S2S\nmodel with training and inference code to foster reproducibility.\n","authors":["Ke Hu","Ehsan Hosseini-Asl","Chen Chen","Edresson Casanova","Subhankar Ghosh","Piotr Żelasko","Zhehuai Chen","Jason Li","Jagadeesh Balam","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2505.15670v4.pdf","comment":"Accepted to Interspeech 2025"},{"id":"http://arxiv.org/abs/2507.19356v1","updated":"2025-07-25T15:05:20Z","published":"2025-07-25T15:05:20Z","title":"Enhancing Speech Emotion Recognition Leveraging Aligning Timestamps of\n  ASR Transcripts and Speaker Diarization","summary":"  In this paper, we investigate the impact of incorporating timestamp-based\nalignment between Automatic Speech Recognition (ASR) transcripts and Speaker\nDiarization (SD) outputs on Speech Emotion Recognition (SER) accuracy.\nMisalignment between these two modalities often reduces the reliability of\nmultimodal emotion recognition systems, particularly in conversational\ncontexts. To address this issue, we introduce an alignment pipeline utilizing\npre-trained ASR and speaker diarization models, systematically synchronizing\ntimestamps to generate accurately labeled speaker segments. Our multimodal\napproach combines textual embeddings extracted via RoBERTa with audio\nembeddings from Wav2Vec, leveraging cross-attention fusion enhanced by a gating\nmechanism. Experimental evaluations on the IEMOCAP benchmark dataset\ndemonstrate that precise timestamp alignment improves SER accuracy,\noutperforming baseline methods that lack synchronization. The results highlight\nthe critical importance of temporal alignment, demonstrating its effectiveness\nin enhancing overall emotion recognition accuracy and providing a foundation\nfor robust multimodal emotion analysis.\n","authors":["Hsuan-Yu Wang","Pei-Ying Lee","Berlin Chen"],"pdf_url":"https://arxiv.org/pdf/2507.19356v1.pdf","comment":"6 pages, 3 figures, to appear in the Proceedings of the 2025\n  International Conference on Asian Language Processing (IALP)"},{"id":"http://arxiv.org/abs/2505.19630v2","updated":"2025-07-25T15:04:53Z","published":"2025-05-26T07:48:14Z","title":"DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning\n  System for Multi-Turn Clinical Dialogue","summary":"  Large language models (LLMs) have demonstrated excellent capabilities in the\nfield of biomedical question answering, but their application in real-world\nclinical consultations still faces core challenges. Single-round consultation\nsystems require patients to describe all symptoms upfront, leading to vague\ndiagnosis with unclear complaints. Traditional multi-turn dialogue models,\nconstrained by static supervised learning, lack flexibility and fail to\nintelligently extract key clinical information. To address these limitations,\nwe propose \\Ours{}, a reinforcement learning (RL)-based multi-agent\ncollaborative framework that models medical consultations as a dynamic\ndecision-making process under uncertainty. The doctor agent continuously\noptimizes its questioning strategy within the RL framework through multi-turn\ninteractions with the patient agent, dynamically adjusting its\ninformation-gathering path based on comprehensive rewards from the Consultation\nEvaluator. This RL fine-tuning mechanism enables LLMs to autonomously develop\ninteraction strategies aligned with clinical reasoning logic, rather than\nsuperficially imitating patterns in existing dialogue data. Notably, we\nconstructed MTMedDialog, the first English multi-turn medical consultation\ndataset capable of simulating patient interactions. Experiments demonstrate\nthat \\Ours{} outperforms existing models in both multi-turn reasoning\ncapability and final diagnostic performance. This approach shows immense\npractical value by reducing misdiagnosis risks in time-pressured settings,\nfreeing clinicians for complex cases, and pioneering a strategy to optimize\nmedical resource allocation and alleviate workforce shortages. Code and data\nare available at https://github.com/JarvisUSTC/DoctorAgent-RL\n","authors":["Yichun Feng","Jiawei Wang","Lu Zhou","Zhen Lei","Yixue Li"],"pdf_url":"https://arxiv.org/pdf/2505.19630v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19353v1","updated":"2025-07-25T15:02:45Z","published":"2025-07-25T15:02:45Z","title":"Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM\n  on Long-Context Tasks","summary":"  Recently, recurrent large language models (Recurrent LLMs) with linear\ncomputational complexity have re-emerged as efficient alternatives to\nself-attention-based LLMs (Self-Attention LLMs), which have quadratic\ncomplexity. However, Recurrent LLMs often underperform on long-context tasks\ndue to their limited fixed-size memory. Previous research has primarily focused\non enhancing the memory capacity of Recurrent LLMs through architectural\ninnovations, but these approaches have not yet enabled Recurrent LLMs to match\nthe performance of Self-Attention LLMs on long-context tasks. We argue that\nthis limitation arises because processing the entire context at once is not\nwell-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a\nchunk-wise inference method inspired by human reading strategies. Smooth\nReading processes context in chunks and iteratively summarizes the contextual\ninformation, thereby reducing memory demands and making the approach more\ncompatible with Recurrent LLMs. Our experimental results show that this method\nsubstantially narrows the performance gap between Recurrent and Self-Attention\nLLMs on long-context tasks, while preserving the efficiency advantages of\nRecurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from\n5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.\nBesides, our method maintains the high efficiency, training 3x faster and\ninferring 2x faster at 64k context compared to Self-Attention LLMs. To our\nknowledge, this is the first work to achieve comparable performance using\nRecurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope\nour method will inspire future research in this area. To facilitate further\nprogress, we will release code and dataset.\n","authors":["Kai Liu","Zhan Su","Peijie Dong","Fengran Mo","Jianfei Gao","ShaoTing Zhang","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2507.19353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19333v1","updated":"2025-07-25T14:43:31Z","published":"2025-07-25T14:43:31Z","title":"Injecting External Knowledge into the Reasoning Process Enhances\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has been widely adopted to augment large\nlanguage models (LLMs) with external knowledge for knowledge-intensive tasks.\nHowever, its effectiveness is often undermined by the presence of noisy (i.e.,\nlow-quality) retrieved passages. Enhancing LLMs' robustness to such noise is\ncritical for improving the reliability of RAG systems. Recent advances have\nequipped LLMs with strong reasoning and self-reflection capabilities, allowing\nthem to identify and correct errors in their reasoning process. Inspired by\nthis ability, we propose Passage Injection-a simple yet effective method that\nexplicitly incorporates retrieved passages into LLMs' reasoning process, aiming\nto enhance the model's ability to recognize and resist noisy passages. We\nvalidate Passage Injection under general RAG settings using BM25 as the\nretriever. Experiments on four reasoning-enhanced LLMs across four factual QA\ndatasets demonstrate that Passage Injection significantly improves overall RAG\nperformance. Further analysis on two noisy retrieval settings-random noise,\nwhere the model is provided irrelevant passages, and counterfactual noise,\nwhere it is given misleading passages-shows that Passage Injection consistently\nimproves robustness. Controlled experiments confirm that Passage Injection can\nalso effectively leverage helpful passages. These findings suggest that\nincorporating passages in LLMs' reasoning process is a promising direction for\nbuilding more robust RAG systems. The code can be found\n\\href{here}{https://github.com/mh-tang/Passage-Injection}.\n","authors":["Minghao Tang","Shiyu Ni","Jiafeng Guo","Keping Bi"],"pdf_url":"https://arxiv.org/pdf/2507.19333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14335v2","updated":"2025-07-25T14:40:41Z","published":"2025-06-17T09:17:41Z","title":"References Matter: Investigating the Impact of Reference Set Variation\n  on Summarization Evaluation","summary":"  Human language production exhibits remarkable richness and variation,\nreflecting diverse communication styles and intents. However, this variation is\noften overlooked in summarization evaluation. While having multiple reference\nsummaries is known to improve correlation with human judgments, the impact of\nthe reference set on reference-based metrics has not been systematically\ninvestigated. This work examines the sensitivity of widely used reference-based\nmetrics in relation to the choice of reference sets, analyzing three diverse\nmulti-reference summarization datasets: SummEval, GUMSum, and DUC2004. We\ndemonstrate that many popular metrics exhibit significant instability. This\ninstability is particularly concerning for n-gram-based metrics like ROUGE,\nwhere model rankings vary depending on the reference sets, undermining the\nreliability of model comparisons. We also collect human judgments on LLM\noutputs for genre-diverse data and examine their correlation with metrics to\nsupplement existing findings beyond newswire summaries, finding weak-to-no\ncorrelation. Taken together, we recommend incorporating reference set variation\ninto summarization evaluation to enhance consistency alongside correlation with\nhuman judgments, especially when evaluating LLMs.\n","authors":["Silvia Casola","Yang Janet Liu","Siyao Peng","Oliver Kraus","Albert Gatt","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2506.14335v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19315v1","updated":"2025-07-25T14:30:28Z","published":"2025-07-25T14:30:28Z","title":"AutoPCR: Automated Phenotype Concept Recognition by Prompting","summary":"  Phenotype concept recognition (CR) is a fundamental task in biomedical text\nmining, enabling applications such as clinical diagnostics and knowledge graph\nconstruction. However, existing methods often require ontology-specific\ntraining and struggle to generalize across diverse text types and evolving\nbiomedical terminology. We present AutoPCR, a prompt-based phenotype CR method\nthat does not require ontology-specific training. AutoPCR performs CR in three\nstages: entity extraction using a hybrid of rule-based and neural tagging\nstrategies, candidate retrieval via SapBERT, and entity linking through\nprompting a large language model. Experiments on four benchmark datasets show\nthat AutoPCR achieves the best average and most robust performance across both\nmention-level and document-level evaluations, surpassing prior state-of-the-art\nmethods. Further ablation and transfer studies demonstrate its inductive\ncapability and generalizability to new ontologies.\n","authors":["Yicheng Tao","Yuanhao Huang","Jie Liu"],"pdf_url":"https://arxiv.org/pdf/2507.19315v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19303v1","updated":"2025-07-25T14:18:54Z","published":"2025-07-25T14:18:54Z","title":"Identifying Fine-grained Forms of Populism in Political Discourse: A\n  Case Study on Donald Trump's Presidential Campaigns","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\na wide range of instruction-following tasks, yet their grasp of nuanced social\nscience concepts remains underexplored. This paper examines whether LLMs can\nidentify and classify fine-grained forms of populism, a complex and contested\nconcept in both academic and media debates. To this end, we curate and release\nnovel datasets specifically designed to capture populist discourse. We evaluate\na range of pre-trained (large) language models, both open-weight and\nproprietary, across multiple prompting paradigms. Our analysis reveals notable\nvariation in performance, highlighting the limitations of LLMs in detecting\npopulist discourse. We find that a fine-tuned RoBERTa classifier vastly\noutperforms all new-era instruction-tuned LLMs, unless fine-tuned.\nAdditionally, we apply our best-performing model to analyze campaign speeches\nby Donald Trump, extracting valuable insights into his strategic use of\npopulist rhetoric. Finally, we assess the generalizability of these models by\nbenchmarking them on campaign speeches by European politicians, offering a lens\ninto cross-context transferability in political discourse analysis. In this\nsetting, we find that instruction-tuned LLMs exhibit greater robustness on\nout-of-domain data.\n","authors":["Ilias Chalkidis","Stephanie Brandl","Paris Aslanidis"],"pdf_url":"https://arxiv.org/pdf/2507.19303v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2507.19247v1","updated":"2025-07-25T13:14:03Z","published":"2025-07-25T13:14:03Z","title":"A Markov Categorical Framework for Language Modeling","summary":"  Auto-regressive language models factorize sequence probabilities and are\ntrained by minimizing the negative log-likelihood (NLL) objective. While\nempirically powerful, a deep theoretical understanding of why this simple\nobjective yields such versatile representations remains elusive. This work\nintroduces a unifying analytical framework using Markov Categories (MCs) to\ndeconstruct the AR generation process and the NLL objective. We model the\nsingle-step generation map as a composition of Markov kernels in the category\nStoch. This compositional view, when enriched with statistical divergences,\nallows us to dissect information flow and learned geometry. Our framework makes\nthree main contributions. First, we provide a formal, information-theoretic\nrationale for the success of modern speculative decoding methods like EAGLE,\nquantifying the information surplus in hidden states that these methods\nexploit. Second, we formalize how NLL minimization forces the model to learn\nnot just the next token, but the data's intrinsic conditional stochasticity, a\nprocess we analyze using categorical entropy. Third, and most centrally, we\nprove that NLL training acts as an implicit form of spectral contrastive\nlearning. By analyzing the information geometry of the model's prediction head,\nwe show that NLL implicitly forces the learned representation space to align\nwith the eigenspectrum of a predictive similarity operator, thereby learning a\ngeometrically structured space without explicit contrastive pairs. This\ncompositional and information-geometric perspective reveals the deep structural\nprinciples underlying the effectiveness of modern LMs. Project Page:\nhttps://github.com/asiresearch/lm-theory\n","authors":["Yifan Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.19247v1.pdf","comment":"Project Page: https://github.com/asiresearch/lm-theory"},{"id":"http://arxiv.org/abs/2507.19227v1","updated":"2025-07-25T12:53:03Z","published":"2025-07-25T12:53:03Z","title":"Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety\n  Flaws in Diffusion-Based Text Generation","summary":"  Large Language Diffusion Models (LLDMs) exhibit comparable performance to\nLLMs while offering distinct advantages in inference speed and mathematical\nreasoning tasks.The precise and rapid generation capabilities of LLDMs amplify\nconcerns of harmful generations, while existing jailbreak methodologies\ndesigned for Large Language Models (LLMs) prove limited effectiveness against\nLLDMs and fail to expose safety vulnerabilities.Successful defense cannot\ndefinitively resolve harmful generation concerns, as it remains unclear whether\nLLDMs possess safety robustness or existing attacks are incompatible with\ndiffusion-based architectures.To address this, we first reveal the\nvulnerability of LLDMs to jailbreak and demonstrate that attack failure in\nLLDMs stems from fundamental architectural differences.We present a PArallel\nDecoding jailbreak (PAD) for diffusion-based language models. PAD introduces\nMulti-Point Attention Attack, which guides parallel generative processes toward\nharmful outputs that inspired by affirmative response patterns in LLMs.\nExperimental evaluations across four LLDMs demonstrate that PAD achieves\njailbreak attack success rates by 97%, revealing significant safety\nvulnerabilities. Furthermore, compared to autoregressive LLMs of the same size,\nLLDMs increase the harmful generation speed by 2x, significantly highlighting\nrisks of uncontrolled misuse.Through comprehensive analysis, we provide an\ninvestigation into LLDM architecture, offering critical insights for the secure\ndeployment of diffusion-based language models.\n","authors":["Yuanhe Zhang","Fangzhou Xie","Zhenhong Zhou","Zherui Li","Hao Chen","Kun Wang","Yufei Guo"],"pdf_url":"https://arxiv.org/pdf/2507.19227v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19219v1","updated":"2025-07-25T12:39:03Z","published":"2025-07-25T12:39:03Z","title":"How Much Do Large Language Model Cheat on Evaluation? Benchmarking\n  Overestimation under the One-Time-Pad-Based Framework","summary":"  Overestimation in evaluating large language models (LLMs) has become an\nincreasing concern. Due to the contamination of public benchmarks or imbalanced\nmodel training, LLMs may achieve unreal evaluation results on public\nbenchmarks, either intentionally or unintentionally, which leads to unfair\ncomparisons among LLMs and undermines their realistic capability assessments.\nExisting benchmarks attempt to address these issues by keeping test cases\npermanently secret, mitigating contamination through human evaluation, or\nrepeatedly collecting and constructing new samples. However, these approaches\nfail to ensure reproducibility, transparency, and high efficiency\nsimultaneously. Moreover, the extent of overestimation in current LLMs remains\nunquantified. To address these issues, we propose ArxivRoll, a dynamic\nevaluation framework inspired by one-time pad encryption in cryptography.\nArxivRoll comprises two key components: \\emph{i) SCP (Sequencing, Cloze, and\nPrediction)}, an automated generator for private test cases, and \\emph{ii)\nRugged Scores (RS)}, metrics that measure the proportion of public benchmark\ncontamination and training bias. Leveraging SCP, ArxivRoll constructs a new\nbenchmark every six months using recent articles from ArXiv and employs them\nfor one-time evaluations of LLM performance. Extensive experiments demonstrate\nthe high quality of our benchmark, and we provide a systematic evaluation of\ncurrent LLMs. The source code is available at\nhttps://github.com/liangzid/ArxivRoll/.\n","authors":["Zi Liang","Liantong Yu","Shiyu Zhang","Qingqing Ye","Haibo Hu"],"pdf_url":"https://arxiv.org/pdf/2507.19219v1.pdf","comment":"Source code: https://github.com/liangzid/ArxivRoll/ Website:\n  https://arxivroll.moreoverai.com/"},{"id":"http://arxiv.org/abs/2507.15850v3","updated":"2025-07-25T12:36:12Z","published":"2025-07-21T17:58:27Z","title":"3LM: Bridging Arabic, STEM, and Code through Benchmarking","summary":"  Arabic is one of the most widely spoken languages in the world, yet efforts\nto develop and evaluate Large Language Models (LLMs) for Arabic remain\nrelatively limited. Most existing Arabic benchmarks focus on linguistic,\ncultural, or religious content, leaving a significant gap in domains like STEM\nand code which are increasingly relevant for real-world LLM applications. To\nhelp bridge this gap, we present 3LM, a suite of three benchmarks designed\nspecifically for Arabic. The first is a set of STEM-related question-answer\npairs, naturally sourced from Arabic textbooks and educational worksheets. The\nsecond consists of synthetically generated STEM questions, created using the\nsame sources. The third benchmark focuses on code generation, built through a\ncareful translation of two widely used code benchmarks, incorporating a\nhuman-in-the-loop process with several rounds of review to ensure high-quality\nand faithful translations. We release all three benchmarks publicly to support\nthe growth of Arabic LLM research in these essential but underrepresented\nareas.\n","authors":["Basma El Amel Boussaha","Leen AlQadi","Mugariya Farooq","Shaikha Alsuwaidi","Giulia Campesan","Ahmed Alzubaidi","Mohammed Alyafeai","Hakim Hacid"],"pdf_url":"https://arxiv.org/pdf/2507.15850v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19204v1","updated":"2025-07-25T12:19:16Z","published":"2025-07-25T12:19:16Z","title":"Should Top-Down Clustering Affect Boundaries in Unsupervised Word\n  Discovery?","summary":"  We investigate the problem of segmenting unlabeled speech into word-like\nunits and clustering these to create a lexicon. Prior work can be categorized\ninto two frameworks. Bottom-up methods first determine boundaries and then\ncluster the fixed segmented words into a lexicon. In contrast, top-down methods\nincorporate information from the clustered words to inform boundary selection.\nHowever, it is unclear whether top-down information is necessary to improve\nsegmentation. To explore this, we look at two similar approaches that differ in\nwhether top-down clustering informs boundary selection. Our simple bottom-up\nstrategy predicts word boundaries using the dissimilarity between adjacent\nself-supervised features, then clusters the resulting segments to construct a\nlexicon. Our top-down system is an updated version of the ES-KMeans dynamic\nprogramming method that iteratively uses K-means to update its boundaries. On\nthe five-language ZeroSpeech benchmarks, both approaches achieve comparable\nstate-of-the-art results, with the bottom-up system being nearly five times\nfaster. Through detailed analyses, we show that the top-down influence of\nES-KMeans can be beneficial (depending on factors like the candidate\nboundaries), but in many cases the simple bottom-up method performs just as\nwell. For both methods, we show that the clustering step is a limiting factor.\nTherefore, we recommend that future work focus on improved clustering\ntechniques and learning more discriminative word-like representations. Project\ncode repository: https://github.com/s-malan/prom-seg-clus.\n","authors":["Simon Malan","Benjamin van Niekerk","Herman Kamper"],"pdf_url":"https://arxiv.org/pdf/2507.19204v1.pdf","comment":"5 figures, 5 tables"},{"id":"http://arxiv.org/abs/2507.19196v1","updated":"2025-07-25T12:06:53Z","published":"2025-07-25T12:06:53Z","title":"Towards Multimodal Social Conversations with Robots: Using\n  Vision-Language Models","summary":"  Large language models have given social robots the ability to autonomously\nengage in open-domain conversations. However, they are still missing a\nfundamental social skill: making use of the multiple modalities that carry\nsocial interactions. While previous work has focused on task-oriented\ninteractions that require referencing the environment or specific phenomena in\nsocial interactions such as dialogue breakdowns, we outline the overall needs\nof a multimodal system for social conversations with robots. We then argue that\nvision-language models are able to process this wide range of visual\ninformation in a sufficiently general manner for autonomous social robots. We\ndescribe how to adapt them to this setting, which technical challenges remain,\nand briefly discuss evaluation practices.\n","authors":["Ruben Janssens","Tony Belpaeme"],"pdf_url":"https://arxiv.org/pdf/2507.19196v1.pdf","comment":"Submitted to the workshop \"Human - Foundation Models Interaction: A\n  Focus On Multimodal Information\" (FoMo-HRI) at IEEE RO-MAN 2025"},{"id":"http://arxiv.org/abs/2507.19195v1","updated":"2025-07-25T12:05:47Z","published":"2025-07-25T12:05:47Z","title":"Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large\n  Language Models?","summary":"  Despite the ongoing improvements in the design of large language models\n(LLMs) to foster inclusion and balanced responses, these systems remain\nsusceptible to encoding and amplifying social biases. This study examines how\ndialectal variation, specifically African American Vernacular English (AAVE)\nversus Standard American English (SAE), interacts with data poisoning to\ninfluence toxicity in outputs. Using both small- and medium-scale LLaMA models,\nwe show that even minimal exposure to poisoned data significantly increases\ntoxicity for AAVE inputs, while it remains comparatively unaffected for SAE.\nLarger models exhibit a more significant amplification effect which suggests\nheightened susceptibility with scale. To further assess these disparities, we\nemployed GPT-4o as a fairness auditor, which identified harmful stereotypical\npatterns disproportionately tied to AAVE inputs, including portrayals of\naggression, criminality, and intellectual inferiority. These findings\nunderscore the compounding impact of data poisoning and dialectal bias and\nemphasize the need for dialect-aware evaluation, targeted debiasing\ninterventions, and socially responsible training protocols during development.\n","authors":["Chaymaa Abbas","Mariette Awad","Razane Tajeddine"],"pdf_url":"https://arxiv.org/pdf/2507.19195v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.17974v2","updated":"2025-07-25T11:58:42Z","published":"2025-07-23T22:45:30Z","title":"Natural Language Processing for Tigrinya: Current State and Future\n  Directions","summary":"  Despite being spoken by millions of people, Tigrinya remains severely\nunderrepresented in Natural Language Processing (NLP) research. This work\npresents a comprehensive survey of NLP research for Tigrinya, analyzing over 40\nstudies spanning more than a decade of work from 2011 to 2025. We\nsystematically review the current state of computational resources, models, and\napplications across ten distinct downstream tasks, including morphological\nprocessing, machine translation, speech recognition, and question-answering.\nOur analysis reveals a clear trajectory from foundational, rule-based systems\nto modern neural architectures, with progress consistently unlocked by resource\ncreation milestones. We identify key challenges rooted in Tigrinya's\nmorphological complexity and resource scarcity, while highlighting promising\nresearch directions, including morphology-aware modeling, cross-lingual\ntransfer, and community-centered resource development. This work serves as both\na comprehensive reference for researchers and a roadmap for advancing Tigrinya\nNLP. A curated metadata of the surveyed studies and resources is made publicly\navailable.\n","authors":["Fitsum Gaim","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2507.17974v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.10616v2","updated":"2025-07-25T11:09:53Z","published":"2025-07-13T19:04:17Z","title":"Scalpel vs. Hammer: GRPO Amplifies Existing Capabilities, SFT Replaces\n  Them","summary":"  Training large language models (LLMs) for reasoning via maths and code\ndatasets has become a major new focus in LLM post-training. Two particularly\npopular approaches are reinforcement learning (RL) and supervised fine-tuning\n(SFT), but their training dynamics are poorly understood. We present a\ncomparative analysis of RL and SFT on the same maths problems with the same\nmodel and similar hyperparameters. We find that RL yields minor in-domain gains\non maths and slight degradation on knowledge-intensive benchmarks like MMLU,\nwhile both trends are more pronounced in SFT. We also analyse model parameters\nacross checkpoints, observing that both algorithms modify query and key weights\nthe most. Meanwhile, SFT exhibits greater updates and also affects mid-layer\nMLPs more, leading us to hypothesise that this may have caused the\nout-of-domain degradation. We therefore investigate whether freezing parts of\nthe model during training can mitigate the reduced performance on\nknowledge-intensive benchmarks. However, our results are inconclusive, with\nbenefits on GPQA:Diamond and degradation on other benchmarks. Taken together,\nour observations provide a preliminary indication for why RL amplifies existing\ncapabilities, while SFT replaces old skills with new ones.\n","authors":["Neel Rajani","Aryo Pradipta Gema","Seraphina Goldfarb-Tarrant","Ivan Titov"],"pdf_url":"https://arxiv.org/pdf/2507.10616v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19156v1","updated":"2025-07-25T10:57:29Z","published":"2025-07-25T10:57:29Z","title":"An Empirical Investigation of Gender Stereotype Representation in Large\n  Language Models: The Italian Case","summary":"  The increasing use of Large Language Models (LLMs) in a large variety of\ndomains has sparked worries about how easily they can perpetuate stereotypes\nand contribute to the generation of biased content. With a focus on gender and\nprofessional bias, this work examines in which manner LLMs shape responses to\nungendered prompts, contributing to biased outputs. This analysis uses a\nstructured experimental method, giving different prompts involving three\ndifferent professional job combinations, which are also characterized by a\nhierarchical relationship. This study uses Italian, a language with extensive\ngrammatical gender differences, to highlight potential limitations in current\nLLMs' ability to generate objective text in non-English languages. Two popular\nLLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google\nGemini (gemini-1.5-flash). Through APIs, we collected a range of 3600\nresponses. The results highlight how content generated by LLMs can perpetuate\nstereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'\npronouns to the 'assistant' rather than the 'manager'. The presence of bias in\nAI-generated text can have significant implications in many fields, such as in\nthe workplaces or in job selections, raising ethical concerns about its use.\nUnderstanding these risks is pivotal to developing mitigation strategies and\nassuring that AI-based systems do not increase social inequalities, but rather\ncontribute to more equitable outcomes. Future research directions include\nexpanding the study to additional chatbots or languages, refining prompt\nengineering methods or further exploiting a larger experimental base.\n","authors":["Gioele Giachino","Marco Rondina","Antonio Vetrò","Riccardo Coppola","Juan Carlos De Martin"],"pdf_url":"https://arxiv.org/pdf/2507.19156v1.pdf","comment":"16 pages, European Conference on Machine Learning and Principles and\n  Practice of Knowledge Discovery in Databases (ECML PKDD 2025) - 5th Workshop\n  on Bias and Fairness in AI (BIAS25)"},{"id":"http://arxiv.org/abs/2411.19628v2","updated":"2025-07-25T10:41:09Z","published":"2024-11-29T11:24:23Z","title":"Accelerating Multimodal Large Language Models via Dynamic Visual-Token\n  Exit and the Empirical Findings","summary":"  The excessive use of visual tokens in existing Multimoal Large Language\nModels (MLLMs) often exhibits obvious redundancy and brings in prohibitively\nexpensive computation. To gain insights into this problem, we first conduct\nextensive empirical studies on the attention behaviors of MLLMs, and summarize\nthree main inference stages in MLLMs: (i) Early fusion between tokens is first\naccomplished quickly. (ii) Intra-modality modeling then comes to play. (iii)\nMultimodal reasoning} resumes and lasts until the end of inference. In\nparticular, we reveal that visual tokens will stop contributing to reasoning\nwhen the text tokens receive enough image information, yielding obvious visual\nredundancy. Based on these generalized observations, we propose a simple yet\neffective method to improve the efficiency of MLLMs, termed dynamic\nvisual-token exit (DyVTE). DyVTE uses lightweight hyper-networks to perceive\nthe text token status and decide the removal of all visual tokens after a\ncertain layer, thereby addressing the observed visual redundancy. To validate\nVTE, we apply it to a set of MLLMs, including LLaVA, VILA, Eagle and InternVL,\nand conduct extensive experiments on a bunch of benchmarks. The experiment\nresults not only show the effectiveness of our VTE in improving MLLMs'\nefficiency, but also yield the general modeling patterns of MLLMs, well\nfacilitating the in-depth understanding of MLLMs. Our code is released at\nhttps://github.com/DoubtedSteam/DyVTE.\n","authors":["Qiong Wu","Wenhao Lin","Yiyi Zhou","Weihao Ye","Zhanpeng Zen","Xiaoshuai Sun","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2411.19628v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19132v1","updated":"2025-07-25T10:14:53Z","published":"2025-07-25T10:14:53Z","title":"OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?","summary":"  Computer-using agents have shown strong potential to boost human productivity\nand enable new application forms across platforms. While recent advances have\nled to usable applications, existing benchmarks fail to account for the\ninternal task heterogeneity and the corresponding agent capabilities, as well\nas their alignment with actual user demands-hindering both targeted capability\ndevelopment and the reliable transition of research progress into practical\ndeployment. To bridge the gap, we present OS-MAP, a benchmark for daily\ncomputer-using automation that organizes its 416 realistic tasks across 15\napplications along two key dimensions: a five-level taxonomy of automation and\na generalization scope derived from a real-world user demand hierarchy. To\nenable fine-grained analysis of required capabilities and alignment with\nreal-world scenarios, OS-MAP evaluates agents along two dimensions: automation\nlevel across a five-level taxonomy, and generalization scope across a demand\nhierarchy. This design captures varying levels of required agent autonomy and\ngeneralization, forming a performance-generalization evaluation matrix for\nstructured and comprehensive assessment. Experiments show that even\nState-of-the-Art agents with VLM backbones struggle with higher-level tasks\ninvolving perception, reasoning, and coordination-highlighting the need for a\ndeeper understanding of current strengths and limitations to drive the future\nprogress in computer-using agents research and deployment. All code,\nenvironments, baselines, and data are publicly available at\nhttps://github.com/OS-Copilot/OS-Map.\n","authors":["Xuetian Chen","Yinghao Chen","Xinfeng Yuan","Zhuo Peng","Lu Chen","Yuekeng Li","Zhoujia Zhang","Yingqian Huang","Leyan Huang","Jiaqing Liang","Tianbao Xie","Zhiyong Wu","Qiushi Sun","Biqing Qi","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.19132v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2505.16142v3","updated":"2025-07-25T09:52:33Z","published":"2025-05-22T02:36:36Z","title":"Distilling the Implicit Multi-Branch Structure in LLMs' Reasoning via\n  Reinforcement Learning","summary":"  Distilling reasoning paths from teacher to student models via supervised\nfine-tuning (SFT) provides a shortcut for improving the reasoning ability of\nsmaller Large Language Models (LLMs). However, the reasoning paths generated by\nteacher models often reflect only surface-level traces of their underlying\nauthentic reasoning. Insights from cognitive neuroscience suggest that\nauthentic reasoning involves a complex interweaving between meta-reasoning\n(which selects appropriate sub-problems from multiple candidates) and solving\n(which addresses the sub-problem). This implies authentic reasoning has an\nimplicit multi-branch structure. Supervised fine-tuning collapses this rich\nstructure into a flat sequence of token prediction in the teacher's reasoning\npath, preventing effective distillation of this structure to students. To\naddress this limitation, we propose RLKD, a reinforcement learning (RL)-based\ndistillation framework guided by a novel Generative Structure Reward Model\n(GSRM). Our GSRM converts reasoning paths into multiple meta-reasoning-solving\nsteps and computes rewards to measure structural alignment between student and\nteacher reasoning. RLKD combines this reward with RL, enabling student LLMs to\ninternalize the teacher's implicit multi-branch reasoning structure rather than\nmerely mimicking fixed output paths. Experiments show RLKD surpasses standard\nSFT-RL pipelines even when trained on 0.1% of data under an RL-only regime,\nunlocking greater student reasoning potential than SFT-based distillation.\n","authors":["Shicheng Xu","Liang Pang","Yunchang Zhu","Jia Gu","Zihao Wei","Jingcheng Deng","Feiyang Pan","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2505.16142v3.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2507.19117v1","updated":"2025-07-25T09:51:42Z","published":"2025-07-25T09:51:42Z","title":"Objectifying the Subjective: Cognitive Biases in Topic Interpretations","summary":"  Interpretation of topics is crucial for their downstream applications.\nState-of-the-art evaluation measures of topic quality such as coherence and\nword intrusion do not measure how much a topic facilitates the exploration of a\ncorpus. To design evaluation measures grounded on a task, and a population of\nusers, we do user studies to understand how users interpret topics. We propose\nconstructs of topic quality and ask users to assess them in the context of a\ntopic and provide rationale behind evaluations. We use reflexive thematic\nanalysis to identify themes of topic interpretations from rationales. Users\ninterpret topics based on availability and representativeness heuristics rather\nthan probability. We propose a theory of topic interpretation based on the\nanchoring-and-adjustment heuristic: users anchor on salient words and make\nsemantic adjustments to arrive at an interpretation. Topic interpretation can\nbe viewed as making a judgment under uncertainty by an ecologically rational\nuser, and hence cognitive biases aware user models and evaluation frameworks\nare needed.\n","authors":["Swapnil Hingmire","Ze Shi Li"," Shiyu"," Zeng","Ahmed Musa Awon","Luiz Franciscatto Guerra","Neil Ernst"],"pdf_url":"https://arxiv.org/pdf/2507.19117v1.pdf","comment":"Accepted for publication at the Transactions of ACL (TACL) (pre-MIT\n  Press publication version)"},{"id":"http://arxiv.org/abs/2503.17799v2","updated":"2025-07-25T09:47:57Z","published":"2025-03-22T15:36:41Z","title":"Relation Extraction with Instance-Adapted Predicate Descriptions","summary":"  Relation extraction (RE) is a standard information extraction task playing a\nmajor role in downstream applications such as knowledge discovery and question\nanswering. Although decoder-only large language models are excelling in\ngenerative tasks, smaller encoder models are still the go to architecture for\nRE. In this paper, we revisit fine-tuning such smaller models using a novel\ndual-encoder architecture with a joint contrastive and cross-entropy loss.\nUnlike previous methods that employ a fixed linear layer for predicate\nrepresentations, our approach uses a second encoder to compute\ninstance-specific predicate representations by infusing them with real entity\nspans from corresponding input instances. We conducted experiments on two\nbiomedical RE datasets and two general domain datasets. Our approach achieved\nF1 score improvements ranging from 1% to 2% over state-of-the-art methods with\na simple but elegant formulation. Ablation studies justify the importance of\nvarious components built into the proposed architecture.\n","authors":["Yuhang Jiang","Ramakanth Kavuluru"],"pdf_url":"https://arxiv.org/pdf/2503.17799v2.pdf","comment":"This paper has been accepted to appear in the proceedings of AMIA\n  2025"},{"id":"http://arxiv.org/abs/2503.05157v4","updated":"2025-07-25T09:39:26Z","published":"2025-03-07T05:34:31Z","title":"Ensemble Debiasing Across Class and Sample Levels for Fairer Prompting\n  Accuracy","summary":"  Language models are strong few-shot learners and achieve good overall\naccuracy in text classification tasks, masking the fact that their results\nsuffer from great class accuracy imbalance. We believe that the pursuit of\noverall accuracy should not come from enriching the strong classes, but from\nraising up the weak ones. To address the imbalance, we propose a Heaviside step\nfunction based ensemble debiasing method, which enables flexible rectifications\nof in-context learned class probabilities at both class and sample levels.\nEvaluations with Llama-2-13B on seven text classification benchmarks show that\nour approach achieves state-of-the-art overall accuracy gains with balanced\nclass accuracies. More importantly, we perform analyses on the resulted\nprobability correction scheme, showing that sample-level corrections are\nnecessary to elevate weak classes. Due to effectively correcting weak classes,\nour method also brings significant performance gains to a larger model variant,\nLlama-2-70B, especially on a biomedical domain task, further demonstrating the\nnecessity of ensemble debiasing at both levels. Our source code is available at\nhttps://github.com/NUS-HPC-AI-Lab/DCS.\n","authors":["Ruixi Lin","Ziqiao Wang","Yang You"],"pdf_url":"https://arxiv.org/pdf/2503.05157v4.pdf","comment":"Published as a conference paper at COLM 2025"},{"id":"http://arxiv.org/abs/2311.13729v3","updated":"2025-07-25T09:37:28Z","published":"2023-11-22T22:52:00Z","title":"Comparison of pipeline, sequence-to-sequence, and GPT models for\n  end-to-end relation extraction: experiments with the rare disease use-case","summary":"  End-to-end relation extraction (E2ERE) is an important and realistic\napplication of natural language processing (NLP) in biomedicine. In this paper,\nwe aim to compare three prevailing paradigms for E2ERE using a complex dataset\nfocused on rare diseases involving discontinuous and nested entities. We use\nthe RareDis information extraction dataset to evaluate three competing\napproaches (for E2ERE): NER $\\rightarrow$ RE pipelines, joint sequence to\nsequence models, and generative pre-trained transformer (GPT) models. We use\ncomparable state-of-the-art models and best practices for each of these\napproaches and conduct error analyses to assess their failure modes. Our\nfindings reveal that pipeline models are still the best, while\nsequence-to-sequence models are not far behind; GPT models with eight times as\nmany parameters are worse than even sequence-to-sequence models and lose to\npipeline models by over 10 F1 points. Partial matches and discontinuous\nentities caused many NER errors contributing to lower overall E2E performances.\nWe also verify these findings on a second E2ERE dataset for chemical-protein\ninteractions. Although generative LM-based methods are more suitable for\nzero-shot settings, when training data is available, our results show that it\nis better to work with more conventional models trained and tailored for E2ERE.\nMore innovative methods are needed to marry the best of the both worlds from\nsmaller encoder-decoder pipeline models and the larger GPT models to improve\nE2ERE. As of now, we see that well designed pipeline models offer substantial\nperformance gains at a lower cost and carbon footprint for E2ERE. Our\ncontribution is also the first to conduct E2ERE for the RareDis dataset.\n","authors":["Shashank Gupta","Xuguang Ai","Ramakanth Kavuluru"],"pdf_url":"https://arxiv.org/pdf/2311.13729v3.pdf","comment":"An updated version of this paper has appeared in the proceedings of\n  NLDB 2025 with a different title. The corresonding DOI is in the metadata\n  provided below"},{"id":"http://arxiv.org/abs/2507.19102v1","updated":"2025-07-25T09:32:29Z","published":"2025-07-25T09:32:29Z","title":"Distilling a Small Utility-Based Passage Selector to Enhance\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nincorporating retrieved information. Standard retrieval process prioritized\nrelevance, focusing on topical alignment between queries and passages. In\ncontrast, in RAG, the emphasis has shifted to utility, which considers the\nusefulness of passages for generating accurate answers. Despite empirical\nevidence showing the benefits of utility-based retrieval in RAG, the high\ncomputational cost of using LLMs for utility judgments limits the number of\npassages evaluated. This restriction is problematic for complex queries\nrequiring extensive information. To address this, we propose a method to\ndistill the utility judgment capabilities of LLMs into smaller, more efficient\nmodels. Our approach focuses on utility-based selection rather than ranking,\nenabling dynamic passage selection tailored to specific queries without the\nneed for fixed thresholds. We train student models to learn pseudo-answer\ngeneration and utility judgments from teacher LLMs, using a sliding window\nmethod that dynamically selects useful passages. Our experiments demonstrate\nthat utility-based selection provides a flexible and cost-effective solution\nfor RAG, significantly reducing computational costs while improving answer\nquality. We present the distillation results using Qwen3-32B as the teacher\nmodel for both relevance ranking and utility-based selection, distilled into\nRankQwen1.7B and UtilityQwen1.7B. Our findings indicate that for complex\nquestions, utility-based selection is more effective than relevance ranking in\nenhancing answer generation performance. We will release the relevance ranking\nand utility-based selection annotations for the MS MARCO dataset, supporting\nfurther research in this area.\n","authors":["Hengran Zhang","Keping Bi","Jiafeng Guo","Jiaming Zhang","Shuaiqiang Wang","Dawei Yin","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2507.19102v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2402.13470v2","updated":"2025-07-25T09:32:04Z","published":"2024-02-21T01:57:58Z","title":"How Important is Domain Specificity in Language Models and Instruction\n  Finetuning for Biomedical Relation Extraction?","summary":"  Cutting edge techniques developed in the general NLP domain are often\nsubsequently applied to the high-value, data-rich biomedical domain. The past\nfew years have seen generative language models (LMs), instruction finetuning,\nand few-shot learning become foci of NLP research. As such, generative LMs\npretrained on biomedical corpora have proliferated and biomedical instruction\nfinetuning has been attempted as well, all with the hope that domain\nspecificity improves performance on downstream tasks. Given the nontrivial\neffort in training such models, we investigate what, if any, benefits they have\nin the key biomedical NLP task of relation extraction. Specifically, we address\ntwo questions: (1) Do LMs trained on biomedical corpora outperform those\ntrained on general domain corpora? (2) Do models instruction finetuned on\nbiomedical datasets outperform those finetuned on assorted datasets or those\nsimply pretrained? We tackle these questions using existing LMs, testing across\nfour datasets. In a surprising result, general-domain models typically\noutperformed biomedical-domain models. However, biomedical instruction\nfinetuning improved performance to a similar degree as general instruction\nfinetuning, despite having orders of magnitude fewer instructions. Our findings\nsuggest it may be more fruitful to focus research effort on larger-scale\nbiomedical instruction finetuning of general LMs over building domain-specific\nbiomedical LMs\n","authors":["Aviv Brokman","Ramakanth Kavuluru"],"pdf_url":"https://arxiv.org/pdf/2402.13470v2.pdf","comment":"A version of this paper has appeared in the proceedings of NLDB 2025\n  with a slightly different title. The corresponding DOI is also listed below\n  in the metadata"},{"id":"http://arxiv.org/abs/2506.19315v2","updated":"2025-07-25T09:26:59Z","published":"2025-06-24T05:12:32Z","title":"JCAPT: A Joint Modeling Approach for CAPT","summary":"  Effective pronunciation feedback is critical in second language (L2)\nlearning, for which computer-assisted pronunciation training (CAPT) systems\noften encompass two key tasks: automatic pronunciation assessment (APA) and\nmispronunciation detection and diagnosis (MDD). Recent work has shown that\njoint modeling of these two tasks can yield mutual benefits. Our unified\nframework leverages Mamba, a selective state space model (SSM), while\nintegrating phonological features and think token strategies to jointly enhance\ninterpretability and fine-grained temporal reasoning in APA and MDD. To our\nknowledge, this is the first study to combine phonological attribution,\nSSM-based modeling, and prompting in CAPT. A series of experiments conducted on\nthe speechocean762 benchmark demonstrate that our model consistently\noutperforms prior methods, particularly on the MDD task.\n","authors":["Tzu-Hsuan Yang","Yue-Yang He","Berlin Chen"],"pdf_url":"https://arxiv.org/pdf/2506.19315v2.pdf","comment":"Accepted to the ISCA SLaTE-2025 Workshop"},{"id":"http://arxiv.org/abs/2412.12591v2","updated":"2025-07-25T09:22:04Z","published":"2024-12-17T06:48:24Z","title":"LLMs are Also Effective Embedding Models: An In-depth Overview","summary":"  Large language models (LLMs) have revolutionized natural language processing\nby achieving state-of-the-art performance across various tasks. Recently, their\neffectiveness as embedding models has gained attention, marking a paradigm\nshift from traditional encoder-only models like ELMo and BERT to decoder-only,\nlarge-scale LLMs such as GPT, LLaMA, and Mistral. This survey provides an\nin-depth overview of this transition, beginning with foundational techniques\nbefore the LLM era, followed by LLM-based embedding models through two main\nstrategies to derive embeddings from LLMs. 1) Direct prompting: We mainly\ndiscuss the prompt designs and the underlying rationale for deriving\ncompetitive embeddings. 2) Data-centric tuning: We cover extensive aspects that\naffect tuning an embedding model, including model architecture, training\nobjectives, data constructions, etc. Upon the above, we also cover advanced\nmethods for producing embeddings from longer texts, multilingual, code,\ncross-modal data, as well as reasoning-aware and other domain-specific\nscenarios. Furthermore, we discuss factors affecting choices of embedding\nmodels, such as performance/efficiency comparisons, dense vs sparse embeddings,\npooling strategies, and scaling law. Lastly, the survey highlights the\nlimitations and challenges in adapting LLMs for embeddings, including\ncross-task embedding quality, trade-offs between efficiency and accuracy,\nlow-resource, long-context, data bias, robustness, etc. This survey serves as a\nvaluable resource for researchers and practitioners by synthesizing current\nadvancements, highlighting key challenges, and offering a comprehensive\nframework for future work aimed at enhancing the effectiveness and efficiency\nof LLMs as embedding models.\n","authors":["Chongyang Tao","Tao Shen","Shen Gao","Junshuo Zhang","Zhen Li","Kai Hua","Wenpeng Hu","Zhengwei Tao","Shuai Ma"],"pdf_url":"https://arxiv.org/pdf/2412.12591v2.pdf","comment":"38 pages"},{"id":"http://arxiv.org/abs/2507.19090v1","updated":"2025-07-25T09:19:25Z","published":"2025-07-25T09:19:25Z","title":"Debating Truth: Debate-driven Claim Verification with Multiple Large\n  Language Model Agents","summary":"  Claim verification is critical for enhancing digital literacy. However, the\nstate-of-the-art single-LLM methods struggle with complex claim verification\nthat involves multi-faceted evidences. Inspired by real-world fact-checking\npractices, we propose DebateCV, the first claim verification framework that\nadopts a debate-driven methodology using multiple LLM agents. In our framework,\ntwo Debaters take opposing stances on a claim and engage in multi-round\nargumentation, while a Moderator evaluates the arguments and renders a verdict\nwith justifications. To further improve the performance of the Moderator, we\nintroduce a novel post-training strategy that leverages synthetic debate data\ngenerated by the zero-shot DebateCV, effectively addressing the scarcity of\nreal-world debate-driven claim verification data. Experimental results show\nthat our method outperforms existing claim verification methods under varying\nlevels of evidence quality. Our code and dataset are publicly available at\nhttps://anonymous.4open.science/r/DebateCV-6781.\n","authors":["Haorui He","Yupeng Li","Dacheng Wen","Reynold Cheng","Francis C. M. Lau"],"pdf_url":"https://arxiv.org/pdf/2507.19090v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19081v1","updated":"2025-07-25T09:07:52Z","published":"2025-07-25T09:07:52Z","title":"Arg-LLaDA: Argument Summarization via Large Language Diffusion Models\n  and Sufficiency-Aware Refinement","summary":"  Argument summarization aims to generate concise, structured representations\nof complex, multi-perspective debates. While recent work has advanced the\nidentification and clustering of argumentative components, the generation stage\nremains underexplored. Existing approaches typically rely on single-pass\ngeneration, offering limited support for factual correction or structural\nrefinement. To address this gap, we introduce Arg-LLaDA, a novel large language\ndiffusion framework that iteratively improves summaries via sufficiency-guided\nremasking and regeneration. Our method combines a flexible masking controller\nwith a sufficiency-checking module to identify and revise unsupported,\nredundant, or incomplete spans, yielding more faithful, concise, and coherent\noutputs. Empirical results on two benchmark datasets demonstrate that Arg-LLaDA\nsurpasses state-of-the-art baselines in 7 out of 10 automatic evaluation\nmetrics. In addition, human evaluations reveal substantial improvements across\ncore dimensions, coverage, faithfulness, and conciseness, validating the\neffectiveness of our iterative, sufficiency-aware generation strategy.\n","authors":["Hao Li","Yizheng Sun","Viktor Schlegel","Kailai Yang","Riza Batista-Navarro","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2507.19081v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2507.16331v2","updated":"2025-07-25T08:30:10Z","published":"2025-07-22T08:13:01Z","title":"Re:Form -- Reducing Human Priors in Scalable Formal Software\n  Verification with RL in LLMs: A Preliminary Study on Dafny","summary":"  Existing informal language-based (e.g., human language) Large Language Models\n(LLMs) trained with Reinforcement Learning (RL) face a significant challenge:\ntheir verification processes, which provide crucial training signals, are\nneither reliable nor scalable. In fact, the prevalent large proprietary models\ncould hardly generate verifiable programs. A promising yet largely uncharted\nalternative is formal language-based reasoning. Grounding LLMs in rigorous\nformal systems where generative models operate in formal language spaces (e.g.,\nDafny) enables the automatic and mathematically provable verification of their\nreasoning processes and outcomes. This capability is pivotal for achieving\nlarge-scale, reliable formal software verification. It is a common practice to\nemploy human-annotated chain-of-thought and other human priors to induce the\nreasoning and coding capabilities of LLMs. Unfortunately, it becomes\nunacceptably all-consuming to provide such priors for supervising complex\nprogramming tasks. In this work, we systematically explore ways to reduce human\npriors with the formal language, Dafny, as the main environment for our pilot\nstudy. Our pipeline mainly relies on introducing an automatic and scalable data\ncuration pipeline, and careful RL designs integrated with feedback from the\nformal language verifier. We introduce DafnyComp, a benchmark of compositional\nformal programs with auto-formalized specifications for specification\nreasoning. Our supervised fine-tuning (SFT) stage enables even small models\n(e.g., 0.5B) to generate syntactically valid and verifiable Dafny code,\nsurpassing proprietary models. RL with regularization further improves\nperformance, achieving stronger generalization to out-of-domain tasks and\noutperforming all strong baselines on the challenging DafnyComp benchmark.\n","authors":["Chuanhao Yan","Fengdi Che","Xuhan Huang","Xu Xu","Xin Li","Yizhi Li","Xingwei Qu","Jingzhe Shi","Zhuangzhuang He","Chenghua Lin","Yaodong Yang","Binhang Yuan","Hang Zhao","Yu Qiao","Bowen Zhou","Jie Fu"],"pdf_url":"https://arxiv.org/pdf/2507.16331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00920v2","updated":"2025-07-25T08:26:54Z","published":"2024-09-02T03:19:56Z","title":"ToolACE: Winning the Points of LLM Function Calling","summary":"  Function calling significantly extends the application boundary of large\nlanguage models, where high-quality and diverse training data is critical for\nunlocking this capability. However, real function-calling data is quite\nchallenging to collect and annotate, while synthetic data generated by existing\npipelines tends to lack coverage and accuracy. In this paper, we present\nToolACE, an automatic agentic pipeline designed to generate accurate, complex,\nand diverse tool-learning data. ToolACE leverages a novel self-evolution\nsynthesis process to curate a comprehensive API pool of 26,507 diverse APIs.\nDialogs are further generated through the interplay among multiple agents,\nguided by a formalized thinking process. To ensure data accuracy, we implement\na dual-layer verification system combining rule-based and model-based checks.\nWe demonstrate that models trained on our synthesized data, even with only 8B\nparameters, achieve state-of-the-art performance on the Berkeley\nFunction-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a\nsubset of the data are publicly available at https://huggingface.co/Team-ACE.\n","authors":["Weiwen Liu","Xu Huang","Xingshan Zeng","Xinlong Hao","Shuai Yu","Dexun Li","Shuai Wang","Weinan Gan","Zhengying Liu","Yuanqing Yu","Zezhong Wang","Yuxian Wang","Wu Ning","Yutai Hou","Bin Wang","Chuhan Wu","Xinzhi Wang","Yong Liu","Yasheng Wang","Duyu Tang","Dandan Tu","Lifeng Shang","Xin Jiang","Ruiming Tang","Defu Lian","Qun Liu","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2409.00920v2.pdf","comment":"21 pages, 22 figures"},{"id":"http://arxiv.org/abs/2507.18119v2","updated":"2025-07-25T08:25:27Z","published":"2025-07-24T06:10:29Z","title":"GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker\n  Characteristic Awareness","summary":"  Recent advances in end-to-end spoken language models (SLMs) have\nsignificantly improved the ability of AI systems to engage in natural spoken\ninteractions. However, most existing models treat speech merely as a vehicle\nfor linguistic content, often overlooking the rich paralinguistic and speaker\ncharacteristic cues embedded in human speech, such as dialect, age, emotion,\nand non-speech vocalizations. In this work, we introduce GOAT-SLM, a novel\nspoken language model with paralinguistic and speaker characteristic awareness,\ndesigned to extend spoken language modeling beyond text semantics. GOAT-SLM\nadopts a dual-modality head architecture that decouples linguistic modeling\nfrom acoustic realization, enabling robust language understanding while\nsupporting expressive and adaptive speech generation. To enhance model\nefficiency and versatility, we propose a modular, staged training strategy that\nprogressively aligns linguistic, paralinguistic, and speaker characteristic\ninformation using large-scale speech-text corpora. Experimental results on\nTELEVAL, a multi-dimensional evaluation benchmark, demonstrate that GOAT-SLM\nachieves well-balanced performance across both semantic and non-semantic tasks,\nand outperforms existing open-source models in handling emotion, dialectal\nvariation, and age-sensitive interactions. This work highlights the importance\nof modeling beyond linguistic content and advances the development of more\nnatural, adaptive, and socially aware spoken language systems.\n","authors":["Hongjie Chen","Zehan Li","Yaodong Song","Wenming Deng","Yitong Yao","Yuxin Zhang","Hang Lv","Xuechao Zhu","Jian Kang","Jie Lian","Jie Li","Chao Wang","Shuangyong Song","Yongxiang Li","Zhongjiang He","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2507.18119v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06270v4","updated":"2025-07-25T08:24:58Z","published":"2024-05-10T06:52:44Z","title":"XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced\n  In-Context Learning in Healthcare","summary":"  Clinical decision support systems require models that are not only highly\naccurate but also equitable and sensitive to the implications of missed\ndiagnoses. In this study, we introduce a knowledge-guided in-context learning\n(ICL) framework designed to enable large language models (LLMs) to effectively\nprocess structured clinical data. Our approach integrates domain-specific\nfeature groupings, carefully balanced few-shot examples, and task-specific\nprompting strategies. We systematically evaluate this method across seventy\ndistinct ICL designs by various prompt variations and two different\ncommunication styles-natural-language narrative and numeric conversational-and\ncompare its performance to robust classical machine learning (ML) benchmarks on\ntasks involving heart disease and diabetes prediction.\n  Our findings indicate that while traditional ML models maintain superior\nperformance in balanced precision-recall scenarios, LLMs employing narrative\nprompts with integrated domain knowledge achieve higher recall and\nsignificantly reduce gender bias, effectively narrowing fairness disparities by\nan order of magnitude. Despite the current limitation of increased inference\nlatency, LLMs provide notable advantages, including the capacity for zero-shot\ndeployment and enhanced equity. This research offers the first comprehensive\nanalysis of ICL design considerations for applying LLMs to tabular clinical\ntasks and highlights distillation and multimodal extensions as promising\ndirections for future research.\n","authors":["Fatemeh Nazary","Yashar Deldjoo","Tommaso Di Noia","Eugenio di Sciascio"],"pdf_url":"https://arxiv.org/pdf/2405.06270v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19060v1","updated":"2025-07-25T08:23:00Z","published":"2025-07-25T08:23:00Z","title":"PurpCode: Reasoning for Safer Code Generation","summary":"  We introduce PurpCode, the first post-training recipe for training safe code\nreasoning models towards generating secure code and defending against malicious\ncyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule\nLearning, which explicitly teaches the model to reference cybersafety rules to\ngenerate vulnerability-free code and to avoid facilitating malicious\ncyberactivities; and (ii) Reinforcement Learning, which optimizes model safety\nand preserves model utility through diverse, multi-objective reward mechanisms.\nTo empower the training pipelines with comprehensive cybersafety data, we\nconduct internal red-teaming to synthesize comprehensive and high-coverage\nprompts based on real-world tasks for inducing unsafe cyberactivities in the\nmodel. Based on PurpCode, we develop a reasoning-based coding model, namely\nPurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming\nvarious frontier models. Meanwhile, our alignment method decreases the model\noverrefusal rates in both general and cybersafety-specific scenarios, while\npreserving model utility in both code generation and common security knowledge.\n","authors":["Jiawei Liu","Nirav Diwan","Zhe Wang","Haoyu Zhai","Xiaona Zhou","Kiet A. Nguyen","Tianjiao Yu","Muntasir Wahed","Yinlin Deng","Hadjer Benkraouda","Yuxiang Wei","Lingming Zhang","Ismini Lourentzou","Gang Wang"],"pdf_url":"https://arxiv.org/pdf/2507.19060v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.12612v3","updated":"2025-07-25T08:18:26Z","published":"2025-01-22T03:29:43Z","title":"T2ISafety: Benchmark for Assessing Fairness, Toxicity, and Privacy in\n  Image Generation","summary":"  Text-to-image (T2I) models have rapidly advanced, enabling the generation of\nhigh-quality images from text prompts across various domains. However, these\nmodels present notable safety concerns, including the risk of generating\nharmful, biased, or private content. Current research on assessing T2I safety\nremains in its early stages. While some efforts have been made to evaluate\nmodels on specific safety dimensions, many critical risks remain unexplored. To\naddress this gap, we introduce T2ISafety, a safety benchmark that evaluates T2I\nmodels across three key domains: toxicity, fairness, and bias. We build a\ndetailed hierarchy of 12 tasks and 44 categories based on these three domains,\nand meticulously collect 70K corresponding prompts. Based on this taxonomy and\nprompt set, we build a large-scale T2I dataset with 68K manually annotated\nimages and train an evaluator capable of detecting critical risks that previous\nwork has failed to identify, including risks that even ultra-large proprietary\nmodels like GPTs cannot correctly detect. We evaluate 12 prominent diffusion\nmodels on T2ISafety and reveal several concerns including persistent issues\nwith racial fairness, a tendency to generate toxic content, and significant\nvariation in privacy protection across the models, even with defense methods\nlike concept erasing. Data and evaluator are released under\nhttps://github.com/adwardlee/t2i_safety.\n","authors":["Lijun Li","Zhelun Shi","Xuhao Hu","Bowen Dong","Yiran Qin","Xihui Liu","Lu Sheng","Jing Shao"],"pdf_url":"https://arxiv.org/pdf/2501.12612v3.pdf","comment":"Accepted at CVPR 2025"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2507.19473v1","updated":"2025-07-25T17:57:31Z","published":"2025-07-25T17:57:31Z","title":"Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization","summary":"  Many sequential recommender systems suffer from the cold start problem, where\nitems with few or no interactions cannot be effectively used by the model due\nto the absence of a trained embedding. Content-based approaches, which leverage\nitem metadata, are commonly used in such scenarios. One possible way is to use\nembeddings derived from content features such as textual descriptions as\ninitialization for the model embeddings. However, directly using frozen content\nembeddings often results in suboptimal performance, as they may not fully adapt\nto the recommendation task. On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation. Instead of entirely freezing the content embeddings or\nfine-tuning them extensively, we introduce a small trainable delta to frozen\nembeddings that enables the model to adapt item representations without letting\nthem go too far from their original semantic structure. This approach\ndemonstrates consistent improvements across multiple datasets and modalities,\nincluding e-commerce datasets with textual descriptions and a music dataset\nwith audio-based representation.\n","authors":["Anton Pembek","Artem Fatkulin","Anton Klenitskiy","Alexey Vasilev"],"pdf_url":"https://arxiv.org/pdf/2507.19473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12949v3","updated":"2025-07-25T16:46:03Z","published":"2024-11-20T00:43:32Z","title":"Epidemiology-informed Network for Robust Rumor Detection","summary":"  The rapid spread of rumors on social media has posed significant challenges\nto maintaining public trust and information integrity. Since an information\ncascade process is essentially a propagation tree, recent rumor detection\nmodels leverage graph neural networks to additionally capture information\npropagation patterns, thus outperforming text-only solutions. Given the\nvariations in topics and social impact of the root node, different source\ninformation naturally has distinct outreach capabilities, resulting in\ndifferent heights of propagation trees. This variation, however, impedes the\ndata-driven design of existing graph-based rumor detectors. Given a shallow\npropagation tree with limited interactions, it is unlikely for graph-based\napproaches to capture sufficient cascading patterns, questioning their ability\nto handle less popular news or early detection needs. In contrast, a deep\npropagation tree is prone to noisy user responses, and this can in turn\nobfuscate the predictions. In this paper, we propose a novel\nEpidemiology-informed Network (EIN) that integrates epidemiological knowledge\nto enhance performance by overcoming data-driven methods sensitivity to data\nquality. Meanwhile, to adapt epidemiology theory to rumor detection, it is\nexpected that each users stance toward the source information will be\nannotated. To bypass the costly and time-consuming human labeling process, we\ntake advantage of large language models to generate stance labels, facilitating\noptimization objectives for learning epidemiology-informed representations. Our\nexperimental results demonstrate that the proposed EIN not only outperforms\nstate-of-the-art methods on real-world datasets but also exhibits enhanced\nrobustness across varying tree depths.\n","authors":["Wei Jiang","Tong Chen","Xinyi Gao","Wentao Zhang","Lizhen Cui","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2411.12949v3.pdf","comment":"Accepted by The Web Conference 2025 (WWW2025)"},{"id":"http://arxiv.org/abs/2507.19333v1","updated":"2025-07-25T14:43:31Z","published":"2025-07-25T14:43:31Z","title":"Injecting External Knowledge into the Reasoning Process Enhances\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) has been widely adopted to augment large\nlanguage models (LLMs) with external knowledge for knowledge-intensive tasks.\nHowever, its effectiveness is often undermined by the presence of noisy (i.e.,\nlow-quality) retrieved passages. Enhancing LLMs' robustness to such noise is\ncritical for improving the reliability of RAG systems. Recent advances have\nequipped LLMs with strong reasoning and self-reflection capabilities, allowing\nthem to identify and correct errors in their reasoning process. Inspired by\nthis ability, we propose Passage Injection-a simple yet effective method that\nexplicitly incorporates retrieved passages into LLMs' reasoning process, aiming\nto enhance the model's ability to recognize and resist noisy passages. We\nvalidate Passage Injection under general RAG settings using BM25 as the\nretriever. Experiments on four reasoning-enhanced LLMs across four factual QA\ndatasets demonstrate that Passage Injection significantly improves overall RAG\nperformance. Further analysis on two noisy retrieval settings-random noise,\nwhere the model is provided irrelevant passages, and counterfactual noise,\nwhere it is given misleading passages-shows that Passage Injection consistently\nimproves robustness. Controlled experiments confirm that Passage Injection can\nalso effectively leverage helpful passages. These findings suggest that\nincorporating passages in LLMs' reasoning process is a promising direction for\nbuilding more robust RAG systems. The code can be found\n\\href{here}{https://github.com/mh-tang/Passage-Injection}.\n","authors":["Minghao Tang","Shiyu Ni","Jiafeng Guo","Keping Bi"],"pdf_url":"https://arxiv.org/pdf/2507.19333v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19295v1","updated":"2025-07-25T14:12:00Z","published":"2025-07-25T14:12:00Z","title":"On the Security of a Code-Based PIR Scheme","summary":"  Private Information Retrieval (PIR) schemes allow clients to retrieve files\nfrom a database without disclosing the requested file's identity to the server.\nIn the pursuit of post-quantum security, most recent PIR schemes rely on hard\nlattice problems. In contrast, the so called CB-cPIR scheme stands out as a\npioneering effort to base PIR schemes on hard problems in coding theory,\nthereby contributing significantly to the diversification of security\nfoundations. However, our research reveals a critical vulnerability in CB-cPIR,\nsubstantially diminishing its security levels. Moreover, a comparative analysis\nwith state-of-the-art PIR schemes shows that CB-cPIR's advantages are reduced,\nmaking it less competitive in terms of the communication cost. Nevertheless,\nour findings highlight the importance of continued research into code-based PIR\nschemes, as they have the potential to provide a valuable alternative to\nlattice-based approaches.\n","authors":["Svenja Lage","Hannes Bartz"],"pdf_url":"https://arxiv.org/pdf/2507.19295v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19283v1","updated":"2025-07-25T13:59:54Z","published":"2025-07-25T13:59:54Z","title":"Towards LLM-Enhanced Group Recommender Systems","summary":"  In contrast to single-user recommender systems, group recommender systems are\ndesigned to generate and explain recommendations for groups. This\ngroup-oriented setting introduces additional complexities, as several factors -\nabsent in individual contexts - must be addressed. These include understanding\ngroup dynamics (e.g., social dependencies within the group), defining effective\ndecision-making processes, ensuring that recommendations are suitable for all\ngroup members, and providing group-level explanations as well as explanations\nfor individual users. In this paper, we analyze in which way large language\nmodels (LLMs) can support these aspects and help to increase the overall\ndecision support quality and applicability of group recommender systems.\n","authors":["Sebastian Lubos","Alexander Felfernig","Thi Ngoc Trang Tran","Viet-Man Le","Damian Garber","Manuel Henrich","Reinhard Willfort","Jeremias Fuchs"],"pdf_url":"https://arxiv.org/pdf/2507.19283v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19102v1","updated":"2025-07-25T09:32:29Z","published":"2025-07-25T09:32:29Z","title":"Distilling a Small Utility-Based Passage Selector to Enhance\n  Retrieval-Augmented Generation","summary":"  Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nincorporating retrieved information. Standard retrieval process prioritized\nrelevance, focusing on topical alignment between queries and passages. In\ncontrast, in RAG, the emphasis has shifted to utility, which considers the\nusefulness of passages for generating accurate answers. Despite empirical\nevidence showing the benefits of utility-based retrieval in RAG, the high\ncomputational cost of using LLMs for utility judgments limits the number of\npassages evaluated. This restriction is problematic for complex queries\nrequiring extensive information. To address this, we propose a method to\ndistill the utility judgment capabilities of LLMs into smaller, more efficient\nmodels. Our approach focuses on utility-based selection rather than ranking,\nenabling dynamic passage selection tailored to specific queries without the\nneed for fixed thresholds. We train student models to learn pseudo-answer\ngeneration and utility judgments from teacher LLMs, using a sliding window\nmethod that dynamically selects useful passages. Our experiments demonstrate\nthat utility-based selection provides a flexible and cost-effective solution\nfor RAG, significantly reducing computational costs while improving answer\nquality. We present the distillation results using Qwen3-32B as the teacher\nmodel for both relevance ranking and utility-based selection, distilled into\nRankQwen1.7B and UtilityQwen1.7B. Our findings indicate that for complex\nquestions, utility-based selection is more effective than relevance ranking in\nenhancing answer generation performance. We will release the relevance ranking\nand utility-based selection annotations for the MS MARCO dataset, supporting\nfurther research in this area.\n","authors":["Hengran Zhang","Keping Bi","Jiafeng Guo","Jiaming Zhang","Shuaiqiang Wang","Dawei Yin","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2507.19102v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.19067v1","updated":"2025-07-25T08:29:32Z","published":"2025-07-25T08:29:32Z","title":"PBiLoss: Popularity-Aware Regularization to Improve Fairness in\n  Graph-Based Recommender Systems","summary":"  Recommender systems, especially those based on graph neural networks (GNNs),\nhave achieved remarkable success in capturing user-item interaction patterns.\nHowever, they remain susceptible to popularity bias--the tendency to\nover-recommend popular items--resulting in reduced content diversity and\ncompromised fairness. In this paper, we propose PBiLoss, a novel\nregularization-based loss function designed to counteract popularity bias in\ngraph-based recommender models explicitly. PBiLoss augments traditional\ntraining objectives by penalizing the model's inclination toward popular items,\nthereby encouraging the recommendation of less popular but potentially more\npersonalized content. We introduce two sampling strategies: Popular Positive\n(PopPos) and Popular Negative (PopNeg), which respectively modulate the\ncontribution of the positive and negative popular items during training. We\nfurther explore two methods to distinguish popular items: one based on a fixed\npopularity threshold and another without any threshold, making the approach\nflexible and adaptive. Our proposed method is model-agnostic and can be\nseamlessly integrated into state-of-the-art graph-based frameworks such as\nLightGCN and its variants. Comprehensive experiments across multiple real-world\ndatasets demonstrate that PBiLoss significantly improves fairness, as\ndemonstrated by reductions in the Popularity-Rank Correlation for Users (PRU)\nand Popularity-Rank Correlation for Items (PRI), while maintaining or even\nenhancing standard recommendation accuracy and ranking metrics. These results\nhighlight the effectiveness of directly embedding fairness objectives into the\noptimization process, providing a practical and scalable solution for balancing\naccuracy and equitable content exposure in modern recommender systems.\n","authors":["Mohammad Naeimi","Mostafa Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2507.19067v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.07237v2","updated":"2025-07-25T08:26:13Z","published":"2024-09-11T12:48:52Z","title":"Negative Sampling in Recommendation: A Survey and Future Directions","summary":"  Recommender system (RS) aims to capture personalized preferences from massive\nuser behaviors, making them pivotal in the era of information explosion.\nHowever, the presence of ``information cocoons'', interaction sparsity,\ncold-start problem and feedback loops inherent in RS make users interact with a\nlimited number of items. Conventional recommendation algorithms typically focus\non the positive historical behaviors, while neglecting the essential role of\nnegative feedback in user preference understanding. As a promising but\neasy-to-ignored area, negative sampling is proficients in revealing the genuine\nnegative aspect inherent in user behaviors, emerging as an inescapable\nprocedure in RS. In this survey, we first discuss existing user feedback, the\ncritical role of negative sampling and the optimization objectives in RS and\nthoroughly analyze challenges that consistently impede its progress. Then, we\nconduct an extensive literature review on the existing negative sampling\nstrategies in RS and classify them into five categories with their discrepant\ntechniques. Finally, we detail the insights of the tailored negative sampling\nstrategies in diverse RS scenarios and outline an overview of the prospective\nresearch directions toward which the community may engage and benefit.\n","authors":["Haokai Ma","Ruobing Xie","Lei Meng","Fuli Feng","Xiaoyu Du","Xingwu Sun","Zhanhui Kang","Xiangxu Meng"],"pdf_url":"https://arxiv.org/pdf/2409.07237v2.pdf","comment":"39 pages, 10 figures; Under review"},{"id":"http://arxiv.org/abs/2507.19054v1","updated":"2025-07-25T08:15:28Z","published":"2025-07-25T08:15:28Z","title":"Closing the Modality Gap for Mixed Modality Search","summary":"  Mixed modality search -- retrieving information across a heterogeneous corpus\ncomposed of images, texts, and multimodal documents -- is an important yet\nunderexplored real-world application. In this work, we investigate how\ncontrastive vision-language models, such as CLIP, perform on the mixed modality\nsearch task. Our analysis reveals a critical limitation: these models exhibit a\npronounced modality gap in the embedding space, where image and text embeddings\nform distinct clusters, leading to intra-modal ranking bias and inter-modal\nfusion failure. To address this issue, we propose GR-CLIP, a lightweight\npost-hoc calibration method that removes the modality gap in CLIP's embedding\nspace. Evaluated on MixBench -- the first benchmark specifically designed for\nmixed modality search -- GR-CLIP improves NDCG@10 by up to 26 percentage points\nover CLIP, surpasses recent vision-language generative embedding models by 4\npercentage points, while using 75x less compute.\n","authors":["Binxu Li","Yuhui Zhang","Xiaohan Wang","Weixin Liang","Ludwig Schmidt","Serena Yeung-Levy"],"pdf_url":"https://arxiv.org/pdf/2507.19054v1.pdf","comment":"Project page: https://yuhui-zh15.github.io/MixedModalitySearch/"},{"id":"http://arxiv.org/abs/2507.19033v1","updated":"2025-07-25T07:42:01Z","published":"2025-07-25T07:42:01Z","title":"SelfRACG: Enabling LLMs to Self-Express and Retrieve for Code Generation","summary":"  Existing retrieval-augmented code generation (RACG) methods typically use an\nexternal retrieval module to fetch semantically similar code snippets used for\ngenerating subsequent fragments. However, even for consecutive code fragments,\nthe content often diverges due to logical progression, resulting in a content\ngap. This gap undermines the performance of current RACG methods, as\n\\textit{external} retrieval modules based on content matching fail to infer the\nspecific information need of LLMs to generate the next code fragment.\nTherefore, we propose \\textbf{SelfRACG}, a novel paradigm that enables large\nlanguage models (LLMs) to \\textbf{Self}-express their information needs to\nenhance \\textbf{RACG}. Specifically, SelfRACG includes an information need\nexpression module and a two-stage information need-guided training strategy,\nwhich encourages LLMs to express their information need. Extensive experiments\ndemonstrate that SelfRACG can retrieve external knowledge that better aligns\nwith the LLM's own information needs, resulting in superior generation\nperformance compared to vanilla RACG.\n","authors":["Qian Dong","Jia Chen","Qingyao Ai","Hongning Wang","Haitao Li","Yi Wu","Yao Hu","Yiqun Liu","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2507.19033v1.pdf","comment":"Tsinghua&Xiaohongshu"},{"id":"http://arxiv.org/abs/2408.08088v2","updated":"2025-07-25T07:41:37Z","published":"2024-08-15T11:32:46Z","title":"KGV: Integrating Large Language Models with Knowledge Graphs for Cyber\n  Threat Intelligence Credibility Assessment","summary":"  Cyber threat intelligence (CTI) is a crucial tool to prevent sophisticated,\norganized, and weaponized cyber attacks. However, few studies have focused on\nthe credibility assessment of CTI, and this work still requires manual analysis\nby cybersecurity experts. In this paper, we propose Knowledge Graph-based\nVerifier (KGV), the first framework integrating large language models (LLMs)\nwith simple structured knowledge graphs (KGs) for automated CTI credibility\nassessment. Unlike entity-centric KGs, KGV constructs paragraph-level semantic\ngraphs where nodes represent text segments connected through similarity\nanalysis, which effectively enhances the semantic understanding ability of the\nmodel, reduces KG density and greatly improves response speed. Experimental\nresults demonstrate that our KGV outperforms state-of-the-art fact reasoning\nmethods on the CTI-200 dataset, achieving a 5.7\\% improvement in F1.\nAdditionally, it shows strong scalability on factual QA and fake news detection\ndatasets. Compared to entity-based knowledge graphs (KGs) for equivalent-length\ntexts, our structurally simple KG reduces node quantities by nearly two-thirds\nwhile boosting precision by 1.7\\% and cutting response time by 46.7\\%. In\naddition, we have created and publicly released the first CTI credibility\nassessment dataset, CTI-200. Distinct from CTI identification datasets, CTI-200\nrefines CTI summaries and key sentences to focus specifically on credibility\nassessment.\n","authors":["Zongzong Wu","Fengxiao Tang","Ming Zhao","Yufeng Li"],"pdf_url":"https://arxiv.org/pdf/2408.08088v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18993v1","updated":"2025-07-25T06:45:10Z","published":"2025-07-25T06:45:10Z","title":"Agent0: Leveraging LLM Agents to Discover Multi-value Features from Text\n  for Enhanced Recommendations","summary":"  Large language models (LLMs) and their associated agent-based frameworks have\nsignificantly advanced automated information extraction, a critical component\nof modern recommender systems. While these multitask frameworks are widely used\nin code generation, their application in data-centric research is still largely\nuntapped. This paper presents Agent0, an LLM-driven, agent-based system\ndesigned to automate information extraction and feature construction from raw,\nunstructured text. Categorical features are crucial for large-scale recommender\nsystems but are often expensive to acquire. Agent0 coordinates a group of\ninteracting LLM agents to automatically identify the most valuable text aspects\nfor subsequent tasks (such as models or AutoML pipelines). Beyond its feature\nengineering capabilities, Agent0 also offers an automated prompt-engineering\ntuning method that utilizes dynamic feedback loops from an oracle. Our findings\ndemonstrate that this closed-loop methodology is both practical and effective\nfor automated feature discovery, which is recognized as one of the most\nchallenging phases in current recommender system development.\n","authors":["Blaž Škrlj","Benoît Guilleminot","Andraž Tori"],"pdf_url":"https://arxiv.org/pdf/2507.18993v1.pdf","comment":"Agent4IR, KDD '25"},{"id":"http://arxiv.org/abs/2406.14117v4","updated":"2025-07-25T01:51:32Z","published":"2024-06-20T09:03:18Z","title":"An Investigation of Prompt Variations for Zero-shot LLM-based Rankers","summary":"  We provide a systematic understanding of the impact of specific components\nand wordings used in prompts on the effectiveness of rankers based on zero-shot\nLarge Language Models (LLMs). Several zero-shot ranking methods based on LLMs\nhave recently been proposed. Among many aspects, methods differ across (1) the\nranking algorithm they implement, e.g., pointwise vs. listwise, (2) the\nbackbone LLMs used, e.g., GPT3.5 vs. FLAN-T5, (3) the components and wording\nused in prompts, e.g., the use or not of role-definition (role-playing) and the\nactual words used to express this. It is currently unclear whether performance\ndifferences are due to the underlying ranking algorithm, or because of spurious\nfactors such as better choice of words used in prompts. This confusion risks to\nundermine future research. Through our large-scale experimentation and\nanalysis, we find that ranking algorithms do contribute to differences between\nmethods for zero-shot LLM ranking. However, so do the LLM backbones -- but even\nmore importantly, the choice of prompt components and wordings affect the\nranking. In fact, in our experiments, we find that, at times, these latter\nelements have more impact on the ranker's effectiveness than the actual ranking\nalgorithms, and that differences among ranking methods become more blurred when\nprompt variations are considered.\n","authors":["Shuoqi Sun","Shengyao Zhuang","Shuai Wang","Guido Zuccon"],"pdf_url":"https://arxiv.org/pdf/2406.14117v4.pdf","comment":"Accepted for publication at the 47th European Conference on\n  Information Retrieval (ECIR 2025)"},{"id":"http://arxiv.org/abs/2507.18882v1","updated":"2025-07-25T01:43:07Z","published":"2025-07-25T01:43:07Z","title":"A Comprehensive Review of AI-based Intelligent Tutoring Systems:\n  Applications and Challenges","summary":"  AI-based Intelligent Tutoring Systems (ITS) have significant potential to\ntransform teaching and learning. As efforts continue to design, develop, and\nintegrate ITS into educational contexts, mixed results about their\neffectiveness have emerged. This paper provides a comprehensive review to\nunderstand how ITS operate in real educational settings and to identify the\nassociated challenges in their application and evaluation. We use a systematic\nliterature review method to analyze numerous qualified studies published from\n2010 to 2025, examining domains such as pedagogical strategies, NLP, adaptive\nlearning, student modeling, and domain-specific applications of ITS. The\nresults reveal a complex landscape regarding the effectiveness of ITS,\nhighlighting both advancements and persistent challenges. The study also\nidentifies a need for greater scientific rigor in experimental design and data\nanalysis. Based on these findings, suggestions for future research and\npractical implications are proposed.\n","authors":["Meriem Zerkouk","Miloud Mihoubi","Belkacem Chikhaoui"],"pdf_url":"https://arxiv.org/pdf/2507.18882v1.pdf","comment":"Journal of Computers in Education ( 2025 )"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2507.19477v1","updated":"2025-07-25T17:59:13Z","published":"2025-07-25T17:59:13Z","title":"Advancing Event Forecasting through Massive Training of Large Language\n  Models: Challenges, Solutions, and Broader Impacts","summary":"  Many recent papers have studied the development of superforecaster-level\nevent forecasting LLMs. While methodological problems with early studies cast\ndoubt on the use of LLMs for event forecasting, recent studies with improved\nevaluation methods have shown that state-of-the-art LLMs are gradually reaching\nsuperforecaster-level performance, and reinforcement learning has also been\nreported to improve future forecasting. Additionally, the unprecedented success\nof recent reasoning models and Deep Research-style models suggests that\ntechnology capable of greatly improving forecasting performance has been\ndeveloped. Therefore, based on these positive recent trends, we argue that the\ntime is ripe for research on large-scale training of superforecaster-level\nevent forecasting LLMs. We discuss two key research directions: training\nmethods and data acquisition. For training, we first introduce three\ndifficulties of LLM-based event forecasting training: noisiness-sparsity,\nknowledge cut-off, and simple reward structure problems. Then, we present\nrelated ideas to mitigate these problems: hypothetical event Bayesian networks,\nutilizing poorly-recalled and counterfactual events, and auxiliary reward\nsignals. For data, we propose aggressive use of market, public, and crawling\ndatasets to enable large-scale training and evaluation. Finally, we explain how\nthese technical advances could enable AI to provide predictive intelligence to\nsociety in broader areas. This position paper presents promising specific paths\nand considerations for getting closer to superforecaster-level AI technology,\naiming to call for researchers' interest in these directions.\n","authors":["Sang-Woo Lee","Sohee Yang","Donghyun Kwak","Noah Y. Siegel"],"pdf_url":"https://arxiv.org/pdf/2507.19477v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19473v1","updated":"2025-07-25T17:57:31Z","published":"2025-07-25T17:57:31Z","title":"Let It Go? Not Quite: Addressing Item Cold Start in Sequential\n  Recommendations with Content-Based Initialization","summary":"  Many sequential recommender systems suffer from the cold start problem, where\nitems with few or no interactions cannot be effectively used by the model due\nto the absence of a trained embedding. Content-based approaches, which leverage\nitem metadata, are commonly used in such scenarios. One possible way is to use\nembeddings derived from content features such as textual descriptions as\ninitialization for the model embeddings. However, directly using frozen content\nembeddings often results in suboptimal performance, as they may not fully adapt\nto the recommendation task. On the other hand, fine-tuning these embeddings can\ndegrade performance for cold-start items, as item representations may drift far\nfrom their original structure after training. We propose a novel approach to\naddress this limitation. Instead of entirely freezing the content embeddings or\nfine-tuning them extensively, we introduce a small trainable delta to frozen\nembeddings that enables the model to adapt item representations without letting\nthem go too far from their original semantic structure. This approach\ndemonstrates consistent improvements across multiple datasets and modalities,\nincluding e-commerce datasets with textual descriptions and a music dataset\nwith audio-based representation.\n","authors":["Anton Pembek","Artem Fatkulin","Anton Klenitskiy","Alexey Vasilev"],"pdf_url":"https://arxiv.org/pdf/2507.19473v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18262v2","updated":"2025-07-25T17:54:43Z","published":"2025-07-24T10:07:31Z","title":"ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic\n  Grounding for Generalizable Robotic Manipulation","summary":"  Semantics-driven 3D spatial constraints align highlevel semantic\nrepresentations with low-level action spaces, facilitating the unification of\ntask understanding and execution in robotic manipulation. The synergistic\nreasoning of Multimodal Large Language Models (MLLMs) and Vision Foundation\nModels (VFMs) enables cross-modal 3D spatial constraint construction.\nNevertheless, existing methods have three key limitations: (1) coarse semantic\ngranularity in constraint modeling, (2) lack of real-time closed-loop planning,\n(3) compromised robustness in semantically diverse environments. To address\nthese challenges, we propose ReSem3D, a unified manipulation framework for\nsemantically diverse environments, leveraging the synergy between VFMs and\nMLLMs to achieve fine-grained visual grounding and dynamically constructs\nhierarchical 3D spatial constraints for real-time manipulation. Specifically,\nthe framework is driven by hierarchical recursive reasoning in MLLMs, which\ninteract with VFMs to automatically construct 3D spatial constraints from\nnatural language instructions and RGB-D observations in two stages: part-level\nextraction and region-level refinement. Subsequently, these constraints are\nencoded as real-time optimization objectives in joint space, enabling reactive\nbehavior to dynamic disturbances. Extensive simulation and real-world\nexperiments are conducted in semantically rich household and sparse chemical\nlab environments. The results demonstrate that ReSem3D performs diverse\nmanipulation tasks under zero-shot conditions, exhibiting strong adaptability\nand generalization. Code and videos are available at\nhttps://github.com/scy-v/ReSem3D and https://resem3d.github.io.\n","authors":["Chenyu Su","Weiwei Shang","Chen Qian","Fei Zhang","Shuang Cong"],"pdf_url":"https://arxiv.org/pdf/2507.18262v2.pdf","comment":"12 pages,9 figures"},{"id":"http://arxiv.org/abs/2507.19465v1","updated":"2025-07-25T17:50:43Z","published":"2025-07-25T17:50:43Z","title":"Linearly Convergent Algorithms for Nonsmooth Problems with Unknown\n  Smooth Pieces","summary":"  We develop efficient algorithms for optimizing piecewise smooth (PWS)\nfunctions where the underlying partition of the domain into smooth pieces is\n\\emph{unknown}. For PWS functions satisfying a quadratic growth (QG) condition,\nwe propose a bundle-level (BL) type method that achieves global linear\nconvergence -- to our knowledge, the first such result for any algorithm for\nthis problem class. We extend this method to handle approximately PWS functions\nand to solve weakly-convex PWS problems, improving the state-of-the-art\ncomplexity to match the benchmark for smooth non-convex optimization.\nFurthermore, we introduce the first verifiable and accurate termination\ncriterion for PWS optimization. Similar to the gradient norm in smooth\noptimization, this certificate tightly characterizes the optimality gap under\nthe QG condition, and can moreover be evaluated without knowledge of any\nproblem parameters. We develop a search subroutine for this certificate and\nembed it within a guess-and-check framework, resulting in an almost\nparameter-free algorithm for both the convex QG and weakly-convex settings.\n","authors":["Zhe Zhang","Suvrit Sra"],"pdf_url":"https://arxiv.org/pdf/2507.19465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.03005v3","updated":"2025-07-25T17:46:09Z","published":"2025-05-05T20:03:28Z","title":"RADLADS: Rapid Attention Distillation to Linear Attention Decoders at\n  Scale","summary":"  We present Rapid Attention Distillation to Linear Attention Decoders at Scale\n(RADLADS), a protocol for rapidly converting softmax attention transformers\ninto linear attention decoder models, along with two new RWKV-variant\narchitectures, and models converted from popular Qwen2.5 open source models in\n7B, 32B, and 72B sizes. Our conversion process requires only 350-700M tokens,\nless than 0.005% of the token count used to train the original teacher models.\nConverting to our 72B linear attention model costs less than \\$2,000 USD at\ntoday's prices, yet quality at inference remains close to the original\ntransformer. These models achieve state-of-the-art downstream performance\nacross a set of standard benchmarks for linear attention models of their size.\nWe release all our models on HuggingFace under the Apache 2.0 license, with the\nexception of our 72B models which are also governed by the Qwen License\nAgreement.\n  Models at\nhttps://huggingface.co/collections/recursal/radlads-6818ee69e99e729ba8a87102\nTraining Code at https://github.com/recursal/RADLADS-paper\n","authors":["Daniel Goldstein","Eric Alcaide","Janna Lu","Eugene Cheah"],"pdf_url":"https://arxiv.org/pdf/2505.03005v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19459v1","updated":"2025-07-25T17:43:29Z","published":"2025-07-25T17:43:29Z","title":"Fast Learning of Non-Cooperative Spacecraft 3D Models through Primitive\n  Initialization","summary":"  The advent of novel view synthesis techniques such as NeRF and 3D Gaussian\nSplatting (3DGS) has enabled learning precise 3D models only from posed\nmonocular images. Although these methods are attractive, they hold two major\nlimitations that prevent their use in space applications: they require poses\nduring training, and have high computational cost at training and inference. To\naddress these limitations, this work contributes: (1) a Convolutional Neural\nNetwork (CNN) based primitive initializer for 3DGS using monocular images; (2)\na pipeline capable of training with noisy or implicit pose estimates; and (3)\nand analysis of initialization variants that reduce the training cost of\nprecise 3D models. A CNN takes a single image as input and outputs a coarse 3D\nmodel represented as an assembly of primitives, along with the target's pose\nrelative to the camera. This assembly of primitives is then used to initialize\n3DGS, significantly reducing the number of training iterations and input images\nneeded -- by at least an order of magnitude. For additional flexibility, the\nCNN component has multiple variants with different pose estimation techniques.\nThis work performs a comparison between these variants, evaluating their\neffectiveness for downstream 3DGS training under noisy or implicit pose\nestimates. The results demonstrate that even with imperfect pose supervision,\nthe pipeline is able to learn high-fidelity 3D representations, opening the\ndoor for the use of novel view synthesis in space applications.\n","authors":["Pol Francesch Huc","Emily Bates","Simone D'Amico"],"pdf_url":"https://arxiv.org/pdf/2507.19459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19458v1","updated":"2025-07-25T17:42:34Z","published":"2025-07-25T17:42:34Z","title":"Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset\n  Management Under Budget Constraints","summary":"  Budget planning and maintenance optimization are crucial for infrastructure\nasset management, ensuring cost-effectiveness and sustainability. However, the\ncomplexity arising from combinatorial action spaces, diverse asset\ndeterioration, stringent budget constraints, and environmental uncertainty\nsignificantly limits existing methods' scalability. This paper proposes a\nHierarchical Deep Reinforcement Learning methodology specifically tailored to\nmulti-year infrastructure planning. Our approach decomposes the problem into\ntwo hierarchical levels: a high-level Budget Planner allocating annual budgets\nwithin explicit feasibility bounds, and a low-level Maintenance Planner\nprioritizing assets within the allocated budget. By structurally separating\nmacro-budget decisions from asset-level prioritization and integrating linear\nprogramming projection within a hierarchical Soft Actor-Critic framework, the\nmethod efficiently addresses exponential growth in the action space and ensures\nrigorous budget compliance. A case study evaluating sewer networks of varying\nsizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed\napproach. Compared to conventional Deep Q-Learning and enhanced genetic\nalgorithms, our methodology converges more rapidly, scales effectively, and\nconsistently delivers near-optimal solutions even as network size grows.\n","authors":["Amir Fard","Arnold X. -X. Yuan"],"pdf_url":"https://arxiv.org/pdf/2507.19458v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19457v1","updated":"2025-07-25T17:42:32Z","published":"2025-07-25T17:42:32Z","title":"GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning","summary":"  Large language models (LLMs) are increasingly adapted to downstream tasks via\nreinforcement learning (RL) methods like Group Relative Policy Optimization\n(GRPO), which often require thousands of rollouts to learn new tasks. We argue\nthat the interpretable nature of language can often provide a much richer\nlearning medium for LLMs, compared with policy gradients derived from sparse,\nscalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt\noptimizer that thoroughly incorporates natural language reflection to learn\nhigh-level rules from trial and error. Given any AI system containing one or\nmore LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool\ncalls, and tool outputs) and reflects on them in natural language to diagnose\nproblems, propose and test prompt updates, and combine complementary lessons\nfrom the Pareto frontier of its own attempts. As a result of GEPA's design, it\ncan often turn even just a few rollouts into a large quality gain. Across four\ntasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up\nto 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,\nMIPROv2, by over 10% across two LLMs, and demonstrates promising results as an\ninference-time search strategy for code optimization.\n","authors":["Lakshya A Agrawal","Shangyin Tan","Dilara Soylu","Noah Ziems","Rishi Khare","Krista Opsahl-Ong","Arnav Singhvi","Herumb Shandilya","Michael J Ryan","Meng Jiang","Christopher Potts","Koushik Sen","Alexandros G. Dimakis","Ion Stoica","Dan Klein","Matei Zaharia","Omar Khattab"],"pdf_url":"https://arxiv.org/pdf/2507.19457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19455v1","updated":"2025-07-25T17:41:39Z","published":"2025-07-25T17:41:39Z","title":"Forest-Guided Clustering -- Shedding Light into the Random Forest Black\n  Box","summary":"  As machine learning models are increasingly deployed in sensitive application\nareas, the demand for interpretable and trustworthy decision-making has\nincreased. Random Forests (RF), despite their widespread use and strong\nperformance on tabular data, remain difficult to interpret due to their\nensemble nature. We present Forest-Guided Clustering (FGC), a model-specific\nexplainability method that reveals both local and global structure in RFs by\ngrouping instances according to shared decision paths. FGC produces\nhuman-interpretable clusters aligned with the model's internal logic and\ncomputes cluster-specific and global feature importance scores to derive\ndecision rules underlying RF predictions. FGC accurately recovered latent\nsubclass structure on a benchmark dataset and outperformed classical clustering\nand post-hoc explanation methods. Applied to an AML transcriptomic dataset, FGC\nuncovered biologically coherent subpopulations, disentangled disease-relevant\nsignals from confounders, and recovered known and novel gene expression\npatterns. FGC bridges the gap between performance and interpretability by\nproviding structure-aware insights that go beyond feature-level attribution.\n","authors":["Lisa Barros de Andrade e Sousa","Gregor Miller","Ronan Le Gleut","Dominik Thalmeier","Helena Pelin","Marie Piraud"],"pdf_url":"https://arxiv.org/pdf/2507.19455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18330v2","updated":"2025-07-25T17:32:47Z","published":"2025-07-24T11:57:59Z","title":"GVCCS: A Dataset for Contrail Identification and Tracking on Visible\n  Whole Sky Camera Sequences","summary":"  Aviation's climate impact includes not only CO2 emissions but also\nsignificant non-CO2 effects, especially from contrails. These ice clouds can\nalter Earth's radiative balance, potentially rivaling the warming effect of\naviation CO2. Physics-based models provide useful estimates of contrail\nformation and climate impact, but their accuracy depends heavily on the quality\nof atmospheric input data and on assumptions used to represent complex\nprocesses like ice particle formation and humidity-driven persistence.\nObservational data from remote sensors, such as satellites and ground cameras,\ncould be used to validate and calibrate these models. However, existing\ndatasets don't explore all aspect of contrail dynamics and formation: they\ntypically lack temporal tracking, and do not attribute contrails to their\nsource flights. To address these limitations, we present the Ground Visible\nCamera Contrail Sequences (GVCCS), a new open data set of contrails recorded\nwith a ground-based all-sky camera in the visible range. Each contrail is\nindividually labeled and tracked over time, allowing a detailed analysis of its\nlifecycle. The dataset contains 122 video sequences (24,228 frames) and\nincludes flight identifiers for contrails that form above the camera. As\nreference, we also propose a unified deep learning framework for contrail\nanalysis using a panoptic segmentation model that performs semantic\nsegmentation (contrail pixel identification), instance segmentation (individual\ncontrail separation), and temporal tracking in a single architecture. By\nproviding high-quality, temporally resolved annotations and a benchmark for\nmodel evaluation, our work supports improved contrail monitoring and will\nfacilitate better calibration of physical models. This sets the groundwork for\nmore accurate climate impact understanding and assessments.\n","authors":["Gabriel Jarry","Ramon Dalmau","Philippe Very","Franck Ballerini","Stefania-Denisa Bocu"],"pdf_url":"https://arxiv.org/pdf/2507.18330v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20380v2","updated":"2025-07-25T17:22:48Z","published":"2025-06-25T12:46:26Z","title":"TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation\n  and Analysis","summary":"  Satellite remote sensing from repeated observations and multiple sensors\nenables a wide range of downstream applications, including climate modeling,\ncarbon accounting, and strategies for conservation and sustainable land use.\nHowever, satellite time series are voluminous, often corrupted by sensor noise,\nclouds, and atmospheric conditions, and unevenly spaced in time, making them\nchallenging to use. We present TESSERA, an open, global, land-oriented remote\nsensing foundation model that uses self-supervised learning to generate\n`ready-to-use' embeddings at 10~m scale from pixel-level satellite time series\ndata. TESSERA uses two parallel Transformer-based encoders to combine optical\ndata from ten Sentinel-2 spectral bands at 10-60~m spatial resolution and two\nSentinel-1 synthetic aperture radar backscatter coefficients at 10~m resolution\nto create embeddings that are subsequently fused with a multilayer perceptron\nto create annual global embedding maps. We compare our work with\nstate-of-the-art task-specific models and other foundation models in five\ndiverse downstream tasks and find that TESSERA closely matches or outperforms\nthese baselines. We believe that TESSERA's ease of use, openness, computation-,\nlabel-, and data-efficiency, and high performance will prove transformative in\na wide range of vegetation-oriented ecological and agricultural applications.\n","authors":["Zhengpeng Feng","Clement Atzberger","Sadiq Jaffer","Jovana Knezevic","Silja Sormunen","Robin Young","Madeline C Lisaius","Markus Immitzer","David A. Coomes","Anil Madhavapeddy","Andrew Blake","Srinivasan Keshav"],"pdf_url":"https://arxiv.org/pdf/2506.20380v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.09063v4","updated":"2025-07-25T17:22:26Z","published":"2023-05-15T23:12:15Z","title":"Bounded KRnet and its applications to density estimation and\n  approximation","summary":"  In this paper, we develop an invertible mapping, called B-KRnet, on a bounded\ndomain and apply it to density estimation/approximation for data or the\nsolutions of PDEs such as the Fokker-Planck equation and the Keller-Segel\nequation. Similar to KRnet, B-KRnet consists of a series of coupling layers\nwith progressively fewer active transformation dimensions, inspired by the\ntriangular structure of the Knothe-Rosenblatt (KR) rearrangement. The main\ndifference between B-KRnet and KRnet is that B-KRnet is defined on a hypercube\nwhile KRnet is defined on the whole space, in other words, a new mechanism is\nintroduced in B-KRnet to maintain the exact invertibility. Using B-KRnet as a\ntransport map, we obtain an explicit probability density function (PDF) model\nthat corresponds to the pushforward of a base (uniform) distribution on the\nhypercube. It can be directly applied to density estimation when only data are\navailable. By coupling KRnet and B-KRnet, we define a deep generative model on\na high-dimensional domain where some dimensions are bounded and other\ndimensions are unbounded. A typical case is the solution of the stationary\nkinetic Fokker-Planck equation, which is a PDF of position and momentum. Based\non B-KRnet, we develop an adaptive learning approach to approximate partial\ndifferential equations whose solutions are PDFs or can be treated as PDFs. A\nvariety of numerical experiments is presented to demonstrate the effectiveness\nof B-KRnet.\n","authors":["Li Zeng","Xiaoliang Wan","Tao Zhou"],"pdf_url":"https://arxiv.org/pdf/2305.09063v4.pdf","comment":"26 pages, 16 figures"},{"id":"http://arxiv.org/abs/2507.19438v1","updated":"2025-07-25T17:13:41Z","published":"2025-07-25T17:13:41Z","title":"Gradient-based grand canonical optimization enabled by graph neural\n  networks with fractional atomic existence","summary":"  Machine learning interatomic potentials have become an indispensable tool for\nmaterials science, enabling the study of larger systems and longer timescales.\nState-of-the-art models are generally graph neural networks that employ message\npassing to iteratively update atomic embeddings that are ultimately used for\npredicting properties. In this work we extend the message passing formalism\nwith the inclusion of a continuous variable that accounts for fractional atomic\nexistence. This allows us to calculate the gradient of the Gibbs free energy\nwith respect to both the Cartesian coordinates of atoms and their existence.\nUsing this we propose a gradient-based grand canonical optimization method and\ndocument its capabilities for a Cu(110) surface oxide.\n","authors":["Mads-Peter Verner Christiansen","Bjørk Hammer"],"pdf_url":"https://arxiv.org/pdf/2507.19438v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19437v1","updated":"2025-07-25T17:08:16Z","published":"2025-07-25T17:08:16Z","title":"Observations Meet Actions: Learning Control-Sufficient Representations\n  for Robust Policy Generalization","summary":"  Capturing latent variations (\"contexts\") is key to deploying\nreinforcement-learning (RL) agents beyond their training regime. We recast\ncontext-based RL as a dual inference-control problem and formally characterize\ntwo properties and their hierarchy: observation sufficiency (preserving all\npredictive information) and control sufficiency (retaining decision-making\nrelevant information). Exploiting this dichotomy, we derive a contextual\nevidence lower bound(ELBO)-style objective that cleanly separates\nrepresentation learning from policy learning and optimizes it with Bottlenecked\nContextual Policy Optimization (BCPO), an algorithm that places a variational\ninformation-bottleneck encoder in front of any off-policy policy learner. On\nstandard continuous-control benchmarks with shifting physical parameters, BCPO\nmatches or surpasses other baselines while using fewer samples and retaining\nperformance far outside the training regime. The framework unifies theory,\ndiagnostics, and practice for context-based RL.\n","authors":["Yuliang Gu","Hongpeng Cao","Marco Caccamo","Naira Hovakimyan"],"pdf_url":"https://arxiv.org/pdf/2507.19437v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.10643v2","updated":"2025-07-25T17:02:54Z","published":"2025-07-14T16:38:30Z","title":"TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc\n  Attributions for Opaque Models","summary":"  Existing post-hoc model-agnostic methods generate external explanations for\nopaque models, primarily by locally attributing the model output to its input\nfeatures. However, they often lack an explicit and systematic framework for\nquantifying the contribution of individual features. Building on the Taylor\nexpansion framework introduced by Deng et al. (2024) to unify existing local\nattribution methods, we propose a rigorous set of postulates -- \"precision\",\n\"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific\nattribution. Guided by these postulates, we introduce TaylorPODA (Taylor\nexpansion-derived imPortance-Order aDapted Attribution), which incorporates an\nadditional \"adaptation\" property. This property enables alignment with\ntask-specific goals, especially in post-hoc settings lacking ground-truth\nexplanations. Empirical evaluations demonstrate that TaylorPODA achieves\ncompetitive results against baseline methods, providing principled and\nvisualization-friendly explanations. This work represents a step toward the\ntrustworthy deployment of opaque models by offering explanations with stronger\ntheoretical grounding.\n","authors":["Yuchi Tang","Iñaki Esnaola","George Panoutsos"],"pdf_url":"https://arxiv.org/pdf/2507.10643v2.pdf","comment":"17 pages, 6 figures. To be submitted to AAAI 2026. Re-upload with\n  amended author list"},{"id":"http://arxiv.org/abs/2507.17765v2","updated":"2025-07-25T17:02:11Z","published":"2025-07-14T20:23:47Z","title":"ASR-Guided Speaker-Role Diarization and Diarization-Guided ASR Decoding","summary":"  From an application standpoint, speaker-role diarization (RD), such as doctor\nvs. patient, host vs. guest, etc. is often more useful than traditional speaker\ndiarization (SD), which assigns generic labels like speaker-1, speaker-2 etc.\nIn the context of joint automatic speech recognition (ASR) + SD (who spoke\nwhat?), recent end-to-end models employ an auxiliary SD transducer,\nsynchronized with the ASR transducer, to predict speakers per word. In this\npaper, we extend this framework to RD with three key contributions: (1) we\nsimplify the training via forced alignment and cross-entropy loss instead of\nRNNT loss, (2) we show that word prediction and role prediction require\ndifferent amounts of predictor's context, leading to separate task-specific\npredictors, unlike existing shared-predictor models, and (3) we propose a way\nto leverage RD posterior activity to influence ASR decoding and reduce\nsmall-word deletion errors.\n","authors":["Arindam Ghosh","Mark Fuhs","Bongjun Kim","Anurag Chowdhury","Monika Woszczyna"],"pdf_url":"https://arxiv.org/pdf/2507.17765v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2502.08606v2","updated":"2025-07-25T16:55:43Z","published":"2025-02-12T17:52:47Z","title":"Distillation Scaling Laws","summary":"  We propose a distillation scaling law that estimates distilled model\nperformance based on a compute budget and its allocation between the student\nand teacher. Our findings mitigate the risks associated with large-scale\ndistillation by enabling compute-optimal allocation for both the teacher and\nstudent to maximize student performance. We provide compute-optimal\ndistillation recipes for two key scenarios: when a teacher already exists, and\nwhen a teacher needs training. In settings involving many students or an\nexisting teacher, distillation outperforms supervised learning up to a compute\nlevel that scales predictably with student size. Conversely, if only one\nstudent is to be distilled and a teacher also requires training, supervised\nlearning is generally preferable. Additionally, our large-scale study of\ndistillation increases our understanding of the process and helps inform\nexperimental design.\n","authors":["Dan Busbridge","Amitis Shidani","Floris Weers","Jason Ramapuram","Etai Littwin","Russ Webb"],"pdf_url":"https://arxiv.org/pdf/2502.08606v2.pdf","comment":"Version accepted to ICML 2025. 69 pages, 54 figures, 13 tables"},{"id":"http://arxiv.org/abs/2411.11467v3","updated":"2025-07-25T16:54:47Z","published":"2024-11-18T11:03:15Z","title":"Integrating Physics and Topology in Neural Networks for Learning Rigid\n  Body Dynamics","summary":"  Rigid body interactions are fundamental to numerous scientific disciplines,\nbut remain challenging to simulate due to their abrupt nonlinear nature and\nsensitivity to complex, often unknown environmental factors. These challenges\ncall for adaptable learning-based methods capable of capturing complex\ninteractions beyond explicit physical models and simulations. While graph\nneural networks can handle simple scenarios, they struggle with complex scenes\nand long-term predictions. We introduce a novel framework for modeling rigid\nbody dynamics and learning collision interactions, addressing key limitations\nof existing graph-based methods. Our approach extends the traditional\nrepresentation of meshes by incorporating higher-order topology complexes,\noffering a physically consistent representation. Additionally, we propose a\nphysics-informed message-passing neural architecture, embedding physical laws\ndirectly in the model. Our method demonstrates superior accuracy, even during\nlong rollouts, and exhibits strong generalization to unseen scenarios.\nImportantly, this work addresses the challenge of multi-entity dynamic\ninteractions, with applications spanning diverse scientific and engineering\ndomains.\n","authors":["Amaury Wei","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2411.11467v3.pdf","comment":"20 pages, 10 figures. Published in Nature Communications"},{"id":"http://arxiv.org/abs/2507.19427v1","updated":"2025-07-25T16:53:13Z","published":"2025-07-25T16:53:13Z","title":"Step-3 is Large yet Affordable: Model-system Co-design for\n  Cost-effective Decoding","summary":"  Large language models (LLMs) face low hardware efficiency during decoding,\nespecially for long-context reasoning tasks. This paper introduces Step-3, a\n321B-parameter VLM with hardware-aware model-system co-design optimized for\nminimizing decoding costs. Step-3 innovates in two key dimensions: (1) A novel\nMulti-Matrix Factorization Attention (MFA) mechanism that significantly reduces\nboth KV cache size and computation while maintaining high attention\nexpressiveness, and (2) Attention-FFN Disaggregation (AFD), a distributed\ninference system that decouples attention and Feed-Forward Network (FFN) layers\ninto specialized subsystems. This co-design achieves unprecedented cost\nefficiency: Step-3 significantly reduces theoretical decoding costs compared\nwith models like DeepSeek-V3 and Qwen3 MoE 235B, with the gains widening at\nlonger context. Step-3 achieves low cost while activating 38B parameters per\ntoken (more than DeepSeek-V3 and Qwen3 MoE 235B), demonstrating that\nhardware-aligned attention arithmetic intensity, MoE sparsity, and AFD are\ncritical to cost-effectiveness. We perform a head-to-head comparison with\nDeepSeek-V3 in its favorable scenarios. Our implementation on Hopper GPUs\nachieves a decoding throughput of up to 4,039 tokens per second per GPU under\n50ms TPOT SLA (4K context, FP8, no MTP). It is higher than DeepSeek-V3's 2,324\nin the same setup and sets a new Pareto frontier for LLM decoding.\n","authors":[" StepFun"," :","Bin Wang","Bojun Wang","Changyi Wan","Guanzhe Huang","Hanpeng Hu","Haonan Jia","Hao Nie","Mingliang Li","Nuo Chen","Siyu Chen","Song Yuan","Wuxun Xie","Xiaoniu Song","Xing Chen","Xingping Yang","Xuelin Zhang","Yanbo Yu","Yaoyu Wang","Yibo Zhu","Yimin Jiang","Yu Zhou","Yuanwei Lu","Houyi Li","Jingcheng Hu","Ka Man Lo","Ailin Huang","Binxing Jiao","Bo Li","Boyu Chen","Changxin Miao","Chang Lou","Chen Hu","Chen Xu","Chenfeng Yu","Chengyuan Yao","Daokuan Lv","Dapeng Shi","Deshan Sun","Ding Huang","Dingyuan Hu","Dongqing Pang","Enle Liu","Fajie Zhang","Fanqi Wan","Gulin Yan","Han Zhang","Han Zhou","Hanghao Wu","Hangyu Guo","Hanqi Chen","Hanshan Zhang","Hao Wu","Haocheng Zhang","Haolong Yan","Haoran Lv","Haoran Wei","Hebin Zhou","Heng Wang","Heng Wang","Hongxin Li","Hongyu Zhou","Hongyuan Wang","Huiyong Guo","Jia Wang","Jiahao Gong","Jialing Xie","Jian Zhou","Jianjian Sun","Jiaoren Wu","Jiaran Zhang","Jiayu Liu","Jie Cheng","Jie Luo","Jie Yan","Jie Yang","Jieyi Hou","Jinguang Zhang","Jinlan Cao","Jisheng Yin","Junfeng Liu","Junhao Huang","Junzhe Lin","Kaijun Tan","Kaixiang Li","Kang An","Kangheng Lin","Kenkun Liu","Lei Yang","Liang Zhao","Liangyu Chen","Lieyu Shi","Liguo Tan","Lin Lin","Lin Zhang","Lina Chen","Liwen Huang","Liying Shi","Longlong Gu","Mei Chen","Mengqiang Ren","Ming Li","Mingzhe Chen","Na Wang","Nan Wu","Qi Han","Qian Zhao","Qiang Zhang","Qianni Liu","Qiaohui Chen","Qiling Wu","Qinglin He","Qinyuan Tan","Qiufeng Wang","Qiuping Wu","Qiuyan Liang","Quan Sun","Rui Li","Ruihang Miao","Ruosi Wan","Ruyan Guo","Shangwu Zhong","Shaoliang Pang","Shengjie Fan","Shijie Shang","Shilei Jiang","Shiliang Yang","Shiming Hao","Shuli Gao","Siming Huang","Siqi Liu","Tiancheng Cao","Tianhao Cheng","Tianhao Peng","Wang You","Wei Ji","Wen Sun","Wenjin Deng","Wenqing He","Wenzhen Zheng","Xi Chen","Xiangwen Kong","Xianzhen Luo","Xiaobo Yang","Xiaojia Liu","Xiaoxiao Ren","Xin Han","Xin Li","Xin Wu","Xu Zhao","Yanan Wei","Yang Li","Yangguang Li","Yangshijie Xu","Yanming Xu","Yaqiang Shi","Yeqing Shen","Yi Yang","Yifei Yang","Yifeng Gong","Yihan Chen","Yijing Yang","Yinmin Zhang","Yizhuang Zhou","Yuanhao Ding","Yuantao Fan","Yuanzhen Yang","Yuchu Luo","Yue Peng","Yufan Lu","Yuhang Deng","Yuhe Yin","Yujie Liu","Yukun Chen","Yuling Zhao","Yun Mou","Yunlong Li","Yunzhou Ju","Yusheng Li","Yuxiang Yang","Yuxiang Zhang","Yuyang Chen","Zejia Weng","Zhe Xie","Zheng Ge","Zheng Gong","Zhenyi Lu","Zhewei Huang","Zhichao Chang","Zhiguo Huang","Zhirui Wang","Zidong Yang","Zili Wang","Ziqi Wang","Zixin Zhang","Binxing Jiao","Daxin Jiang","Heung-Yeung Shum","Xiangyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.19427v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19423v1","updated":"2025-07-25T16:43:42Z","published":"2025-07-25T16:43:42Z","title":"Perfect Clustering in Very Sparse Diverse Multiplex Networks","summary":"  The paper studies the DIverse MultiPLEx Signed Generalized Random Dot Product\nGraph (DIMPLE-SGRDPG) network model (Pensky (2024)), where all layers of the\nnetwork have the same collection of nodes. In addition, all layers can be\npartitioned into groups such that the layers in the same group are embedded in\nthe same ambient subspace but otherwise matrices of connection probabilities\ncan be all different. This setting includes majority of multilayer network\nmodels as its particular cases. The key task in this model is to recover the\ngroups of layers with unique subspace structures, since the case where all\nlayers of the network are embedded in the same subspace has been fairly well\nstudied. Until now, clustering of layers in such networks was based on the\nlayer-per-layer analysis, which required the multilayer network to be\nsufficiently dense. Nevertheless, in this paper we succeeded in pooling\ninformation in all layers together and providing a tensor-based methodology\nthat ensures perfect clustering for a much sparser network. Our theoretical\nresults, established under intuitive non-restrictive assumptions, assert that\nthe new technique achieves perfect clustering under sparsity conditions that,\nup to logarithmic factors, coincide with the computational lower bound derived\nfor a much simpler model.\n","authors":["Marianna Pensky"],"pdf_url":"https://arxiv.org/pdf/2507.19423v1.pdf","comment":"5 figures"},{"id":"http://arxiv.org/abs/2507.19420v1","updated":"2025-07-25T16:38:18Z","published":"2025-07-25T16:38:18Z","title":"CircuitProbe: Dissecting Spatiotemporal Visual Semantics with Circuit\n  Tracing","summary":"  The processing mechanisms underlying language and image understanding in\nlarge vision-language models (LVLMs) have been extensively studied. However,\nthe internal reasoning mechanisms of LVLMs for spatiotemporal understanding\nremain poorly understood. In this work, we introduce a systematic,\ncircuit-based framework designed to investigate how spatiotemporal visual\nsemantics are represented and processed within these LVLMs. Specifically, our\nframework comprises three circuits: visual auditing circuit, semantic tracing\ncircuit, and attention flow circuit. Through the lens of these circuits, we\ndiscover that visual semantics are highly localized to specific object\ntokens--removing these tokens can degrade model performance by up to 92.6%.\nFurthermore, we identify that interpretable concepts of objects and actions\nemerge and become progressively refined in the middle-to-late layers of LVLMs.\nIn contrary to the current works that solely focus on objects in one image, we\nreveal that the middle-to-late layers of LVLMs exhibit specialized functional\nlocalization for spatiotemporal semantics. Our findings offer significant\nmechanistic insights into spatiotemporal semantics analysis of LVLMs, laying a\nfoundation for designing more robust and interpretable models.\n","authors":["Yiming Zhang","Chengzhang Yu","Zhuokai Zhao","Kun Wang","Qiankun Li","Zihan Chen","Yang Liu","Zenghui Ding","Yining Sun"],"pdf_url":"https://arxiv.org/pdf/2507.19420v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19411v1","updated":"2025-07-25T16:21:18Z","published":"2025-07-25T16:21:18Z","title":"SILS: Strategic Influence on Liquidity Stability and Whale Detection in\n  Concentrated-Liquidity DEXs","summary":"  Traditional methods for identifying impactful liquidity providers (LPs) in\nConcentrated Liquidity Market Makers (CLMMs) rely on broad measures, such as\nnominal capital size or surface-level activity, which often lead to inaccurate\nrisk analysis. The SILS framework offers a significantly more detailed\napproach, characterizing LPs not just as capital holders but as dynamic\nsystemic agents whose actions directly impact market stability. This represents\na fundamental paradigm shift from the static, volume-based analysis to a\ndynamic, impact-focused understanding. This advanced approach uses on-chain\nevent logs and smart contract execution traces to compute Exponential\nTime-Weighted Liquidity (ETWL) profiles and apply unsupervised anomaly\ndetection. Most importantly, it defines an LP's functional importance through\nthe Liquidity Stability Impact Score (LSIS), a counterfactual metric that\nmeasures the potential degradation of the market if the LP withdraws. This\ncombined approach provides a more detailed and realistic characterization of an\nLP's impact, moving beyond the binary and often misleading classifications used\nby existing methods. This impact-focused and comprehensive approach enables\nSILS to accurately identify high-impact LPs-including those missed by\ntraditional methods and supports essential applications like a protective\noracle layer and actionable trader signals, thereby significantly enhancing\nDeFi ecosystem. The framework provides unprecedented transparency into the\nunderlying liquidity structure and associated risks, effectively reducing the\ncommon false positives and uncovering critical false negatives found in\ntraditional models. Therefore, SILS provides an effective mechanism for\nproactive risk management, transforming how DeFi protocols safeguard their\necosystems against asymmetric liquidity behavior.\n","authors":["Ali RajabiNekoo","Laleh Rasoul","Amirfarhad Farhadi","Azadeh Zamanifar"],"pdf_url":"https://arxiv.org/pdf/2507.19411v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19408v1","updated":"2025-07-25T16:15:59Z","published":"2025-07-25T16:15:59Z","title":"On Arbitrary Predictions from Equally Valid Models","summary":"  Model multiplicity refers to the existence of multiple machine learning\nmodels that describe the data equally well but may produce different\npredictions on individual samples. In medicine, these models can admit\nconflicting predictions for the same patient -- a risk that is poorly\nunderstood and insufficiently addressed.\n  In this study, we empirically analyze the extent, drivers, and ramifications\nof predictive multiplicity across diverse medical tasks and model\narchitectures, and show that even small ensembles can mitigate/eliminate\npredictive multiplicity in practice. Our analysis reveals that (1) standard\nvalidation metrics fail to identify a uniquely optimal model and (2) a\nsubstantial amount of predictions hinges on arbitrary choices made during model\ndevelopment. Using multiple models instead of a single model reveals instances\nwhere predictions differ across equally plausible models -- highlighting\npatients that would receive arbitrary diagnoses if any single model were used.\nIn contrast, (3) a small ensemble paired with an abstention strategy can\neffectively mitigate measurable predictive multiplicity in practice;\npredictions with high inter-model consensus may thus be amenable to automated\nclassification. While accuracy is not a principled antidote to predictive\nmultiplicity, we find that (4) higher accuracy achieved through increased model\ncapacity reduces predictive multiplicity.\n  Our findings underscore the clinical importance of accounting for model\nmultiplicity and advocate for ensemble-based strategies to improve diagnostic\nreliability. In cases where models fail to reach sufficient consensus, we\nrecommend deferring decisions to expert review.\n","authors":["Sarah Lockfisch","Kristian Schwethelm","Martin Menten","Rickmer Braren","Daniel Rueckert","Alexander Ziller","Georgios Kaissis"],"pdf_url":"https://arxiv.org/pdf/2507.19408v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19402v1","updated":"2025-07-25T16:08:22Z","published":"2025-07-25T16:08:22Z","title":"FD4QC: Application of Classical and Quantum-Hybrid Machine Learning for\n  Financial Fraud Detection A Technical Report","summary":"  The increasing complexity and volume of financial transactions pose\nsignificant challenges to traditional fraud detection systems. This technical\nreport investigates and compares the efficacy of classical, quantum, and\nquantum-hybrid machine learning models for the binary classification of\nfraudulent financial activities.\n  As of our methodology, first, we develop a comprehensive behavioural feature\nengineering framework to transform raw transactional data into a rich,\ndescriptive feature set. Second, we implement and evaluate a range of models on\nthe IBM Anti-Money Laundering (AML) dataset. The classical baseline models\ninclude Logistic Regression, Decision Tree, Random Forest, and XGBoost. These\nare compared against three hybrid classic quantum algorithms architectures: a\nQuantum Support Vector Machine (QSVM), a Variational Quantum Classifier (VQC),\nand a Hybrid Quantum Neural Network (HQNN).\n  Furthermore, we propose Fraud Detection for Quantum Computing (FD4QC), a\npractical, API-driven system architecture designed for real-world deployment,\nfeaturing a classical-first, quantum-enhanced philosophy with robust fallback\nmechanisms.\n  Our results demonstrate that classical tree-based models, particularly\n\\textit{Random Forest}, significantly outperform the quantum counterparts in\nthe current setup, achieving high accuracy (\\(97.34\\%\\)) and F-measure\n(\\(86.95\\%\\)). Among the quantum models, \\textbf{QSVM} shows the most promise,\ndelivering high precision (\\(77.15\\%\\)) and a low false-positive rate\n(\\(1.36\\%\\)), albeit with lower recall and significant computational overhead.\n  This report provides a benchmark for a real-world financial application,\nhighlights the current limitations of quantum machine learning in this domain,\nand outlines promising directions for future research.\n","authors":["Matteo Cardaioli","Luca Marangoni","Giada Martini","Francesco Mazzolin","Luca Pajola","Andrea Ferretto Parodi","Alessandra Saitta","Maria Chiara Vernillo"],"pdf_url":"https://arxiv.org/pdf/2507.19402v1.pdf","comment":"This is a technical report"},{"id":"http://arxiv.org/abs/2506.16629v4","updated":"2025-07-25T16:03:47Z","published":"2025-06-19T21:56:30Z","title":"Learning Causally Predictable Outcomes from Psychiatric Longitudinal\n  Data","summary":"  Causal inference in longitudinal biomedical data remains a central challenge,\nespecially in psychiatry, where symptom heterogeneity and latent confounding\nfrequently undermine classical estimators. Most existing methods for treatment\neffect estimation presuppose a fixed outcome variable and address confounding\nthrough observed covariate adjustment. However, the assumption of\nunconfoundedness may not hold for a fixed outcome in practice. To address this\nfoundational limitation, we directly optimize the outcome definition to\nmaximize causal identifiability. Our DEBIAS (Durable Effects with\nBackdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,\nclinically interpretable weights for outcome aggregation, maximizing durable\ntreatment effects and empirically minimizing both observed and latent\nconfounding by leveraging the time-limited direct effects of prior treatments\nin psychiatric longitudinal data. The algorithm also furnishes an empirically\nverifiable test for outcome unconfoundedness. DEBIAS consistently outperforms\nstate-of-the-art methods in recovering causal effects for clinically\ninterpretable composite outcomes across comprehensive experiments in depression\nand schizophrenia.\n","authors":["Eric V. Strobl"],"pdf_url":"https://arxiv.org/pdf/2506.16629v4.pdf","comment":"R code is available at github.com/ericstrobl/DEBIAS"},{"id":"http://arxiv.org/abs/2310.09278v3","updated":"2025-07-25T16:01:55Z","published":"2023-10-13T17:40:39Z","title":"Disentangled Latent Spaces Facilitate Data-Driven Auxiliary Learning","summary":"  Auxiliary tasks facilitate learning in situations where data is scarce or the\nprincipal task of interest is extremely complex. This idea is primarily\ninspired by the improved generalization capability induced by solving multiple\ntasks simultaneously, which leads to a more robust shared representation.\nNevertheless, finding optimal auxiliary tasks is a crucial problem that often\nrequires hand-crafted solutions or expensive meta-learning approaches. In this\npaper, we propose a novel framework, dubbed Detaux, whereby a weakly supervised\ndisentanglement procedure is used to discover a new unrelated auxiliary\nclassification task, which allows us to go from a Single-Task Learning (STL) to\na Multi-Task Learning (MTL) problem. The disentanglement procedure works at the\nrepresentation level, isolating the variation related to the principal task\ninto an isolated subspace and additionally producing an arbitrary number of\northogonal subspaces, each of which encourages high separability among\nprojections. We generate the auxiliary classification task through a clustering\nprocedure on the most disentangled subspace, obtaining a discrete set of\nlabels. Subsequently, the original data, the labels associated with the\nprincipal task, and the newly discovered ones can be fed into any MTL\nframework. Experimental validation on both synthetic and real data, along with\nvarious ablation studies, demonstrates promising results, revealing the\npotential in what has been, so far, an unexplored connection between learning\ndisentangled representations and MTL. The source code is available at\nhttps://github.com/intelligolabs/Detaux.\n","authors":["Geri Skenderi","Luigi Capogrosso","Andrea Toaiari","Matteo Denitto","Franco Fummi","Simone Melzi"],"pdf_url":"https://arxiv.org/pdf/2310.09278v3.pdf","comment":"Accepted at ICIAP25"},{"id":"http://arxiv.org/abs/2407.02348v3","updated":"2025-07-25T15:38:39Z","published":"2024-07-02T15:14:12Z","title":"Agreement-Based Cascading for Efficient Inference","summary":"  Adaptive inference schemes reduce the cost of machine learning inference by\nassigning smaller models to easier examples, attempting to avoid invocation of\nlarger models when possible. In this work we explore a simple, effective\nadaptive inference technique we term Agreement-Based Cascading (ABC). ABC\nbuilds a cascade of models of increasing size/complexity, and uses agreement\nbetween ensembles of models at each level of the cascade as a basis for\ndata-dependent routing. Although ensemble execution introduces additional\nexpense, we show that these costs can be easily offset in practice due to large\nexpected differences in model sizes, parallel inference execution capabilities,\nand accuracy benefits of ensembling. We examine ABC theoretically and\nempirically in terms of these parameters, showing that the approach can\nreliably act as a drop-in replacement for existing models and surpass the best\nsingle model it aims to replace in terms of both efficiency and accuracy.\nAdditionally, we explore the performance of ABC relative to existing cascading\nmethods in three common scenarios: (1) edge-to-cloud inference, where ABC\nreduces communication costs by up to 14x; (2) cloud-based model serving, where\nit achieves a 3x reduction in rental costs; and (3) inference via model API\nservices, where ABC achieves a 2-25x reduction in average price per\ntoken/request relative to state-of-the-art LLM cascades.\n","authors":["Steven Kolawole","Don Dennis","Ameet Talwalkar","Virginia Smith"],"pdf_url":"https://arxiv.org/pdf/2407.02348v3.pdf","comment":"Published at TMLR (July 2025)"},{"id":"http://arxiv.org/abs/2507.17897v2","updated":"2025-07-25T15:38:12Z","published":"2025-07-23T19:48:27Z","title":"Multimodal Recurrent Ensembles for Predicting Brain Responses to\n  Naturalistic Movies (Algonauts 2025)","summary":"  Accurately predicting distributed cortical responses to naturalistic stimuli\nrequires models that integrate visual, auditory and semantic information over\ntime. We present a hierarchical multimodal recurrent ensemble that maps\npretrained video, audio, and language embeddings to fMRI time series recorded\nwhile four subjects watched almost 80 hours of movies provided by the Algonauts\n2025 challenge. Modality-specific bidirectional RNNs encode temporal dynamics;\ntheir hidden states are fused and passed to a second recurrent layer, and\nlightweight subject-specific heads output responses for 1000 cortical parcels.\nTraining relies on a composite MSE-correlation loss and a curriculum that\ngradually shifts emphasis from early sensory to late association regions.\nAveraging 100 model variants further boosts robustness. The resulting system\nranked third on the competition leaderboard, achieving an overall Pearson r =\n0.2094 and the highest single-parcel peak score (mean r = 0.63) among all\nparticipants, with particularly strong gains for the most challenging subject\n(Subject 5). The approach establishes a simple, extensible baseline for future\nmultimodal brain-encoding benchmarks.\n","authors":["Semih Eren","Deniz Kucukahmetler","Nico Scherf"],"pdf_url":"https://arxiv.org/pdf/2507.17897v2.pdf","comment":"8 pages, 2 figures, 1 table. Invited report, CCN 2025 Algonauts\n  Project session (3rd-place team). Code:\n  https://github.com/erensemih/Algonauts2025_ModalityRNN"},{"id":"http://arxiv.org/abs/2507.19372v1","updated":"2025-07-25T15:24:56Z","published":"2025-07-25T15:24:56Z","title":"Learning neuro-symbolic convergent term rewriting systems","summary":"  Building neural systems that can learn to execute symbolic algorithms is a\nchallenging open problem in artificial intelligence, especially when aiming for\nstrong generalization and out-of-distribution performance. In this work, we\nintroduce a general framework for learning convergent term rewriting systems\nusing a neuro-symbolic architecture inspired by the rewriting algorithm itself.\nWe present two modular implementations of such architecture: the Neural\nRewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a\nresult of algorithmic-inspired design and key architectural elements, both\nmodels can generalize to out-of-distribution instances, with FastNRS offering\nsignificant improvements in terms of memory efficiency, training speed, and\ninference time. We evaluate both architectures on four tasks involving the\nsimplification of mathematical formulas and further demonstrate their\nversatility in a multi-domain learning scenario, where a single model is\ntrained to solve multiple types of problems simultaneously. The proposed system\nsignificantly outperforms two strong neural baselines: the Neural Data Router,\na recent transformer variant specifically designed to solve algorithmic\nproblems, and GPT-4o, one of the most powerful general-purpose large-language\nmodels. Moreover, our system matches or outperforms the latest o1-preview model\nfrom OpenAI that excels in reasoning benchmarks.\n","authors":["Flavio Petruzzellis","Alberto Testolin","Alessandro Sperduti"],"pdf_url":"https://arxiv.org/pdf/2507.19372v1.pdf","comment":"48 pages, 31 figures. Submitted for review by Artificial Intelligence\n  Journal"},{"id":"http://arxiv.org/abs/2504.05355v2","updated":"2025-07-25T15:21:48Z","published":"2025-04-07T08:56:32Z","title":"Deep Learning for Double Auction","summary":"  Auctions are important mechanisms extensively implemented in various markets,\ne.g., search engines' keyword auctions, antique auctions, etc. Finding an\noptimal auction mechanism is extremely difficult due to the constraints of\nimperfect information, incentive compatibility (IC), and individual rationality\n(IR). In addition to the traditional economic methods, some recently attempted\nto find the optimal (single) auction using deep learning methods. Unlike those\nattempts focusing on single auctions, we develop deep learning methods for\ndouble auctions, where imperfect information exists on both the demand and\nsupply sides. The previous attempts on single auction cannot directly apply to\nour contexts and those attempts additionally suffer from limited\ngeneralizability, inefficiency in ensuring the constraints, and learning\nfluctuations. We innovate in designing deep learning models for solving the\nmore complex problem and additionally addressing the previous models' three\nlimitations. Specifically, we achieve generalizability by leveraging a\ntransformer-based architecture to model market participants as sequences for\nvarying market sizes; we utilize the numerical features of the constraints and\npre-treat them for a higher learning efficiency; we develop a\ngradient-conflict-elimination scheme to address the problem of learning\nfluctuation. Extensive experimental evaluations demonstrate the superiority of\nour approach to classical and machine learning baselines.\n","authors":["Jiayin Liu","Chenglong Zhang"],"pdf_url":"https://arxiv.org/pdf/2504.05355v2.pdf","comment":"This submission has been withdrawn in accordance with our\n  institution's publication policy, which requires additional internal review\n  and approval prior to public release"},{"id":"http://arxiv.org/abs/2507.19368v1","updated":"2025-07-25T15:19:32Z","published":"2025-07-25T15:19:32Z","title":"Counterfactual Explanations in Medical Imaging: Exploring SPN-Guided\n  Latent Space Manipulation","summary":"  Artificial intelligence is increasingly leveraged across various domains to\nautomate decision-making processes that significantly impact human lives. In\nmedical image analysis, deep learning models have demonstrated remarkable\nperformance. However, their inherent complexity makes them black box systems,\nraising concerns about reliability and interpretability. Counterfactual\nexplanations provide comprehensible insights into decision processes by\npresenting hypothetical \"what-if\" scenarios that alter model classifications.\nBy examining input alterations, counterfactual explanations provide patterns\nthat influence the decision-making process. Despite their potential, generating\nplausible counterfactuals that adhere to similarity constraints providing\nhuman-interpretable explanations remains a challenge. In this paper, we\ninvestigate this challenge by a model-specific optimization approach. While\ndeep generative models such as variational autoencoders (VAEs) exhibit\nsignificant generative power, probabilistic models like sum-product networks\n(SPNs) efficiently represent complex joint probability distributions. By\nmodeling the likelihood of a semi-supervised VAE's latent space with an SPN, we\nleverage its dual role as both a latent space descriptor and a classifier for a\ngiven discrimination task. This formulation enables the optimization of latent\nspace counterfactuals that are both close to the original data distribution and\naligned with the target class distribution. We conduct experimental evaluation\non the cheXpert dataset. To evaluate the effectiveness of the integration of\nSPNs, our SPN-guided latent space manipulation is compared against a neural\nnetwork baseline. Additionally, the trade-off between latent variable\nregularization and counterfactual quality is analyzed.\n","authors":["Julia Siekiera","Stefan Kramer"],"pdf_url":"https://arxiv.org/pdf/2507.19368v1.pdf","comment":"10 pages, 3 figures"},{"id":"http://arxiv.org/abs/2507.19365v1","updated":"2025-07-25T15:16:54Z","published":"2025-07-25T15:16:54Z","title":"A Data-Driven Approach to Estimate LEO Orbit Capacity Models","summary":"  Utilizing the Sparse Identification of Nonlinear Dynamics algorithm (SINDy)\nand Long Short-Term Memory Recurrent Neural Networks (LSTM), the population of\nresident space objects, divided into Active, Derelict, and Debris, in LEO can\nbe accurately modeled to predict future satellite and debris propagation. This\nproposed approach makes use of a data set coming from a computational expensive\nhigh-fidelity model, the MOCAT-MC, to provide a light, low-fidelity counterpart\nthat provides accurate forecasting in a shorter time frame.\n","authors":["Braden Stock","Maddox McVarthy","Simone Servadio"],"pdf_url":"https://arxiv.org/pdf/2507.19365v1.pdf","comment":"18 pages, 15 figures"},{"id":"http://arxiv.org/abs/2507.19362v1","updated":"2025-07-25T15:12:42Z","published":"2025-07-25T15:12:42Z","title":"LOTUS: A Leaderboard for Detailed Image Captioning from Quality to\n  Societal Bias and User Preferences","summary":"  Large Vision-Language Models (LVLMs) have transformed image captioning,\nshifting from concise captions to detailed descriptions. We introduce LOTUS, a\nleaderboard for evaluating detailed captions, addressing three main gaps in\nexisting evaluations: lack of standardized criteria, bias-aware assessments,\nand user preference considerations. LOTUS comprehensively evaluates various\naspects, including caption quality (e.g., alignment, descriptiveness), risks\n(\\eg, hallucination), and societal biases (e.g., gender bias) while enabling\npreference-oriented evaluations by tailoring criteria to diverse user\npreferences. Our analysis of recent LVLMs reveals no single model excels across\nall criteria, while correlations emerge between caption detail and bias risks.\nPreference-oriented evaluations demonstrate that optimal model selection\ndepends on user priorities.\n","authors":["Yusuke Hirota","Boyi Li","Ryo Hachiuma","Yueh-Hua Wu","Boris Ivanovic","Yuta Nakashima","Marco Pavone","Yejin Choi","Yu-Chiang Frank Wang","Chao-Han Huck Yang"],"pdf_url":"https://arxiv.org/pdf/2507.19362v1.pdf","comment":"Accepted to ACL 2025. Leaderboard:\n  huggingface.co/spaces/nvidia/lotus-vlm-bias-leaderboard"},{"id":"http://arxiv.org/abs/2507.19354v1","updated":"2025-07-25T15:03:26Z","published":"2025-07-25T15:03:26Z","title":"EffiComm: Bandwidth Efficient Multi Agent Communication","summary":"  Collaborative perception allows connected vehicles to exchange sensor\ninformation and overcome each vehicle's blind spots. Yet transmitting raw point\nclouds or full feature maps overwhelms Vehicle-to-Vehicle (V2V) communications,\ncausing latency and scalability problems. We introduce EffiComm, an end-to-end\nframework that transmits less than 40% of the data required by prior art while\nmaintaining state-of-the-art 3D object detection accuracy. EffiComm operates on\nBird's-Eye-View (BEV) feature maps from any modality and applies a two-stage\nreduction pipeline: (1) Selective Transmission (ST) prunes low-utility regions\nwith a confidence mask; (2) Adaptive Grid Reduction (AGR) uses a Graph Neural\nNetwork (GNN) to assign vehicle-specific keep ratios according to role and\nnetwork load. The remaining features are fused with a soft-gated\nMixture-of-Experts (MoE) attention layer, offering greater capacity and\nspecialization for effective feature integration. On the OPV2V benchmark,\nEffiComm reaches 0.84 mAP@0.7 while sending only an average of approximately\n1.5 MB per frame, outperforming previous methods on the accuracy-per-bit curve.\nThese results highlight the value of adaptive, learned communication for\nscalable Vehicle-to-Everything (V2X) perception.\n","authors":["Melih Yazgan","Allen Xavier Arasan","J. Marius Zöllner"],"pdf_url":"https://arxiv.org/pdf/2507.19354v1.pdf","comment":"Accepted for publication at ITSC 2025"},{"id":"http://arxiv.org/abs/2507.19349v1","updated":"2025-07-25T14:59:44Z","published":"2025-07-25T14:59:44Z","title":"Reconstruction of Sparse Urban Wireless Signals via Group Equivariant\n  Non-Expansive Operators","summary":"  In emerging communication systems such as sixth generation (6G) wireless\nnetworks, efficient resource management and service delivery rely on accurate\nknowledge of spatially-varying quantities like signal-to-interference-noise\nratio (SINR) maps, which are costly to acquire at high resolution. This work\nexplores the reconstruction of such spatial signals from sparse measurements\nusing Group Equivariant Non-Expansive Operators (GENEOs), offering a\nlow-complexity alternative to traditional neural networks. The concept of\nGENEO, which originated in topological data analysis (TDA), is a mathematical\ntool used in machine learning to represent agents modelled as functional\noperators acting on data while incorporating application-specific invariances.\nLeveraging these invariances reduces the number of parameters with respect to\ntraditional neural networks and mitigates data scarcity by enforcing known\nalgebraic and geometric constraints that reflect symmetries in the agents'\nactions. In this paper, we introduce a novel GENEO-based approach for SINR map\nreconstruction in urban wireless communication networks using extremely sparse\nsampling. We demonstrate that this mathematical framework achieves competitive\nperformance compared to established methods. Our evaluation, conducted using\nboth statistical and TDA metrics, highlights the advantages of our approach in\naccurately reconstructing spatial signals under severe data limitations on the\nnumber of samples.\n","authors":["Lorenzo Mario Amorosa","Francesco Conti","Nicola Quercioli","Flavio Zabini","Tayebeh Lotfi Mahyari","Yiqun Ge","Patrizio Frosini"],"pdf_url":"https://arxiv.org/pdf/2507.19349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19346v1","updated":"2025-07-25T14:57:04Z","published":"2025-07-25T14:57:04Z","title":"Short-Form Video Recommendations with Multimodal Embeddings: Addressing\n  Cold-Start and Bias Challenges","summary":"  In recent years, social media users have spent significant amounts of time on\nshort-form video platforms. As a result, established platforms in other\ndomains, such as e-commerce, have begun introducing short-form video content to\nengage users and increase their time spent on the platform. The success of\nthese experiences is due not only to the content itself but also to a unique UI\ninnovation: instead of offering users a list of choices to click, platforms\nactively recommend content for users to watch one at a time. This creates new\nchallenges for recommender systems, especially when launching a new video\nexperience. Beyond the limited interaction data, immersive feed experiences\nintroduce stronger position bias due to the UI and duration bias when\noptimizing for watch-time, as models tend to favor shorter videos. These\nissues, together with the feedback loop inherent in recommender systems, make\nit difficult to build effective solutions. In this paper, we highlight the\nchallenges faced when introducing a new short-form video experience and present\nour experience showing that, even with sufficient video interaction data, it\ncan be more beneficial to leverage a video retrieval system using a fine-tuned\nmultimodal vision-language model to overcome these challenges. This approach\ndemonstrated greater effectiveness compared to conventional supervised learning\nmethods in online experiments conducted on our e-commerce platform.\n","authors":["Andrii Dzhoha","Katya Mirylenka","Egor Malykh","Marco-Andrea Buchmann","Francesca Catino"],"pdf_url":"https://arxiv.org/pdf/2507.19346v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20933v2","updated":"2025-07-25T14:48:30Z","published":"2025-06-26T01:44:23Z","title":"Lower Bounds on the Size of Markov Equivalence Classes","summary":"  Causal discovery algorithms typically recover causal graphs only up to their\nMarkov equivalence classes unless additional parametric assumptions are made.\nThe sizes of these equivalence classes reflect the limits of what can be\nlearned about the underlying causal graph from purely observational data. Under\nthe assumptions of acyclicity, causal sufficiency, and a uniform model prior,\nMarkov equivalence classes are known to be small on average. In this paper, we\nshow that this is no longer the case when any of these assumptions is relaxed.\nSpecifically, we prove exponentially large lower bounds for the expected size\nof Markov equivalence classes in three settings: sparse random directed acyclic\ngraphs, uniformly random acyclic directed mixed graphs, and uniformly random\ndirected cyclic graphs.\n","authors":["Erik Jahn","Frederick Eberhardt","Leonard J. Schulman"],"pdf_url":"https://arxiv.org/pdf/2506.20933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19334v1","updated":"2025-07-25T14:43:50Z","published":"2025-07-25T14:43:50Z","title":"Doubling Your Data in Minutes: Ultra-fast Tabular Data Generation via\n  LLM-Induced Dependency Graphs","summary":"  Tabular data is critical across diverse domains, yet high-quality datasets\nremain scarce due to privacy concerns and the cost of collection. Contemporary\napproaches adopt large language models (LLMs) for tabular augmentation, but\nexhibit two major limitations: (1) dense dependency modeling among tabular\nfeatures that can introduce bias, and (2) high computational overhead in\nsampling. To address these issues, we propose SPADA for SPArse\nDependency-driven Augmentation, a lightweight generative framework that\nexplicitly captures sparse dependencies via an LLM-induced graph. We treat each\nfeature as a node and synthesize values by traversing the graph, conditioning\neach feature solely on its parent nodes. We explore two synthesis strategies: a\nnon-parametric method using Gaussian kernel density estimation, and a\nconditional normalizing flow model that learns invertible mappings for\nconditional density estimation. Experiments on four datasets show that SPADA\nreduces constraint violations by 4% compared to diffusion-based methods and\naccelerates generation by nearly 9,500 times over LLM-based baselines.\n","authors":["Shuo Yang","Zheyu Zhang","Bardh Prenkaj","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2507.19334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19321v1","updated":"2025-07-25T14:34:15Z","published":"2025-07-25T14:34:15Z","title":"SIDE: Sparse Information Disentanglement for Explainable Artificial\n  Intelligence","summary":"  Understanding the decisions made by deep neural networks is essential in\nhigh-stakes domains such as medical imaging and autonomous driving. Yet, these\nmodels often lack transparency, particularly in computer vision.\nPrototypical-parts-based neural networks have emerged as a promising solution\nby offering concept-level explanations. However, most are limited to\nfine-grained classification tasks, with few exceptions such as InfoDisent.\nInfoDisent extends prototypical models to large-scale datasets like ImageNet,\nbut produces complex explanations.\n  We introduce Sparse Information Disentanglement for Explainability (SIDE), a\nnovel method that improves the interpretability of prototypical parts through a\ndedicated training and pruning scheme that enforces sparsity. Combined with\nsigmoid activations in place of softmax, this approach allows SIDE to associate\neach class with only a small set of relevant prototypes. Extensive experiments\nshow that SIDE matches the accuracy of existing methods while reducing\nexplanation size by over $90\\%$, substantially enhancing the understandability\nof prototype-based explanations.\n","authors":["Viktar Dubovik","Łukasz Struski","Jacek Tabor","Dawid Rymarczyk"],"pdf_url":"https://arxiv.org/pdf/2507.19321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19316v1","updated":"2025-07-25T14:30:37Z","published":"2025-07-25T14:30:37Z","title":"Human-AI Synergy in Adaptive Active Learning for Continuous Lithium\n  Carbonate Crystallization Optimization","summary":"  As demand for high-purity lithium surges with the growth of the electric\nvehicle (EV) industry, cost-effective extraction from lower-grade North\nAmerican sources like the Smackover Formation is critical. These resources,\nunlike high-purity South American brines, require innovative purification\ntechniques to be economically viable. Continuous crystallization is a promising\nmethod for producing battery-grade lithium carbonate, but its optimization is\nchallenged by a complex parameter space and limited data. This study introduces\na Human-in-the-Loop (HITL) assisted active learning framework to optimize the\ncontinuous crystallization of lithium carbonate. By integrating human expertise\nwith data-driven insights, our approach accelerates the optimization of lithium\nextraction from challenging sources. Our results demonstrate the framework's\nability to rapidly adapt to new data, significantly improving the process's\ntolerance to critical impurities like magnesium from the industry standard of a\nfew hundred ppm to as high as 6000 ppm. This breakthrough makes the\nexploitation of low-grade, impurity-rich lithium resources feasible,\npotentially reducing the need for extensive pre-refinement processes. By\nleveraging artificial intelligence, we have refined operational parameters and\ndemonstrated that lower-grade materials can be used without sacrificing product\nquality. This advancement is a significant step towards economically harnessing\nNorth America's vast lithium reserves, such as those in the Smackover\nFormation, and enhancing the sustainability of the global lithium supply chain.\n","authors":["Shayan S. Mousavi Masouleh","Corey A. Sanz","Ryan P. Jansonius","Cara Cronin","Jason E. Hein","Jason Hattrick-Simpers"],"pdf_url":"https://arxiv.org/pdf/2507.19316v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.20719v2","updated":"2025-07-25T14:26:39Z","published":"2025-02-28T05:06:04Z","title":"Generating Clinically Realistic EHR Data via a Hierarchy- and\n  Semantics-Guided Transformer","summary":"  Generating realistic synthetic electronic health records (EHRs) holds\ntremendous promise for accelerating healthcare research, facilitating AI model\ndevelopment and enhancing patient privacy. However, existing generative methods\ntypically treat EHRs as flat sequences of discrete medical codes. This approach\noverlooks two critical aspects: the inherent hierarchical organization of\nclinical coding systems and the rich semantic context provided by code\ndescriptions. Consequently, synthetic patient sequences often lack high\nclinical fidelity and have limited utility in downstream clinical tasks. In\nthis paper, we propose the Hierarchy- and Semantics-Guided Transformer (HiSGT),\na novel framework that leverages both hierarchical and semantic information for\nthe generative process. HiSGT constructs a hierarchical graph to encode\nparent-child and sibling relationships among clinical codes and employs a graph\nneural network to derive hierarchy-aware embeddings. These are then fused with\nsemantic embeddings extracted from a pre-trained clinical language model (e.g.,\nClinicalBERT), enabling the Transformer-based generator to more accurately\nmodel the nuanced clinical patterns inherent in real EHRs. Extensive\nexperiments on the MIMIC-III and MIMIC-IV datasets demonstrate that HiSGT\nsignificantly improves the statistical alignment of synthetic data with real\npatient records, as well as supports robust downstream applications such as\nchronic disease classification. By addressing the limitations of conventional\nraw code-based generative models, HiSGT represents a significant step toward\nclinically high-fidelity synthetic data generation and a general paradigm\nsuitable for interpretable medical code representation, offering valuable\napplications in data augmentation and privacy-preserving healthcare analytics.\n","authors":["Guanglin Zhou","Sebastiano Barbieri"],"pdf_url":"https://arxiv.org/pdf/2502.20719v2.pdf","comment":"The camera ready version for ECAI-2025"},{"id":"http://arxiv.org/abs/2502.10112v2","updated":"2025-07-25T14:23:24Z","published":"2025-02-14T12:17:59Z","title":"Accelerometry-based Energy Expenditure Estimation During Activities of\n  Daily Living: A Comparison Among Different Accelerometer Compositions","summary":"  Physical activity energy expenditure (PAEE) can be measured from\nbreath-by-breath respiratory data, which can serve as a reference.\nAlternatively, PAEE can be predicted from the body movements, which can be\nmeasured and estimated with accelerometers. The body center of mass (COM)\nacceleration reflects the movements of the whole body and thus serves as a good\npredictor for PAEE. However, the wrist has also become a popular location due\nto recent advancements in wrist-worn devices. Therefore, in this work, using\nthe respiratory data measured by COSMED K5 as the reference, we evaluated and\ncompared the performances of COM-based settings and wrist-based settings. The\nCOM-based settings include two different accelerometer compositions, using only\nthe pelvis accelerometer (pelvis-acc) and the pelvis accelerometer with two\naccelerometers from two thighs (3-acc). The wrist-based settings include using\nonly the left wrist accelerometer (l-wrist-acc) and only the right wrist\naccelerometer (r-wrist-acc). We implemented two existing PAEE estimation\nmethods on our collected dataset, where 9 participants performed activities of\ndaily living while wearing 5 accelerometers (i.e., pelvis, two thighs, and two\nwrists). These two methods include a linear regression (LR) model and a\nCNN-LSTM model. Both models yielded the best results with the COM-based 3-acc\nsetting (LR: $R^2$ = 0.41, CNN-LSTM: $R^2$ = 0.53). No significant difference\nwas found between the 3-acc and pelvis-acc settings (p-value = 0.278). For both\nmodels, neither the l-wrist-acc nor the r-wrist-acc settings demonstrated\npredictive power on PAEE with $R^2$ values close to 0, significantly\noutperformed by the two COM-based settings (p-values $<$ 0.05). No significant\ndifference was found between the two wrists (p-value = 0.329).\n","authors":["Shuhao Que","Remco Poelarends","Peter Veltink","Miriam Vollenbroek-Hutten","Ying Wang"],"pdf_url":"https://arxiv.org/pdf/2502.10112v2.pdf","comment":"This work has been accepted by IEEE EMBC 2025"},{"id":"http://arxiv.org/abs/2507.19300v1","updated":"2025-07-25T14:14:19Z","published":"2025-07-25T14:14:19Z","title":"Negative news posts are less prevalent and generate lower user\n  engagement than non-negative news posts across six countries","summary":"  Although news negativity is often studied, missing is comparative evidence on\nthe prevalence of and engagement with negative political and non-political news\nposts on social media. We use 6,081,134 Facebook posts published between\nJanuary 1, 2020, and April 1, 2024, by 97 media organizations in six countries\n(U.S., UK, Ireland, Poland, France, Spain) and develop two multilingual\nclassifiers for labeling posts as (non-)political and (non-)negative. We show\nthat: (1) negative news posts constitute a relatively small fraction (12.6%);\n(2) political news posts are neither more nor less negative than non-political\nnews posts; (3) U.S. political news posts are less negative relative to the\nother countries on average (40% lower odds); (4) Negative news posts get 15%\nfewer likes and 13% fewer comments than non-negative news posts. Lastly, (5) we\nprovide estimates of the proportion of the total volume of user engagement with\nnegative news posts and show that only between 10.2% to 13.1% of engagement is\nlinked to negative posts by the analyzed news organizations.\n","authors":["Szymon Talaga","Dominik Batorski","Magdalena Wojcieszak"],"pdf_url":"https://arxiv.org/pdf/2507.19300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19298v1","updated":"2025-07-25T14:12:11Z","published":"2025-07-25T14:12:11Z","title":"Controlling Topological Defects in Polar Fluids via Reinforcement\n  Learning","summary":"  Topological defects in active polar fluids exhibit complex dynamics driven by\ninternally generated stresses, reflecting the deep interplay between topology,\nflow, and non-equilibrium hydrodynamics. Feedback control offers a powerful\nmeans to guide such systems, enabling transitions between dynamic states. We\ninvestigated closed-loop steering of integer-charged defects in a confined\nactive fluid by modulating the spatial profile of activity. Using a continuum\nhydrodynamic model, we show that localized control of active stress induces\nflow fields that can reposition and direct defects along prescribed\ntrajectories by exploiting non-linear couplings in the system. A reinforcement\nlearning framework is used to discover effective control strategies that\nproduce robust defect transport across both trained and novel trajectories. The\nresults highlight how AI agents can learn the underlying dynamics and spatially\nstructure activity to manipulate topological excitations, offering insights\ninto the controllability of active matter and the design of adaptive,\nself-organized materials.\n","authors":["Abhinav Singh","Petros Koumoutsakos"],"pdf_url":"https://arxiv.org/pdf/2507.19298v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.21211v2","updated":"2025-07-25T14:11:49Z","published":"2025-03-27T06:55:29Z","title":"Interpretable Cross-Sphere Multiscale Deep Learning Predicts ENSO\n  Skilfully Beyond 2 Years","summary":"  El Ni\\~no-Southern Oscillation (ENSO) exerts global climate and societal\nimpacts, but real-time prediction with lead times beyond one year remains\nchallenging. Dynamical models suffer from large biases and uncertainties, while\ndeep learning struggles with interpretability and multi-scale dynamics. Here,\nwe introduce PTSTnet, an interpretable model that unifies dynamical processes\nand cross-scale spatiotemporal learning in an innovative neural-network\nframework with physics-encoding learning. PTSTnet produces interpretable\npredictions significantly outperforming state-of-the-art benchmarks with lead\ntimes beyond 24 months, providing physical insights into error propagation in\nocean-atmosphere interactions. PTSTnet learns feature representations with\nphysical consistency from sparse data to tackle inherent multi-scale and\nmulti-physics challenges underlying ocean-atmosphere processes, thereby\ninherently enhancing long-term prediction skill. Our successful realizations\nmark substantial steps forward in interpretable insights into innovative neural\nocean modelling.\n","authors":["Rixu Hao","Yuxin Zhao","Shaoqing Zhang","Guihua Wang","Xiong Deng"],"pdf_url":"https://arxiv.org/pdf/2503.21211v2.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.19290v1","updated":"2025-07-25T14:04:20Z","published":"2025-07-25T14:04:20Z","title":"Query Efficient Structured Matrix Learning","summary":"  We study the problem of learning a structured approximation (low-rank,\nsparse, banded, etc.) to an unknown matrix $A$ given access to matrix-vector\nproduct (matvec) queries of the form $x \\rightarrow Ax$ and $x \\rightarrow\nA^Tx$. This problem is of central importance to algorithms across scientific\ncomputing and machine learning, with applications to fast multiplication and\ninversion for structured matrices, building preconditioners for first-order\noptimization, and as a model for differential operator learning. Prior work\nfocuses on obtaining query complexity upper and lower bounds for learning\nspecific structured matrix families that commonly arise in applications.\n  We initiate the study of the problem in greater generality, aiming to\nunderstand the query complexity of learning approximations from general matrix\nfamilies. Our main result focuses on finding a near-optimal approximation to\n$A$ from any finite-sized family of matrices, $\\mathcal{F}$. Standard results\nfrom matrix sketching show that $O(\\log|\\mathcal{F}|)$ matvec queries suffice\nin this setting. This bound can also be achieved, and is optimal, for\nvector-matrix-vector queries of the form $x,y\\rightarrow x^TAy$, which have\nbeen widely studied in work on rank-$1$ matrix sensing.\n  Surprisingly, we show that, in the matvec model, it is possible to obtain a\nnearly quadratic improvement in complexity, to\n$\\tilde{O}(\\sqrt{\\log|\\mathcal{F}|})$. Further, we prove that this bound is\ntight up to log-log factors.Via covering number arguments, our result extends\nto well-studied infinite families. As an example, we establish that a\nnear-optimal approximation from any \\emph{linear matrix family} of dimension\n$q$ can be learned with $\\tilde{O}(\\sqrt{q})$ matvec queries, improving on an\n$O(q)$ bound achievable via sketching techniques and vector-matrix-vector\nqueries.\n","authors":["Noah Amsel","Pratyush Avi","Tyler Chen","Feyza Duman Keles","Chinmay Hegde","Cameron Musco","Christopher Musco","David Persson"],"pdf_url":"https://arxiv.org/pdf/2507.19290v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19261v1","updated":"2025-07-25T13:37:45Z","published":"2025-07-25T13:37:45Z","title":"Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in\n  Resource-Constrained Environments","summary":"  The increasing adoption of Artificial Intelligence (AI) has led to larger,\nmore complex models with numerous parameters that require substantial computing\npower -- resources often unavailable in many real-world application scenarios.\nOur paper addresses this challenge by introducing knowledge grafting, a novel\nmechanism that optimizes AI models for resource-constrained environments by\ntransferring selected features (the scion) from a large donor model to a\nsmaller rootstock model. The approach achieves an 88.54% reduction in model\nsize (from 64.39 MB to 7.38 MB), while improving generalization capability of\nthe model. Our new rootstock model achieves 89.97% validation accuracy (vs.\ndonor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and\nperforms exceptionally well on unseen test data with 90.45% accuracy. It\naddresses the typical size vs performance trade-off, and enables deployment of\nAI frameworks on resource-constrained devices with enhanced performance. We\nhave tested our approach on an agricultural weed detection scenario, however,\nit can be extended across various edge computing scenarios, potentially\naccelerating AI adoption in areas with limited hardware/software support -- by\nmirroring in a similar manner the horticultural grafting enables productive\ncultivation in challenging agri-based environments.\n","authors":["Osama Almurshed","Ashish Kaushal","Asmail Muftah","Nitin Auluck","Omer Rana"],"pdf_url":"https://arxiv.org/pdf/2507.19261v1.pdf","comment":"18 pages, 4 figures, ArXiv preprint - Novel \"knowledge grafting\"\n  technique achieving 88.54% AI model size reduction while improving accuracy\n  for resource-constrained deployment"},{"id":"http://arxiv.org/abs/2507.16039v2","updated":"2025-07-25T13:33:48Z","published":"2025-07-21T20:13:02Z","title":"Reactivation: Empirical NTK Dynamics Under Task Shifts","summary":"  The Neural Tangent Kernel (NTK) offers a powerful tool to study the\nfunctional dynamics of neural networks. In the so-called lazy, or kernel\nregime, the NTK remains static during training and the network function is\nlinear in the static neural tangents feature space. The evolution of the NTK\nduring training is necessary for feature learning, a key driver of deep\nlearning success. The study of the NTK dynamics has led to several critical\ndiscoveries in recent years, in generalization and scaling behaviours. However,\nthis body of work has been limited to the single task setting, where the data\ndistribution is assumed constant over time. In this work, we present a\ncomprehensive empirical analysis of NTK dynamics in continual learning, where\nthe data distribution shifts over time. Our findings highlight continual\nlearning as a rich and underutilized testbed for probing the dynamics of neural\ntraining. At the same time, they challenge the validity of static-kernel\napproximations in theoretical treatments of continual learning, even at large\nscale.\n","authors":["Yuzhi Liu","Zixuan Chen","Zirui Zhang","Yufei Liu","Giulia Lanzillotta"],"pdf_url":"https://arxiv.org/pdf/2507.16039v2.pdf","comment":"Accepted by the 3rd Workshop on High-dimensional Learning Dynamics\n  (HiLD), ICML 2025"},{"id":"http://arxiv.org/abs/2506.06410v2","updated":"2025-07-25T13:23:22Z","published":"2025-06-06T15:40:16Z","title":"Delphos: A reinforcement learning framework for assisting discrete\n  choice model specification","summary":"  We introduce Delphos, a deep reinforcement learning framework for assisting\nthe discrete choice model specification process. Unlike traditional approaches\nthat treat model specification as a static optimisation problem, Delphos\nrepresents a paradigm shift: it frames this specification challenge as a\nsequential decision-making problem, formalised as a Markov Decision Process. In\nthis setting, an agent learns to specify well-performing model candidates by\nchoosing a sequence of modelling actions - such as selecting variables,\naccommodating both generic and alternative-specific taste parameters, applying\nnon-linear transformations, and including interactions with covariates - and\ninteracting with a modelling environment that estimates each candidate and\nreturns a reward signal. Specifically, Delphos uses a Deep Q-Network that\nreceives delayed rewards based on modelling outcomes (e.g., log-likelihood) and\nbehavioural expectations (e.g., parameter signs), and distributes rewards\nacross the sequence of actions to learn which modelling decisions lead to\nwell-performing candidates. We evaluate Delphos on both simulated and empirical\ndatasets, varying the size of the modelling space and the reward function. To\nassess the agent's performance in navigating the model space, we analyse the\nlearning curve, the distribution of Q-values, occupancy metrics, and Pareto\nfronts. Our results show that the agent learns to adaptively explore strategies\nto identify well-performing models across search spaces, even without prior\ndomain knowledge. It efficiently explores large modelling spaces, concentrates\nits search in high-reward regions, and suggests candidates that define Pareto\nfrontiers balancing model fit and behavioural plausibility. These findings\nhighlight the potential of this novel adaptive, learning-based framework to\nassist in the model specification process.\n","authors":["Gabriel Nova","Stephane Hess","Sander van Cranenburgh"],"pdf_url":"https://arxiv.org/pdf/2506.06410v2.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.19247v1","updated":"2025-07-25T13:14:03Z","published":"2025-07-25T13:14:03Z","title":"A Markov Categorical Framework for Language Modeling","summary":"  Auto-regressive language models factorize sequence probabilities and are\ntrained by minimizing the negative log-likelihood (NLL) objective. While\nempirically powerful, a deep theoretical understanding of why this simple\nobjective yields such versatile representations remains elusive. This work\nintroduces a unifying analytical framework using Markov Categories (MCs) to\ndeconstruct the AR generation process and the NLL objective. We model the\nsingle-step generation map as a composition of Markov kernels in the category\nStoch. This compositional view, when enriched with statistical divergences,\nallows us to dissect information flow and learned geometry. Our framework makes\nthree main contributions. First, we provide a formal, information-theoretic\nrationale for the success of modern speculative decoding methods like EAGLE,\nquantifying the information surplus in hidden states that these methods\nexploit. Second, we formalize how NLL minimization forces the model to learn\nnot just the next token, but the data's intrinsic conditional stochasticity, a\nprocess we analyze using categorical entropy. Third, and most centrally, we\nprove that NLL training acts as an implicit form of spectral contrastive\nlearning. By analyzing the information geometry of the model's prediction head,\nwe show that NLL implicitly forces the learned representation space to align\nwith the eigenspectrum of a predictive similarity operator, thereby learning a\ngeometrically structured space without explicit contrastive pairs. This\ncompositional and information-geometric perspective reveals the deep structural\nprinciples underlying the effectiveness of modern LMs. Project Page:\nhttps://github.com/asiresearch/lm-theory\n","authors":["Yifan Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.19247v1.pdf","comment":"Project Page: https://github.com/asiresearch/lm-theory"}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2507.10643v2","updated":"2025-07-25T17:02:54Z","published":"2025-07-14T16:38:30Z","title":"TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc\n  Attributions for Opaque Models","summary":"  Existing post-hoc model-agnostic methods generate external explanations for\nopaque models, primarily by locally attributing the model output to its input\nfeatures. However, they often lack an explicit and systematic framework for\nquantifying the contribution of individual features. Building on the Taylor\nexpansion framework introduced by Deng et al. (2024) to unify existing local\nattribution methods, we propose a rigorous set of postulates -- \"precision\",\n\"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific\nattribution. Guided by these postulates, we introduce TaylorPODA (Taylor\nexpansion-derived imPortance-Order aDapted Attribution), which incorporates an\nadditional \"adaptation\" property. This property enables alignment with\ntask-specific goals, especially in post-hoc settings lacking ground-truth\nexplanations. Empirical evaluations demonstrate that TaylorPODA achieves\ncompetitive results against baseline methods, providing principled and\nvisualization-friendly explanations. This work represents a step toward the\ntrustworthy deployment of opaque models by offering explanations with stronger\ntheoretical grounding.\n","authors":["Yuchi Tang","Iñaki Esnaola","George Panoutsos"],"pdf_url":"https://arxiv.org/pdf/2507.10643v2.pdf","comment":"17 pages, 6 figures. To be submitted to AAAI 2026. Re-upload with\n  amended author list"},{"id":"http://arxiv.org/abs/2502.08606v2","updated":"2025-07-25T16:55:43Z","published":"2025-02-12T17:52:47Z","title":"Distillation Scaling Laws","summary":"  We propose a distillation scaling law that estimates distilled model\nperformance based on a compute budget and its allocation between the student\nand teacher. Our findings mitigate the risks associated with large-scale\ndistillation by enabling compute-optimal allocation for both the teacher and\nstudent to maximize student performance. We provide compute-optimal\ndistillation recipes for two key scenarios: when a teacher already exists, and\nwhen a teacher needs training. In settings involving many students or an\nexisting teacher, distillation outperforms supervised learning up to a compute\nlevel that scales predictably with student size. Conversely, if only one\nstudent is to be distilled and a teacher also requires training, supervised\nlearning is generally preferable. Additionally, our large-scale study of\ndistillation increases our understanding of the process and helps inform\nexperimental design.\n","authors":["Dan Busbridge","Amitis Shidani","Floris Weers","Jason Ramapuram","Etai Littwin","Russ Webb"],"pdf_url":"https://arxiv.org/pdf/2502.08606v2.pdf","comment":"Version accepted to ICML 2025. 69 pages, 54 figures, 13 tables"},{"id":"http://arxiv.org/abs/2507.19423v1","updated":"2025-07-25T16:43:42Z","published":"2025-07-25T16:43:42Z","title":"Perfect Clustering in Very Sparse Diverse Multiplex Networks","summary":"  The paper studies the DIverse MultiPLEx Signed Generalized Random Dot Product\nGraph (DIMPLE-SGRDPG) network model (Pensky (2024)), where all layers of the\nnetwork have the same collection of nodes. In addition, all layers can be\npartitioned into groups such that the layers in the same group are embedded in\nthe same ambient subspace but otherwise matrices of connection probabilities\ncan be all different. This setting includes majority of multilayer network\nmodels as its particular cases. The key task in this model is to recover the\ngroups of layers with unique subspace structures, since the case where all\nlayers of the network are embedded in the same subspace has been fairly well\nstudied. Until now, clustering of layers in such networks was based on the\nlayer-per-layer analysis, which required the multilayer network to be\nsufficiently dense. Nevertheless, in this paper we succeeded in pooling\ninformation in all layers together and providing a tensor-based methodology\nthat ensures perfect clustering for a much sparser network. Our theoretical\nresults, established under intuitive non-restrictive assumptions, assert that\nthe new technique achieves perfect clustering under sparsity conditions that,\nup to logarithmic factors, coincide with the computational lower bound derived\nfor a much simpler model.\n","authors":["Marianna Pensky"],"pdf_url":"https://arxiv.org/pdf/2507.19423v1.pdf","comment":"5 figures"},{"id":"http://arxiv.org/abs/2506.16629v4","updated":"2025-07-25T16:03:47Z","published":"2025-06-19T21:56:30Z","title":"Learning Causally Predictable Outcomes from Psychiatric Longitudinal\n  Data","summary":"  Causal inference in longitudinal biomedical data remains a central challenge,\nespecially in psychiatry, where symptom heterogeneity and latent confounding\nfrequently undermine classical estimators. Most existing methods for treatment\neffect estimation presuppose a fixed outcome variable and address confounding\nthrough observed covariate adjustment. However, the assumption of\nunconfoundedness may not hold for a fixed outcome in practice. To address this\nfoundational limitation, we directly optimize the outcome definition to\nmaximize causal identifiability. Our DEBIAS (Durable Effects with\nBackdoor-Invariant Aggregated Symptoms) algorithm learns non-negative,\nclinically interpretable weights for outcome aggregation, maximizing durable\ntreatment effects and empirically minimizing both observed and latent\nconfounding by leveraging the time-limited direct effects of prior treatments\nin psychiatric longitudinal data. The algorithm also furnishes an empirically\nverifiable test for outcome unconfoundedness. DEBIAS consistently outperforms\nstate-of-the-art methods in recovering causal effects for clinically\ninterpretable composite outcomes across comprehensive experiments in depression\nand schizophrenia.\n","authors":["Eric V. Strobl"],"pdf_url":"https://arxiv.org/pdf/2506.16629v4.pdf","comment":"R code is available at github.com/ericstrobl/DEBIAS"},{"id":"http://arxiv.org/abs/2506.20933v2","updated":"2025-07-25T14:48:30Z","published":"2025-06-26T01:44:23Z","title":"Lower Bounds on the Size of Markov Equivalence Classes","summary":"  Causal discovery algorithms typically recover causal graphs only up to their\nMarkov equivalence classes unless additional parametric assumptions are made.\nThe sizes of these equivalence classes reflect the limits of what can be\nlearned about the underlying causal graph from purely observational data. Under\nthe assumptions of acyclicity, causal sufficiency, and a uniform model prior,\nMarkov equivalence classes are known to be small on average. In this paper, we\nshow that this is no longer the case when any of these assumptions is relaxed.\nSpecifically, we prove exponentially large lower bounds for the expected size\nof Markov equivalence classes in three settings: sparse random directed acyclic\ngraphs, uniformly random acyclic directed mixed graphs, and uniformly random\ndirected cyclic graphs.\n","authors":["Erik Jahn","Frederick Eberhardt","Leonard J. Schulman"],"pdf_url":"https://arxiv.org/pdf/2506.20933v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2303.11844v2","updated":"2025-07-25T11:16:33Z","published":"2023-03-21T13:42:43Z","title":"Doubly Regularized Entropic Wasserstein Barycenters","summary":"  We study a general formulation of regularized Wasserstein barycenters that\nenjoys favorable regularity, approximation, stability and (grid-free)\noptimization properties. This barycenter is defined as the unique probability\nmeasure that minimizes the sum of entropic optimal transport (EOT) costs with\nrespect to a family of given probability measures, plus an entropy term. We\ndenote it $(\\lambda,\\tau)$-barycenter, where $\\lambda$ is the inner\nregularization strength and $\\tau$ the outer one. This formulation recovers\nseveral previously proposed EOT barycenters for various choices of\n$\\lambda,\\tau \\geq 0$ and generalizes them. First, in spite of -- and in fact\nowing to -- being \\emph{doubly} regularized, we show that our formulation is\ndebiased for $\\tau=\\lambda/2$: the suboptimality in the (unregularized)\nWasserstein barycenter objective is, for smooth densities, of the order of the\nstrength $\\lambda^2$ of entropic regularization, instead of\n$\\max\\{\\lambda,\\tau\\}$ in general. We discuss this phenomenon for isotropic\nGaussians where all $(\\lambda,\\tau)$-barycenters have closed form. Second, we\nshow that for $\\lambda,\\tau>0$, this barycenter has a smooth density and is\nstrongly stable under perturbation of the marginals. In particular, it can be\nestimated efficiently: given $n$ samples from each of the probability measures,\nit converges in relative entropy to the population barycenter at a rate\n$n^{-1/2}$. And finally, this formulation lends itself naturally to a grid-free\noptimization algorithm: we propose a simple \\emph{noisy particle gradient\ndescent} which, in the mean-field limit, converges globally at an exponential\nrate to the barycenter.\n","authors":["Lénaïc Chizat"],"pdf_url":"https://arxiv.org/pdf/2303.11844v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19028v1","updated":"2025-07-25T07:30:24Z","published":"2025-07-25T07:30:24Z","title":"Nonparametric Linear Discriminant Analysis for High Dimensional\n  Matrix-Valued Data","summary":"  This paper addresses classification problems with matrix-valued data, which\ncommonly arises in applications such as neuroimaging and signal processing.\nBuilding on the assumption that the data from each class follows a matrix\nnormal distribution, we propose a novel extension of Fisher's Linear\nDiscriminant Analysis (LDA) tailored for matrix-valued observations. To\neffectively capture structural information while maintaining estimation\nflexibility, we adopt a nonparametric empirical Bayes framework based on\nNonparametric Maximum Likelihood Estimation (NPMLE), applied to vectorized and\nscaled matrices. The NPMLE method has been shown to provide robust, flexible,\nand accurate estimates for vector-valued data with various structures in the\nmean vector or covariance matrix. By leveraging its strengths, our method is\neffectively generalized to the matrix setting, thereby improving classification\nperformance. Through extensive simulation studies and real data applications,\nincluding electroencephalography (EEG) and magnetic resonance imaging (MRI)\nanalysis, we demonstrate that the proposed method consistently outperforms\nexisting approaches across a variety of data structures.\n","authors":["Seungyeon Oh","Seongoh Park","Hoyoung Park"],"pdf_url":"https://arxiv.org/pdf/2507.19028v1.pdf","comment":"23 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2311.10207v2","updated":"2025-07-25T07:29:36Z","published":"2023-11-16T21:43:05Z","title":"Stella Nera: A Differentiable Maddness-Based Hardware Accelerator for\n  Efficient Approximate Matrix Multiplication","summary":"  Artificial intelligence has surged in recent years, with advancements in\nmachine learning rapidly impacting nearly every area of life. However, the\ngrowing complexity of these models has far outpaced advancements in available\nhardware accelerators, leading to significant computational and energy demands,\nprimarily due to matrix multiplications, which dominate the compute workload.\nMaddness (i.e., Multiply-ADDitioN-lESS) presents a hash-based version of\nproduct quantization, which renders matrix multiplications into lookups and\nadditions, eliminating the need for multipliers entirely. We present Stella\nNera, the first Maddness-based accelerator achieving an energy efficiency of\n161 TOp/s/W@0.55V, 25x better than conventional MatMul accelerators due to its\nsmall components and reduced computational complexity. We further enhance\nMaddness with a differentiable approximation, allowing for gradient-based\nfine-tuning and achieving an end-to-end performance of 92.5% Top-1 accuracy on\nCIFAR-10.\n","authors":["Jannis Schönleber","Lukas Cavigelli","Matteo Perotti","Luca Benini","Renzo Andri"],"pdf_url":"https://arxiv.org/pdf/2311.10207v2.pdf","comment":"Accepted as full paper at IEEE Computer Society Annual Symposium on\n  VLSI (ISVLSI) 2025"},{"id":"http://arxiv.org/abs/2507.17792v2","updated":"2025-07-25T07:07:32Z","published":"2025-07-23T10:35:37Z","title":"Causal Mechanism Estimation in Multi-Sensor Systems Across Multiple\n  Domains","summary":"  To gain deeper insights into a complex sensor system through the lens of\ncausality, we present common and individual causal mechanism estimation\n(CICME), a novel three-step approach to inferring causal mechanisms from\nheterogeneous data collected across multiple domains. By leveraging the\nprinciple of Causal Transfer Learning (CTL), CICME is able to reliably detect\ndomain-invariant causal mechanisms when provided with sufficient samples. The\nidentified common causal mechanisms are further used to guide the estimation of\nthe remaining causal mechanisms in each domain individually. The performance of\nCICME is evaluated on linear Gaussian models under scenarios inspired from a\nmanufacturing process. Building upon existing continuous optimization-based\ncausal discovery methods, we show that CICME leverages the benefits of applying\ncausal discovery on the pooled data and repeatedly on data from individual\ndomains, and it even outperforms both baseline methods under certain scenarios.\n","authors":["Jingyi Yu","Tim Pychynski","Marco F. Huber"],"pdf_url":"https://arxiv.org/pdf/2507.17792v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18555v2","updated":"2025-07-25T04:19:13Z","published":"2025-07-24T16:26:52Z","title":"Neural Tangent Kernels and Fisher Information Matrices for Simple ReLU\n  Networks with Random Hidden Weights","summary":"  Fisher information matrices and neural tangent kernels (NTK) for 2-layer ReLU\nnetworks with random hidden weight are argued. We discuss the relation between\nboth notions as a linear transformation and show that spectral decomposition of\nNTK with concrete forms of eigenfunctions with major eigenvalues. We also\nobtain an approximation formula of the functions presented by the 2-layer\nneural networks.\n","authors":["Jun'ichi Takeuchi","Yoshinari Takeishi","Noboru Murata","Kazushi Mimura","Ka Long Keith Ho","Hiroshi Nagaoka"],"pdf_url":"https://arxiv.org/pdf/2507.18555v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.09567v3","updated":"2025-07-25T03:07:14Z","published":"2025-04-13T13:38:25Z","title":"From Conditional to Unconditional Independence: Testing Conditional\n  Independence via Transport Maps","summary":"  Testing conditional independence between two random vectors given a third is\na fundamental and challenging problem in statistics, particularly in\nmultivariate nonparametric settings due to the complexity of conditional\nstructures. We propose a novel method for testing conditional independence by\ntransforming it to an unconditional independence test problem. We achieve this\nby constructing two transport maps that transform conditional independence into\nunconditional independence, this substantially simplifies the problem. These\ntransport maps are estimated from data using conditional continuous normalizing\nflow models. Within this framework, we derive a test statistic and prove its\nasymptotic validity under both the null and alternative hypotheses. A\npermutation-based procedure is employed to evaluate the significance of the\ntest. We validate the proposed method through extensive simulations and\nreal-data analysis. Our numerical studies demonstrate the practical\neffectiveness of the proposed method for conditional independence\n","authors":["Chenxuan He","Yuan Gao","Liping Zhu","Jian Huang"],"pdf_url":"https://arxiv.org/pdf/2504.09567v3.pdf","comment":"41 pages"},{"id":"http://arxiv.org/abs/2507.18903v1","updated":"2025-07-25T02:51:15Z","published":"2025-07-25T02:51:15Z","title":"Probably Approximately Correct Causal Discovery","summary":"  The discovery of causal relationships is a foundational problem in artificial\nintelligence, statistics, epidemiology, economics, and beyond. While elegant\ntheories exist for accurate causal discovery given infinite data, real-world\napplications are inherently resource-constrained. Effective methods for\ninferring causal relationships from observational data must perform well under\nfinite data and time constraints, where \"performing well\" implies achieving\nhigh, though not perfect accuracy. In his seminal paper A Theory of the\nLearnable, Valiant highlighted the importance of resource constraints in\nsupervised machine learning, introducing the concept of Probably Approximately\nCorrect (PAC) learning as an alternative to exact learning. Inspired by\nValiant's work, we propose the Probably Approximately Correct Causal (PACC)\nDiscovery framework, which extends PAC learning principles to the causal field.\nThis framework emphasizes both computational and sample efficiency for\nestablished causal methods such as propensity score techniques and instrumental\nvariable approaches. Furthermore, we show that it can also provide theoretical\nguarantees for other widely used methods, such as the Self-Controlled Case\nSeries (SCCS) method, which had previously lacked such guarantees.\n","authors":["Mian Wei","Somesh Jha","David Page"],"pdf_url":"https://arxiv.org/pdf/2507.18903v1.pdf","comment":null}],"Computation":[{"id":"http://arxiv.org/abs/2507.19338v1","updated":"2025-07-25T14:48:34Z","published":"2025-07-25T14:48:34Z","title":"Branch-and-bound method for calculating Viterbi path in triplet Markov\n  models","summary":"  We consider a bivariate, possibly non-homogeneous, finite-state Markov chain\n$(X,U)=\\{(X_t,U_t)\\}_{t=1}^n$. We are interested in the marginal process $X$,\nwhich typically is not a Markov chain. The goal is to find a realization (path)\n$x=(x_1,\\ldots,x_n)$ with maximal probability $P(X=x)$. If $X$ is Markov chain,\nthen such path can be efficiently found using the celebrated Viterbi algorithm.\nHowever, when $X$ is not Markovian, identifying the most probable path --\nhereafter referred to as the Viterbi path -- becomes computationally expensive.\nIn this paper, we explore the branch-and-bound method for finding Viterbi\npaths. The method is based on the lower and upper bounds on maximum probability\n$\\max_x P(X=x)$, and the objective of the paper is to exploit the joint Markov\nproperty of $(X,Y)$ to calculate possibly good bounds in possibly cheap way.\n  This research is motivated by decoding or segmentation problem in triplet\nMarkov models. A triplet Markov model is trivariate homogeneous Markov process\n$(X,U,Y)$. In decoding, a realization of one marginal process $Y$ is observed\n(representing the data), while $X$ and $U$ are latent processes. The process\n$U$ serves as a nuisance variable, whereas $X$ is the process of primary\ninterest. Decoding refers to estimating the hidden sequence $X$ based solely on\nthe observation $Y$. Conditional on $Y$, the latent processes $(X, U)$ form a\nnon-homogeneous Markov chain. In this context, the Viterbi path corresponds to\nthe maximum a posteriori (MAP) estimate of $X$, making it a natural choice for\nsignal reconstruction.\n","authors":["Oskar Soop","Jüri Lember"],"pdf_url":"https://arxiv.org/pdf/2507.19338v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.10870v2","updated":"2025-07-25T14:45:58Z","published":"2025-07-15T00:21:23Z","title":"Start from the End: A Framework for Computational Policy Exploration to\n  Inform Effective and Geospatially Consistent Interventions applied to\n  COVID-19 in St. Louis","summary":"  Mathematical models are a powerful tool to study infectious disease dynamics\nand intervention strategies against them in social systems. However, due to\ntheir detailed implementation and steep computational requirements,\npractitioners and stakeholders are typically only able to explore a small\nsubset of all possible intervention scenarios, a severe limitation when\npreparing for disease outbreaks. In this work, we propose a parameter\nexploration framework utilizing emulator models to make uncertainty-aware\npredictions of high-dimensional parameter spaces and identify large numbers of\nfeasible response strategies. We apply our framework to a case study of a\nlarge-scale agent-based disease model of the COVID-19 ``Omicron wave'' in St.\nLouis, Missouri that took place from December 2021 to February 2022. We\nidentify large numbers of response strategies that would have been estimated to\nhave reduced disease spread by a substantial amount. We also identify policy\ninterventions that would have been able to reduce the geospatial variation in\ndisease spread, which has additional implications for designing thoughtful\nresponse strategies.\n","authors":["David O'Gara","Matt Kasman","Matthew D. Haslam","Ross A. Hammond"],"pdf_url":"https://arxiv.org/pdf/2507.10870v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18990v1","updated":"2025-07-25T06:35:28Z","published":"2025-07-25T06:35:28Z","title":"Hysteretic Multivariate Bayesian Structural GARCH Model with Soft\n  Information","summary":"  This study introduces the SH-MBS-GARCH model, a hysteretic multivariate\nBayesian structural GARCH framework that integrates hard and soft information\nto capture the joint dynamics of multiple financial time series, incorporating\nhysteretic effects and addressing conditional heteroscedasticity through GARCH\ncomponents. Various model specifications could utilize soft information to\ndefine the regime indicator in distinct ways. We propose a flexible,\nstraightforward method for embedding soft information into the regime\ncomponent, applicable across all SH-MBS-GARCH model variants. We further\npropose a generally applicable Bayesian estimation approach that combines\nadaptive MCMC, spike-and-slab regression, and a simulation smoother, ensuring\naccurate parameter estimation, validated through extensive simulations.\nEmpirical analysis of the Dow Jones Industrial Average, NASDAQ Composite, and\nPHLX Semiconductor indices from January 2016 to December 2020 demonstrates that\nthe SH-MBS-GARCH model outperforms competing models in fitting and prediction\naccuracy, effectively capturing regime-switching dynamics.\n","authors":["Tzu-Hsin Chien","Ning Ning","Shih-Feng Huang"],"pdf_url":"https://arxiv.org/pdf/2507.18990v1.pdf","comment":"40 pages and 8 figures"},{"id":"http://arxiv.org/abs/2507.18951v1","updated":"2025-07-25T04:38:23Z","published":"2025-07-25T04:38:23Z","title":"Bayesian Inverse Problems on Metric Graphs","summary":"  This paper studies the formulation, well-posedness, and numerical solution of\nBayesian inverse problems on metric graphs, in which the edges represent\none-dimensional wires connecting vertices. We focus on the inverse problem of\nrecovering the diffusion coefficient of a (fractional) elliptic equation on a\nmetric graph from noisy measurements of the solution. Well-posedness hinges on\nboth stability of the forward model and an appropriate choice of prior. We\nestablish the stability of elliptic and fractional elliptic forward models\nusing recent regularity theory for differential equations on metric graphs. For\nthe prior, we leverage modern Gaussian Whittle--Mat\\'ern process models on\nmetric graphs with sufficiently smooth sample paths. Numerical results\ndemonstrate accurate reconstruction and effective uncertainty quantification.\n","authors":["David Bolin","Wenwen Li","Daniel Sanz-Alonso"],"pdf_url":"https://arxiv.org/pdf/2507.18951v1.pdf","comment":"27 pages, 4 figures, to be submitted"}]},"2025-07-28T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2507.21028v1","updated":"2025-07-28T17:48:40Z","published":"2025-07-28T17:48:40Z","title":"Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with\n  Multi-Dimensional Human Evaluation","summary":"  Nearly all human work is collaborative; thus, the evaluation of real-world\nNLP applications often requires multiple dimensions that align with diverse\nhuman perspectives. As real human evaluator resources are often scarce and\ncostly, the emerging \"LLM-as-a-judge\" paradigm sheds light on a promising\napproach to leverage LLM agents to believably simulate human evaluators. Yet,\nto date, existing LLM-as-a-judge approaches face two limitations: persona\ndescriptions of agents are often arbitrarily designed, and the frameworks are\nnot generalizable to other tasks. To address these challenges, we propose\nMAJ-EVAL, a Multi-Agent-as-Judge evaluation framework that can automatically\nconstruct multiple evaluator personas with distinct dimensions from relevant\ntext documents (e.g., research papers), instantiate LLM agents with the\npersonas, and engage in-group debates with multi-agents to Generate\nmulti-dimensional feedback. Our evaluation experiments in both the educational\nand medical domains demonstrate that MAJ-EVAL can generate evaluation results\nthat better align with human experts' ratings compared with conventional\nautomated evaluation metrics and existing LLM-as-a-judge methods.\n","authors":["Jiaju Chen","Yuxuan Lu","Xiaojie Wang","Huimin Zeng","Jing Huang","Jiri Gesi","Ying Xu","Bingsheng Yao","Dakuo Wang"],"pdf_url":"https://arxiv.org/pdf/2507.21028v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.12854v3","updated":"2025-07-28T17:46:50Z","published":"2025-03-17T06:28:25Z","title":"Enhancing LLM Reasoning with Iterative DPO: A Comprehensive Empirical\n  Investigation","summary":"  Recent advancements in post-training methodologies for large language models\n(LLMs) have highlighted reinforcement learning (RL) as a critical component for\nenhancing reasoning. However, the substantial computational costs associated\nwith RL-based approaches have led to growing interest in alternative paradigms,\nsuch as Direct Preference Optimization (DPO). In this study, we investigate the\neffectiveness of DPO in facilitating self-improvement for LLMs through\niterative preference-based learning. We demonstrate that a single round of DPO\nwith coarse filtering significantly enhances mathematical reasoning\nperformance, particularly for strong base model. Furthermore, we design an\niterative enhancement framework for both the generator and the reward model\n(RM), enabling their mutual improvement through online interaction across\nmultiple rounds of DPO. Finally, with simple verifiable rewards, our model\nDPO-VP achieves RL-level performance with significantly lower computational\noverhead. These findings highlight DPO as a scalable and cost-effective\nalternative to RL, offering a practical solution for enhancing LLM reasoning in\nresource-constrained situations.\n","authors":["Songjun Tu","Jiahao Lin","Xiangyu Tian","Qichao Zhang","Linjing Li","Yuqian Fu","Nan Xu","Wei He","Xiangyuan Lan","Dongmei Jiang","Dongbin Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.12854v3.pdf","comment":"23pages"},{"id":"http://arxiv.org/abs/2507.02087v2","updated":"2025-07-28T17:26:01Z","published":"2025-07-02T19:02:18Z","title":"Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions","summary":"  The use of large language models (LLMs) in hiring promises to streamline\ncandidate screening, but it also raises serious concerns regarding accuracy and\nalgorithmic bias where sufficient safeguards are not in place. In this work, we\nbenchmark several state-of-the-art foundational LLMs - including models from\nOpenAI, Anthropic, Google, Meta, and Deepseek, and compare them with our\nproprietary domain-specific hiring model (Match Score) for job candidate\nmatching. We evaluate each model's predictive accuracy (ROC AUC,\nPrecision-Recall AUC, F1-score) and fairness (impact ratio of cut-off analysis\nacross declared gender, race, and intersectional subgroups). Our experiments on\na dataset of roughly 10,000 real-world recent candidate-job pairs show that\nMatch Score outperforms the general-purpose LLMs on accuracy (ROC AUC 0.85 vs\n0.77) and achieves significantly more equitable outcomes across demographic\ngroups. Notably, Match Score attains a minimum race-wise impact ratio of 0.957\n(near-parity), versus 0.809 or lower for the best LLMs, (0.906 vs 0.773 for the\nintersectionals, respectively). We discuss why pretraining biases may cause\nLLMs with insufficient safeguards to propagate societal biases in hiring\nscenarios, whereas a bespoke supervised model can more effectively mitigate\nthese biases. Our findings highlight the importance of domain-specific modeling\nand bias auditing when deploying AI in high-stakes domains such as hiring, and\ncaution against relying on off-the-shelf LLMs for such tasks without extensive\nfairness safeguards. Furthermore, we show with empirical evidence that there\nshouldn't be a dichotomy between choosing accuracy and fairness in hiring: a\nwell-designed algorithm can achieve both accuracy in hiring and fairness in\noutcomes.\n","authors":["Eitan Anzenberg","Arunava Samajpati","Sivasankaran Chandrasekar","Varun Kacholia"],"pdf_url":"https://arxiv.org/pdf/2507.02087v2.pdf","comment":"10 pages, 2 figures, 2 tables. Submitted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2507.21009v1","updated":"2025-07-28T17:22:10Z","published":"2025-07-28T17:22:10Z","title":"Memorization in Fine-Tuned Large Language Models","summary":"  This study investigates the mechanisms and factors influencing memorization\nin fine-tuned large language models (LLMs), with a focus on the medical domain\ndue to its privacy-sensitive nature. We examine how different aspects of the\nfine-tuning process affect a model's propensity to memorize training data,\nusing the PHEE dataset of pharmacovigilance events.\n  Our research employs two main approaches: a membership inference attack to\ndetect memorized data, and a generation task with prompted prefixes to assess\nverbatim reproduction. We analyze the impact of adapting different weight\nmatrices in the transformer architecture, the relationship between perplexity\nand memorization, and the effect of increasing the rank in low-rank adaptation\n(LoRA) fine-tuning.\n  Key findings include: (1) Value and Output matrices contribute more\nsignificantly to memorization compared to Query and Key matrices; (2) Lower\nperplexity in the fine-tuned model correlates with increased memorization; (3)\nHigher LoRA ranks lead to increased memorization, but with diminishing returns\nat higher ranks.\n  These results provide insights into the trade-offs between model performance\nand privacy risks in fine-tuned LLMs. Our findings have implications for\ndeveloping more effective and responsible strategies for adapting large\nlanguage models while managing data privacy concerns.\n","authors":["Danil Savine","Muni Sreenivas Pydi","Jamal Atif","Olivier Cappé"],"pdf_url":"https://arxiv.org/pdf/2507.21009v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20999v1","updated":"2025-07-28T17:11:26Z","published":"2025-07-28T17:11:26Z","title":"LoRA-PAR: A Flexible Dual-System LoRA Partitioning Approach to Efficient\n  LLM Fine-Tuning","summary":"  Large-scale generative models like DeepSeek-R1 and OpenAI-O1 benefit\nsubstantially from chain-of-thought (CoT) reasoning, yet pushing their\nperformance typically requires vast data, large model sizes, and full-parameter\nfine-tuning. While parameter-efficient fine-tuning (PEFT) helps reduce cost,\nmost existing approaches primarily address domain adaptation or layer-wise\nallocation rather than explicitly tailoring data and parameters to different\nresponse demands. Inspired by \"Thinking, Fast and Slow,\" which characterizes\ntwo distinct modes of thought-System 1 (fast, intuitive, often automatic) and\nSystem 2 (slower, more deliberative and analytic)-we draw an analogy that\ndifferent \"subregions\" of an LLM's parameters might similarly specialize for\ntasks that demand quick, intuitive responses versus those requiring multi-step\nlogical reasoning. Therefore, we propose LoRA-PAR, a dual-system LoRA framework\nthat partitions both data and parameters by System 1 or System 2 demands, using\nfewer yet more focused parameters for each task. Specifically, we classify task\ndata via multi-model role-playing and voting, and partition parameters based on\nimportance scoring, then adopt a two-stage fine-tuning strategy of training\nSystem 1 tasks with supervised fine-tuning (SFT) to enhance knowledge and\nintuition and refine System 2 tasks with reinforcement learning (RL) to\nreinforce deeper logical deliberation next. Extensive experiments show that the\ntwo-stage fine-tuning strategy, SFT and RL, lowers active parameter usage while\nmatching or surpassing SOTA PEFT baselines.\n","authors":["Yining Huang","Bin Li","Keke Tang","Meilian Chen"],"pdf_url":"https://arxiv.org/pdf/2507.20999v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2507.15846v3","updated":"2025-07-28T16:54:13Z","published":"2025-07-21T17:53:42Z","title":"GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding","summary":"  Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.\n","authors":["Fei Tang","Zhangxuan Gu","Zhengxi Lu","Xuyang Liu","Shuheng Shen","Changhua Meng","Wen Wang","Wenqi Zhang","Yongliang Shen","Weiming Lu","Jun Xiao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2507.15846v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00022v3","updated":"2025-07-28T16:50:18Z","published":"2025-05-21T17:06:28Z","title":"Scaling Physical Reasoning with the PHYSICS Dataset","summary":"  Large Language Models (LLMs) have achieved remarkable progress on advanced\nreasoning tasks such as mathematics and coding competitions. Meanwhile,\nphysics, despite being both reasoning-intensive and essential to real-world\nunderstanding, received limited academic and industrial attention. This paper\nintroduces PHYSICS, a dataset containing 16,568 high-quality physics problems\nspanning subjects and difficulty levels, to facilitate this issue.\nSpecifically, PHYSICS is curated with exercises from over 100 textbooks through\na carefully designed pipeline for quality control. It covers five major physics\ndomains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern\nPhysics. It also spans a wide range of difficulty levels, from high school to\ngraduate-level physics courses. To utilize the data for improving and\nevaluating the model's physical reasoning capabilities, we split the dataset\ninto training and test sets, and provide reasoning paths generated by powerful\nreasoning models for the training data to facilitate model training. In\naddition, for the evaluation part, we find that existing evaluation frameworks\nexhibit biases in aspects such as units, simplification, and precision in\nphysics domain. To balance efficiency and accuracy, we introduce a Rule+Model\nevaluation framework tailored to physics problems. Our evaluations on current\nstate-of-the-art open-source and proprietary models highlight the limitations\nof current models in handling physics-related tasks. We hope that our dataset\nand evaluation methodology will jointly advance the development of LLMs in the\nfield of physics.\n","authors":["Shenghe Zheng","Qianjia Cheng","Junchi Yao","Mengsong Wu","Haonan He","Ning Ding","Yu Cheng","Shuyue Hu","Lei Bai","Dongzhan Zhou","Ganqu Cui","Peng Ye"],"pdf_url":"https://arxiv.org/pdf/2506.00022v3.pdf","comment":"Work on physical datasets"},{"id":"http://arxiv.org/abs/2505.17137v2","updated":"2025-07-28T16:30:46Z","published":"2025-05-22T05:40:12Z","title":"Cog-TiPRO: Iterative Prompt Refinement with LLMs to Detect Cognitive\n  Decline via Longitudinal Voice Assistant Commands","summary":"  Early detection of cognitive decline is crucial for enabling interventions\nthat can slow neurodegenerative disease progression. Traditional diagnostic\napproaches rely on labor-intensive clinical assessments, which are impractical\nfor frequent monitoring. Our pilot study investigates voice assistant systems\n(VAS) as non-invasive tools for detecting cognitive decline through\nlongitudinal analysis of speech patterns in voice commands. Over an 18-month\nperiod, we collected voice commands from 35 older adults, with 15 participants\nproviding daily at-home VAS interactions. To address the challenges of\nanalyzing these short, unstructured and noisy commands, we propose Cog-TiPRO, a\nframework that combines (1) LLM-driven iterative prompt refinement for\nlinguistic feature extraction, (2) HuBERT-based acoustic feature extraction,\nand (3) transformer-based temporal modeling. Using iTransformer, our approach\nachieves 73.80% accuracy and 72.67% F1-score in detecting MCI, outperforming\nits baseline by 27.13%. Through our LLM approach, we identify linguistic\nfeatures that uniquely characterize everyday command usage patterns in\nindividuals experiencing cognitive decline.\n","authors":["Kristin Qi","Youxiang Zhu","Caroline Summerour","John A. Batsis","Xiaohui Liang"],"pdf_url":"https://arxiv.org/pdf/2505.17137v2.pdf","comment":"IEEE Global Communications Conference (GlobeCom) 2025"},{"id":"http://arxiv.org/abs/2507.11936v4","updated":"2025-07-28T16:29:33Z","published":"2025-07-16T06:03:08Z","title":"A Survey of Deep Learning for Geometry Problem Solving","summary":"  Geometry problem solving is a key area of mathematical reasoning, which is\nwidely involved in many important fields such as education, mathematical\nability assessment of artificial intelligence, and multimodal ability\nassessment. In recent years, the rapid development of deep learning technology,\nespecially the rise of multimodal large language models, has triggered a\nwidespread research boom. This paper provides a survey of the applications of\ndeep learning in geometry problem solving, including (i) a comprehensive\nsummary of the relevant tasks in geometry problem solving; (ii) a thorough\nreview of related deep learning methods; (iii) a detailed analysis of\nevaluation metrics and methods; and (iv) a critical discussion of the current\nchallenges and future directions that can be explored. Our goal is to provide a\ncomprehensive and practical reference of deep learning for geometry problem\nsolving to promote further developments in this field. We create a continuously\nupdated list of papers on GitHub: https://github.com/majianz/dl4gps.\n","authors":["Jianzhe Ma","Wenxuan Wang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2507.11936v4.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2505.17067v3","updated":"2025-07-28T16:28:49Z","published":"2025-05-19T03:03:08Z","title":"Unveil Multi-Picture Descriptions for Multilingual Mild Cognitive\n  Impairment Detection via Contrastive Learning","summary":"  Detecting Mild Cognitive Impairment from picture descriptions is critical yet\nchallenging, especially in multilingual and multiple picture settings. Prior\nwork has primarily focused on English speakers describing a single picture\n(e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this scope by\nintroducing multilingual speakers and multiple pictures, which presents new\nchallenges in analyzing picture-dependent content. To address these challenges,\nwe propose a framework with three components: (1) enhancing discriminative\nrepresentation learning via supervised contrastive learning, (2) involving\nimage modality rather than relying solely on speech and text modalities, and\n(3) applying a Product of Experts (PoE) strategy to mitigate spurious\ncorrelations and overfitting. Our framework improves MCI detection performance,\nachieving a +7.1% increase in Unweighted Average Recall (UAR) (from 68.1% to\n75.2%) and a +2.9% increase in F1 score (from 80.6% to 83.5%) compared to the\ntext unimodal baseline. Notably, the contrastive learning component yields\ngreater gains for the text modality compared to speech. These results highlight\nour framework's effectiveness in multilingual and multi-picture MCI detection.\n","authors":["Kristin Qi","Jiali Cheng","Youxiang Zhu","Hadi Amiri","Xiaohui Liang"],"pdf_url":"https://arxiv.org/pdf/2505.17067v3.pdf","comment":"IEEE Global Communications Conference (GlobeCom) 2025"},{"id":"http://arxiv.org/abs/2507.20957v1","updated":"2025-07-28T16:09:38Z","published":"2025-07-28T16:09:38Z","title":"Your AI, Not Your View: The Bias of LLMs in Investment Analysis","summary":"  In finance, Large Language Models (LLMs) face frequent knowledge conflicts\ndue to discrepancies between pre-trained parametric knowledge and real-time\nmarket data. These conflicts become particularly problematic when LLMs are\ndeployed in real-world investment services, where misalignment between a\nmodel's embedded preferences and those of the financial institution can lead to\nunreliable recommendations. Yet little research has examined what investment\nviews LLMs actually hold. We propose an experimental framework to investigate\nsuch conflicts, offering the first quantitative analysis of confirmation bias\nin LLM-based investment analysis. Using hypothetical scenarios with balanced\nand imbalanced arguments, we extract models' latent preferences and measure\ntheir persistence. Focusing on sector, size, and momentum, our analysis reveals\ndistinct, model-specific tendencies. In particular, we observe a consistent\npreference for large-cap stocks and contrarian strategies across most models.\nThese preferences often harden into confirmation bias, with models clinging to\ninitial judgments despite counter-evidence.\n","authors":["Hoyoung Lee","Junhyuk Seo","Suhwan Park","Junhyeong Lee","Wonbin Ahn","Chanyeol Choi","Alejandro Lopez-Lira","Yongjae Lee"],"pdf_url":"https://arxiv.org/pdf/2507.20957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20956v1","updated":"2025-07-28T16:04:25Z","published":"2025-07-28T16:04:25Z","title":"Mind the Gap: Conformative Decoding to Improve Output Diversity of\n  Instruction-Tuned Large Language Models","summary":"  Instruction-tuning large language models (LLMs) reduces the diversity of\ntheir outputs, which has implications for many tasks, particularly for creative\ntasks. This paper investigates the ``diversity gap'' for a writing prompt\nnarrative generation task. This gap emerges as measured by current diversity\nmetrics for various open-weight and open-source LLMs. The results show\nsignificant decreases in diversity due to instruction-tuning. We explore the\ndiversity loss at each fine-tuning stage for the OLMo and OLMo 2 models to\nfurther understand how output diversity is affected. The results indicate that\nDPO has the most substantial impact on diversity. Motivated by these findings,\nwe present a new decoding strategy, conformative decoding, which guides an\ninstruct model using its more diverse base model to reintroduce output\ndiversity. We show that conformative decoding typically increases diversity and\neven maintains or improves quality.\n","authors":["Max Peeperkorn","Tom Kouwenhoven","Dan Brown","Anna Jordanous"],"pdf_url":"https://arxiv.org/pdf/2507.20956v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2507.20936v1","updated":"2025-07-28T15:45:31Z","published":"2025-07-28T15:45:31Z","title":"Dissecting Persona-Driven Reasoning in Language Models via Activation\n  Patching","summary":"  Large language models (LLMs) exhibit remarkable versatility in adopting\ndiverse personas. In this study, we examine how assigning a persona influences\na model's reasoning on an objective task. Using activation patching, we take a\nfirst step toward understanding how key components of the model encode\npersona-specific information. Our findings reveal that the early Multi-Layer\nPerceptron (MLP) layers attend not only to the syntactic structure of the input\nbut also process its semantic content. These layers transform persona tokens\ninto richer representations, which are then used by the middle Multi-Head\nAttention (MHA) layers to shape the model's output. Additionally, we identify\nspecific attention heads that disproportionately attend to racial and\ncolor-based identities.\n","authors":["Ansh Poonia","Maeghal Jain"],"pdf_url":"https://arxiv.org/pdf/2507.20936v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2507.20930v1","updated":"2025-07-28T15:41:53Z","published":"2025-07-28T15:41:53Z","title":"FRED: Financial Retrieval-Enhanced Detection and Editing of\n  Hallucinations in Language Models","summary":"  Hallucinations in large language models pose a critical challenge for\napplications requiring factual reliability, particularly in high-stakes domains\nsuch as finance. This work presents an effective approach for detecting and\nediting factually incorrect content in model-generated responses based on the\nprovided context. Given a user-defined domain-specific error taxonomy, we\nconstruct a synthetic dataset by inserting tagged errors into financial\nquestion-answering corpora and then fine-tune four language models, Phi-4,\nPhi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual\ninaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%\nimprovement in binary F1 score and a 30% gain in overall detection performance\ncompared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having\nonly 4 billion parameters, maintains competitive performance with just a 2%\ndrop in binary detection and a 0.1% decline in overall detection compared to\nOpenAI-o3. Our work provides a practical solution for detecting and editing\nfactual inconsistencies in financial text generation while introducing a\ngeneralizable framework that can enhance the trustworthiness and alignment of\nlarge language models across diverse applications beyond finance. Our code and\ndata are available at https://github.com/pegasi-ai/fine-grained-editting.\n","authors":["Likun Tan","Kuan-Wei Huang","Kevin Wu"],"pdf_url":"https://arxiv.org/pdf/2507.20930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14917v3","updated":"2025-07-28T15:37:20Z","published":"2024-06-21T07:20:51Z","title":"LLM2TEA: An Agentic AI Designer for Discovery with Generative\n  Evolutionary Multitasking","summary":"  This paper presents LLM2TEA, a Large Language Model (LLM) driven MultiTask\nEvolutionary Algorithm, representing the first agentic AI designer of its kind\noperating with generative evolutionary multitasking (GEM). LLM2TEA enables the\ncrossbreeding of solutions from multiple domains, fostering novel solutions\nthat transcend disciplinary boundaries. Of particular interest is the ability\nto discover designs that are both novel and conforming to real-world physical\nspecifications. LLM2TEA comprises an LLM to generate genotype samples from text\nprompts describing target objects, a text-to-3D generative model to produce\ncorresponding phenotypes, a classifier to interpret its semantic\nrepresentations, and a computational simulator to assess its physical\nproperties. Novel LLM-based multitask evolutionary operators are introduced to\nguide the search towards high-performing, practically viable designs.\nExperimental results in conceptual design optimization validate the\neffectiveness of LLM2TEA, showing 97% to 174% improvements in the diversity of\nnovel designs over the current text-to-3D baseline. Moreover, over 73% of the\ngenerated designs outperform the top 1% of designs produced by the text-to-3D\nbaseline in terms of physical performance. The designs produced by LLM2TEA are\nnot only aesthetically creative but also functional in real-world contexts.\nSeveral of these designs have been successfully 3D printed, demonstrating the\nability of our approach to transform AI-generated outputs into tangible,\nphysical designs. These designs underscore the potential of LLM2TEA as a\npowerful tool for complex design optimization and discovery, capable of\nproducing novel and physically viable designs.\n","authors":["Melvin Wong","Jiao Liu","Thiago Rios","Stefan Menzel","Yew Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2406.14917v3.pdf","comment":"This work is accepted by IEEE CIM. IEEE copyrights applies"},{"id":"http://arxiv.org/abs/2507.20924v1","updated":"2025-07-28T15:30:17Z","published":"2025-07-28T15:30:17Z","title":"FHSTP@EXIST 2025 Benchmark: Sexism Detection with Transparent Speech\n  Concept Bottleneck Models","summary":"  Sexism has become widespread on social media and in online conversation. To\nhelp address this issue, the fifth Sexism Identification in Social Networks\n(EXIST) challenge is initiated at CLEF 2025. Among this year's international\nbenchmarks, we concentrate on solving the first task aiming to identify and\nclassify sexism in social media textual posts. In this paper, we describe our\nsolutions and report results for three subtasks: Subtask 1.1 - Sexism\nIdentification in Tweets, Subtask 1.2 - Source Intention in Tweets, and Subtask\n1.3 - Sexism Categorization in Tweets. We implement three models to address\neach subtask which constitute three individual runs: Speech Concept Bottleneck\nModel (SCBM), Speech Concept Bottleneck Model with Transformer (SCBMT), and a\nfine-tuned XLM-RoBERTa transformer model. SCBM uses descriptive adjectives as\nhuman-interpretable bottleneck concepts. SCBM leverages large language models\n(LLMs) to encode input texts into a human-interpretable representation of\nadjectives, then used to train a lightweight classifier for downstream tasks.\nSCBMT extends SCBM by fusing adjective-based representation with contextual\nembeddings from transformers to balance interpretability and classification\nperformance. Beyond competitive results, these two models offer fine-grained\nexplanations at both instance (local) and class (global) levels. We also\ninvestigate how additional metadata, e.g., annotators' demographic profiles,\ncan be leveraged. For Subtask 1.1, XLM-RoBERTa, fine-tuned on provided data\naugmented with prior datasets, ranks 6th for English and Spanish and 4th for\nEnglish in the Soft-Soft evaluation. Our SCBMT achieves 7th for English and\nSpanish and 6th for Spanish.\n","authors":["Roberto Labadie-Tamayo","Adrian Jaques Böck","Djordje Slijepčević","Xihui Chen","Andreas Babic","Matthias Zeppelzauer"],"pdf_url":"https://arxiv.org/pdf/2507.20924v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2507.20917v1","updated":"2025-07-28T15:17:48Z","published":"2025-07-28T15:17:48Z","title":"MediQAl: A French Medical Question Answering Dataset for Knowledge and\n  Reasoning Evaluation","summary":"  This work introduces MediQAl, a French medical question answering dataset\ndesigned to evaluate the capabilities of language models in factual medical\nrecall and reasoning over real-world clinical scenarios. MediQAl contains\n32,603 questions sourced from French medical examinations across 41 medical\nsubjects. The dataset includes three tasks: (i) Multiple-Choice Question with\nUnique answer, (ii) Multiple-Choice Question with Multiple answer, and (iii)\nOpen-Ended Question with Short-Answer. Each question is labeled as\nUnderstanding or Reasoning, enabling a detailed analysis of models' cognitive\ncapabilities. We validate the MediQAl dataset through extensive evaluation with\n14 large language models, including recent reasoning-augmented models, and\nobserve a significant performance gap between factual recall and reasoning\ntasks. Our evaluation provides a comprehensive benchmark for assessing language\nmodels' performance on French medical question answering, addressing a crucial\ngap in multilingual resources for the medical domain.\n","authors":["Adrien Bazoge"],"pdf_url":"https://arxiv.org/pdf/2507.20917v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05167v2","updated":"2025-07-28T15:07:08Z","published":"2024-12-06T16:34:15Z","title":"Benchmarking Open-ended Audio Dialogue Understanding for Large\n  Audio-Language Models","summary":"  Large Audio-Language Models (LALMs), such as GPT-4o, have recently unlocked\naudio dialogue capabilities, enabling direct spoken exchanges with humans. The\npotential of LALMs broadens their applicability across a wide range of\npractical scenarios supported by audio dialogues. However, given these\nadvancements, a comprehensive benchmark to evaluate the performance of LALMs in\nthe open-ended audio dialogue understanding remains absent currently. To\naddress this gap, we propose an Audio Dialogue Understanding Benchmark\n(ADU-Bench), which consists of 4 benchmark datasets. They assess the open-ended\naudio dialogue ability for LALMs in 3 general scenarios, 12 skills, 9\nmultilingual languages, and 4 categories of ambiguity handling. Notably, we\nfirstly propose the evaluation of ambiguity handling in audio dialogues that\nexpresses different intentions beyond the same literal meaning of sentences,\ne.g., \"Really!?\" with different intonations. In summary, ADU-Bench includes\nover 20,000 open-ended audio dialogues for the assessment of LALMs. Through\nextensive experiments on 16 LALMs, our analysis reveals that existing LALMs\nstruggle with mathematical symbols and formulas, understanding human behavior\nsuch as roleplay, comprehending multiple languages, and handling audio dialogue\nambiguities from different phonetic elements, such as intonations, pause\npositions, and homophones. The benchmark is available at\nhttps://adu-bench.github.io/.\n","authors":["Kuofeng Gao","Shu-Tao Xia","Ke Xu","Philip Torr","Jindong Gu"],"pdf_url":"https://arxiv.org/pdf/2412.05167v2.pdf","comment":"Accepted by ACL 2025"},{"id":"http://arxiv.org/abs/2507.20906v1","updated":"2025-07-28T14:59:17Z","published":"2025-07-28T14:59:17Z","title":"Soft Injection of Task Embeddings Outperforms Prompt-Based In-Context\n  Learning","summary":"  In-Context Learning (ICL) enables Large Language Models (LLMs) to perform\ntasks by conditioning on input-output examples in the prompt, without requiring\nany update in model parameters. While widely adopted, it remains unclear\nwhether prompting with multiple examples is the most effective and efficient\nway to convey task information. In this work, we propose Soft Injection of task\nembeddings. The task embeddings are constructed only once using few-shot ICL\nprompts and repeatedly used during inference. Soft injection is performed by\nsoftly mixing task embeddings with attention head activations using\npre-optimized mixing parameters, referred to as soft head-selection parameters.\nThis method not only allows a desired task to be performed without in-prompt\ndemonstrations but also significantly outperforms existing ICL approaches while\nreducing memory usage and compute cost at inference time. An extensive\nevaluation is performed across 57 tasks and 12 LLMs, spanning four model\nfamilies of sizes from 4B to 70B. Averaged across 57 tasks, our method\noutperforms 10-shot ICL by 10.1%-13.9% across 12 LLMs. Additional analyses show\nthat our method also serves as an insightful tool for analyzing task-relevant\nroles of attention heads, revealing that task-relevant head positions selected\nby our method transfer across similar tasks but not across dissimilar ones --\nunderscoring the task-specific nature of head functionality. Our soft injection\nmethod opens a new paradigm for reducing prompt length and improving task\nperformance by shifting task conditioning from the prompt space to the\nactivation space.\n","authors":["Jungwon Park","Wonjong Rhee"],"pdf_url":"https://arxiv.org/pdf/2507.20906v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2507.19204v2","updated":"2025-07-28T14:43:23Z","published":"2025-07-25T12:19:16Z","title":"Should Top-Down Clustering Affect Boundaries in Unsupervised Word\n  Discovery?","summary":"  We investigate the problem of segmenting unlabeled speech into word-like\nunits and clustering these to create a lexicon. Prior work can be categorized\ninto two frameworks. Bottom-up methods first determine boundaries and then\ncluster the fixed segmented words into a lexicon. In contrast, top-down methods\nincorporate information from the clustered words to inform boundary selection.\nHowever, it is unclear whether top-down information is necessary to improve\nsegmentation. To explore this, we look at two similar approaches that differ in\nwhether top-down clustering informs boundary selection. Our simple bottom-up\nstrategy predicts word boundaries using the dissimilarity between adjacent\nself-supervised features, then clusters the resulting segments to construct a\nlexicon. Our top-down system is an updated version of the ES-KMeans dynamic\nprogramming method that iteratively uses K-means to update its boundaries. On\nthe five-language ZeroSpeech benchmarks, both approaches achieve comparable\nstate-of-the-art results, with the bottom-up system being nearly five times\nfaster. Through detailed analyses, we show that the top-down influence of\nES-KMeans can be beneficial (depending on factors like the candidate\nboundaries), but in many cases the simple bottom-up method performs just as\nwell. For both methods, we show that the clustering step is a limiting factor.\nTherefore, we recommend that future work focus on improved clustering\ntechniques and learning more discriminative word-like representations. Project\ncode repository: https://github.com/s-malan/prom-seg-clus.\n","authors":["Simon Malan","Benjamin van Niekerk","Herman Kamper"],"pdf_url":"https://arxiv.org/pdf/2507.19204v2.pdf","comment":"Submitted to the IEEE/ACM Transactions on Audio, Speech and Language\n  Processing"},{"id":"http://arxiv.org/abs/2507.20890v1","updated":"2025-07-28T14:41:57Z","published":"2025-07-28T14:41:57Z","title":"$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with\n  Attention-Guided Refinement","summary":"  Img2LaTeX is a practically significant task that involves converting\nmathematical expressions or tabular data from images into LaTeX code. In recent\nyears, vision-language models (VLMs) have demonstrated strong performance\nacross a variety of visual understanding tasks, owing to their generalization\ncapabilities. While some studies have explored the use of VLMs for the\nImg2LaTeX task, their performance often falls short of expectations.\nEmpirically, VLMs sometimes struggle with fine-grained visual elements, leading\nto inaccurate LaTeX predictions. To address this challenge, we propose\n$A^2R^2$: Advancing Img2LaTeX Conversion via Visual Reasoning with\nAttention-Guided Refinement, a framework that effectively integrates attention\nlocalization and iterative refinement within a visual reasoning framework,\nenabling VLMs to perform self-correction and progressively improve prediction\nquality. For effective evaluation, we introduce a new dataset,\nImg2LaTex-Hard-1K, consisting of 1,100 carefully curated and challenging\nexamples designed to rigorously evaluate the capabilities of VLMs within this\ntask domain. Extensive experimental results demonstrate that: (1) $A^2R^2$\nsignificantly improves model performance across six evaluation metrics spanning\nboth textual and visual levels, consistently outperforming other baseline\nmethods; (2) Increasing the number of inference rounds yields notable\nperformance gains, underscoring the potential of $A^2R^2$ in test-time scaling\nscenarios; (3) Ablation studies and human evaluations validate the practical\neffectiveness of our approach, as well as the strong synergy among its core\ncomponents during inference.\n","authors":["Zhecheng Li","Guoxian Song","Yiwei Wang","Zhen Xiong","Junsong Yuan","Yujun Cai"],"pdf_url":"https://arxiv.org/pdf/2507.20890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20888v1","updated":"2025-07-28T14:39:46Z","published":"2025-07-28T14:39:46Z","title":"Enhancing Project-Specific Code Completion by Inferring Internal API\n  Information","summary":"  Project-specific code completion is a critical task that leverages context\nfrom a project to generate accurate code. State-of-the-art methods use\nretrieval-augmented generation (RAG) with large language models (LLMs) and\nproject information for code completion. However, they often struggle to\nincorporate internal API information, which is crucial for accuracy, especially\nwhen APIs are not explicitly imported in the file.\n  To address this, we propose a method to infer internal API information\nwithout relying on imports. Our method extends the representation of APIs by\nconstructing usage examples and semantic descriptions, building a knowledge\nbase for LLMs to generate relevant completions. We also introduce ProjBench, a\nbenchmark that avoids leaked imports and consists of large-scale real-world\nprojects.\n  Experiments on ProjBench and CrossCodeEval show that our approach\nsignificantly outperforms existing methods, improving code exact match by\n22.72% and identifier exact match by 18.31%. Additionally, integrating our\nmethod with existing baselines boosts code match by 47.80% and identifier match\nby 35.55%.\n","authors":["Le Deng","Xiaoxue Ren","Chao Ni","Ming Liang","David Lo","Zhongxin Liu"],"pdf_url":"https://arxiv.org/pdf/2507.20888v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20884v1","updated":"2025-07-28T14:36:46Z","published":"2025-07-28T14:36:46Z","title":"The Importance of Facial Features in Vision-based Sign Language\n  Recognition: Eyes, Mouth or Full Face?","summary":"  Non-manual facial features play a crucial role in sign language\ncommunication, yet their importance in automatic sign language recognition\n(ASLR) remains underexplored. While prior studies have shown that incorporating\nfacial features can improve recognition, related work often relies on\nhand-crafted feature extraction and fails to go beyond the comparison of manual\nfeatures versus the combination of manual and facial features. In this work, we\nsystematically investigate the contribution of distinct facial regionseyes,\nmouth, and full faceusing two different deep learning models (a CNN-based model\nand a transformer-based model) trained on an SLR dataset of isolated signs with\nrandomly selected classes. Through quantitative performance and qualitative\nsaliency map evaluation, we reveal that the mouth is the most important\nnon-manual facial feature, significantly improving accuracy. Our findings\nhighlight the necessity of incorporating facial features in ASLR.\n","authors":["Dinh Nam Pham","Eleftherios Avramidis"],"pdf_url":"https://arxiv.org/pdf/2507.20884v1.pdf","comment":"Accepted at 9th International Workshop on Sign Language Translation\n  and Avatar Technologies @ ACM IVA'25"},{"id":"http://arxiv.org/abs/2507.20859v1","updated":"2025-07-28T14:12:37Z","published":"2025-07-28T14:12:37Z","title":"Leveraging Open-Source Large Language Models for Clinical Information\n  Extraction in Resource-Constrained Settings","summary":"  Medical reports contain rich clinical information but are often unstructured\nand written in domain-specific language, posing challenges for information\nextraction. While proprietary large language models (LLMs) have shown promise\nin clinical natural language processing, their lack of transparency and data\nprivacy concerns limit their utility in healthcare. This study therefore\nevaluates nine open-source generative LLMs on the DRAGON benchmark, which\nincludes 28 clinical information extraction tasks in Dutch. We developed\n\\texttt{llm\\_extractinator}, a publicly available framework for information\nextraction using open-source generative LLMs, and used it to assess model\nperformance in a zero-shot setting. Several 14 billion parameter models,\nPhi-4-14B, Qwen-2.5-14B, and DeepSeek-R1-14B, achieved competitive results,\nwhile the bigger Llama-3.3-70B model achieved slightly higher performance at\ngreater computational cost. Translation to English prior to inference\nconsistently degraded performance, highlighting the need of native-language\nprocessing. These findings demonstrate that open-source LLMs, when used with\nour framework, offer effective, scalable, and privacy-conscious solutions for\nclinical information extraction in low-resource settings.\n","authors":["Luc Builtjes","Joeran Bosma","Mathias Prokop","Bram van Ginneken","Alessa Hering"],"pdf_url":"https://arxiv.org/pdf/2507.20859v1.pdf","comment":"34 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.20858v1","updated":"2025-07-28T14:12:34Z","published":"2025-07-28T14:12:34Z","title":"A survey of diversity quantification in natural language processing: The\n  why, what, where and how","summary":"  The concept of diversity has received increased consideration in Natural\nLanguage Processing (NLP) in recent years. This is due to various motivations\nlike promoting and inclusion, approximating human linguistic behavior, and\nincreasing systems' performance. Diversity has however often been addressed in\nan ad hoc manner in NLP, and with few explicit links to other domains where\nthis notion is better theorized. We survey articles in the ACL Anthology from\nthe past 6 years, with \"diversity\" or \"diverse\" in their title. We find a wide\nrange of settings in which diversity is quantified, often highly specialized\nand using inconsistent terminology. We put forward a unified taxonomy of why,\nwhat on, where, and how diversity is measured in NLP. Diversity measures are\ncast upon a unified framework from ecology and economy (Stirling, 2007) with 3\ndimensions of diversity: variety, balance and disparity. We discuss the trends\nwhich emerge due to this systematized approach. We believe that this study\npaves the way towards a better formalization of diversity in NLP, which should\nbring a better understanding of this notion and a better comparability between\nvarious approaches.\n","authors":["Louis Estève","Marie-Catherine de Marneffe","Nurit Melnik","Agata Savary","Olha Kanishcheva"],"pdf_url":"https://arxiv.org/pdf/2507.20858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.07274v2","updated":"2025-07-28T14:12:27Z","published":"2025-04-09T21:02:12Z","title":"Language Modeling for the Future of Finance: A Survey into Metrics,\n  Tasks, and Data Opportunities","summary":"  Recent advances in language modeling have led to growing interest in applying\nNatural Language Processing (NLP) techniques to financial problems, enabling\nnew approaches to analysis and decision-making. To systematically examine this\ntrend, we review 374 NLP research papers published between 2017 and 2024 across\n38 conferences and workshops, with a focused analysis of 221 papers that\ndirectly address finance-related tasks. We evaluate these papers across 11\nquantitative and qualitative dimensions, and our study identifies the following\nopportunities: (i) expanding the scope of forecasting tasks; (ii) enriching\nevaluation with financial metrics; (iii) leveraging multilingual and\ncrisis-period datasets; and (iv) balancing PLMs with efficient or interpretable\nalternatives. We identify actionable directions for research and practice,\nsupported by dataset and tool recommendations, with implications for both the\nacademia and industry communities.\n","authors":["Nikita Tatarinov","Siddhant Sukhani","Agam Shah","Sudheer Chava"],"pdf_url":"https://arxiv.org/pdf/2504.07274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20849v1","updated":"2025-07-28T14:00:57Z","published":"2025-07-28T14:00:57Z","title":"Latent Inter-User Difference Modeling for LLM Personalization","summary":"  Large language models (LLMs) are increasingly integrated into users' daily\nlives, leading to a growing demand for personalized outputs. Previous work\nfocuses on leveraging a user's own history, overlooking inter-user differences\nthat are crucial for effective personalization. While recent work has attempted\nto model such differences, the reliance on language-based prompts often hampers\nthe effective extraction of meaningful distinctions. To address these issues,\nwe propose Difference-aware Embedding-based Personalization (DEP), a framework\nthat models inter-user differences in the latent space instead of relying on\nlanguage prompts. DEP constructs soft prompts by contrasting a user's embedding\nwith those of peers who engaged with similar content, highlighting relative\nbehavioral signals. A sparse autoencoder then filters and compresses both\nuser-specific and difference-aware embeddings, preserving only task-relevant\nfeatures before injecting them into a frozen LLM. Experiments on personalized\nreview generation show that DEP consistently outperforms baseline methods\nacross multiple metrics. Our code is available at\nhttps://github.com/SnowCharmQ/DEP.\n","authors":["Yilun Qiu","Tianhao Shi","Xiaoyan Zhao","Fengbin Zhu","Yang Zhang","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2507.20849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15748v2","updated":"2025-07-28T13:13:02Z","published":"2024-12-20T10:06:52Z","title":"Critique of Impure Reason: Unveiling the reasoning behaviour of medical\n  Large Language Models","summary":"  Background: Despite the current ubiquity of Large Language Models (LLMs)\nacross the medical domain, there is a surprising lack of studies which address\ntheir reasoning behaviour. We emphasise the importance of understanding\nreasoning behaviour as opposed to high-level prediction accuracies, since it is\nequivalent to explainable AI (XAI) in this context. In particular, achieving\nXAI in medical LLMs used in the clinical domain will have a significant impact\nacross the healthcare sector. Results: Therefore, in this work, we adapt the\nexisting concept of reasoning behaviour and articulate its interpretation\nwithin the specific context of medical LLMs. We survey and categorise current\nstate-of-the-art approaches for modeling and evaluating reasoning reasoning in\nmedical LLMs. Additionally, we propose theoretical frameworks which can empower\nmedical professionals or machine learning engineers to gain insight into the\nlow-level reasoning operations of these previously obscure models. We also\noutline key open challenges facing the development of Large Reasoning Models.\nConclusion: The subsequent increased transparency and trust in medical machine\nlearning models by clinicians as well as patients will accelerate the\nintegration, application as well as further development of medical AI for the\nhealthcare system as a whole.\n","authors":["Shamus Sim","Tyrone Chen"],"pdf_url":"https://arxiv.org/pdf/2412.15748v2.pdf","comment":"25 pages, 7 figures, 3 tables. Conceptualization, both authors.\n  formal analysis, both authors. funding acquisition, both authors.\n  investigation, both authors. resources, both authors. supervision, T.C..\n  validation, both authors. visualization, both authors. writing original\n  draft, both authors. writing review and editing, both authors"},{"id":"http://arxiv.org/abs/2501.06645v3","updated":"2025-07-28T13:00:58Z","published":"2025-01-11T21:41:27Z","title":"FocalPO: Enhancing Preference Optimizing by Focusing on Correct\n  Preference Rankings","summary":"  Efficient preference optimization algorithms such as Direct Preference\nOptimization (DPO) have become a popular approach in aligning large language\nmodels (LLMs) with human preferences. These algorithms implicitly treat the LLM\nas a reward model, and focus on training it to correct misranked preference\npairs. However, recent work~\\citep{chen2024preference} empirically finds that\nDPO training \\textit{rarely improves these misranked preference pairs}, despite\nits gradient emphasizing on these cases. We introduce FocalPO, a DPO variant\nthat instead \\textit{down-weighs} misranked preference pairs and prioritizes\nenhancing the model's understanding of pairs that it can already rank\ncorrectly. Inspired by Focal Loss used in vision tasks, FocalPO achieves this\nby adding a modulating factor to dynamically scale DPO loss. Our experiment\ndemonstrates that FocalPO surpasses DPO and its variants on popular benchmarks\nlike Alpaca Eval 2.0 using Mistral-Base-7B and Llama-3-Instruct-8B, with the\nintroduced hyperparameter fixed. Additionally, we empirically reveals how\nFocalPO affects training on correct and incorrect sample groups, further\nunderscoring its effectiveness.\n","authors":["Tong Liu","Xiao Yu","Wenxuan Zhou","Jindong Gu","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2501.06645v3.pdf","comment":"ACL 2025"},{"id":"http://arxiv.org/abs/2507.20786v1","updated":"2025-07-28T12:56:31Z","published":"2025-07-28T12:56:31Z","title":"Automating Thematic Review of Prevention of Future Deaths Reports:\n  Replicating the ONS Child Suicide Study using Large Language Models","summary":"  Prevention of Future Deaths (PFD) reports, issued by coroners in England and\nWales, flag systemic hazards that may lead to further loss of life. Analysis of\nthese reports has previously been constrained by the manual effort required to\nidentify and code relevant cases. In 2025, the Office for National Statistics\n(ONS) published a national thematic review of child-suicide PFD reports ($\\leq$\n18 years), identifying 37 cases from January 2015 to November 2023 - a process\nbased entirely on manual curation and coding. We evaluated whether a fully\nautomated, open source \"text-to-table\" language-model pipeline (PFD Toolkit)\ncould reproduce the ONS's identification and thematic analysis of child-suicide\nPFD reports, and assessed gains in efficiency and reliability. All 4,249 PFD\nreports published from July 2013 to November 2023 were processed via PFD\nToolkit's large language model pipelines. Automated screening identified cases\nwhere the coroner attributed death to suicide in individuals aged 18 or\nyounger, and eligible reports were coded for recipient category and 23 concern\nsub-themes, replicating the ONS coding frame. PFD Toolkit identified 72\nchild-suicide PFD reports - almost twice the ONS count. Three blinded\nclinicians adjudicated a stratified sample of 144 reports to validate the\nchild-suicide screening. Against the post-consensus clinical annotations, the\nLLM-based workflow showed substantial to almost-perfect agreement (Cohen's\n$\\kappa$ = 0.82, 95% CI: 0.66-0.98, raw agreement = 91%). The end-to-end script\nruntime was 8m 16s, transforming a process that previously took months into one\nthat can be completed in minutes. This demonstrates that automated LLM analysis\ncan reliably and efficiently replicate manual thematic reviews of coronial\ndata, enabling scalable, reproducible, and timely insights for public health\nand safety. The PFD Toolkit is openly available for future research.\n","authors":["Sam Osian","Arpan Dutta","Sahil Bhandari","Iain E. Buchan","Dan W. Joyce"],"pdf_url":"https://arxiv.org/pdf/2507.20786v1.pdf","comment":"8 pages, 1 figure"},{"id":"http://arxiv.org/abs/2507.20783v1","updated":"2025-07-28T12:52:24Z","published":"2025-07-28T12:52:24Z","title":"On The Role of Pretrained Language Models in General-Purpose Text\n  Embeddings: A Survey","summary":"  Text embeddings have attracted growing interest due to their effectiveness\nacross a wide range of natural language processing (NLP) tasks, such as\nretrieval, classification, clustering, bitext mining, and summarization. With\nthe emergence of pretrained language models (PLMs), general-purpose text\nembeddings (GPTE) have gained significant traction for their ability to produce\nrich, transferable representations. The general architecture of GPTE typically\nleverages PLMs to derive dense text representations, which are then optimized\nthrough contrastive learning on large-scale pairwise datasets. In this survey,\nwe provide a comprehensive overview of GPTE in the era of PLMs, focusing on the\nroles PLMs play in driving its development. We first examine the fundamental\narchitecture and describe the basic roles of PLMs in GPTE, i.e., embedding\nextraction, expressivity enhancement, training strategies, learning objectives,\nand data construction. Then, we describe advanced roles enabled by PLMs, such\nas multilingual support, multimodal integration, code understanding, and\nscenario-specific adaptation. Finally, we highlight potential future research\ndirections that move beyond traditional improvement goals, including ranking\nintegration, safety considerations, bias mitigation, structural information\nincorporation, and the cognitive extension of embeddings. This survey aims to\nserve as a valuable reference for both newcomers and established researchers\nseeking to understand the current state and future potential of GPTE.\n","authors":["Meishan Zhang","Xin Zhang","Xinping Zhao","Shouzheng Huang","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.20783v1.pdf","comment":"45 pages, 2 figures, 9 tables"},{"id":"http://arxiv.org/abs/2507.18190v2","updated":"2025-07-28T12:33:37Z","published":"2025-07-24T08:40:08Z","title":"TN-AutoRCA: Benchmark Construction and Agentic Framework for\n  Self-Improving Alarm-Based Root Cause Analysis in Telecommunication Networks","summary":"  Root Cause Analysis (RCA) in telecommunication networks is a critical task,\nyet it presents a formidable challenge for Artificial Intelligence (AI) due to\nits complex, graph-based reasoning requirements and the scarcity of realistic\nbenchmarks.\n","authors":["Keyu Wu","Qianjin Yu","Manlin Mei","Ruiting Liu","Jun Wang","Kailai Zhang","Yelun Bao"],"pdf_url":"https://arxiv.org/pdf/2507.18190v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2407.19299v3","updated":"2025-07-28T12:20:24Z","published":"2024-07-27T16:48:03Z","title":"The Impact of LoRA Adapters on LLMs for Clinical Text Classification\n  Under Computational and Data Constraints","summary":"  Fine-tuning Large Language Models (LLMs) for clinical Natural Language\nProcessing (NLP) poses significant challenges due to domain gap, limited data,\nand stringent hardware constraints. In this study, we evaluate four adapter\ntechniques-Adapter, Lightweight, TinyAttention, and Gated Residual Network\n(GRN) - equivalent to Low-Rank Adaptation (LoRA), for clinical note\nclassification under real-world, resource-constrained conditions. All\nexperiments were conducted on a single NVIDIA Quadro P620 GPU (2 GB VRAM, 512\nCUDA cores, 1.386 TFLOPS FP32), limiting batch sizes to <8 sequences and\nmaximum sequence length to 256 tokens. Our clinical corpus comprises only 580\n000 tokens, several orders of magnitude smaller than standard LLM pre-training\ndatasets. We fine-tuned three biomedical pre-trained LLMs (CamemBERT-bio,\nAliBERT, DrBERT) and two lightweight Transformer models trained from scratch.\nResults show that 1) adapter structures provide no consistent gains when\nfine-tuning biomedical LLMs under these constraints, and 2) simpler\nTransformers, with minimal parameter counts and training times under six hours,\noutperform adapter-augmented LLMs, which required over 1000 GPU-hours. Among\nadapters, GRN achieved the best metrics (accuracy, precision, recall, F1 =\n0.88). These findings demonstrate that, in low-resource clinical settings with\nlimited data and compute, lightweight Transformers trained from scratch offer a\nmore practical and efficient solution than large LLMs, while GRN remains a\nviable adapter choice when minimal adaptation is needed.\n","authors":["Thanh-Dung Le","Ti Ti Nguyen","Vu Nguyen Ha","Symeon Chatzinotas","Philippe Jouvet","Rita Noumeir"],"pdf_url":"https://arxiv.org/pdf/2407.19299v3.pdf","comment":"Accepted for publication in the IEEE Access"},{"id":"http://arxiv.org/abs/2507.20752v1","updated":"2025-07-28T12:01:59Z","published":"2025-07-28T12:01:59Z","title":"Multilingual Self-Taught Faithfulness Evaluators","summary":"  The growing use of large language models (LLMs) has increased the need for\nautomatic evaluation systems, particularly to address the challenge of\ninformation hallucination. Although existing faithfulness evaluation approaches\nhave shown promise, they are predominantly English-focused and often require\nexpensive human-labeled training data for fine-tuning specialized models. As\nLLMs see increased adoption in multilingual contexts, there is a need for\naccurate faithfulness evaluators that can operate across languages without\nextensive labeled data. This paper presents Self-Taught Evaluators for\nMultilingual Faithfulness, a framework that learns exclusively from synthetic\nmultilingual summarization data while leveraging cross-lingual transfer\nlearning. Through experiments comparing language-specific and mixed-language\nfine-tuning approaches, we demonstrate a consistent relationship between an\nLLM's general language capabilities and its performance in language-specific\nevaluation tasks. Our framework shows improvements over existing baselines,\nincluding state-of-the-art English evaluators and machine translation-based\napproaches.\n","authors":["Carlo Alfano","Aymen Al Marjani","Zeno Jonke","Amin Mantrach","Saab Mansour","Marcello Federico"],"pdf_url":"https://arxiv.org/pdf/2507.20752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20749v1","updated":"2025-07-28T11:57:52Z","published":"2025-07-28T11:57:52Z","title":"Investigating Structural Pruning and Recovery Techniques for Compressing\n  Multimodal Large Language Models: An Empirical Study","summary":"  While Multimodal Large Language Models (MLLMs) demonstrate impressive\ncapabilities, their substantial computational and memory requirements pose\nsignificant barriers to practical deployment. Current parameter reduction\ntechniques primarily involve training MLLMs from Small Language Models (SLMs),\nbut these methods offer limited flexibility and remain computationally\nintensive. To address this gap, we propose to directly compress existing MLLMs\nthrough structural pruning combined with efficient recovery training.\nSpecifically, we investigate two structural pruning paradigms--layerwise and\nwidthwise pruning--applied to the language model backbone of MLLMs, alongside\nsupervised finetuning and knowledge distillation. Additionally, we assess the\nfeasibility of conducting recovery training with only a small fraction of the\navailable data. Our results show that widthwise pruning generally maintains\nbetter performance in low-resource scenarios with limited computational\nresources or insufficient finetuning data. As for the recovery training,\nfinetuning only the multimodal projector is sufficient at small compression\nlevels (< 20%). Furthermore, a combination of supervised finetuning and\nhidden-state distillation yields optimal recovery across various pruning\nlevels. Notably, effective recovery can be achieved with as little as 5% of the\noriginal training data, while retaining over 95% of the original performance.\nThrough empirical study on two representative MLLMs, i.e., LLaVA-v1.5-7B and\nBunny-v1.0-3B, this study offers actionable insights for practitioners aiming\nto compress MLLMs effectively without extensive computation resources or\nsufficient data.\n","authors":["Yiran Huang","Lukas Thede","Massimiliano Mancini","Wenjia Xu","Zeynep Akata"],"pdf_url":"https://arxiv.org/pdf/2507.20749v1.pdf","comment":"Accepted at GCPR 2025"},{"id":"http://arxiv.org/abs/2411.10503v2","updated":"2025-07-28T11:18:49Z","published":"2024-11-15T12:59:37Z","title":"Everything is a Video: Unifying Modalities through Next-Frame Prediction","summary":"  Multimodal learning, which involves integrating information from various\nmodalities such as text, images, audio, and video, is pivotal for numerous\ncomplex tasks like visual question answering, cross-modal retrieval, and\ncaption generation. Traditional approaches rely on modality-specific encoders\nand late fusion techniques, which can hinder scalability and flexibility when\nadapting to new tasks or modalities. To address these limitations, we introduce\na novel framework that extends the concept of task reformulation beyond natural\nlanguage processing (NLP) to multimodal learning. We propose to reformulate\ndiverse multimodal tasks into a unified next-frame prediction problem, allowing\na single model to handle different modalities without modality-specific\ncomponents. This method treats all inputs and outputs as sequential frames in a\nvideo, enabling seamless integration of modalities and effective knowledge\ntransfer across tasks. Our approach is evaluated on a range of tasks, including\ntext-to-text, image-to-text, video-to-video, video-to-text, and audio-to-text,\ndemonstrating the model's ability to generalize across modalities with minimal\nadaptation. We show that task reformulation can significantly simplify\nmultimodal model design across various tasks, laying the groundwork for more\ngeneralized multimodal foundation models.\n","authors":["G. Thomas Hudson","Dean Slack","Thomas Winterbottom","Jamie Sterling","Chenghao Xiao","Junjie Shentu","Noura Al Moubayed"],"pdf_url":"https://arxiv.org/pdf/2411.10503v2.pdf","comment":"10 pages, 10 figures"},{"id":"http://arxiv.org/abs/2507.18071v2","updated":"2025-07-28T11:11:33Z","published":"2025-07-24T03:50:32Z","title":"Group Sequence Policy Optimization","summary":"  This paper introduces Group Sequence Policy Optimization (GSPO), our stable,\nefficient, and performant reinforcement learning algorithm for training large\nlanguage models. Unlike previous algorithms that adopt token-level importance\nratios, GSPO defines the importance ratio based on sequence likelihood and\nperforms sequence-level clipping, rewarding, and optimization. We demonstrate\nthat GSPO achieves superior training efficiency and performance compared to the\nGRPO algorithm, notably stabilizes Mixture-of-Experts (MoE) RL training, and\nhas the potential for simplifying the design of RL infrastructure. These merits\nof GSPO have contributed to the remarkable improvements in the latest Qwen3\nmodels.\n","authors":["Chujie Zheng","Shixuan Liu","Mingze Li","Xiong-Hui Chen","Bowen Yu","Chang Gao","Kai Dang","Yuqiong Liu","Rui Men","An Yang","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2507.18071v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20704v1","updated":"2025-07-28T10:57:44Z","published":"2025-07-28T10:57:44Z","title":"Text2VLM: Adapting Text-Only Datasets to Evaluate Alignment Training in\n  Visual Language Models","summary":"  The increasing integration of Visual Language Models (VLMs) into AI systems\nnecessitates robust model alignment, especially when handling multimodal\ncontent that combines text and images. Existing evaluation datasets heavily\nlean towards text-only prompts, leaving visual vulnerabilities under evaluated.\nTo address this gap, we propose \\textbf{Text2VLM}, a novel multi-stage pipeline\nthat adapts text-only datasets into multimodal formats, specifically designed\nto evaluate the resilience of VLMs against typographic prompt injection\nattacks. The Text2VLM pipeline identifies harmful content in the original text\nand converts it into a typographic image, creating a multimodal prompt for\nVLMs. Also, our evaluation of open-source VLMs highlights their increased\nsusceptibility to prompt injection when visual inputs are introduced, revealing\ncritical weaknesses in the current models' alignment. This is in addition to a\nsignificant performance gap compared to closed-source frontier models. We\nvalidate Text2VLM through human evaluations, ensuring the alignment of\nextracted salient concepts; text summarization and output classification align\nwith human expectations. Text2VLM provides a scalable tool for comprehensive\nsafety assessment, contributing to the development of more robust safety\nmechanisms for VLMs. By enhancing the evaluation of multimodal vulnerabilities,\nText2VLM plays a role in advancing the safe deployment of VLMs in diverse,\nreal-world applications.\n","authors":["Gabriel Downer","Sean Craven","Damian Ruck","Jake Thomas"],"pdf_url":"https://arxiv.org/pdf/2507.20704v1.pdf","comment":"9 pages, 9 figures. Jake Thomas served as Editor for this manuscript"},{"id":"http://arxiv.org/abs/2412.17063v4","updated":"2025-07-28T10:54:03Z","published":"2024-12-22T15:20:53Z","title":"Computational Analysis of Character Development in Holocaust Testimonies","summary":"  This work presents a computational approach to analyze character development\nalong the narrative timeline. The analysis characterizes the inner and outer\nchanges the protagonist undergoes within a narrative, and the interplay between\nthem. We consider transcripts of Holocaust survivor testimonies as a test case,\neach telling the story of an individual in first-person terms. We focus on the\nsurvivor's religious trajectory, examining the evolution of their disposition\ntoward religious belief and practice along the testimony. Clustering the\nresulting trajectories in the dataset, we identify common sequences in the\ndata. Our findings highlight multiple common structures of religiosity across\nthe narratives: in terms of belief, most present a constant disposition, while\nfor practice, most present an oscillating structure, serving as valuable\nmaterial for historical and sociological research. This work demonstrates the\npotential of natural language processing techniques for analyzing character\nevolution through thematic trajectories in narratives.\n","authors":["Esther Shizgal","Eitan Wagner","Renana Keydar","Omri Abend"],"pdf_url":"https://arxiv.org/pdf/2412.17063v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20700v1","updated":"2025-07-28T10:49:04Z","published":"2025-07-28T10:49:04Z","title":"When Scale Meets Diversity: Evaluating Language Models on Fine-Grained\n  Multilingual Claim Verification","summary":"  The rapid spread of multilingual misinformation requires robust automated\nfact verification systems capable of handling fine-grained veracity assessments\nacross diverse languages. While large language models have shown remarkable\ncapabilities across many NLP tasks, their effectiveness for multilingual claim\nverification with nuanced classification schemes remains understudied. We\nconduct a comprehensive evaluation of five state-of-the-art language models on\nthe X-Fact dataset, which spans 25 languages with seven distinct veracity\ncategories. Our experiments compare small language models (encoder-based XLM-R\nand mT5) with recent decoder-only LLMs (Llama 3.1, Qwen 2.5, Mistral Nemo)\nusing both prompting and fine-tuning approaches. Surprisingly, we find that\nXLM-R (270M parameters) substantially outperforms all tested LLMs (7-12B\nparameters), achieving 57.7% macro-F1 compared to the best LLM performance of\n16.9%. This represents a 15.8% improvement over the previous state-of-the-art\n(41.9%), establishing new performance benchmarks for multilingual fact\nverification. Our analysis reveals problematic patterns in LLM behavior,\nincluding systematic difficulties in leveraging evidence and pronounced biases\ntoward frequent categories in imbalanced data settings. These findings suggest\nthat for fine-grained multilingual fact verification, smaller specialized\nmodels may be more effective than general-purpose large models, with important\nimplications for practical deployment of fact-checking systems.\n","authors":["Hanna Shcharbakova","Tatiana Anikina","Natalia Skachkova","Josef van Genabith"],"pdf_url":"https://arxiv.org/pdf/2507.20700v1.pdf","comment":"Published at the FEVER Workshop, ACL 2025"},{"id":"http://arxiv.org/abs/2507.20673v1","updated":"2025-07-28T09:54:05Z","published":"2025-07-28T09:54:05Z","title":"Geometric-Mean Policy Optimization","summary":"  Recent advancements, such as Group Relative Policy Optimization (GRPO), have\nenhanced the reasoning capabilities of large language models by optimizing the\narithmetic mean of token-level rewards. However, GRPO suffers from unstable\npolicy updates when processing tokens with outlier importance-weighted rewards,\nwhich manifests as extreme importance sampling ratios during training, i.e.,\nthe ratio between the sampling probabilities assigned to a token by the current\nand old policies. In this work, we propose Geometric-Mean Policy Optimization\n(GMPO), a stabilized variant of GRPO. Instead of optimizing the arithmetic\nmean, GMPO maximizes the geometric mean of token-level rewards, which is\ninherently less sensitive to outliers and maintains a more stable range of\nimportance sampling ratio. In addition, we provide comprehensive theoretical\nand experimental analysis to justify the design and stability benefits of GMPO.\nBeyond improved stability, GMPO-7B outperforms GRPO by an average of 4.1% on\nmultiple mathematical benchmarks and 1.4% on multimodal reasoning benchmark,\nincluding AIME24, AMC, MATH500, OlympiadBench, Minerva, and Geometry3K. Code is\navailable at https://github.com/callsys/GMPO.\n","authors":["Yuzhong Zhao","Yue Liu","Junpeng Liu","Jingye Chen","Xun Wu","Yaru Hao","Tengchao Lv","Shaohan Huang","Lei Cui","Qixiang Ye","Fang Wan","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2507.20673v1.pdf","comment":"Code is available at https://github.com/callsys/GMPO"},{"id":"http://arxiv.org/abs/2505.14699v2","updated":"2025-07-28T09:10:12Z","published":"2025-05-12T10:59:30Z","title":"Benchmarking Graph Neural Networks for Document Layout Analysis in\n  Public Affairs","summary":"  The automatic analysis of document layouts in digital-born PDF documents\nremains a challenging problem due to the heterogeneous arrangement of textual\nand nontextual elements and the imprecision of the textual metadata in the\nPortable Document Format. In this work, we benchmark Graph Neural Network (GNN)\narchitectures for the task of fine-grained layout classification of text blocks\nfrom digital native documents. We introduce two graph construction structures:\na k-closest-neighbor graph and a fully connected graph, and generate node\nfeatures via pre-trained text and vision models, thus avoiding manual feature\nengineering. Three experimental frameworks are evaluated: single-modality (text\nor visual), concatenated multimodal, and dual-branch multimodal. We evaluated\nfour foundational GNN models and compared them with the baseline. Our\nexperiments are specifically conducted on a rich dataset of public affairs\ndocuments that includes more than 20 sources (e.g., regional and national-level\nofficial gazettes), 37K PDF documents, with 441K pages in total. Our results\ndemonstrate that GraphSAGE operating on the k-closest-neighbor graph in a\ndual-branch configuration achieves the highest per-class and overall accuracy,\noutperforming the baseline in some sources. These findings confirm the\nimportance of local layout relationships and multimodal fusion exploited\nthrough GNNs for the analysis of native digital document layouts.\n","authors":["Miguel Lopez-Duran","Julian Fierrez","Aythami Morales","Ruben Tolosana","Oscar Delgado-Mohatar","Alvaro Ortigosa"],"pdf_url":"https://arxiv.org/pdf/2505.14699v2.pdf","comment":"15 pages, 2 figures, accepted paper at The Fifth ICDAR International\n  Workshop on Machine Learning"},{"id":"http://arxiv.org/abs/2507.19396v2","updated":"2025-07-28T09:02:30Z","published":"2025-07-25T16:02:02Z","title":"Detection of Adverse Drug Events in Dutch clinical free text documents\n  using Transformer Models: benchmark study","summary":"  In this study, we establish a benchmark for adverse drug event (ADE)\ndetection in Dutch clinical free-text documents using several transformer\nmodels, clinical scenarios, and fit-for-purpose performance measures. We\ntrained a Bidirectional Long Short-Term Memory (Bi-LSTM) model and four\ntransformer-based Dutch and/or multilingual encoder models (BERTje, RobBERT,\nMedRoBERTa(.)nl, and NuNER) for the tasks of named entity recognition (NER) and\nrelation classification (RC) using 102 richly annotated Dutch ICU clinical\nprogress notes. Anonymized free-text clinical progress notes of patients\nadmitted to the intensive care unit (ICU) of one academic hospital and\ndischarge letters of patients admitted to Internal Medicine wards of two\nnon-academic hospitals were reused. We evaluated our ADE RC models internally\nusing the gold standard (two-step task) and predicted entities (end-to-end\ntask). In addition, all models were externally validated for detecting ADEs at\nthe document level. We report both micro- and macro-averaged F1 scores, given\nthe dataset imbalance in ADEs. Although differences for the ADE RC task between\nthe models were small, MedRoBERTa(.)nl was the best performing model with a\nmacro-averaged F1 score of 0.63 using the gold standard and 0.62 using\npredicted entities. The MedRoBERTa(.)nl models also performed the best in our\nexternal validation and achieved a recall of between 0.67 to 0.74 using\npredicted entities, meaning between 67 to 74% of discharge letters with ADEs\nwere detected. Our benchmark study presents a robust and clinically meaningful\napproach for evaluating language models for ADE detection in clinical free-text\ndocuments. Our study highlights the need to use appropriate performance\nmeasures fit for the task of ADE detection in clinical free-text documents and\nenvisioned future clinical use.\n","authors":["Rachel M. Murphy","Nishant Mishra","Nicolette F. de Keizer","Dave A. Dongelmans","Kitty J. Jager","Ameen Abu-Hanna","Joanna E. Klopotowska","Iacer Calixto"],"pdf_url":"https://arxiv.org/pdf/2507.19396v2.pdf","comment":"30 Pages, 5 Figures (Main Paper), 19 Pages, 2 Figures(Supplements).\n  Rachel M. Murphy and Nishant Mishra are shared first authors. Joanna E.\n  Klopotowska and Iacer Calixto are shared last authors"},{"id":"http://arxiv.org/abs/2507.20643v1","updated":"2025-07-28T09:00:48Z","published":"2025-07-28T09:00:48Z","title":"Ontology-Enhanced Knowledge Graph Completion using Large Language Models","summary":"  Large Language Models (LLMs) have been extensively adopted in Knowledge Graph\nCompletion (KGC), showcasing significant research advancements. However, as\nblack-box models driven by deep neural architectures, current LLM-based KGC\nmethods rely on implicit knowledge representation with parallel propagation of\nerroneous knowledge, thereby hindering their ability to produce conclusive and\ndecisive reasoning outcomes. We aim to integrate neural-perceptual structural\ninformation with ontological knowledge, leveraging the powerful capabilities of\nLLMs to achieve a deeper understanding of the intrinsic logic of the knowledge.\nWe propose an ontology enhanced KGC method using LLMs -- OL-KGC. It first\nleverages neural perceptual mechanisms to effectively embed structural\ninformation into the textual space, and then uses an automated extraction\nalgorithm to retrieve ontological knowledge from the knowledge graphs (KGs)\nthat needs to be completed, which is further transformed into a textual format\ncomprehensible to LLMs for providing logic guidance. We conducted extensive\nexperiments on three widely-used benchmarks -- FB15K-237, UMLS and WN18RR. The\nexperimental results demonstrate that OL-KGC significantly outperforms existing\nmainstream KGC methods across multiple evaluation metrics, achieving\nstate-of-the-art performance.\n","authors":["Wenbin Guo","Xin Wang","Jiaoyan Chen","Zhao Li","Zirui Chen"],"pdf_url":"https://arxiv.org/pdf/2507.20643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.06201v2","updated":"2025-07-28T08:49:27Z","published":"2025-03-08T13:04:20Z","title":"Explainable Synthetic Image Detection through Diffusion Timestep\n  Ensembling","summary":"  Recent advances in diffusion models have enabled the creation of deceptively\nreal images, posing significant security risks when misused. In this study, we\nempirically show that different timesteps of DDIM inversion reveal varying\nsubtle distinctions between synthetic and real images that are extractable for\ndetection, in the forms of such as Fourier power spectrum high-frequency\ndiscrepancies and inter-pixel variance distributions. Based on these\nobservations, we propose a novel synthetic image detection method that directly\nutilizes features of intermediately noised images by training an ensemble on\nmultiple noised timesteps, circumventing conventional reconstruction-based\nstrategies. To enhance human comprehension, we introduce a metric-grounded\nexplanation generation and refinement module to identify and explain\nAI-generated flaws. Additionally, we construct the GenHard and GenExplain\nbenchmarks to provide detection samples of greater difficulty and high-quality\nrationales for fake images. Extensive experiments show that our method achieves\nstate-of-the-art performance with 98.91% and 95.89% detection accuracy on\nregular and challenging samples respectively, and demonstrates generalizability\nand robustness. Our code and datasets are available at\nhttps://github.com/Shadowlized/ESIDE.\n","authors":["Yixin Wu","Feiran Zhang","Tianyuan Shi","Ruicheng Yin","Zhenghua Wang","Zhenliang Gan","Xiaohua Wang","Changze Lv","Xiaoqing Zheng","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2503.06201v2.pdf","comment":"16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2507.20614v1","updated":"2025-07-28T08:27:58Z","published":"2025-07-28T08:27:58Z","title":"Before the Outrage: Challenges and Advances in Predicting Online\n  Antisocial Behavior","summary":"  Antisocial behavior (ASB) on social media-including hate speech, harassment,\nand trolling-poses growing challenges for platform safety and societal\nwellbeing. While prior work has primarily focused on detecting harmful content\nafter it appears, predictive approaches aim to forecast future harmful\nbehaviors-such as hate speech propagation, conversation derailment, or user\nrecidivism-before they fully unfold. Despite increasing interest, the field\nremains fragmented, lacking a unified taxonomy or clear synthesis of existing\nmethods. This paper presents a systematic review of over 49 studies on ASB\nprediction, offering a structured taxonomy of five core task types: early harm\ndetection, harm emergence prediction, harm propagation prediction, behavioral\nrisk prediction, and proactive moderation support. We analyze how these tasks\ndiffer by temporal framing, prediction granularity, and operational goals. In\naddition, we examine trends in modeling techniques-from classical machine\nlearning to pre-trained language models-and assess the influence of dataset\ncharacteristics on task feasibility and generalization. Our review highlights\nmethodological challenges, such as dataset scarcity, temporal drift, and\nlimited benchmarks, while outlining emerging research directions including\nmultilingual modeling, cross-platform generalization, and human-in-the-loop\nsystems. By organizing the field around a coherent framework, this survey aims\nto guide future work toward more robust and socially responsible ASB\nprediction.\n","authors":["Anaïs Ollagnier"],"pdf_url":"https://arxiv.org/pdf/2507.20614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.02820v2","updated":"2025-07-28T07:46:27Z","published":"2025-05-05T17:47:49Z","title":"AutoLibra: Agent Metric Induction from Open-Ended Feedback","summary":"  Agents are predominantly evaluated and optimized via task success metrics,\nwhich are coarse, rely on manual design from experts, and fail to reward\nintermediate emergent behaviors. We propose AutoLibra, a framework for agent\nevaluation, that transforms open-ended human feedback e.g. \"If you find that\nthe button is disabled, don't click it again\", or \"This agent has too much\nautonomy to decide what to do on its own\" into metrics for evaluating\nfine-grained behaviors in agent trajectories. AutoLibra accomplishes this by\ngrounding feedback to an agent's behavior, clustering similar positive and\nnegative behaviors, and creating concrete metrics with clear definitions and\nconcrete examples, which can be used for prompting LLM-as-a-Judge as\nevaluators. We further propose two meta-metrics to evaluate the alignment of a\nset of (induced) metrics with open feedback: \"coverage\" and \"redundancy\".\nThrough optimizing these meta-metrics, we experimentally demonstrate\nAutoLibra's ability to induce more concrete agent evaluation metrics than the\nones proposed in previous agent evaluation benchmarks and discover new metrics\nto analyze agents. We also present two applications of AutoLibra in agent\nimprovement: First, we show that AutoLibra-induced metrics serve as better\nprompt-engineering targets than the task success rate on a wide range of text\ngame tasks, improving agent performance over baseline by a mean of 20%. Second,\nwe show that AutoLibra can iteratively select high-quality fine-tuning data for\nweb navigation agents. Our results suggest that AutoLibra is a powerful\ntask-agnostic tool for evaluating and improving language agents.\n","authors":["Hao Zhu","Phil Cuvin","Xinkai Yu","Charlotte Ka Yee Yan","Jason Zhang","Diyi Yang"],"pdf_url":"https://arxiv.org/pdf/2505.02820v2.pdf","comment":"https://opensocial.world/"},{"id":"http://arxiv.org/abs/2502.03387v2","updated":"2025-07-28T07:21:10Z","published":"2025-02-05T17:23:45Z","title":"LIMO: Less is More for Reasoning","summary":"  We challenge the prevailing assumption that complex reasoning in large\nlanguage models (LLMs) necessitates massive training data. We demonstrate that\nsophisticated mathematical reasoning can emerge with only a few examples.\nSpecifically, through simple supervised fine-tuning, our model, LIMO, achieves\n63.3\\% accuracy on AIME24 and 95.6\\% on MATH500, surpassing previous fine-tuned\nmodels (6.5\\% on AIME24, 59.2\\% on MATH500) while using only 1\\% of the\ntraining data required by prior approaches. Furthermore, LIMO exhibits strong\nout-of-distribution generalization, achieving a 45.8\\% absolute improvement\nacross diverse benchmarks, outperforming models trained on 100x more data.\nSynthesizing these findings, we propose the Less-Is-More Reasoning Hypothesis\n(LIMO Hypothesis): In foundation models where domain knowledge has been\ncomprehensively encoded during pre-training, sophisticated reasoning can emerge\nthrough minimal but strategically designed demonstrations of cognitive\nprocesses. This hypothesis suggests that the threshold for eliciting complex\nreasoning is not dictated by task complexity but rather by two key factors: (1)\nthe completeness of the model's pre-trained knowledge base and (2) the\neffectiveness of post-training examples in serving as \"cognitive templates\"\nthat guide reasoning.\n","authors":["Yixin Ye","Zhen Huang","Yang Xiao","Ethan Chern","Shijie Xia","Pengfei Liu"],"pdf_url":"https://arxiv.org/pdf/2502.03387v2.pdf","comment":"COLM 2025"},{"id":"http://arxiv.org/abs/2507.20564v1","updated":"2025-07-28T06:58:35Z","published":"2025-07-28T06:58:35Z","title":"ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided\n  Captioning","summary":"  We present ZSE-Cap (Zero-Shot Ensemble for Captioning), our 4th place system\nin Event-Enriched Image Analysis (EVENTA) shared task on article-grounded image\nretrieval and captioning. Our zero-shot approach requires no finetuning on the\ncompetition's data. For retrieval, we ensemble similarity scores from CLIP,\nSigLIP, and DINOv2. For captioning, we leverage a carefully engineered prompt\nto guide the Gemma 3 model, enabling it to link high-level events from the\narticle to the visual content in the image. Our system achieved a final score\nof 0.42002, securing a top-4 position on the private test set, demonstrating\nthe effectiveness of combining foundation models through ensembling and\nprompting. Our code is available at https://github.com/ductai05/ZSE-Cap.\n","authors":["Duc-Tai Dinh","Duc Anh Khoa Dinh"],"pdf_url":"https://arxiv.org/pdf/2507.20564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20546v1","updated":"2025-07-28T06:13:23Z","published":"2025-07-28T06:13:23Z","title":"Enhancing Hallucination Detection via Future Context","summary":"  Large Language Models (LLMs) are widely used to generate plausible text on\nonline platforms, without revealing the generation process. As users\nincreasingly encounter such black-box outputs, detecting hallucinations has\nbecome a critical challenge. To address this challenge, we focus on developing\na hallucination detection framework for black-box generators. Motivated by the\nobservation that hallucinations, once introduced, tend to persist, we sample\nfuture contexts. The sampled future contexts provide valuable clues for\nhallucination detection and can be effectively integrated with various\nsampling-based methods. We extensively demonstrate performance improvements\nacross multiple methods using our proposed sampling approach.\n","authors":["Joosung Lee","Cheonbok Park","Hwiyeol Jo","Jeonghoon Kim","Joonsuk Park","Kang Min Yoo"],"pdf_url":"https://arxiv.org/pdf/2507.20546v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2507.20919v1","updated":"2025-07-28T15:19:54Z","published":"2025-07-28T15:19:54Z","title":"Modeling User Behavior from Adaptive Surveys with Supplemental Context","summary":"  Modeling user behavior is critical across many industries where understanding\npreferences, intent, or decisions informs personalization, targeting, and\nstrategic outcomes. Surveys have long served as a classical mechanism for\ncollecting such behavioral data due to their interpretability, structure, and\nease of deployment. However, surveys alone are inherently limited by user\nfatigue, incomplete responses, and practical constraints on their length making\nthem insufficient for capturing user behavior. In this work, we present LANTERN\n(Late-Attentive Network for Enriched Response Modeling), a modular architecture\nfor modeling user behavior by fusing adaptive survey responses with\nsupplemental contextual signals. We demonstrate the architectural value of\nmaintaining survey primacy through selective gating, residual connections and\nlate fusion via cross-attention, treating survey data as the primary signal\nwhile incorporating external modalities only when relevant. LANTERN outperforms\nstrong survey-only baselines in multi-label prediction of survey responses. We\nfurther investigate threshold sensitivity and the benefits of selective\nmodality reliance through ablation and rare/frequent attribute analysis.\nLANTERN's modularity supports scalable integration of new encoders and evolving\ndatasets. This work provides a practical and extensible blueprint for behavior\nmodeling in survey-centric applications.\n","authors":["Aman Shukla","Daniel Patrick Scantlebury","Rishabh Kumar"],"pdf_url":"https://arxiv.org/pdf/2507.20919v1.pdf","comment":"Best Paper, NewInML @ ICML 2025"},{"id":"http://arxiv.org/abs/2507.20762v1","updated":"2025-07-28T12:16:52Z","published":"2025-07-28T12:16:52Z","title":"Watermarking Large Language Model-based Time Series Forecasting","summary":"  Large Language Model-based Time Series Forecasting (LLMTS) has shown\nremarkable promise in handling complex and diverse temporal data, representing\na significant step toward foundation models for time series analysis. However,\nthis emerging paradigm introduces two critical challenges. First, the\nsubstantial commercial potential and resource-intensive development raise\nurgent concerns about intellectual property (IP) protection. Second, their\npowerful time series forecasting capabilities may be misused to produce\nmisleading or fabricated deepfake time series data. To address these concerns,\nwe explore watermarking the outputs of LLMTS models, that is, embedding\nimperceptible signals into the generated time series data that remain\ndetectable by specialized algorithms. We propose a novel post-hoc watermarking\nframework, Waltz, which is broadly compatible with existing LLMTS models. Waltz\nis inspired by the empirical observation that time series patch embeddings are\nrarely aligned with a specific set of LLM tokens, which we term ``cold\ntokens''. Leveraging this insight, Waltz embeds watermarks by rewiring the\nsimilarity statistics between patch embeddings and cold token embeddings, and\ndetects watermarks using similarity z-scores. To minimize potential side\neffects, we introduce a similarity-based embedding position identification\nstrategy and employ projected gradient descent to constrain the watermark noise\nwithin a defined boundary. Extensive experiments using two popular LLMTS models\nacross seven benchmark datasets demonstrate that Waltz achieves high watermark\ndetection accuracy with minimal impact on the quality of the generated time\nseries.\n","authors":["Wei Yuan","Chaoqun Yang","Yu Xing","Tong Chen","Nguyen Quoc Viet Hung","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2507.20762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20753v1","updated":"2025-07-28T12:02:02Z","published":"2025-07-28T12:02:02Z","title":"Industry Insights from Comparing Deep Learning and GBDT Models for\n  E-Commerce Learning-to-Rank","summary":"  In e-commerce recommender and search systems, tree-based models, such as\nLambdaMART, have set a strong baseline for Learning-to-Rank (LTR) tasks.\nDespite their effectiveness and widespread adoption in industry, the debate\ncontinues whether deep neural networks (DNNs) can outperform traditional\ntree-based models in this domain. To contribute to this discussion, we\nsystematically benchmark DNNs against our production-grade LambdaMART model. We\nevaluate multiple DNN architectures and loss functions on a proprietary dataset\nfrom OTTO and validate our findings through an 8-week online A/B test. The\nresults show that a simple DNN architecture outperforms a strong tree-based\nbaseline in terms of total clicks and revenue, while achieving parity in total\nunits sold.\n","authors":["Yunus Lutz","Timo Wilm","Philipp Duwe"],"pdf_url":"https://arxiv.org/pdf/2507.20753v1.pdf","comment":"This work was accepted for publication in the 19th ACM Conference on\n  Recommender Systems (RecSys 2025). The final published version will be\n  available at the ACM Digital Library"},{"id":"http://arxiv.org/abs/2507.20578v1","updated":"2025-07-28T07:22:06Z","published":"2025-07-28T07:22:06Z","title":"Beyond Interactions: Node-Level Graph Generation for Knowledge-Free\n  Augmentation in Recommender Systems","summary":"  Recent advances in recommender systems rely on external resources such as\nknowledge graphs or large language models to enhance recommendations, which\nlimit applicability in real-world settings due to data dependency and\ncomputational overhead. Although knowledge-free models are able to bolster\nrecommendations by direct edge operations as well, the absence of augmentation\nprimitives drives them to fall short in bridging semantic and structural gaps\nas high-quality paradigm substitutes. Unlike existing diffusion-based works\nthat remodel user-item interactions, this work proposes NodeDiffRec, a\npioneering knowledge-free augmentation framework that enables fine-grained\nnode-level graph generation for recommendations and expands the scope of\nrestricted augmentation primitives via diffusion. By synthesizing pseudo-items\nand corresponding interactions that align with the underlying distribution for\ninjection, and further refining user preferences through a denoising preference\nmodeling process, NodeDiffRec dramatically enhances both semantic diversity and\nstructural connectivity without external knowledge. Extensive experiments\nacross diverse datasets and recommendation algorithms demonstrate the\nsuperiority of NodeDiffRec, achieving State-of-the-Art (SOTA) performance, with\nmaximum average performance improvement 98.6% in Recall@5 and 84.0% in NDCG@5\nover selected baselines.\n","authors":["Zhaoyan Wang","Hyunjun Ahn","In-Young Ko"],"pdf_url":"https://arxiv.org/pdf/2507.20578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20564v1","updated":"2025-07-28T06:58:35Z","published":"2025-07-28T06:58:35Z","title":"ZSE-Cap: A Zero-Shot Ensemble for Image Retrieval and Prompt-Guided\n  Captioning","summary":"  We present ZSE-Cap (Zero-Shot Ensemble for Captioning), our 4th place system\nin Event-Enriched Image Analysis (EVENTA) shared task on article-grounded image\nretrieval and captioning. Our zero-shot approach requires no finetuning on the\ncompetition's data. For retrieval, we ensemble similarity scores from CLIP,\nSigLIP, and DINOv2. For captioning, we leverage a carefully engineered prompt\nto guide the Gemma 3 model, enabling it to link high-level events from the\narticle to the visual content in the image. Our system achieved a final score\nof 0.42002, securing a top-4 position on the private test set, demonstrating\nthe effectiveness of combining foundation models through ensembling and\nprompting. Our code is available at https://github.com/ductai05/ZSE-Cap.\n","authors":["Duc-Tai Dinh","Duc Anh Khoa Dinh"],"pdf_url":"https://arxiv.org/pdf/2507.20564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.20308v2","updated":"2025-07-28T05:26:47Z","published":"2025-05-20T18:27:22Z","title":"Large Language Model Powered Decision Support for a Metal Additive\n  Manufacturing Knowledge Graph","summary":"  Metal additive manufacturing (AM) involves complex interdependencies among\nprocesses, materials, feedstock, and post-processing steps. However, the\nunderlying relationships and domain knowledge remain fragmented across\nliterature and static databases that often require expert-level queries,\nlimiting their applicability in design and planning. To address these\nlimitations, we develop a novel and structured knowledge graph (KG),\nrepresenting 53 distinct metals and alloys across seven material categories,\nnine AM processes, four feedstock types, and corresponding post-processing\nrequirements. A large language model (LLM) interface, guided by a few-shot\nprompting strategy, enables natural language querying without the need for\nformal query syntax. The system supports a range of tasks, including\ncompatibility evaluation, constraint-based filtering, and design for AM (DfAM)\nguidance. User queries in natural language are normalized, translated into\nCypher, and executed on the KG, with results returned in a structured format.\nThis work introduces the first interactive system that connects a\ndomain-specific metal AM KG with an LLM interface, delivering accessible and\nexplainable decision support for engineers and promoting human-centered tools\nin manufacturing knowledge systems.\n","authors":["Muhammad Tayyab Khan","Lequn Chen","Wenhe Feng","Seung Ki Moon"],"pdf_url":"https://arxiv.org/pdf/2505.20308v2.pdf","comment":"The paper has been accepted at 11th International Conference of Asian\n  Society for Precision Engineering and Nanotechnology"},{"id":"http://arxiv.org/abs/2312.02031v2","updated":"2025-07-28T02:39:19Z","published":"2023-12-04T16:51:28Z","title":"Virtual Quantum Markov Chains","summary":"  Quantum Markov chains generalize classical Markov chains for random variables\nto the quantum realm and exhibit unique inherent properties, making them an\nimportant feature in quantum information theory. In this work, we propose the\nconcept of virtual quantum Markov chains (VQMCs), focusing on scenarios where\nsubsystems retain classical information about global systems from measurement\nstatistics. As a generalization of quantum Markov chains, VQMCs characterize\nstates where arbitrary global shadow information can be recovered from\nsubsystems through local quantum operations and measurements. We present an\nalgebraic characterization for virtual quantum Markov chains and show that the\nvirtual quantum recovery is fully determined by the block matrices of a quantum\nstate on its subsystems. Notably, we find a distinction between two classes of\ntripartite entanglement by showing that the W state is a VQMC while the GHZ\nstate is not. Furthermore, we introduce the virtual non-Markovianity to\nquantify the non-Markovianity of a given quantum state, which also assesses the\noptimal sampling overhead for virtually recovering this state. Our findings\nelucidate distinctions between quantum Markov chains and virtual quantum Markov\nchains, extending our understanding of quantum recovery to scenarios\nprioritizing classical information from measurement statistics.\n","authors":["Yu-Ao Chen","Chengkai Zhu","Keming He","Mingrui Jing","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2312.02031v2.pdf","comment":"19 pages including appendix, 6 figures, v2: results and references\n  updated"},{"id":"http://arxiv.org/abs/2507.20449v1","updated":"2025-07-28T00:48:33Z","published":"2025-07-28T00:48:33Z","title":"Improving Community Detection in Academic Networks by Handling\n  Publication Bias","summary":"  Finding potential research collaborators is a challenging task, especially in\ntoday's fast-growing and interdisciplinary research landscape. While\ntraditional methods often rely on observable relationships such as\nco-authorships and citations to construct the research network, in this work,\nwe focus solely on publication content to build a topic-based research network\nusing BERTopic with a fine-tuned SciBERT model that connects and recommends\nresearchers across disciplines based on shared topical interests. A major\nchallenge we address is publication imbalance, where some researchers publish\nmuch more than others, often across several topics. Without careful handling,\ntheir less frequent interests are hidden under dominant topics, limiting the\nnetwork's ability to detect their full research scope. To tackle this, we\nintroduce a cloning strategy that clusters a researcher's publications and\ntreats each cluster as a separate node. This allows researchers to be part of\nmultiple communities, improving the detection of interdisciplinary links.\nEvaluation on the proposed method shows that the cloned network structure leads\nto more meaningful communities and uncovers a broader set of collaboration\nopportunities.\n","authors":["Md Asaduzzaman Noor","John Sheppard","Jason Clark"],"pdf_url":"https://arxiv.org/pdf/2507.20449v1.pdf","comment":"This paper is an extended version of a work accepted at ASONAM 2025"},{"id":"http://arxiv.org/abs/2507.21340v1","updated":"2025-07-28T21:20:44Z","published":"2025-07-28T21:20:44Z","title":"StructText: A Synthetic Table-to-Text Approach for Benchmark Generation\n  with Multi-Dimensional Evaluation","summary":"  Extracting structured information from text, such as key-value pairs that\ncould augment tabular data, is quite useful in many enterprise use cases.\nAlthough large language models (LLMs) have enabled numerous automated pipelines\nfor converting natural language into structured formats, there is still a lack\nof benchmarks for evaluating their extraction quality, especially in specific\ndomains or focused documents specific to a given organization. Building such\nbenchmarks by manual annotations is labour-intensive and limits the size and\nscalability of the benchmarks. In this work, we present StructText, an\nend-to-end framework for automatically generating high-fidelity benchmarks for\nkey-value extraction from text using existing tabular data. It uses available\ntabular data as structured ground truth, and follows a two-stage\n``plan-then-execute'' pipeline to synthetically generate corresponding\nnatural-language text. To ensure alignment between text and structured source,\nwe introduce a multi-dimensional evaluation strategy that combines (a)\nLLM-based judgments on factuality, hallucination, and coherence and (b)\nobjective extraction metrics measuring numeric and temporal accuracy. We\nevaluated the proposed method on 71,539 examples across 49 datasets. Results\nreveal that while LLMs achieve strong factual accuracy and avoid hallucination,\nthey struggle with narrative coherence in producing extractable text. Notably,\nmodels presume numerical and temporal information with high fidelity yet this\ninformation becomes embedded in narratives that resist automated extraction. We\nrelease a framework, including datasets, evaluation tools, and baseline\nextraction systems, to support continued research.\n","authors":["Satyananda Kashyap","Sola Shirai","Nandana Mihindukulasooriya","Horst Samulowitz"],"pdf_url":"https://arxiv.org/pdf/2507.21340v1.pdf","comment":"Data available:\n  https://huggingface.co/datasets/ibm-research/struct-text and code available\n  at: https://github.com/ibm/struct-text"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2507.21053v1","updated":"2025-07-28T17:59:57Z","published":"2025-07-28T17:59:57Z","title":"Flow Matching Policy Gradients","summary":"  Flow-based generative models, including diffusion models, excel at modeling\ncontinuous distributions in high-dimensional spaces. In this work, we introduce\nFlow Policy Optimization (FPO), a simple on-policy reinforcement learning\nalgorithm that brings flow matching into the policy gradient framework. FPO\ncasts policy optimization as maximizing an advantage-weighted ratio computed\nfrom the conditional flow matching loss, in a manner compatible with the\npopular PPO-clip framework. It sidesteps the need for exact likelihood\ncomputation while preserving the generative capabilities of flow-based models.\nUnlike prior approaches for diffusion-based reinforcement learning that bind\ntraining to a specific sampling method, FPO is agnostic to the choice of\ndiffusion or flow integration at both training and inference time. We show that\nFPO can train diffusion-style policies from scratch in a variety of continuous\ncontrol tasks. We find that flow-based models can capture multimodal action\ndistributions and achieve higher performance than Gaussian policies,\nparticularly in under-conditioned settings.\n","authors":["David McAllister","Songwei Ge","Brent Yi","Chung Min Kim","Ethan Weber","Hongsuk Choi","Haiwen Feng","Angjoo Kanazawa"],"pdf_url":"https://arxiv.org/pdf/2507.21053v1.pdf","comment":"See our blog post: https://flowreinforce.github.io"},{"id":"http://arxiv.org/abs/2507.21049v1","updated":"2025-07-28T17:59:28Z","published":"2025-07-28T17:59:28Z","title":"Rep-MTL: Unleashing the Power of Representation-level Task Saliency for\n  Multi-Task Learning","summary":"  Despite the promise of Multi-Task Learning in leveraging complementary\nknowledge across tasks, existing multi-task optimization (MTO) techniques\nremain fixated on resolving conflicts via optimizer-centric loss scaling and\ngradient manipulation strategies, yet fail to deliver consistent gains. In this\npaper, we argue that the shared representation space, where task interactions\nnaturally occur, offers rich information and potential for operations\ncomplementary to existing optimizers, especially for facilitating the\ninter-task complementarity, which is rarely explored in MTO. This intuition\nleads to Rep-MTL, which exploits the representation-level task saliency to\nquantify interactions between task-specific optimization and shared\nrepresentation learning. By steering these saliencies through entropy-based\npenalization and sample-wise cross-task alignment, Rep-MTL aims to mitigate\nnegative transfer by maintaining the effective training of individual tasks\ninstead pure conflict-solving, while explicitly promoting complementary\ninformation sharing. Experiments are conducted on four challenging MTL\nbenchmarks covering both task-shift and domain-shift scenarios. The results\nshow that Rep-MTL, even paired with the basic equal weighting policy, achieves\ncompetitive performance gains with favorable efficiency. Beyond standard\nperformance metrics, Power Law exponent analysis demonstrates Rep-MTL's\nefficacy in balancing task-specific learning and cross-task sharing. The\nproject page is available at HERE.\n","authors":["Zedong Wang","Siyuan Li","Dan Xu"],"pdf_url":"https://arxiv.org/pdf/2507.21049v1.pdf","comment":"ICCV 2025 (Highlight). Project page:\n  https://jacky1128.github.io/RepMTL/"},{"id":"http://arxiv.org/abs/2507.21040v1","updated":"2025-07-28T17:56:34Z","published":"2025-07-28T17:56:34Z","title":"Transformers as Unrolled Inference in Probabilistic Laplacian Eigenmaps:\n  An Interpretation and Potential Improvements","summary":"  We propose a probabilistic interpretation of transformers as unrolled\ninference steps assuming a probabilistic Laplacian Eigenmaps model from the\nProbDR framework. Our derivation shows that at initialisation, transformers\nperform \"linear\" dimensionality reduction. We also show that within the\ntransformer block, a graph Laplacian term arises from our arguments, rather\nthan an attention matrix (which we interpret as an adjacency matrix). We\ndemonstrate that simply subtracting the identity from the attention matrix (and\nthereby taking a graph diffusion step) improves validation performance on a\nlanguage model and a simple vision transformer.\n","authors":["Aditya Ravuri","Neil D. Lawrence"],"pdf_url":"https://arxiv.org/pdf/2507.21040v1.pdf","comment":"Initial version"},{"id":"http://arxiv.org/abs/2507.21037v1","updated":"2025-07-28T17:55:26Z","published":"2025-07-28T17:55:26Z","title":"When Brain Foundation Model Meets Cauchy-Schwarz Divergence: A New\n  Framework for Cross-Subject Motor Imagery Decoding","summary":"  Decoding motor imagery (MI) electroencephalogram (EEG) signals, a key\nnon-invasive brain-computer interface (BCI) paradigm for controlling external\nsystems, has been significantly advanced by deep learning. However, MI-EEG\ndecoding remains challenging due to substantial inter-subject variability and\nlimited labeled target data, which necessitate costly calibration for new\nusers. Many existing multi-source domain adaptation (MSDA) methods\nindiscriminately incorporate all available source domains, disregarding the\nlarge inter-subject differences in EEG signals, which leads to negative\ntransfer and excessive computational costs. Moreover, while many approaches\nfocus on feature distribution alignment, they often neglect the explicit\ndependence between features and decision-level outputs, limiting their ability\nto preserve discriminative structures. To address these gaps, we propose a\nnovel MSDA framework that leverages a pretrained large Brain Foundation Model\n(BFM) for dynamic and informed source subject selection, ensuring only relevant\nsources contribute to adaptation. Furthermore, we employ Cauchy-Schwarz (CS)\nand Conditional CS (CCS) divergences to jointly perform feature-level and\ndecision-level alignment, enhancing domain invariance while maintaining class\ndiscriminability. Extensive evaluations on two benchmark MI-EEG datasets\ndemonstrate that our framework outperforms a broad range of state-of-the-art\nbaselines. Additional experiments with a large source pool validate the\nscalability and efficiency of BFM-guided selection, which significantly reduces\ntraining time without sacrificing performance.\n","authors":["Jinzhou Wu","Baoping Tang","Qikang Li","Yi Wang","Cheng Li","Shujian Yu"],"pdf_url":"https://arxiv.org/pdf/2507.21037v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2507.21035v1","updated":"2025-07-28T17:55:08Z","published":"2025-07-28T17:55:08Z","title":"GenoMAS: A Multi-Agent Framework for Scientific Discovery via\n  Code-Driven Gene Expression Analysis","summary":"  Gene expression analysis holds the key to many biomedical discoveries, yet\nextracting insights from raw transcriptomic data remains formidable due to the\ncomplexity of multiple large, semi-structured files and the need for extensive\ndomain expertise. Current automation approaches are often limited by either\ninflexible workflows that break down in edge cases or by fully autonomous\nagents that lack the necessary precision for rigorous scientific inquiry.\nGenoMAS charts a different course by presenting a team of LLM-based scientists\nthat integrates the reliability of structured workflows with the adaptability\nof autonomous agents. GenoMAS orchestrates six specialized LLM agents through\ntyped message-passing protocols, each contributing complementary strengths to a\nshared analytic canvas. At the heart of GenoMAS lies a guided-planning\nframework: programming agents unfold high-level task guidelines into Action\nUnits and, at each juncture, elect to advance, revise, bypass, or backtrack,\nthereby maintaining logical coherence while bending gracefully to the\nidiosyncrasies of genomic data.\n  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation\nof 89.13% for data preprocessing and an F$_1$ of 60.48% for gene\nidentification, surpassing the best prior art by 10.61% and 16.85%\nrespectively. Beyond metrics, GenoMAS surfaces biologically plausible\ngene-phenotype associations corroborated by the literature, all while adjusting\nfor latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.\n","authors":["Haoyang Liu","Yijiang Li","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2507.21035v1.pdf","comment":"51 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.21024v1","updated":"2025-07-28T17:45:10Z","published":"2025-07-28T17:45:10Z","title":"Optimization Performance of Factorization Machine with Annealing under\n  Limited Training Data","summary":"  Black-box (BB) optimization problems aim to identify an input that minimizes\nthe output of a function (the BB function) whose input-output relationship is\nunknown. Factorization machine with annealing (FMA) is a promising approach to\nthis task, employing a factorization machine (FM) as a surrogate model to\niteratively guide the solution search via an Ising machine. Although FMA has\ndemonstrated strong optimization performance across various applications, its\nperformance often stagnates as the number of optimization iterations increases.\nOne contributing factor to this stagnation is the growing number of data points\nin the dataset used to train FM. It is hypothesized that as more data points\nare accumulated, the contribution of newly added data points becomes diluted\nwithin the entire dataset, thereby reducing their impact on improving the\nprediction accuracy of FM. To address this issue, we propose a novel method for\nsequential dataset construction that retains at most a specified number of the\nmost recently added data points. This strategy is designed to enhance the\ninfluence of newly added data points on the surrogate model. Numerical\nexperiments demonstrate that the proposed FMA achieves lower-cost solutions\nwith fewer BB function evaluations compared to the conventional FMA.\n","authors":["Mayumi Nakano","Yuya Seki","Shuta Kikuchi","Shu Tanaka"],"pdf_url":"https://arxiv.org/pdf/2507.21024v1.pdf","comment":"9 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.21023v1","updated":"2025-07-28T17:43:53Z","published":"2025-07-28T17:43:53Z","title":"On Using the Shapley Value for Anomaly Localization: A Statistical\n  Investigation","summary":"  Recent publications have suggested using the Shapley value for anomaly\nlocalization for sensor data systems. Using a reasonable mathematical anomaly\nmodel for full control, experiments indicate that using a single fixed term in\nthe Shapley value calculation achieves a lower complexity anomaly localization\ntest, with the same probability of error, as a test using the Shapley value for\nall cases tested. A proof demonstrates these conclusions must be true for all\nindependent observation cases. For dependent observation cases, no proof is\navailable.\n","authors":["Rick S. Blum","Franziska Freytag"],"pdf_url":"https://arxiv.org/pdf/2507.21023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21021v1","updated":"2025-07-28T17:42:57Z","published":"2025-07-28T17:42:57Z","title":"Behavior-Specific Filtering for Enhanced Pig Behavior Classification in\n  Precision Livestock Farming","summary":"  This study proposes a behavior-specific filtering method to improve behavior\nclassification accuracy in Precision Livestock Farming. While traditional\nfiltering methods, such as wavelet denoising, achieved an accuracy of 91.58%,\nthey apply uniform processing to all behaviors. In contrast, the proposed\nbehavior-specific filtering method combines Wavelet Denoising with a Low Pass\nFilter, tailored to active and inactive pig behaviors, and achieved a peak\naccuracy of 94.73%. These results highlight the effectiveness of\nbehavior-specific filtering in enhancing animal behavior monitoring, supporting\nbetter health management and farm efficiency.\n","authors":["Zhen Zhang","Dong Sam Ha","Gota Morota","Sook Shin"],"pdf_url":"https://arxiv.org/pdf/2507.21021v1.pdf","comment":"11 pages, 4 tables, 3 figures"},{"id":"http://arxiv.org/abs/2507.21018v1","updated":"2025-07-28T17:39:03Z","published":"2025-07-28T17:39:03Z","title":"Deep Learning for Skeleton Based Human Motion Rehabilitation Assessment:\n  A Benchmark","summary":"  Automated assessment of human motion plays a vital role in rehabilitation,\nenabling objective evaluation of patient performance and progress. Unlike\ngeneral human activity recognition, rehabilitation motion assessment focuses on\nanalyzing the quality of movement within the same action class, requiring the\ndetection of subtle deviations from ideal motion. Recent advances in deep\nlearning and video-based skeleton extraction have opened new possibilities for\naccessible, scalable motion assessment using affordable devices such as\nsmartphones or webcams. However, the field lacks standardized benchmarks,\nconsistent evaluation protocols, and reproducible methodologies, limiting\nprogress and comparability across studies. In this work, we address these gaps\nby (i) aggregating existing rehabilitation datasets into a unified archive\ncalled Rehab-Pile, (ii) proposing a general benchmarking framework for\nevaluating deep learning methods in this domain, and (iii) conducting extensive\nbenchmarking of multiple architectures across classification and regression\ntasks. All datasets and implementations are released to the community to\nsupport transparency and reproducibility. This paper aims to establish a solid\nfoundation for future research in automated rehabilitation assessment and\nfoster the development of reliable, accessible, and personalized rehabilitation\nsolutions. The datasets, source-code and results of this article are all\npublicly available.\n","authors":["Ali Ismail-Fawaz","Maxime Devanne","Stefano Berretti","Jonathan Weber","Germain Forestier"],"pdf_url":"https://arxiv.org/pdf/2507.21018v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.04873v3","updated":"2025-07-28T17:30:22Z","published":"2025-01-08T23:07:10Z","title":"Back Home: A Computer Vision Solution to Seashell Identification for\n  Ecological Restoration","summary":"  Illegal souvenir collection strips an estimated five tonnes of seashells from\nCosta Rica's beaches each year. Yet, once these specimens are seized, their\ncoastal origin -- Pacific or Caribbean -- cannot be verified easily due to the\nlack of information, preventing their return when confiscated by local\nauthorities. To solve this issue, we introduce BackHome19K, the first\nlarge-scale image corpus (19{,}058 photographs, 516 species) annotated with\ncoast-level labels, and propose a lightweight pipeline that infers provenance\nin real time on a mobile-grade CPU. A trained anomaly filter pre-screens\nuploads, increasing robustness to user-generated noise. On a held-out test set,\nthe classifier attains 86.3\\% balanced accuracy, while the filter rejects 93\\%\nof 180 out-of-domain objects with zero false negatives. Deployed as a web\napplication, the system has already processed 70{,}000 shells for wildlife\nofficers in under three seconds per image, enabling confiscated specimens to be\nsafely repatriated to their native ecosystems. The dataset is available at\nhttps://huggingface.co/datasets/FIFCO/BackHome19K\n","authors":["Alexander Valverde","Luis Solano","André Montoya"],"pdf_url":"https://arxiv.org/pdf/2501.04873v3.pdf","comment":"ICCV 2025 (CV4E Workshop)"},{"id":"http://arxiv.org/abs/2507.21016v1","updated":"2025-07-28T17:29:22Z","published":"2025-07-28T17:29:22Z","title":"Predicting Cognition from fMRI:A Comparative Study of Graph,\n  Transformer, and Kernel Models Across Task and Rest Conditions","summary":"  Predicting cognition from neuroimaging data in healthy individuals offers\ninsights into the neural mechanisms underlying cognitive abilities, with\npotential applications in precision medicine and early detection of\nneurological and psychiatric conditions. This study systematically benchmarked\nclassical machine learning (Kernel Ridge Regression (KRR)) and advanced deep\nlearning (DL) models (Graph Neural Networks (GNN) and Transformer-GNN (TGNN))\nfor cognitive prediction using Resting-state (RS), Working Memory, and Language\ntask fMRI data from the Human Connectome Project Young Adult dataset.\n  Our results, based on R2 scores, Pearson correlation coefficient, and mean\nabsolute error, revealed that task-based fMRI, eliciting neural responses\ndirectly tied to cognition, outperformed RS fMRI in predicting cognitive\nbehavior. Among the methods compared, a GNN combining structural connectivity\n(SC) and functional connectivity (FC) consistently achieved the highest\nperformance across all fMRI modalities; however, its advantage over KRR using\nFC alone was not statistically significant. The TGNN, designed to model\ntemporal dynamics with SC as a prior, performed competitively with FC-based\napproaches for task-fMRI but struggled with RS data, where its performance\naligned with the lower-performing GNN that directly used fMRI time-series data\nas node features. These findings emphasize the importance of selecting\nappropriate model architectures and feature representations to fully leverage\nthe spatial and temporal richness of neuroimaging data.\n  This study highlights the potential of multimodal graph-aware DL models to\ncombine SC and FC for cognitive prediction, as well as the promise of\nTransformer-based approaches for capturing temporal dynamics. By providing a\ncomprehensive comparison of models, this work serves as a guide for advancing\nbrain-behavior modeling using fMRI, SC and DL.\n","authors":["Jagruti Patel","Mikkel Schöttner","Thomas A. W. Bolton","Patric Hagmann"],"pdf_url":"https://arxiv.org/pdf/2507.21016v1.pdf","comment":"Preliminary version; a revised version will be uploaded later"},{"id":"http://arxiv.org/abs/2507.02087v2","updated":"2025-07-28T17:26:01Z","published":"2025-07-02T19:02:18Z","title":"Evaluating the Promise and Pitfalls of LLMs in Hiring Decisions","summary":"  The use of large language models (LLMs) in hiring promises to streamline\ncandidate screening, but it also raises serious concerns regarding accuracy and\nalgorithmic bias where sufficient safeguards are not in place. In this work, we\nbenchmark several state-of-the-art foundational LLMs - including models from\nOpenAI, Anthropic, Google, Meta, and Deepseek, and compare them with our\nproprietary domain-specific hiring model (Match Score) for job candidate\nmatching. We evaluate each model's predictive accuracy (ROC AUC,\nPrecision-Recall AUC, F1-score) and fairness (impact ratio of cut-off analysis\nacross declared gender, race, and intersectional subgroups). Our experiments on\na dataset of roughly 10,000 real-world recent candidate-job pairs show that\nMatch Score outperforms the general-purpose LLMs on accuracy (ROC AUC 0.85 vs\n0.77) and achieves significantly more equitable outcomes across demographic\ngroups. Notably, Match Score attains a minimum race-wise impact ratio of 0.957\n(near-parity), versus 0.809 or lower for the best LLMs, (0.906 vs 0.773 for the\nintersectionals, respectively). We discuss why pretraining biases may cause\nLLMs with insufficient safeguards to propagate societal biases in hiring\nscenarios, whereas a bespoke supervised model can more effectively mitigate\nthese biases. Our findings highlight the importance of domain-specific modeling\nand bias auditing when deploying AI in high-stakes domains such as hiring, and\ncaution against relying on off-the-shelf LLMs for such tasks without extensive\nfairness safeguards. Furthermore, we show with empirical evidence that there\nshouldn't be a dichotomy between choosing accuracy and fairness in hiring: a\nwell-designed algorithm can achieve both accuracy in hiring and fairness in\noutcomes.\n","authors":["Eitan Anzenberg","Arunava Samajpati","Sivasankaran Chandrasekar","Varun Kacholia"],"pdf_url":"https://arxiv.org/pdf/2507.02087v2.pdf","comment":"10 pages, 2 figures, 2 tables. Submitted to NeurIPS 2025"},{"id":"http://arxiv.org/abs/2507.21004v1","updated":"2025-07-28T17:18:40Z","published":"2025-07-28T17:18:40Z","title":"Compositional Function Networks: A High-Performance Alternative to Deep\n  Neural Networks with Built-in Interpretability","summary":"  Deep Neural Networks (DNNs) deliver impressive performance but their\nblack-box nature limits deployment in high-stakes domains requiring\ntransparency. We introduce Compositional Function Networks (CFNs), a novel\nframework that builds inherently interpretable models by composing elementary\nmathematical functions with clear semantics. Unlike existing interpretable\napproaches that are limited to simple additive structures, CFNs support diverse\ncompositional patterns -- sequential, parallel, and conditional -- enabling\ncomplex feature interactions while maintaining transparency. A key innovation\nis that CFNs are fully differentiable, allowing efficient training through\nstandard gradient descent. We demonstrate CFNs' versatility across multiple\ndomains, from symbolic regression to image classification with deep\nhierarchical networks. Our empirical evaluation shows CFNs achieve competitive\nperformance against black-box models (96.24% accuracy on CIFAR-10) while\noutperforming state-of-the-art interpretable models like Explainable Boosting\nMachines. By combining the hierarchical expressiveness and efficient training\nof deep learning with the intrinsic interpretability of well-defined\nmathematical functions, CFNs offer a powerful framework for applications where\nboth performance and accountability are paramount.\n","authors":["Fang Li"],"pdf_url":"https://arxiv.org/pdf/2507.21004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20999v1","updated":"2025-07-28T17:11:26Z","published":"2025-07-28T17:11:26Z","title":"LoRA-PAR: A Flexible Dual-System LoRA Partitioning Approach to Efficient\n  LLM Fine-Tuning","summary":"  Large-scale generative models like DeepSeek-R1 and OpenAI-O1 benefit\nsubstantially from chain-of-thought (CoT) reasoning, yet pushing their\nperformance typically requires vast data, large model sizes, and full-parameter\nfine-tuning. While parameter-efficient fine-tuning (PEFT) helps reduce cost,\nmost existing approaches primarily address domain adaptation or layer-wise\nallocation rather than explicitly tailoring data and parameters to different\nresponse demands. Inspired by \"Thinking, Fast and Slow,\" which characterizes\ntwo distinct modes of thought-System 1 (fast, intuitive, often automatic) and\nSystem 2 (slower, more deliberative and analytic)-we draw an analogy that\ndifferent \"subregions\" of an LLM's parameters might similarly specialize for\ntasks that demand quick, intuitive responses versus those requiring multi-step\nlogical reasoning. Therefore, we propose LoRA-PAR, a dual-system LoRA framework\nthat partitions both data and parameters by System 1 or System 2 demands, using\nfewer yet more focused parameters for each task. Specifically, we classify task\ndata via multi-model role-playing and voting, and partition parameters based on\nimportance scoring, then adopt a two-stage fine-tuning strategy of training\nSystem 1 tasks with supervised fine-tuning (SFT) to enhance knowledge and\nintuition and refine System 2 tasks with reinforcement learning (RL) to\nreinforce deeper logical deliberation next. Extensive experiments show that the\ntwo-stage fine-tuning strategy, SFT and RL, lowers active parameter usage while\nmatching or surpassing SOTA PEFT baselines.\n","authors":["Yining Huang","Bin Li","Keke Tang","Meilian Chen"],"pdf_url":"https://arxiv.org/pdf/2507.20999v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2507.20997v1","updated":"2025-07-28T17:08:49Z","published":"2025-07-28T17:08:49Z","title":"Modular Delta Merging with Orthogonal Constraints: A Scalable Framework\n  for Continual and Reversible Model Composition","summary":"  In real-world machine learning deployments, models must be continually\nupdated, composed, and when required, selectively undone. However, existing\napproaches to model merging and continual learning often suffer from task\ninterference, catastrophic forgetting, or lack of reversibility. We propose\nModular Delta Merging with Orthogonal Constraints (MDM-OC), a novel framework\nthat enables scalable, interference-free, and reversible composition of\nfine-tuned models. Each task-specific model is encoded as a delta from a shared\nbase and projected into an orthogonal subspace to eliminate conflict. These\nprojected deltas are then merged via gradient-based optimization to form a\nunified model that retains performance across tasks. Our approach supports\ncontinual integration of new models, structured unmerging for compliance such\nas GDPR requirements, and model stability via elastic weight consolidation and\nsynthetic replay. Extensive experiments on vision and natural language\nprocessing benchmarks demonstrate that MDM-OC outperforms prior baselines in\naccuracy, backward transfer, and unmerge fidelity, while remaining\nmemory-efficient and computationally tractable. This framework offers a\nprincipled solution for modular and compliant AI system design.\n","authors":["Haris Khan","Shumaila Asif","Sadia Asif"],"pdf_url":"https://arxiv.org/pdf/2507.20997v1.pdf","comment":"11 pages, 6 figures, 3 tables. Will be Submitted to ICLR 2025 for\n  review"},{"id":"http://arxiv.org/abs/2406.09069v2","updated":"2025-07-28T16:59:49Z","published":"2024-06-13T12:54:53Z","title":"On the Robustness of Global Feature Effect Explanations","summary":"  We study the robustness of global post-hoc explanations for predictive models\ntrained on tabular data. Effects of predictor features in black-box supervised\nlearning are an essential diagnostic tool for model debugging and scientific\ndiscovery in applied sciences. However, how vulnerable they are to data and\nmodel perturbations remains an open research question. We introduce several\ntheoretical bounds for evaluating the robustness of partial dependence plots\nand accumulated local effects. Our experimental results with synthetic and\nreal-world datasets quantify the gap between the best and worst-case scenarios\nof (mis)interpreting machine learning predictions globally.\n","authors":["Hubert Baniecki","Giuseppe Casalicchio","Bernd Bischl","Przemyslaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2406.09069v2.pdf","comment":"Accepted at ECML PKDD 2024"},{"id":"http://arxiv.org/abs/2507.15846v3","updated":"2025-07-28T16:54:13Z","published":"2025-07-21T17:53:42Z","title":"GUI-G$^2$: Gaussian Reward Modeling for GUI Grounding","summary":"  Graphical User Interface (GUI) grounding maps natural language instructions\nto precise interface locations for autonomous interaction. Current\nreinforcement learning approaches use binary rewards that treat elements as\nhit-or-miss targets, creating sparse signals that ignore the continuous nature\nof spatial interactions. Motivated by human clicking behavior that naturally\nforms Gaussian distributions centered on target elements, we introduce GUI\nGaussian Grounding Rewards (GUI-G$^2$), a principled reward framework that\nmodels GUI elements as continuous Gaussian distributions across the interface\nplane. GUI-G$^2$ incorporates two synergistic mechanisms: Gaussian point\nrewards model precise localization through exponentially decaying distributions\ncentered on element centroids, while coverage rewards assess spatial alignment\nby measuring the overlap between predicted Gaussian distributions and target\nregions. To handle diverse element scales, we develop an adaptive variance\nmechanism that calibrates reward distributions based on element dimensions.\nThis framework transforms GUI grounding from sparse binary classification to\ndense continuous optimization, where Gaussian distributions generate rich\ngradient signals that guide models toward optimal interaction positions.\nExtensive experiments across ScreenSpot, ScreenSpot-v2, and ScreenSpot-Pro\nbenchmarks demonstrate that GUI-G$^2$, substantially outperforms\nstate-of-the-art method UI-TARS-72B, with the most significant improvement of\n24.7% on ScreenSpot-Pro. Our analysis reveals that continuous modeling provides\nsuperior robustness to interface variations and enhanced generalization to\nunseen layouts, establishing a new paradigm for spatial reasoning in GUI\ninteraction tasks.\n","authors":["Fei Tang","Zhangxuan Gu","Zhengxi Lu","Xuyang Liu","Shuheng Shen","Changhua Meng","Wen Wang","Wenqi Zhang","Yongliang Shen","Weiming Lu","Jun Xiao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2507.15846v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20993v1","updated":"2025-07-28T16:52:31Z","published":"2025-07-28T16:52:31Z","title":"Personalized Treatment Effect Estimation from Unstructured Data","summary":"  Existing methods for estimating personalized treatment effects typically rely\non structured covariates, limiting their applicability to unstructured data.\nYet, leveraging unstructured data for causal inference has considerable\napplication potential, for instance in healthcare, where clinical notes or\nmedical images are abundant. To this end, we first introduce an approximate\n'plug-in' method trained directly on the neural representations of unstructured\ndata. However, when these fail to capture all confounding information, the\nmethod may be subject to confounding bias. We therefore introduce two\ntheoretically grounded estimators that leverage structured measurements of the\nconfounders during training, but allow estimating personalized treatment\neffects purely from unstructured inputs, while avoiding confounding bias. When\nthese structured measurements are only available for a non-representative\nsubset of the data, these estimators may suffer from sampling bias. To address\nthis, we further introduce a regression-based correction that accounts for the\nnon-uniform sampling, assuming the sampling mechanism is known or can be\nwell-estimated. Our experiments on two benchmark datasets show that the plug-in\nmethod, directly trainable on large unstructured datasets, achieves strong\nempirical performance across all settings, despite its simplicity.\n","authors":["Henri Arno","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2507.20993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.00022v3","updated":"2025-07-28T16:50:18Z","published":"2025-05-21T17:06:28Z","title":"Scaling Physical Reasoning with the PHYSICS Dataset","summary":"  Large Language Models (LLMs) have achieved remarkable progress on advanced\nreasoning tasks such as mathematics and coding competitions. Meanwhile,\nphysics, despite being both reasoning-intensive and essential to real-world\nunderstanding, received limited academic and industrial attention. This paper\nintroduces PHYSICS, a dataset containing 16,568 high-quality physics problems\nspanning subjects and difficulty levels, to facilitate this issue.\nSpecifically, PHYSICS is curated with exercises from over 100 textbooks through\na carefully designed pipeline for quality control. It covers five major physics\ndomains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern\nPhysics. It also spans a wide range of difficulty levels, from high school to\ngraduate-level physics courses. To utilize the data for improving and\nevaluating the model's physical reasoning capabilities, we split the dataset\ninto training and test sets, and provide reasoning paths generated by powerful\nreasoning models for the training data to facilitate model training. In\naddition, for the evaluation part, we find that existing evaluation frameworks\nexhibit biases in aspects such as units, simplification, and precision in\nphysics domain. To balance efficiency and accuracy, we introduce a Rule+Model\nevaluation framework tailored to physics problems. Our evaluations on current\nstate-of-the-art open-source and proprietary models highlight the limitations\nof current models in handling physics-related tasks. We hope that our dataset\nand evaluation methodology will jointly advance the development of LLMs in the\nfield of physics.\n","authors":["Shenghe Zheng","Qianjia Cheng","Junchi Yao","Mengsong Wu","Haonan He","Ning Ding","Yu Cheng","Shuyue Hu","Lei Bai","Dongzhan Zhou","Ganqu Cui","Peng Ye"],"pdf_url":"https://arxiv.org/pdf/2506.00022v3.pdf","comment":"Work on physical datasets"},{"id":"http://arxiv.org/abs/2507.20984v1","updated":"2025-07-28T16:45:14Z","published":"2025-07-28T16:45:14Z","title":"SmallThinker: A Family of Efficient Large Language Models Natively\n  Trained for Local Deployment","summary":"  While frontier large language models (LLMs) continue to push capability\nboundaries, their deployment remains confined to GPU-powered cloud\ninfrastructure. We challenge this paradigm with SmallThinker, a family of LLMs\nnatively designed - not adapted - for the unique constraints of local devices:\nweak computational power, limited memory, and slow storage. Unlike traditional\napproaches that mainly compress existing models built for clouds, we architect\nSmallThinker from the ground up to thrive within these limitations. Our\ninnovation lies in a deployment-aware architecture that transforms constraints\ninto design principles. First, We introduce a two-level sparse structure\ncombining fine-grained Mixture-of-Experts (MoE) with sparse feed-forward\nnetworks, drastically reducing computational demands without sacrificing model\ncapacity. Second, to conquer the I/O bottleneck of slow storage, we design a\npre-attention router that enables our co-designed inference engine to prefetch\nexpert parameters from storage while computing attention, effectively hiding\nstorage latency that would otherwise cripple on-device inference. Third, for\nmemory efficiency, we utilize NoPE-RoPE hybrid sparse attention mechanism to\nslash KV cache requirements. We release SmallThinker-4B-A0.6B and\nSmallThinker-21B-A3B, which achieve state-of-the-art performance scores and\neven outperform larger LLMs. Remarkably, our co-designed system mostly\neliminates the need for expensive GPU hardware: with Q4_0 quantization, both\nmodels exceed 20 tokens/s on ordinary consumer CPUs, while consuming only 1GB\nand 8GB of memory respectively. SmallThinker is publicly available at\nhf.co/PowerInfer/SmallThinker-4BA0.6B-Instruct and\nhf.co/PowerInfer/SmallThinker-21BA3B-Instruct.\n","authors":["Yixin Song","Zhenliang Xue","Dongliang Wei","Feiyang Chen","Jianxiang Gao","Junchen Liu","Hangyu Liang","Guangshuo Qin","Chengrong Tian","Bo Wen","Longyu Zhao","Xinrui Zheng","Zeyu Mi","Haibo Chen"],"pdf_url":"https://arxiv.org/pdf/2507.20984v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20977v1","updated":"2025-07-28T16:39:16Z","published":"2025-07-28T16:39:16Z","title":"Repairing vulnerabilities without invisible hands. A differentiated\n  replication study on LLMs","summary":"  Background: Automated Vulnerability Repair (AVR) is a fast-growing branch of\nprogram repair. Recent studies show that large language models (LLMs)\noutperform traditional techniques, extending their success beyond code\ngeneration and fault detection.\n  Hypothesis: These gains may be driven by hidden factors -- \"invisible hands\"\nsuch as training-data leakage or perfect fault localization -- that let an LLM\nreproduce human-authored fixes for the same code.\n  Objective: We replicate prior AVR studies under controlled conditions by\ndeliberately adding errors to the reported vulnerability location in the\nprompt. If LLMs merely regurgitate memorized fixes, both small and large\nlocalization errors should yield the same number of correct patches, because\nany offset should divert the model from the original fix.\n  Method: Our pipeline repairs vulnerabilities from the Vul4J and VJTrans\nbenchmarks after shifting the fault location by n lines from the ground truth.\nA first LLM generates a patch, a second LLM reviews it, and we validate the\nresult with regression and proof-of-vulnerability tests. Finally, we manually\naudit a sample of patches and estimate the error rate with the\nAgresti-Coull-Wilson method.\n","authors":["Maria Camporese","Fabio Massacci"],"pdf_url":"https://arxiv.org/pdf/2507.20977v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20975v1","updated":"2025-07-28T16:37:56Z","published":"2025-07-28T16:37:56Z","title":"Locally Adaptive Conformal Inference for Operator Models","summary":"  Operator models are regression algorithms for functional data and have become\na key tool for emulating large-scale dynamical systems. Recent advances in deep\nneural operators have dramatically improved the accuracy and scalability of\noperator modeling, but lack an inherent notion of predictive uncertainty. We\nintroduce Local Spectral Conformal Inference (LSCI), a new framework for\nlocally adaptive, distribution-free uncertainty quantification for neural\noperator models. LSCI uses projection-based depth scoring and localized\nconformal inference to generate function-valued prediction sets with\nstatistical guarantees. We prove approximate finite-sample marginal coverage\nunder local exchangeability, and demonstrate significant gains in adaptivity\nand coverage across synthetic and real-world operator learning tasks.\n","authors":["Trevor Harris","Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2507.20975v1.pdf","comment":"9 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2507.20973v1","updated":"2025-07-28T16:36:13Z","published":"2025-07-28T16:36:13Z","title":"Model-Agnostic Gender Bias Control for Text-to-Image Generation via\n  Sparse Autoencoder","summary":"  Text-to-image (T2I) diffusion models often exhibit gender bias, particularly\nby generating stereotypical associations between professions and gendered\nsubjects. This paper presents SAE Debias, a lightweight and model-agnostic\nframework for mitigating such bias in T2I generation. Unlike prior approaches\nthat rely on CLIP-based filtering or prompt engineering, which often require\nmodel-specific adjustments and offer limited control, SAE Debias operates\ndirectly within the feature space without retraining or architectural\nmodifications. By leveraging a k-sparse autoencoder pre-trained on a gender\nbias dataset, the method identifies gender-relevant directions within the\nsparse latent space, capturing professional stereotypes. Specifically, a biased\ndirection per profession is constructed from sparse latents and suppressed\nduring inference to steer generations toward more gender-balanced outputs.\nTrained only once, the sparse autoencoder provides a reusable debiasing\ndirection, offering effective control and interpretable insight into biased\nsubspaces. Extensive evaluations across multiple T2I models, including Stable\nDiffusion 1.4, 1.5, 2.1, and SDXL, demonstrate that SAE Debias substantially\nreduces gender bias while preserving generation quality. To the best of our\nknowledge, this is the first work to apply sparse autoencoders for identifying\nand intervening in gender bias within T2I models. These findings contribute\ntoward building socially responsible generative AI, providing an interpretable\nand model-agnostic tool to support fairness in text-to-image generation.\n","authors":["Chao Wu","Zhenyi Wang","Kangxian Xie","Naresh Kumar Devulapally","Vishnu Suresh Lokhande","Mingchen Gao"],"pdf_url":"https://arxiv.org/pdf/2507.20973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11513v2","updated":"2025-07-28T16:35:44Z","published":"2024-11-18T12:21:48Z","title":"A Modular Open Source Framework for Genomic Variant Calling","summary":"  Variant calling is a fundamental task in genomic research, essential for\ndetecting genetic variations such as single nucleotide polymorphisms (SNPs) and\ninsertions or deletions (indels). This paper presents an enhancement to\nDeepChem, a widely used open-source drug discovery framework, through the\nintegration of DeepVariant. In particular, we introduce a variant calling\npipeline that leverages DeepVariant's convolutional neural network (CNN)\narchitecture to improve the accuracy and reliability of variant detection. The\nimplemented pipeline includes stages for realignment of sequencing reads,\ncandidate variant detection, and pileup image generation, followed by variant\nclassification using a modified Inception v3 model. Our work adds a modular and\nextensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem's drug discovery infrastructure more tightly\nwith bioinformatics pipelines.\n","authors":["Ankita Vaishnobi Bisoi","Shreyas V","Jose Siguenza","Bharath Ramsundar"],"pdf_url":"https://arxiv.org/pdf/2411.11513v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.11936v4","updated":"2025-07-28T16:29:33Z","published":"2025-07-16T06:03:08Z","title":"A Survey of Deep Learning for Geometry Problem Solving","summary":"  Geometry problem solving is a key area of mathematical reasoning, which is\nwidely involved in many important fields such as education, mathematical\nability assessment of artificial intelligence, and multimodal ability\nassessment. In recent years, the rapid development of deep learning technology,\nespecially the rise of multimodal large language models, has triggered a\nwidespread research boom. This paper provides a survey of the applications of\ndeep learning in geometry problem solving, including (i) a comprehensive\nsummary of the relevant tasks in geometry problem solving; (ii) a thorough\nreview of related deep learning methods; (iii) a detailed analysis of\nevaluation metrics and methods; and (iv) a critical discussion of the current\nchallenges and future directions that can be explored. Our goal is to provide a\ncomprehensive and practical reference of deep learning for geometry problem\nsolving to promote further developments in this field. We create a continuously\nupdated list of papers on GitHub: https://github.com/majianz/dl4gps.\n","authors":["Jianzhe Ma","Wenxuan Wang","Qin Jin"],"pdf_url":"https://arxiv.org/pdf/2507.11936v4.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2505.17067v3","updated":"2025-07-28T16:28:49Z","published":"2025-05-19T03:03:08Z","title":"Unveil Multi-Picture Descriptions for Multilingual Mild Cognitive\n  Impairment Detection via Contrastive Learning","summary":"  Detecting Mild Cognitive Impairment from picture descriptions is critical yet\nchallenging, especially in multilingual and multiple picture settings. Prior\nwork has primarily focused on English speakers describing a single picture\n(e.g., the 'Cookie Theft'). The TAUKDIAL-2024 challenge expands this scope by\nintroducing multilingual speakers and multiple pictures, which presents new\nchallenges in analyzing picture-dependent content. To address these challenges,\nwe propose a framework with three components: (1) enhancing discriminative\nrepresentation learning via supervised contrastive learning, (2) involving\nimage modality rather than relying solely on speech and text modalities, and\n(3) applying a Product of Experts (PoE) strategy to mitigate spurious\ncorrelations and overfitting. Our framework improves MCI detection performance,\nachieving a +7.1% increase in Unweighted Average Recall (UAR) (from 68.1% to\n75.2%) and a +2.9% increase in F1 score (from 80.6% to 83.5%) compared to the\ntext unimodal baseline. Notably, the contrastive learning component yields\ngreater gains for the text modality compared to speech. These results highlight\nour framework's effectiveness in multilingual and multi-picture MCI detection.\n","authors":["Kristin Qi","Jiali Cheng","Youxiang Zhu","Hadi Amiri","Xiaohui Liang"],"pdf_url":"https://arxiv.org/pdf/2505.17067v3.pdf","comment":"IEEE Global Communications Conference (GlobeCom) 2025"},{"id":"http://arxiv.org/abs/2507.20968v1","updated":"2025-07-28T16:26:28Z","published":"2025-07-28T16:26:28Z","title":"From Entanglement to Alignment: Representation Space Decomposition for\n  Unsupervised Time Series Domain Adaptation","summary":"  Domain shift poses a fundamental challenge in time series analysis, where\nmodels trained on source domain often fail dramatically when applied in target\ndomain with different yet similar distributions. While current unsupervised\ndomain adaptation (UDA) methods attempt to align cross-domain feature\ndistributions, they typically treat features as indivisible entities, ignoring\ntheir intrinsic compositions that governs domain adaptation. We introduce\nDARSD, a novel UDA framework with theoretical explainability that explicitly\nrealizes UDA tasks from the perspective of representation space decomposition.\nOur core insight is that effective domain adaptation requires not just\nalignment, but principled disentanglement of transferable knowledge from mixed\nrepresentations. DARSD consists three synergistic components: (I) An\nadversarial learnable common invariant basis that projects original features\ninto a domain-invariant subspace while preserving semantic content; (II) A\nprototypical pseudo-labeling mechanism that dynamically separates target\nfeatures based on confidence, hindering error accumulation; (III) A hybrid\ncontrastive optimization strategy that simultaneously enforces feature\nclustering and consistency while mitigating emerging distribution gaps.\nComprehensive experiments conducted on four benchmark datasets (WISDM, HAR,\nHHAR, and MFD) demonstrate DARSD's superiority against 12 UDA algorithms,\nachieving optimal performance in 35 out of 53 cross-domain scenarios.\n","authors":["Rongyao Cai","Ming Jin","Qingsong Wen","Kexin Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.20968v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20967v1","updated":"2025-07-28T16:22:50Z","published":"2025-07-28T16:22:50Z","title":"PROVCREATOR: Synthesizing Complex Heterogenous Graphs with Node and Edge\n  Attributes","summary":"  The rise of graph-structured data has driven interest in graph learning and\nsynthetic data generation. While successful in text and image domains,\nsynthetic graph generation remains challenging -- especially for real-world\ngraphs with complex, heterogeneous schemas. Existing research has focused\nmostly on homogeneous structures with simple attributes, limiting their\nusefulness and relevance for application domains requiring semantic fidelity.\n  In this research, we introduce ProvCreator, a synthetic graph framework\ndesigned for complex heterogeneous graphs with high-dimensional node and edge\nattributes. ProvCreator formulates graph synthesis as a sequence generation\ntask, enabling the use of transformer-based large language models. It features\na versatile graph-to-sequence encoder-decoder that 1. losslessly encodes graph\nstructure and attributes, 2. efficiently compresses large graphs for contextual\nmodeling, and 3. supports end-to-end, learnable graph generation.\n  To validate our research, we evaluate ProvCreator on two challenging domains:\nsystem provenance graphs in cybersecurity and knowledge graphs from\nIntelliGraph Benchmark Dataset. In both cases, ProvCreator captures intricate\ndependencies between structure and semantics, enabling the generation of\nrealistic and privacy-aware synthetic datasets.\n","authors":["Tianhao Wang","Simon Klancher","Kunal Mukherjee","Josh Wiedemeier","Feng Chen","Murat Kantarcioglu","Kangkook Jee"],"pdf_url":"https://arxiv.org/pdf/2507.20967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20966v1","updated":"2025-07-28T16:21:45Z","published":"2025-07-28T16:21:45Z","title":"Handoff Design in User-Centric Cell-Free Massive MIMO Networks Using DRL","summary":"  In the user-centric cell-free massive MIMO (UC-mMIMO) network scheme, user\nmobility necessitates updating the set of serving access points to maintain the\nuser-centric clustering. Such updates are typically performed through handoff\n(HO) operations; however, frequent HOs lead to overheads associated with the\nallocation and release of resources. This paper presents a deep reinforcement\nlearning (DRL)-based solution to predict and manage these connections for\nmobile users. Our solution employs the Soft Actor-Critic algorithm, with\ncontinuous action space representation, to train a deep neural network to serve\nas the HO policy. We present a novel proposition for a reward function that\nintegrates a HO penalty in order to balance the attainable rate and the\nassociated overhead related to HOs. We develop two variants of our system; the\nfirst one uses mobility direction-assisted (DA) observations that are based on\nthe user movement pattern, while the second one uses history-assisted (HA)\nobservations that are based on the history of the large-scale fading (LSF).\nSimulation results show that our DRL-based continuous action space approach is\nmore scalable than discrete space counterpart, and that our derived HO policy\nautomatically learns to gather HOs in specific time slots to minimize the\noverhead of initiating HOs. Our solution can also operate in real time with a\nresponse time less than 0.4 ms.\n","authors":["Hussein A. Ammar","Raviraj Adve","Shahram Shahbazpanahi","Gary Boudreau","Israfil Bahceci"],"pdf_url":"https://arxiv.org/pdf/2507.20966v1.pdf","comment":"Published in IEEE Transactions on Communications (IEEE TCOM)"},{"id":"http://arxiv.org/abs/2507.20964v1","updated":"2025-07-28T16:19:25Z","published":"2025-07-28T16:19:25Z","title":"Core Safety Values for Provably Corrigible Agents","summary":"  We introduce the first implementable framework for corrigibility, with\nprovable guarantees in multi-step, partially observed environments. Our\nframework replaces a single opaque reward with five *structurally separate*\nutility heads -- deference, switch-access preservation, truthfulness,\nlow-impact behavior via a belief-based extension of Attainable Utility\nPreservation, and bounded task reward -- combined lexicographically by strict\nweight gaps. Theorem 1 proves exact single-round corrigibility in the partially\nobservable off-switch game; Theorem 3 extends the guarantee to multi-step,\nself-spawning agents, showing that even if each head is \\emph{learned} to\nmean-squared error $\\varepsilon$ and the planner is $\\varepsilon$-sub-optimal,\nthe probability of violating \\emph{any} safety property is bounded while still\nensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF,\nwhich merge all norms into one learned scalar, our separation makes obedience\nand impact-limits dominate even when incentives conflict. For open-ended\nsettings where adversaries can modify the agent, we prove that deciding whether\nan arbitrary post-hack agent will ever violate corrigibility is undecidable by\nreduction to the halting problem, then carve out a finite-horizon ``decidable\nisland'' where safety can be certified in randomized polynomial time and\nverified with privacy-preserving, constant-round zero-knowledge proofs.\nConsequently, the remaining challenge is the ordinary ML task of data coverage\nand generalization: reward-hacking risk is pushed into evaluation quality\nrather than hidden incentive leak-through, giving clearer implementation\nguidance for today's LLM assistants and future autonomous systems.\n","authors":["Aran Nayebi"],"pdf_url":"https://arxiv.org/pdf/2507.20964v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2507.20958v1","updated":"2025-07-28T16:09:57Z","published":"2025-07-28T16:09:57Z","title":"Mean-Field Langevin Diffusions with Density-dependent Temperature","summary":"  In the context of non-convex optimization, we let the temperature of a\nLangevin diffusion to depend on the diffusion's own density function. The\nrationale is that the induced density reveals to some extent the landscape\nimposed by the non-convex function to be minimized, such that a\ndensity-dependent temperature can provide location-wise random perturbation\nthat may better react to, for instance, the location and depth of local\nminimizers. As the Langevin dynamics is now self-regulated by its own density,\nit forms a mean-field stochastic differential equation (SDE) of the Nemytskii\ntype, distinct from the standard McKean-Vlasov equations. Relying on\nWasserstein subdifferential calculus, we first show that the corresponding\n(nonlinear) Fokker-Planck equation has a unique solution. Next, a weak solution\nto the SDE is constructed from the solution to the Fokker-Planck equation, by\nTrevisan's superposition principle. As time goes to infinity, we further show\nthat the density induced by the SDE converges to an invariant distribution,\nwhich admits an explicit formula in terms of the Lambert $W$ function.\n","authors":["Yu-Jui Huang","Zachariah Malik"],"pdf_url":"https://arxiv.org/pdf/2507.20958v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20954v1","updated":"2025-07-28T16:04:14Z","published":"2025-07-28T16:04:14Z","title":"PySHRED: A Python package for SHallow REcurrent Decoding for sparse\n  sensing, model reduction and scientific discovery","summary":"  SHallow REcurrent Decoders (SHRED) provide a deep learning strategy for\nmodeling high-dimensional dynamical systems and/or spatiotemporal data from\ndynamical system snapshot observations. PySHRED is a Python package that\nimplements SHRED and several of its major extensions, including for robust\nsensing, reduced order modeling and physics discovery. In this paper, we\nintroduce the version 1.0 release of PySHRED, which includes data preprocessors\nand a number of cutting-edge SHRED methods specifically designed to handle\nreal-world data that may be noisy, multi-scale, parameterized, prohibitively\nhigh-dimensional, and strongly nonlinear. The package is easy to install,\nthoroughly-documented, supplemented with extensive code examples, and\nmodularly-structured to support future additions. The entire codebase is\nreleased under the MIT license and is available at\nhttps://github.com/pyshred-dev/pyshred.\n","authors":["David Ye","Jan Williams","Mars Gao","Stefano Riva","Matteo Tomasetto","David Zoro","J. Nathan Kutz"],"pdf_url":"https://arxiv.org/pdf/2507.20954v1.pdf","comment":"15 pages, 9 figures"},{"id":"http://arxiv.org/abs/2507.20941v1","updated":"2025-07-28T15:55:29Z","published":"2025-07-28T15:55:29Z","title":"Multivariate Conformal Prediction via Conformalized Gaussian Scoring","summary":"  While achieving exact conditional coverage in conformal prediction is\nunattainable without making strong, untestable regularity assumptions, the\npromise of conformal prediction hinges on finding approximations to conditional\nguarantees that are realizable in practice. A promising direction for obtaining\nconditional dependence for conformal sets--in particular capturing\nheteroskedasticity--is through estimating the conditional density\n$\\mathbb{P}_{Y|X}$ and conformalizing its level sets. Previous work in this\nvein has focused on nonconformity scores based on the empirical cumulative\ndistribution function (CDF). Such scores are, however, computationally costly,\ntypically requiring expensive sampling methods. To avoid the need for sampling,\nwe observe that the CDF-based score reduces to a Mahalanobis distance in the\ncase of Gaussian scores, yielding a closed-form expression that can be directly\nconformalized. Moreover, the use of a Gaussian-based score opens the door to a\nnumber of extensions of the basic conformal method; in particular, we show how\nto construct conformal sets with missing output values, refine conformal sets\nas partial information about $Y$ becomes available, and construct conformal\nsets on transformations of the output space. Finally, empirical results\nindicate that our approach produces conformal sets that more closely\napproximate conditional coverage in multivariate settings compared to\nalternative methods.\n","authors":["Sacha Braun","Eugène Berta","Michael I. Jordan","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2507.20941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20936v1","updated":"2025-07-28T15:45:31Z","published":"2025-07-28T15:45:31Z","title":"Dissecting Persona-Driven Reasoning in Language Models via Activation\n  Patching","summary":"  Large language models (LLMs) exhibit remarkable versatility in adopting\ndiverse personas. In this study, we examine how assigning a persona influences\na model's reasoning on an objective task. Using activation patching, we take a\nfirst step toward understanding how key components of the model encode\npersona-specific information. Our findings reveal that the early Multi-Layer\nPerceptron (MLP) layers attend not only to the syntactic structure of the input\nbut also process its semantic content. These layers transform persona tokens\ninto richer representations, which are then used by the middle Multi-Head\nAttention (MHA) layers to shape the model's output. Additionally, we identify\nspecific attention heads that disproportionately attend to racial and\ncolor-based identities.\n","authors":["Ansh Poonia","Maeghal Jain"],"pdf_url":"https://arxiv.org/pdf/2507.20936v1.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2503.18945v3","updated":"2025-07-28T15:42:31Z","published":"2025-03-24T17:59:51Z","title":"Aether: Geometric-Aware Unified World Modeling","summary":"  The integration of geometric reconstruction and generative modeling remains a\ncritical challenge in developing AI systems capable of human-like spatial\nreasoning. This paper proposes Aether, a unified framework that enables\ngeometry-aware reasoning in world models by jointly optimizing three core\ncapabilities: (1) 4D dynamic reconstruction, (2) action-conditioned video\nprediction, and (3) goal-conditioned visual planning. Through task-interleaved\nfeature learning, Aether achieves synergistic knowledge sharing across\nreconstruction, prediction, and planning objectives. Building upon video\ngeneration models, our framework demonstrates zero-shot synthetic-to-real\ngeneralization despite never observing real-world data during training.\nFurthermore, our approach achieves zero-shot generalization in both action\nfollowing and reconstruction tasks, thanks to its intrinsic geometric modeling.\nNotably, even without real-world data, its reconstruction performance is\ncomparable with or even better than that of domain-specific models.\nAdditionally, Aether employs camera trajectories as geometry-informed action\nspaces, enabling effective action-conditioned prediction and visual planning.\nWe hope our work inspires the community to explore new frontiers in\nphysically-reasonable world modeling and its applications.\n","authors":[" Aether Team","Haoyi Zhu","Yifan Wang","Jianjun Zhou","Wenzheng Chang","Yang Zhou","Zizun Li","Junyi Chen","Chunhua Shen","Jiangmiao Pang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2503.18945v3.pdf","comment":"Project Page: https://aether-world.github.io/"},{"id":"http://arxiv.org/abs/2507.20930v1","updated":"2025-07-28T15:41:53Z","published":"2025-07-28T15:41:53Z","title":"FRED: Financial Retrieval-Enhanced Detection and Editing of\n  Hallucinations in Language Models","summary":"  Hallucinations in large language models pose a critical challenge for\napplications requiring factual reliability, particularly in high-stakes domains\nsuch as finance. This work presents an effective approach for detecting and\nediting factually incorrect content in model-generated responses based on the\nprovided context. Given a user-defined domain-specific error taxonomy, we\nconstruct a synthetic dataset by inserting tagged errors into financial\nquestion-answering corpora and then fine-tune four language models, Phi-4,\nPhi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual\ninaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%\nimprovement in binary F1 score and a 30% gain in overall detection performance\ncompared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having\nonly 4 billion parameters, maintains competitive performance with just a 2%\ndrop in binary detection and a 0.1% decline in overall detection compared to\nOpenAI-o3. Our work provides a practical solution for detecting and editing\nfactual inconsistencies in financial text generation while introducing a\ngeneralizable framework that can enhance the trustworthiness and alignment of\nlarge language models across diverse applications beyond finance. Our code and\ndata are available at https://github.com/pegasi-ai/fine-grained-editting.\n","authors":["Likun Tan","Kuan-Wei Huang","Kevin Wu"],"pdf_url":"https://arxiv.org/pdf/2507.20930v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20929v1","updated":"2025-07-28T15:41:51Z","published":"2025-07-28T15:41:51Z","title":"Breaking the Precision Ceiling in Physics-Informed Neural Networks: A\n  Hybrid Fourier-Neural Architecture for Ultra-High Accuracy","summary":"  Physics-informed neural networks (PINNs) have plateaued at errors of\n$10^{-3}$-$10^{-4}$ for fourth-order partial differential equations, creating a\nperceived precision ceiling that limits their adoption in engineering\napplications. We break through this barrier with a hybrid Fourier-neural\narchitecture for the Euler-Bernoulli beam equation, achieving unprecedented L2\nerror of $1.94 \\times 10^{-7}$-a 17-fold improvement over standard PINNs and\n\\(15-500\\times\\) better than traditional numerical methods. Our approach\nsynergistically combines a truncated Fourier series capturing dominant modal\nbehavior with a deep neural network providing adaptive residual corrections. A\nsystematic harmonic optimization study revealed a counter-intuitive discovery:\nexactly 10 harmonics yield optimal performance, with accuracy catastrophically\ndegrading from $10^{-7}$ to $10^{-1}$ beyond this threshold. The two-phase\noptimization strategy (Adam followed by L-BFGS) and adaptive weight balancing\nenable stable ultra-precision convergence. GPU-accelerated implementation\nachieves sub-30-minute training despite fourth-order derivative complexity. By\naddressing 12 critical gaps in existing approaches-from architectural rigidity\nto optimization landscapes-this work demonstrates that ultra-precision is\nachievable through proper design, opening new paradigms for scientific\ncomputing where machine learning can match or exceed traditional numerical\nmethods.\n","authors":["Wei Shan Lee","Chi Kiu Althina Chau","Kei Chon Sio","Kam Ian Leong"],"pdf_url":"https://arxiv.org/pdf/2507.20929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14917v3","updated":"2025-07-28T15:37:20Z","published":"2024-06-21T07:20:51Z","title":"LLM2TEA: An Agentic AI Designer for Discovery with Generative\n  Evolutionary Multitasking","summary":"  This paper presents LLM2TEA, a Large Language Model (LLM) driven MultiTask\nEvolutionary Algorithm, representing the first agentic AI designer of its kind\noperating with generative evolutionary multitasking (GEM). LLM2TEA enables the\ncrossbreeding of solutions from multiple domains, fostering novel solutions\nthat transcend disciplinary boundaries. Of particular interest is the ability\nto discover designs that are both novel and conforming to real-world physical\nspecifications. LLM2TEA comprises an LLM to generate genotype samples from text\nprompts describing target objects, a text-to-3D generative model to produce\ncorresponding phenotypes, a classifier to interpret its semantic\nrepresentations, and a computational simulator to assess its physical\nproperties. Novel LLM-based multitask evolutionary operators are introduced to\nguide the search towards high-performing, practically viable designs.\nExperimental results in conceptual design optimization validate the\neffectiveness of LLM2TEA, showing 97% to 174% improvements in the diversity of\nnovel designs over the current text-to-3D baseline. Moreover, over 73% of the\ngenerated designs outperform the top 1% of designs produced by the text-to-3D\nbaseline in terms of physical performance. The designs produced by LLM2TEA are\nnot only aesthetically creative but also functional in real-world contexts.\nSeveral of these designs have been successfully 3D printed, demonstrating the\nability of our approach to transform AI-generated outputs into tangible,\nphysical designs. These designs underscore the potential of LLM2TEA as a\npowerful tool for complex design optimization and discovery, capable of\nproducing novel and physically viable designs.\n","authors":["Melvin Wong","Jiao Liu","Thiago Rios","Stefan Menzel","Yew Soon Ong"],"pdf_url":"https://arxiv.org/pdf/2406.14917v3.pdf","comment":"This work is accepted by IEEE CIM. IEEE copyrights applies"},{"id":"http://arxiv.org/abs/2505.10457v2","updated":"2025-07-28T15:36:46Z","published":"2025-05-15T16:14:18Z","title":"SEAL: Searching Expandable Architectures for Incremental Learning","summary":"  Incremental learning is a machine learning paradigm where a model learns from\na sequential stream of tasks. This setting poses a key challenge: balancing\nplasticity (learning new tasks) and stability (preserving past knowledge).\nNeural Architecture Search (NAS), a branch of AutoML, automates the design of\nthe architecture of Deep Neural Networks and has shown success in static\nsettings. However, existing NAS-based approaches to incremental learning often\nrely on expanding the model at every task, making them impractical in\nresource-constrained environments. In this work, we introduce SEAL, a NAS-based\nframework tailored for data-incremental learning, a scenario where disjoint\ndata samples arrive sequentially and are not stored for future access. SEAL\nadapts the model structure dynamically by expanding it only when necessary,\nbased on a capacity estimation metric. Stability is preserved through\ncross-distillation training after each expansion step. The NAS component\njointly searches for both the architecture and the optimal expansion policy.\nExperiments across multiple benchmarks demonstrate that SEAL effectively\nreduces forgetting and enhances accuracy while maintaining a lower model size\ncompared to prior methods. These results highlight the promise of combining NAS\nand selective expansion for efficient, adaptive learning in incremental\nscenarios.\n","authors":["Matteo Gambella","Manuel Roveri"],"pdf_url":"https://arxiv.org/pdf/2505.10457v2.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.20925v1","updated":"2025-07-28T15:31:15Z","published":"2025-07-28T15:31:15Z","title":"Zero-Shot Learning with Subsequence Reordering Pretraining for\n  Compound-Protein Interaction","summary":"  Given the vastness of chemical space and the ongoing emergence of previously\nuncharacterized proteins, zero-shot compound-protein interaction (CPI)\nprediction better reflects the practical challenges and requirements of\nreal-world drug development. Although existing methods perform adequately\nduring certain CPI tasks, they still face the following challenges: (1)\nRepresentation learning from local or complete protein sequences often\noverlooks the complex interdependencies between subsequences, which are\nessential for predicting spatial structures and binding properties. (2)\nDependence on large-scale or scarce multimodal protein datasets demands\nsignificant training data and computational resources, limiting scalability and\nefficiency. To address these challenges, we propose a novel approach that\npretrains protein representations for CPI prediction tasks using subsequence\nreordering, explicitly capturing the dependencies between protein subsequences.\nFurthermore, we apply length-variable protein augmentation to ensure excellent\npretraining performance on small training datasets. To evaluate the model's\neffectiveness and zero-shot learning ability, we combine it with various\nbaseline methods. The results demonstrate that our approach can improve the\nbaseline model's performance on the CPI task, especially in the challenging\nzero-shot scenario. Compared to existing pre-training models, our model\ndemonstrates superior performance, particularly in data-scarce scenarios where\ntraining samples are limited. Our implementation is available at\nhttps://github.com/Hoch-Zhang/PSRP-CPI.\n","authors":["Hongzhi Zhang","Zhonglie Liu","Kun Meng","Jiameng Chen","Jia Wu","Bo Du","Di Lin","Yan Che","Wenbin Hu"],"pdf_url":"https://arxiv.org/pdf/2507.20925v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20919v1","updated":"2025-07-28T15:19:54Z","published":"2025-07-28T15:19:54Z","title":"Modeling User Behavior from Adaptive Surveys with Supplemental Context","summary":"  Modeling user behavior is critical across many industries where understanding\npreferences, intent, or decisions informs personalization, targeting, and\nstrategic outcomes. Surveys have long served as a classical mechanism for\ncollecting such behavioral data due to their interpretability, structure, and\nease of deployment. However, surveys alone are inherently limited by user\nfatigue, incomplete responses, and practical constraints on their length making\nthem insufficient for capturing user behavior. In this work, we present LANTERN\n(Late-Attentive Network for Enriched Response Modeling), a modular architecture\nfor modeling user behavior by fusing adaptive survey responses with\nsupplemental contextual signals. We demonstrate the architectural value of\nmaintaining survey primacy through selective gating, residual connections and\nlate fusion via cross-attention, treating survey data as the primary signal\nwhile incorporating external modalities only when relevant. LANTERN outperforms\nstrong survey-only baselines in multi-label prediction of survey responses. We\nfurther investigate threshold sensitivity and the benefits of selective\nmodality reliance through ablation and rare/frequent attribute analysis.\nLANTERN's modularity supports scalable integration of new encoders and evolving\ndatasets. This work provides a practical and extensible blueprint for behavior\nmodeling in survey-centric applications.\n","authors":["Aman Shukla","Daniel Patrick Scantlebury","Rishabh Kumar"],"pdf_url":"https://arxiv.org/pdf/2507.20919v1.pdf","comment":"Best Paper, NewInML @ ICML 2025"},{"id":"http://arxiv.org/abs/2503.08960v2","updated":"2025-07-28T14:58:39Z","published":"2025-03-11T23:37:18Z","title":"Are ECGs enough? Deep learning classification of pulmonary embolism\n  using electrocardiograms","summary":"  Pulmonary embolism is a leading cause of out of hospital cardiac arrest that\nrequires fast diagnosis. While computed tomography pulmonary angiography is the\nstandard diagnostic tool, it is not always accessible. Electrocardiography is\nan essential tool for diagnosing multiple cardiac anomalies, as it is\naffordable, fast and available in many settings. However, the availability of\npublic ECG datasets, specially for PE, is limited and, in practice, these\ndatasets tend to be small, making it essential to optimize learning strategies.\nIn this study, we investigate the performance of multiple neural networks in\norder to assess the impact of various approaches. Moreover, we check whether\nthese practices enhance model generalization when transfer learning is used to\ntranslate information learned in larger ECG datasets, such as PTB-XL, CPSC18\nand MedalCare-XL, to a smaller, more challenging dataset for PE. By leveraging\ntransfer learning, we analyze the extent to which we can improve learning\nefficiency and predictive performance on limited data. Code available at\nhttps://github.com/joaodsmarques/Are-ECGs-enough-Deep-Learning-Classifiers .\n","authors":["Joao D. S. Marques","Arlindo L. Oliveira"],"pdf_url":"https://arxiv.org/pdf/2503.08960v2.pdf","comment":"Accepted to the MIRASOL 2025 Workshop (MICCAI 2025)"},{"id":"http://arxiv.org/abs/2506.02394v2","updated":"2025-07-28T14:47:34Z","published":"2025-06-03T03:21:10Z","title":"Joint modeling for learning decision-making dynamics in behavioral\n  experiments","summary":"  Major depressive disorder (MDD), a leading cause of disability and mortality,\nis associated with reward-processing abnormalities and concentration issues.\nMotivated by the probabilistic reward task from the Establishing Moderators and\nBiosignatures of Antidepressant Response in Clinical Care (EMBARC) study, we\npropose a novel framework that integrates the reinforcement learning (RL) model\nand drift-diffusion model (DDM) to jointly analyze reward-based decision-making\nwith response times. To account for emerging evidence suggesting that\ndecision-making may alternate between multiple interleaved strategies, we model\nlatent state switching using a hidden Markov model (HMM). In the ''engaged''\nstate, decisions follow an RL-DDM, simultaneously capturing reward processing,\ndecision dynamics, and temporal structure. In contrast, in the ''lapsed''\nstate, decision-making is modeled using a simplified DDM, where specific\nparameters are fixed to approximate random guessing with equal probability. The\nproposed method is implemented using a computationally efficient generalized\nexpectation-maximization (EM) algorithm with forward-backward procedures.\nThrough extensive numerical studies, we demonstrate that our proposed method\noutperforms competing approaches across various reward-generating\ndistributions, under both strategy-switching and non-switching scenarios, as\nwell as in the presence of input perturbations. When applied to the EMBARC\nstudy, our framework reveals that MDD patients exhibit lower overall engagement\nthan healthy controls and experience longer decision times when they do engage.\nAdditionally, we show that neuroimaging measures of brain activities are\nassociated with decision-making characteristics in the ''engaged'' state but\nnot in the ''lapsed'' state, providing evidence of brain-behavior association\nspecific to the ''engaged'' state.\n","authors":["Yuan Bian","Xingche Guo","Yuanjia Wang"],"pdf_url":"https://arxiv.org/pdf/2506.02394v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20894v1","updated":"2025-07-28T14:47:13Z","published":"2025-07-28T14:47:13Z","title":"Online hierarchical partitioning of the output space in extreme\n  multi-label data stream","summary":"  Mining data streams with multi-label outputs poses significant challenges due\nto evolving distributions, high-dimensional label spaces, sparse label\noccurrences, and complex label dependencies. Moreover, concept drift affects\nnot only input distributions but also label correlations and imbalance ratios\nover time, complicating model adaptation. To address these challenges,\nstructured learners are categorized into local and global methods. Local\nmethods break down the task into simpler components, while global methods adapt\nthe algorithm to the full output space, potentially yielding better predictions\nby exploiting label correlations. This work introduces iHOMER (Incremental\nHierarchy Of Multi-label Classifiers), an online multi-label learning framework\nthat incrementally partitions the label space into disjoint, correlated\nclusters without relying on predefined hierarchies. iHOMER leverages online\ndivisive-agglomerative clustering based on \\textit{Jaccard} similarity and a\nglobal tree-based learner driven by a multivariate \\textit{Bernoulli} process\nto guide instance partitioning. To address non-stationarity, it integrates\ndrift detection mechanisms at both global and local levels, enabling dynamic\nrestructuring of label partitions and subtrees. Experiments across 23\nreal-world datasets show iHOMER outperforms 5 state-of-the-art global\nbaselines, such as MLHAT, MLHT of Pruned Sets and iSOUPT, by 23\\%, and 12 local\nbaselines, such as binary relevance transformations of kNN, EFDT, ARF, and\nADWIN bagging/boosting ensembles, by 32\\%, establishing its robustness for\nonline multi-label classification.\n","authors":["Lara Neves","Afonso Lourenço","Alberto Cano","Goreti Marreiros"],"pdf_url":"https://arxiv.org/pdf/2507.20894v1.pdf","comment":"Accepted at 28th European Conference on Artificial Intelligence (ECAI\n  2025)"},{"id":"http://arxiv.org/abs/2507.11441v2","updated":"2025-07-28T14:28:07Z","published":"2025-07-15T16:05:30Z","title":"Implementing Adaptations for Vision AutoRegressive Model","summary":"  Vision AutoRegressive model (VAR) was recently introduced as an alternative\nto Diffusion Models (DMs) in image generation domain. In this work we focus on\nits adaptations, which aim to fine-tune pre-trained models to perform specific\ndownstream tasks, like medical data generation. While for DMs there exist many\ntechniques, adaptations for VAR remain underexplored. Similarly, differentially\nprivate (DP) adaptations-ones that aim to preserve privacy of the adaptation\ndata-have been extensively studied for DMs, while VAR lacks such solutions. In\nour work, we implement and benchmark many strategies for VAR, and compare them\nto state-of-the-art DM adaptation strategies. We observe that VAR outperforms\nDMs for non-DP adaptations, however, the performance of DP suffers, which\nnecessitates further research in private adaptations for VAR. Code is available\nat https://github.com/sprintml/finetuning_var_dp.\n","authors":["Kaif Shaikh","Franziska Boenisch","Adam Dziedzic"],"pdf_url":"https://arxiv.org/pdf/2507.11441v2.pdf","comment":"Accepted at DIG-BUGS: Data in Generative Models Workshop @ ICML 2025"},{"id":"http://arxiv.org/abs/2507.20873v1","updated":"2025-07-28T14:24:20Z","published":"2025-07-28T14:24:20Z","title":"Testbed and Software Architecture for Enhancing Security in Industrial\n  Private 5G Networks","summary":"  In the era of Industry 4.0, the growing need for secure and efficient\ncommunication systems has driven the development of fifth-generation (5G)\nnetworks characterized by extremely low latency, massive device connectivity\nand high data transfer speeds. However, the deployment of 5G networks presents\nsignificant security challenges, requiring advanced and robust solutions to\ncounter increasingly sophisticated cyber threats. This paper proposes a testbed\nand software architecture to strengthen the security of Private 5G Networks,\nparticularly in industrial communication environments.\n","authors":["Song Son Ha","Florian Foerster","Thomas Robert Doebbert","Tim Kittel","Dominik Merli","Gerd Scholl"],"pdf_url":"https://arxiv.org/pdf/2507.20873v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20872v1","updated":"2025-07-28T14:24:13Z","published":"2025-07-28T14:24:13Z","title":"Not Only Grey Matter: OmniBrain for Robust Multimodal Classification of\n  Alzheimer's Disease","summary":"  Alzheimer's disease affects over 55 million people worldwide and is projected\nto more than double by 2050, necessitating rapid, accurate, and scalable\ndiagnostics. However, existing approaches are limited because they cannot\nachieve clinically acceptable accuracy, generalization across datasets,\nrobustness to missing modalities, and explainability all at the same time. This\ninability to satisfy all these requirements simultaneously undermines their\nreliability in clinical settings. We propose OmniBrain, a multimodal framework\nthat integrates brain MRI, radiomics, gene expression, and clinical data using\na unified model with cross-attention and modality dropout. OmniBrain achieves\n$92.2 \\pm 2.4\\%$accuracy on the ANMerge dataset and generalizes to the MRI-only\nADNI dataset with $70.4 \\pm 2.7\\%$ accuracy, outperforming unimodal and prior\nmultimodal approaches. Explainability analyses highlight neuropathologically\nrelevant brain regions and genes, enhancing clinical trust. OmniBrain offers a\nrobust, interpretable, and practical solution for real-world Alzheimer's\ndiagnosis.\n","authors":["Ahmed Sharshar","Yasser Ashraf","Tameem Bakr","Salma Hassan","Hosam Elgendy","Mohammad Yaqub","Mohsen Guizani"],"pdf_url":"https://arxiv.org/pdf/2507.20872v1.pdf","comment":"Published in Third Workshop on Computer Vision for Automated Medical\n  Diagnosis CVAMD 2025 in ICCV 2025"},{"id":"http://arxiv.org/abs/2507.20871v1","updated":"2025-07-28T14:22:43Z","published":"2025-07-28T14:22:43Z","title":"\\textit{FedABC}: Attention-Based Client Selection for Federated Learning\n  with Long-Term View","summary":"  Native AI support is a key objective in the evolution of 6G networks, with\nFederated Learning (FL) emerging as a promising paradigm. FL allows\ndecentralized clients to collaboratively train an AI model without directly\nsharing their data, preserving privacy. Clients train local models on private\ndata and share model updates, which a central server aggregates to refine the\nglobal model and redistribute it for the next iteration. However, client data\nheterogeneity slows convergence and reduces model accuracy, and frequent client\nparticipation imposes communication and computational burdens. To address these\nchallenges, we propose \\textit{FedABC}, an innovative client selection\nalgorithm designed to take a long-term view in managing data heterogeneity and\noptimizing client participation. Inspired by attention mechanisms,\n\\textit{FedABC} prioritizes informative clients by evaluating both model\nsimilarity and each model's unique contributions to the global model. Moreover,\nconsidering the evolving demands of the global model, we formulate an\noptimization problem to guide \\textit{FedABC} throughout the training process.\nFollowing the ``later-is-better\" principle, \\textit{FedABC} adaptively adjusts\nthe client selection threshold, encouraging greater participation in later\ntraining stages. Extensive simulations on CIFAR-10 demonstrate that\n\\textit{FedABC} significantly outperforms existing approaches in model accuracy\nand client participation efficiency, achieving comparable performance with 32\\%\nfewer clients than the classical FL algorithm \\textit{FedAvg}, and 3.5\\% higher\naccuracy with 2\\% fewer clients than the state-of-the-art. This work marks a\nstep toward deploying FL in heterogeneous, resource-constrained environments,\nthereby supporting native AI capabilities in 6G networks.\n","authors":["Wenxuan Ye","Xueli An","Junfan Wang","Xueqiang Yan","Georg Carle"],"pdf_url":"https://arxiv.org/pdf/2507.20871v1.pdf","comment":"Accepted to ICC 2025"},{"id":"http://arxiv.org/abs/2507.20862v1","updated":"2025-07-28T14:16:01Z","published":"2025-07-28T14:16:01Z","title":"Bi-cephalic self-attended model to classify Parkinson's disease patients\n  with freezing of gait","summary":"  Parkinson Disease (PD) often results in motor and cognitive impairments,\nincluding gait dysfunction, particularly in patients with freezing of gait\n(FOG). Current detection methods are either subjective or reliant on\nspecialized gait analysis tools. This study aims to develop an objective,\ndata-driven, and multi-modal classification model to detect gait dysfunction in\nPD patients using resting-state EEG signals combined with demographic and\nclinical variables. We utilized a dataset of 124 participants: 42 PD patients\nwith FOG (PDFOG+), 41 without FOG (PDFOG-), and 41 age-matched healthy\ncontrols. Features extracted from resting-state EEG and descriptive variables\n(age, education, disease duration) were used to train a novel Bi-cephalic\nSelf-Attention Model (BiSAM). We tested three modalities: signal-only,\ndescriptive-only, and multi-modal, across different EEG channel subsets\n(BiSAM-63, -16, -8, and -4). Signal-only and descriptive-only models showed\nlimited performance, achieving a maximum accuracy of 55% and 68%, respectively.\nIn contrast, the multi-modal models significantly outperformed both, with\nBiSAM-8 and BiSAM-4 achieving the highest classification accuracy of 88%. These\nresults demonstrate the value of integrating EEG with objective descriptive\nfeatures for robust PDFOG+ detection. This study introduces a multi-modal,\nattention-based architecture that objectively classifies PDFOG+ using minimal\nEEG channels and descriptive variables. This approach offers a scalable and\nefficient alternative to traditional assessments, with potential applications\nin routine clinical monitoring and early diagnosis of PD-related gait\ndysfunction.\n","authors":["Shomoita Jahid Mitin","Rodrigue Rizk","Maximilian Scherer","Thomas Koeglsperger","Daniel Lench","KC Santosh","Arun Singh"],"pdf_url":"https://arxiv.org/pdf/2507.20862v1.pdf","comment":"26 pages, 5944 words, 4 figures, 2 tables, European Journal of\n  Neuroscience: Special edition FOG"},{"id":"http://arxiv.org/abs/2311.13349v3","updated":"2025-07-28T14:11:53Z","published":"2023-11-22T12:34:51Z","title":"REDS: Resource-Efficient Deep Subnetworks for Dynamic Resource\n  Constraints","summary":"  Deep learning models deployed on edge devices frequently encounter resource\nvariability, which arises from fluctuating energy levels, timing constraints,\nor prioritization of other critical tasks within the system. State-of-the-art\nmachine learning pipelines generate resource-agnostic models that are not\ncapable to adapt at runtime. In this work, we introduce Resource-Efficient Deep\nSubnetworks (REDS) to tackle model adaptation to variable resources. In\ncontrast to the state-of-the-art, REDS leverages structured sparsity\nconstructively by exploiting permutation invariance of neurons, which allows\nfor hardware-specific optimizations. Specifically, REDS achieves computational\nefficiency by (1) skipping sequential computational blocks identified by a\nnovel iterative knapsack optimizer, and (2) taking advantage of data cache by\nre-arranging the order of operations in REDS computational graph. REDS supports\nconventional deep networks frequently deployed on the edge and provides\ncomputational benefits even for small and simple networks. We evaluate REDS on\neight benchmark architectures trained on the Visual Wake Words, Google Speech\nCommands, Fashion-MNIST, CIFAR-10 and ImageNet-1K datasets, and test on four\noff-the-shelf mobile and embedded hardware platforms. We provide a theoretical\nresult and empirical evidence demonstrating REDS' outstanding performance in\nterms of submodels' test set accuracy, and demonstrate an adaptation time in\nresponse to dynamic resource constraints of under 40$\\mu$s, utilizing a\nfully-connected network on Arduino Nano 33 BLE.\n","authors":["Francesco Corti","Balz Maag","Joachim Schauer","Ulrich Pferschy","Olga Saukh"],"pdf_url":"https://arxiv.org/pdf/2311.13349v3.pdf","comment":null}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2507.21040v1","updated":"2025-07-28T17:56:34Z","published":"2025-07-28T17:56:34Z","title":"Transformers as Unrolled Inference in Probabilistic Laplacian Eigenmaps:\n  An Interpretation and Potential Improvements","summary":"  We propose a probabilistic interpretation of transformers as unrolled\ninference steps assuming a probabilistic Laplacian Eigenmaps model from the\nProbDR framework. Our derivation shows that at initialisation, transformers\nperform \"linear\" dimensionality reduction. We also show that within the\ntransformer block, a graph Laplacian term arises from our arguments, rather\nthan an attention matrix (which we interpret as an adjacency matrix). We\ndemonstrate that simply subtracting the identity from the attention matrix (and\nthereby taking a graph diffusion step) improves validation performance on a\nlanguage model and a simple vision transformer.\n","authors":["Aditya Ravuri","Neil D. Lawrence"],"pdf_url":"https://arxiv.org/pdf/2507.21040v1.pdf","comment":"Initial version"},{"id":"http://arxiv.org/abs/2406.09069v2","updated":"2025-07-28T16:59:49Z","published":"2024-06-13T12:54:53Z","title":"On the Robustness of Global Feature Effect Explanations","summary":"  We study the robustness of global post-hoc explanations for predictive models\ntrained on tabular data. Effects of predictor features in black-box supervised\nlearning are an essential diagnostic tool for model debugging and scientific\ndiscovery in applied sciences. However, how vulnerable they are to data and\nmodel perturbations remains an open research question. We introduce several\ntheoretical bounds for evaluating the robustness of partial dependence plots\nand accumulated local effects. Our experimental results with synthetic and\nreal-world datasets quantify the gap between the best and worst-case scenarios\nof (mis)interpreting machine learning predictions globally.\n","authors":["Hubert Baniecki","Giuseppe Casalicchio","Bernd Bischl","Przemyslaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2406.09069v2.pdf","comment":"Accepted at ECML PKDD 2024"},{"id":"http://arxiv.org/abs/2404.03867v2","updated":"2025-07-28T16:54:47Z","published":"2024-04-05T02:40:45Z","title":"Dimension-free Relaxation Times of Informed MCMC Samplers on Discrete\n  Spaces","summary":"  Convergence analysis of Markov chain Monte Carlo methods in high-dimensional\nstatistical applications is increasingly recognized. In this paper, we develop\ngeneral mixing time bounds for Metropolis-Hastings algorithms on discrete\nspaces by building upon and refining some recent theoretical advancements in\nBayesian model selection problems. We establish sufficient conditions for a\nclass of informed Metropolis-Hastings algorithms to attain relaxation times\nthat are independent of the problem dimension. These conditions are grounded in\nthe high-dimensional statistical theory and allow for possibly multimodal\nposterior distributions. We obtain our results through two independent\ntechniques: the multicommodity flow method and single-element drift condition\nanalysis; we find that the latter yields a slightly tighter mixing time bound.\nOur results are readily applicable to a broad spectrum of statistical problems\nwith discrete parameter spaces, as we demonstrate using both theoretical and\nnumerical examples.\n","authors":["Hyunwoong Chang","Quan Zhou"],"pdf_url":"https://arxiv.org/pdf/2404.03867v2.pdf","comment":"Accepted by Bernoulli"},{"id":"http://arxiv.org/abs/2507.20993v1","updated":"2025-07-28T16:52:31Z","published":"2025-07-28T16:52:31Z","title":"Personalized Treatment Effect Estimation from Unstructured Data","summary":"  Existing methods for estimating personalized treatment effects typically rely\non structured covariates, limiting their applicability to unstructured data.\nYet, leveraging unstructured data for causal inference has considerable\napplication potential, for instance in healthcare, where clinical notes or\nmedical images are abundant. To this end, we first introduce an approximate\n'plug-in' method trained directly on the neural representations of unstructured\ndata. However, when these fail to capture all confounding information, the\nmethod may be subject to confounding bias. We therefore introduce two\ntheoretically grounded estimators that leverage structured measurements of the\nconfounders during training, but allow estimating personalized treatment\neffects purely from unstructured inputs, while avoiding confounding bias. When\nthese structured measurements are only available for a non-representative\nsubset of the data, these estimators may suffer from sampling bias. To address\nthis, we further introduce a regression-based correction that accounts for the\nnon-uniform sampling, assuming the sampling mechanism is known or can be\nwell-estimated. Our experiments on two benchmark datasets show that the plug-in\nmethod, directly trainable on large unstructured datasets, achieves strong\nempirical performance across all settings, despite its simplicity.\n","authors":["Henri Arno","Thomas Demeester"],"pdf_url":"https://arxiv.org/pdf/2507.20993v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20980v1","updated":"2025-07-28T16:43:11Z","published":"2025-07-28T16:43:11Z","title":"LargeMvC-Net: Anchor-based Deep Unfolding Network for Large-scale\n  Multi-view Clustering","summary":"  Deep anchor-based multi-view clustering methods enhance the scalability of\nneural networks by utilizing representative anchors to reduce the computational\ncomplexity of large-scale clustering. Despite their scalability advantages,\nexisting approaches often incorporate anchor structures in a heuristic or\ntask-agnostic manner, either through post-hoc graph construction or as\nauxiliary components for message passing. Such designs overlook the core\nstructural demands of anchor-based clustering, neglecting key optimization\nprinciples. To bridge this gap, we revisit the underlying optimization problem\nof large-scale anchor-based multi-view clustering and unfold its iterative\nsolution into a novel deep network architecture, termed LargeMvC-Net. The\nproposed model decomposes the anchor-based clustering process into three\nmodules: RepresentModule, NoiseModule, and AnchorModule, corresponding to\nrepresentation learning, noise suppression, and anchor indicator estimation.\nEach module is derived by unfolding a step of the original optimization\nprocedure into a dedicated network component, providing structural clarity and\noptimization traceability. In addition, an unsupervised reconstruction loss\naligns each view with the anchor-induced latent space, encouraging consistent\nclustering structures across views. Extensive experiments on several\nlarge-scale multi-view benchmarks show that LargeMvC-Net consistently\noutperforms state-of-the-art methods in terms of both effectiveness and\nscalability.\n","authors":["Shide Du","Chunming Wu","Zihan Fang","Wendi Zhao","Yilin Wu","Changwei Wang","Shiping Wang"],"pdf_url":"https://arxiv.org/pdf/2507.20980v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.20975v1","updated":"2025-07-28T16:37:56Z","published":"2025-07-28T16:37:56Z","title":"Locally Adaptive Conformal Inference for Operator Models","summary":"  Operator models are regression algorithms for functional data and have become\na key tool for emulating large-scale dynamical systems. Recent advances in deep\nneural operators have dramatically improved the accuracy and scalability of\noperator modeling, but lack an inherent notion of predictive uncertainty. We\nintroduce Local Spectral Conformal Inference (LSCI), a new framework for\nlocally adaptive, distribution-free uncertainty quantification for neural\noperator models. LSCI uses projection-based depth scoring and localized\nconformal inference to generate function-valued prediction sets with\nstatistical guarantees. We prove approximate finite-sample marginal coverage\nunder local exchangeability, and demonstrate significant gains in adaptivity\nand coverage across synthetic and real-world operator learning tasks.\n","authors":["Trevor Harris","Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2507.20975v1.pdf","comment":"9 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2507.20941v1","updated":"2025-07-28T15:55:29Z","published":"2025-07-28T15:55:29Z","title":"Multivariate Conformal Prediction via Conformalized Gaussian Scoring","summary":"  While achieving exact conditional coverage in conformal prediction is\nunattainable without making strong, untestable regularity assumptions, the\npromise of conformal prediction hinges on finding approximations to conditional\nguarantees that are realizable in practice. A promising direction for obtaining\nconditional dependence for conformal sets--in particular capturing\nheteroskedasticity--is through estimating the conditional density\n$\\mathbb{P}_{Y|X}$ and conformalizing its level sets. Previous work in this\nvein has focused on nonconformity scores based on the empirical cumulative\ndistribution function (CDF). Such scores are, however, computationally costly,\ntypically requiring expensive sampling methods. To avoid the need for sampling,\nwe observe that the CDF-based score reduces to a Mahalanobis distance in the\ncase of Gaussian scores, yielding a closed-form expression that can be directly\nconformalized. Moreover, the use of a Gaussian-based score opens the door to a\nnumber of extensions of the basic conformal method; in particular, we show how\nto construct conformal sets with missing output values, refine conformal sets\nas partial information about $Y$ becomes available, and construct conformal\nsets on transformations of the output space. Finally, empirical results\nindicate that our approach produces conformal sets that more closely\napproximate conditional coverage in multivariate settings compared to\nalternative methods.\n","authors":["Sacha Braun","Eugène Berta","Michael I. Jordan","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2507.20941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.21420v3","updated":"2025-07-28T13:04:22Z","published":"2024-07-31T08:09:04Z","title":"Whitney extensions on symmetric spaces","summary":"  In 1934, H. Whitney introduced the problem of extending a function on a set\nof points in $\\mathbb{R}^n$ to an analytic function on the ambient space. In\nthis article we prove Whitney type extension theorems for data on some\nhomogeneous spaces. We use harmonic analysis on the homogeneous spaces and\nrepresentation theory of compact as well as noncompact reductive groups.\n","authors":["Birgit Speh","Peter Vang Uttenthal"],"pdf_url":"https://arxiv.org/pdf/2407.21420v3.pdf","comment":"28 pages"},{"id":"http://arxiv.org/abs/2507.11274v2","updated":"2025-07-28T11:03:24Z","published":"2025-07-15T12:52:47Z","title":"Fast Last-Iterate Convergence of SGD in the Smooth Interpolation Regime","summary":"  We study population convergence guarantees of stochastic gradient descent\n(SGD) for smooth convex objectives in the interpolation regime, where the noise\nat optimum is zero or near zero. The behavior of the last iterate of SGD in\nthis setting -- particularly with large (constant) stepsizes -- has received\ngrowing attention in recent years due to implications for the training of\nover-parameterized models, as well as to analyzing forgetting in continual\nlearning and to understanding the convergence of the randomized Kaczmarz method\nfor solving linear systems. We establish that after $T$ steps of SGD on\n$\\beta$-smooth convex loss functions with stepsize $0 < \\eta < 2/\\beta$, the\nlast iterate exhibits expected excess risk $\\widetilde{O}(\\frac{1}{\\eta\n(2-\\beta \\eta) T^{1-\\beta\\eta/2}} + \\frac{\\eta}{(2-\\beta\\eta)^2}\nT^{\\beta\\eta/2} \\sigma_\\star^2)$, where $\\sigma_\\star^2$ denotes the variance\nof the stochastic gradients at the optimum. In particular, for a well-tuned\nstepsize we obtain a near optimal $\\widetilde{O}(1/T + \\sigma_\\star/\\sqrt{T})$\nrate for the last iterate, extending the results of Varre et al. (2021) beyond\nleast squares regression; and when $\\sigma_\\star=0$ we obtain a rate of\n$\\smash{O(1/\\sqrt T)}$ with $\\eta=1/\\beta$, improving upon the best-known\n$\\smash{O(T^{-1/4})}$ rate recently established by Evron et al. (2025) in the\nspecial case of realizable linear regression.\n","authors":["Amit Attia","Matan Schliserman","Uri Sherman","Tomer Koren"],"pdf_url":"https://arxiv.org/pdf/2507.11274v2.pdf","comment":"30 pages"},{"id":"http://arxiv.org/abs/2505.22518v3","updated":"2025-07-28T08:58:45Z","published":"2025-05-28T16:04:17Z","title":"IGNIS: A Robust Neural Network Framework for Constrained Parameter\n  Estimation in Archimedean Copulas","summary":"  Classical estimators, the cornerstones of statistical inference, face\ninsurmountable challenges when applied to important emerging classes of\nArchimedean copulas. These models exhibit pathological properties, including\nnumerically unstable densities, non-monotonic parameter-to-dependence mappings,\nand vanishingly small likelihood gradients, rendering methods like Maximum\nLikelihood (MLE) and Method of Moments (MoM) inconsistent or computationally\ninfeasible. We introduce IGNIS, a unified neural estimation framework that\nsidesteps these barriers by learning a direct, robust mapping from data-driven\ndependency measures to the underlying copula parameter theta. IGNIS utilizes a\nmulti-input architecture and a theory-guided output layer (softplus(z) + 1) to\nautomatically enforce the domain constraint theta_hat >= 1. Trained and\nvalidated on four families (Gumbel, Joe, and the numerically challenging\nA1/A2), IGNIS delivers accurate and stable estimates for real-world financial\nand health datasets, demonstrating its necessity for reliable inference in\nmodern, complex dependence models where traditional methods fail.\n","authors":["Agnideep Aich"],"pdf_url":"https://arxiv.org/pdf/2505.22518v3.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2507.20560v1","updated":"2025-07-28T06:45:15Z","published":"2025-07-28T06:45:15Z","title":"Statistical Inference for Differentially Private Stochastic Gradient\n  Descent","summary":"  Privacy preservation in machine learning, particularly through Differentially\nPrivate Stochastic Gradient Descent (DP-SGD), is critical for sensitive data\nanalysis. However, existing statistical inference methods for SGD predominantly\nfocus on cyclic subsampling, while DP-SGD requires randomized subsampling. This\npaper first bridges this gap by establishing the asymptotic properties of SGD\nunder the randomized rule and extending these results to DP-SGD. For the output\nof DP-SGD, we show that the asymptotic variance decomposes into statistical,\nsampling, and privacy-induced components. Two methods are proposed for\nconstructing valid confidence intervals: the plug-in method and the random\nscaling method. We also perform extensive numerical analysis, which shows that\nthe proposed confidence intervals achieve nominal coverage rates while\nmaintaining privacy.\n","authors":["Xintao Xia","Linjun Zhang","Zhanrui Cai"],"pdf_url":"https://arxiv.org/pdf/2507.20560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20542v1","updated":"2025-07-28T05:59:35Z","published":"2025-07-28T05:59:35Z","title":"Improving Group Fairness in Tensor Completion via Imbalance Mitigating\n  Entity Augmentation","summary":"  Group fairness is important to consider in tensor decomposition to prevent\ndiscrimination based on social grounds such as gender or age. Although few\nworks have studied group fairness in tensor decomposition, they suffer from\nperformance degradation. To address this, we propose STAFF(Sparse Tensor\nAugmentation For Fairness) to improve group fairness by minimizing the gap in\ncompletion errors of different groups while reducing the overall tensor\ncompletion error. Our main idea is to augment a tensor with augmented entities\nincluding sufficient observed entries to mitigate imbalance and group bias in\nthe sparse tensor. We evaluate \\method on tensor completion with various\ndatasets under conventional and deep learning-based tensor models. STAFF\nconsistently shows the best trade-off between completion error and group\nfairness; at most, it yields 36% lower MSE and 59% lower MADE than the\nsecond-best baseline.\n","authors":["Dawon Ahn","Jun-Gi Jang","Evangelos E. Papalexakis"],"pdf_url":"https://arxiv.org/pdf/2507.20542v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2007.00736v4","updated":"2025-07-28T04:10:11Z","published":"2020-07-01T20:28:22Z","title":"Tensor Completion with Nearly Linear Samples Given Weak Side Information","summary":"  Tensor completion exhibits an interesting computational-statistical gap in\nterms of the number of samples needed to perform tensor estimation. While there\nare only $\\Theta(tn)$ degrees of freedom in a $t$-order tensor with $n^t$\nentries, the best known polynomial time algorithm requires $O(n^{t/2})$ samples\nin order to guarantee consistent estimation. In this paper, we show that weak\nside information is sufficient to reduce the sample complexity to $O(n)$. The\nside information consists of a weight vector for each of the modes which is not\northogonal to any of the latent factors along that mode; this is significantly\nweaker than assuming noisy knowledge of the subspaces. We provide an algorithm\nthat utilizes this side information to produce a consistent estimator with\n$O(n^{1+\\kappa})$ samples for any small constant $\\kappa > 0$. We also provide\nexperiments on both synthetic and real-world datasets that validate our\ntheoretical insights.\n","authors":["Christina Lee Yu","Xumei Xi"],"pdf_url":"https://arxiv.org/pdf/2007.00736v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19028v2","updated":"2025-07-28T03:24:56Z","published":"2025-07-25T07:30:24Z","title":"Nonparametric Linear Discriminant Analysis for High Dimensional\n  Matrix-Valued Data","summary":"  This paper addresses classification problems with matrix-valued data, which\ncommonly arises in applications such as neuroimaging and signal processing.\nBuilding on the assumption that the data from each class follows a matrix\nnormal distribution, we propose a novel extension of Fisher's Linear\nDiscriminant Analysis (LDA) tailored for matrix-valued observations. To\neffectively capture structural information while maintaining estimation\nflexibility, we adopt a nonparametric empirical Bayes framework based on\nNonparametric Maximum Likelihood Estimation (NPMLE), applied to vectorized and\nscaled matrices. The NPMLE method has been shown to provide robust, flexible,\nand accurate estimates for vector-valued data with various structures in the\nmean vector or covariance matrix. By leveraging its strengths, our method is\neffectively generalized to the matrix setting, thereby improving classification\nperformance. Through extensive simulation studies and real data applications,\nincluding electroencephalography (EEG) and magnetic resonance imaging (MRI)\nanalysis, we demonstrate that the proposed method consistently outperforms\nexisting approaches across a variety of data structures.\n","authors":["Seungyeon Oh","Seongoh Park","Hoyoung Park"],"pdf_url":"https://arxiv.org/pdf/2507.19028v2.pdf","comment":"23 pages, 12 figures, 3 tables"},{"id":"http://arxiv.org/abs/2110.01950v2","updated":"2025-07-28T03:21:30Z","published":"2021-10-05T11:26:53Z","title":"Classification of high-dimensional data with spiked covariance matrix\n  structure","summary":"  We study the classification problem for high-dimensional data with $n$\nobservations on $p$ features where the $p \\times p$ covariance matrix $\\Sigma$\nexhibits a spiked eigenvalues structure and the vector $\\zeta$, given by the\ndifference between the whitened mean vectors, is sparse with sparsity at most\n$s$. We propose an adaptive classifier (adaptive with respect to the sparsity\n$s$) that first performs dimension reduction on the feature vectors prior to\nclassification in the dimensionally reduced space, i.e., the classifier\nwhitened the data, then screen the features by keeping only those corresponding\nto the $s$ largest coordinates of $\\zeta$ and finally apply Fisher linear\ndiscriminant on the selected features. Leveraging recent results on entrywise\nmatrix perturbation bounds for covariance matrices, we show that the resulting\nclassifier is Bayes optimal whenever $n \\rightarrow \\infty$ and $s \\sqrt{n^{-1}\n\\ln p} \\rightarrow 0$. Experimental results on real and synthetic data sets\nindicate that the proposed classifier is competitive with existing\nstate-of-the-art methods while also selecting a smaller number of features.\n","authors":["Yin-Jen Chen","Minh Tang"],"pdf_url":"https://arxiv.org/pdf/2110.01950v2.pdf","comment":"40 pages, 2 figures"},{"id":"http://arxiv.org/abs/2507.20459v1","updated":"2025-07-28T01:24:55Z","published":"2025-07-28T01:24:55Z","title":"Diagonally-Weighted Generalized Method of Moments Estimation for\n  Gaussian Mixture Modeling","summary":"  Since Pearson [Philosophical Transactions of the Royal Society of London. A,\n185 (1894), pp. 71-110] first applied the method of moments (MM) for modeling\ndata as a mixture of one-dimensional Gaussians, moment-based estimation methods\nhave proliferated. Among these methods, the generalized method of moments (GMM)\nimproves the statistical efficiency of MM by weighting the moments\nappropriately. However, the computational complexity and storage complexity of\nMM and GMM grow exponentially with the dimension, making these methods\nimpractical for high-dimensional data or when higher-order moments are\nrequired. Such computational bottlenecks are more severe in GMM since it\nadditionally requires estimating a large weighting matrix. To overcome these\nbottlenecks, we propose the diagonally-weighted GMM (DGMM), which achieves a\nbalance among statistical efficiency, computational complexity, and numerical\nstability. We apply DGMM to study the parameter estimation problem for weakly\nseparated heteroscedastic low-rank Gaussian mixtures and design a\ncomputationally efficient and numerically stable algorithm that obtains the\nDGMM estimator without explicitly computing or storing the moment tensors. We\nimplement the proposed algorithm and empirically validate the advantages of\nDGMM: in numerical studies, DGMM attains smaller estimation errors while\nrequiring substantially shorter runtime than MM and GMM. The code and data will\nbe available upon publication at https://github.com/liu-lzhang/dgmm.\n","authors":["Liu Zhang","Oscar Mickelin","Sheng Xu","Amit Singer"],"pdf_url":"https://arxiv.org/pdf/2507.20459v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21334v1","updated":"2025-07-28T21:01:00Z","published":"2025-07-28T21:01:00Z","title":"Graph neural networks for residential location choice: connection to\n  classical logit models","summary":"  Researchers have adopted deep learning for classical discrete choice analysis\nas it can capture complex feature relationships and achieve higher predictive\nperformance. However, the existing deep learning approaches cannot explicitly\ncapture the relationship among choice alternatives, which has been a\nlong-lasting focus in classical discrete choice models. To address the gap,\nthis paper introduces Graph Neural Network (GNN) as a novel framework to\nanalyze residential location choice. The GNN-based discrete choice models\n(GNN-DCMs) offer a structured approach for neural networks to capture\ndependence among spatial alternatives, while maintaining clear connections to\nclassical random utility theory. Theoretically, we demonstrate that the\nGNN-DCMs incorporate the nested logit (NL) model and the spatially correlated\nlogit (SCL) model as two specific cases, yielding novel algorithmic\ninterpretation through message passing among alternatives' utilities.\nEmpirically, the GNN-DCMs outperform benchmark MNL, SCL, and feedforward neural\nnetworks in predicting residential location choices among Chicago's 77\ncommunity areas. Regarding model interpretation, the GNN-DCMs can capture\nindividual heterogeneity and exhibit spatially-aware substitution patterns.\nOverall, these results highlight the potential of GNN-DCMs as a unified and\nexpressive framework for synergizing discrete choice modeling and deep learning\nin the complex spatial choice contexts.\n","authors":["Zhanhong Cheng","Lingqian Hu","Yuheng Bu","Yuqi Zhou","Shenhao Wang"],"pdf_url":"https://arxiv.org/pdf/2507.21334v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.01575v3","updated":"2025-07-28T18:22:19Z","published":"2025-02-03T17:59:34Z","title":"Heterogeneous Treatment Effect in Time-to-Event Outcomes: Harnessing\n  Censored Data with Recursively Imputed Trees","summary":"  Tailoring treatments to individual needs is a central goal in fields such as\nmedicine. A key step toward this goal is estimating Heterogeneous Treatment\nEffects (HTE) - the way treatments impact different subgroups. While crucial,\nHTE estimation is challenging with survival data, where time until an event\n(e.g., death) is key. Existing methods often assume complete observation, an\nassumption violated in survival data due to right-censoring, leading to bias\nand inefficiency. Cui et al. (2023) proposed a doubly-robust method for HTE\nestimation in survival data under no hidden confounders, combining a causal\nsurvival forest with an augmented inverse-censoring weighting estimator.\nHowever, we find it struggles under heavy censoring, which is common in\nrare-outcome problems such as Amyotrophic lateral sclerosis (ALS). Moreover,\nmost current methods cannot handle instrumental variables, which are a crucial\ntool in the causal inference arsenal. We introduce Multiple Imputation for\nSurvival Treatment Response (MISTR), a novel, general, and non-parametric\nmethod for estimating HTE in survival data. MISTR uses recursively imputed\nsurvival trees to handle censoring without directly modeling the censoring\nmechanism. Through extensive simulations and analysis of two real-world\ndatasets-the AIDS Clinical Trials Group Protocol 175 and the Illinois\nunemployment dataset we show that MISTR outperforms prior methods under heavy\ncensoring in the no-hidden-confounders setting, and extends to the instrumental\nvariable setting. To our knowledge, MISTR is the first non-parametric approach\nfor HTE estimation with unobserved confounders via instrumental variables.\n","authors":["Tomer Meir","Uri Shalit","Malka Gorfine"],"pdf_url":"https://arxiv.org/pdf/2502.01575v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21197v1","updated":"2025-07-28T04:37:03Z","published":"2025-07-28T04:37:03Z","title":"AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation\n  for EHR-Based Clinical Prediction","summary":"  Machine learning interpretation has primarily been leveraged to build\nclinician trust and uncover actionable insights in EHRs. However, the intrinsic\ncomplexity and heterogeneity of EHR data limit its effectiveness in guiding\nsubgroup-specific modeling. We propose AdaptHetero, a novel MLI-driven\nframework that transforms interpretability insights into actionable guidance\nfor tailoring model training and evaluation across subpopulations within\nindividual hospital systems. Evaluated on three large-scale EHR datasets -\nGOSSIS-1-eICU, WiDS, and MIMIC-IV - AdaptHetero consistently identifies\nheterogeneous model behaviors in predicting ICU mortality, in-hospital death,\nand hidden hypoxemia. By integrating SHAP-based interpretation and unsupervised\nclustering, the framework enhances the identification of clinically meaningful\nsubgroup-specific characteristics, leading to improved predictive performance.\n","authors":["Ling Liao","Eva Aagaard"],"pdf_url":"https://arxiv.org/pdf/2507.21197v1.pdf","comment":"11 pages, 3 figures"}],"Computation":[{"id":"http://arxiv.org/abs/2404.03867v2","updated":"2025-07-28T16:54:47Z","published":"2024-04-05T02:40:45Z","title":"Dimension-free Relaxation Times of Informed MCMC Samplers on Discrete\n  Spaces","summary":"  Convergence analysis of Markov chain Monte Carlo methods in high-dimensional\nstatistical applications is increasingly recognized. In this paper, we develop\ngeneral mixing time bounds for Metropolis-Hastings algorithms on discrete\nspaces by building upon and refining some recent theoretical advancements in\nBayesian model selection problems. We establish sufficient conditions for a\nclass of informed Metropolis-Hastings algorithms to attain relaxation times\nthat are independent of the problem dimension. These conditions are grounded in\nthe high-dimensional statistical theory and allow for possibly multimodal\nposterior distributions. We obtain our results through two independent\ntechniques: the multicommodity flow method and single-element drift condition\nanalysis; we find that the latter yields a slightly tighter mixing time bound.\nOur results are readily applicable to a broad spectrum of statistical problems\nwith discrete parameter spaces, as we demonstrate using both theoretical and\nnumerical examples.\n","authors":["Hyunwoong Chang","Quan Zhou"],"pdf_url":"https://arxiv.org/pdf/2404.03867v2.pdf","comment":"Accepted by Bernoulli"},{"id":"http://arxiv.org/abs/2507.20980v1","updated":"2025-07-28T16:43:11Z","published":"2025-07-28T16:43:11Z","title":"LargeMvC-Net: Anchor-based Deep Unfolding Network for Large-scale\n  Multi-view Clustering","summary":"  Deep anchor-based multi-view clustering methods enhance the scalability of\nneural networks by utilizing representative anchors to reduce the computational\ncomplexity of large-scale clustering. Despite their scalability advantages,\nexisting approaches often incorporate anchor structures in a heuristic or\ntask-agnostic manner, either through post-hoc graph construction or as\nauxiliary components for message passing. Such designs overlook the core\nstructural demands of anchor-based clustering, neglecting key optimization\nprinciples. To bridge this gap, we revisit the underlying optimization problem\nof large-scale anchor-based multi-view clustering and unfold its iterative\nsolution into a novel deep network architecture, termed LargeMvC-Net. The\nproposed model decomposes the anchor-based clustering process into three\nmodules: RepresentModule, NoiseModule, and AnchorModule, corresponding to\nrepresentation learning, noise suppression, and anchor indicator estimation.\nEach module is derived by unfolding a step of the original optimization\nprocedure into a dedicated network component, providing structural clarity and\noptimization traceability. In addition, an unsupervised reconstruction loss\naligns each view with the anchor-induced latent space, encouraging consistent\nclustering structures across views. Extensive experiments on several\nlarge-scale multi-view benchmarks show that LargeMvC-Net consistently\noutperforms state-of-the-art methods in terms of both effectiveness and\nscalability.\n","authors":["Shide Du","Chunming Wu","Zihan Fang","Wendi Zhao","Yilin Wu","Changwei Wang","Shiping Wang"],"pdf_url":"https://arxiv.org/pdf/2507.20980v1.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2410.19568v2","updated":"2025-07-28T12:43:01Z","published":"2024-10-25T13:59:22Z","title":"Prediction of microstructural representativity from a single image","summary":"  In this study, we present a method for predicting the representativity of the\nphase fraction observed in a single image (2D or 3D) of a material. Traditional\napproaches often require large datasets and extensive statistical analysis to\nestimate the Integral Range, a key factor in determining the variance of\nmicrostructural properties. Our method leverages the Two-Point Correlation\nfunction to directly estimate the variance from a single image, thereby\nenabling phase fraction prediction with associated confidence levels. We\nvalidate our approach using open-source datasets, demonstrating its efficacy\nacross diverse microstructures. This technique significantly reduces the data\nrequirements for representativity analysis, providing a practical tool for\nmaterial scientists and engineers working with limited microstructural data. To\nmake the method easily accessible, we have created a web-application,\nwww.imagerep.io, for quick, simple and informative use of the method.\n","authors":["Amir Dahari","Ronan Docherty","Steve Kench","Samuel J. Cooper"],"pdf_url":"https://arxiv.org/pdf/2410.19568v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20609v1","updated":"2025-07-28T08:20:59Z","published":"2025-07-28T08:20:59Z","title":"Independence Testing for Mixed Data","summary":"  We consider the problem of testing independence in mixed-type data that\ncombine count variables with positive, absolutely continuous variables. We\nfirst introduce two distinct classes of test statistics in the bivariate\nsetting, designed to test independence between the components of a bivariate\nmixed-type vector. These statistics are then extended to the multivariate\ncontext to accommodate: (i) testing independence between vectors of different\ntypes and possibly different dimensions, and (ii) testing total independence\namong all components of vectors with different types. The construction is based\non the recently introduced Baringhaus-Gaigall transformation, which\ncharacterizes the joint distribution of such data. We establish the asymptotic\nproperties of the resulting tests and, through an extensive power study,\ndemonstrate that the proposed approach is both competitive and flexible.\n","authors":["Dana Bucalo Jelić","Marija Cuparić","Bojana Milošević"],"pdf_url":"https://arxiv.org/pdf/2507.20609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.14822v2","updated":"2025-07-28T05:14:20Z","published":"2025-06-12T16:10:02Z","title":"Analysis and conditional optimization of projection estimates for\n  distribution of random variable using Legendre polynomials","summary":"  Algorithms for jointly obtaining projection estimates of the density and\ndistribution function of a random variable using Legendre polynomials are\nproposed. For these algorithms, a problem of the conditional optimization is\nsolved. Such optimization allows one to increase the approximation accuracy\nwith minimum computational costs. The proposed algorithms are tested on\nexamples with different degrees of smoothness of the density. A projection\nestimate of the density is compared to a histogram that is often used in\napplications to estimate distributions.\n","authors":["Tatyana A. Averina","Konstantin A. Rybakov"],"pdf_url":"https://arxiv.org/pdf/2506.14822v2.pdf","comment":null}]},"2025-07-27T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2507.20441v1","updated":"2025-07-27T23:31:55Z","published":"2025-07-27T23:31:55Z","title":"TIMEST: Temporal Information Motif Estimator Using Sampling Trees","summary":"  The mining of pattern subgraphs, known as motifs, is a core task in the field\nof graph mining. Edges in real-world networks often have timestamps, so there\nis a need for temporal motif mining. A temporal motif is a richer structure\nthat imposes timing constraints on the edges of the motif. Temporal motifs have\nbeen used to analyze social networks, financial transactions, and biological\nnetworks.\n  Motif counting in temporal graphs is particularly challenging. A graph with\nmillions of edges can have trillions of temporal motifs, since the same edge\ncan occur with multiple timestamps. There is a combinatorial explosion of\npossibilities, and state-of-the-art algorithms cannot manage motifs with more\nthan four vertices.\n  In this work, we present TIMEST: a general, fast, and accurate estimation\nalgorithm to count temporal motifs of arbitrary sizes in temporal networks. Our\napproach introduces a temporal spanning tree sampler that leverages weighted\nsampling to generate substructures of target temporal motifs. This method\ncarefully takes a subset of temporal constraints of the motif that can be\njointly and efficiently sampled. TIMEST uses randomized estimation techniques\nto obtain accurate estimates of motif counts.\n  We give theoretical guarantees on the running time and approximation\nguarantees of TIMEST. We perform an extensive experimental evaluation and show\nthat TIMEST is both faster and more accurate than previous algorithms. Our CPU\nimplementation exhibits an average speedup of 28x over state-of-the-art GPU\nimplementation of the exact algorithm, and 6x speedup over SOTA approximate\nalgorithms while consistently showcasing less than 5% error in most cases. For\nexample, TIMEST can count the number of instances of a financial fraud temporal\nmotif in four minutes with 0.6% error, while exact methods take more than two\ndays.\n","authors":["Yunjie Pan","Omkar Bhalerao","C. Seshadhri","Nishil Talati"],"pdf_url":"https://arxiv.org/pdf/2507.20441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.04626v2","updated":"2025-07-27T16:25:23Z","published":"2025-07-07T03:08:28Z","title":"Heterogeneous User Modeling for LLM-based Recommendation","summary":"  Leveraging Large Language Models (LLMs) for recommendation has demonstrated\nnotable success in various domains, showcasing their potential for open-domain\nrecommendation. A key challenge to advancing open-domain recommendation lies in\neffectively modeling user preferences from users' heterogeneous behaviors\nacross multiple domains. Existing approaches, including ID-based and\nsemantic-based modeling, struggle with poor generalization, an inability to\ncompress noisy interactions effectively, and the domain seesaw phenomenon. To\naddress these challenges, we propose a Heterogeneous User Modeling (HUM)\nmethod, which incorporates a compression enhancer and a robustness enhancer for\nLLM-based recommendation. The compression enhancer uses a customized prompt to\ncompress heterogeneous behaviors into a tailored token, while a masking\nmechanism enhances cross-domain knowledge extraction and understanding. The\nrobustness enhancer introduces a domain importance score to mitigate the domain\nseesaw phenomenon by guiding domain optimization. Extensive experiments on\nheterogeneous datasets validate that HUM effectively models user heterogeneity\nby achieving both high efficacy and robustness, leading to superior performance\nin open-domain recommendation.\n","authors":["Honghui Bao","Wenjie Wang","Xinyu Lin","Fengbin Zhu","Teng Sun","Fuli Feng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2507.04626v2.pdf","comment":"Accepted by RecSys 2025"},{"id":"http://arxiv.org/abs/2507.20327v1","updated":"2025-07-27T15:36:13Z","published":"2025-07-27T15:36:13Z","title":"TADT-CSA: Temporal Advantage Decision Transformer with Contrastive State\n  Abstraction for Generative Recommendation","summary":"  With the rapid advancement of Transformer-based Large Language Models (LLMs),\ngenerative recommendation has shown great potential in enhancing both the\naccuracy and semantic understanding of modern recommender systems. Compared to\nLLMs, the Decision Transformer (DT) is a lightweight generative model applied\nto sequential recommendation tasks. However, DT faces challenges in trajectory\nstitching, often producing suboptimal trajectories. Moreover, due to the high\ndimensionality of user states and the vast state space inherent in\nrecommendation scenarios, DT can incur significant computational costs and\nstruggle to learn effective state representations. To overcome these issues, we\npropose a novel Temporal Advantage Decision Transformer with Contrastive State\nAbstraction (TADT-CSA) model. Specifically, we combine the conventional\nReturn-To-Go (RTG) signal with a novel temporal advantage (TA) signal that\nencourages the model to capture both long-term returns and their sequential\ntrend. Furthermore, we integrate a contrastive state abstraction module into\nthe DT framework to learn more effective and expressive state representations.\nWithin this module, we introduce a TA-conditioned State Vector Quantization\n(TAC-SVQ) strategy, where the TA score guides the state codebooks to\nincorporate contextual token information. Additionally, a reward prediction\nnetwork and a contrastive transition prediction (CTP) network are employed to\nensure the state codebook preserves both the reward information of the current\nstate and the transition information between adjacent states. Empirical results\non both public datasets and an online recommendation system demonstrate the\neffectiveness of the TADT-CSA model and its superiority over baseline methods.\n","authors":["Xiang Gao","Tianyuan Liu","Yisha Li","Jingxin Liu","Lexi Gao","Xin Li","Haiyang Lu","Liyin Hong"],"pdf_url":"https://arxiv.org/pdf/2507.20327v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20227v1","updated":"2025-07-27T11:13:03Z","published":"2025-07-27T11:13:03Z","title":"CTR-Driven Ad Text Generation via Online Feedback Preference\n  Optimization","summary":"  Advertising text plays a critical role in determining click-through rates\n(CTR) in online advertising. Large Language Models (LLMs) offer significant\nefficiency advantages over manual ad text creation. However, LLM-generated ad\ntexts do not guarantee higher CTR performance compared to human-crafted texts,\nrevealing a gap between generation quality and online performance of ad texts.\nIn this work, we propose a novel ad text generation method which optimizes for\nCTR through preference optimization from online feedback. Our approach adopts\nan innovative two-stage framework: (1) diverse ad text sampling via one-shot\nin-context learning, using retrieval-augmented generation (RAG) to provide\nexemplars with chain-of-thought (CoT) reasoning; (2) CTR-driven preference\noptimization from online feedback, which weighs preference pairs according to\ntheir CTR gains and confidence levels. Through our method, the resulting model\nenables end-to-end generation of high-CTR ad texts. Extensive experiments have\ndemonstrated the effectiveness of our method in both offline and online\nmetrics. Notably, we have applied our method on a large-scale online shopping\nplatform and achieved significant CTR improvements, showcasing its strong\napplicability and effectiveness in advertising systems.\n","authors":["Yanda Chen","Zihui Ren","Qixiang Gao","Jiale Chen","Si Chen","Xubin Li","Tiezheng Ge","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2507.20227v1.pdf","comment":"9 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2507.17402v2","updated":"2025-07-27T08:26:55Z","published":"2025-07-23T10:59:46Z","title":"HLFormer: Enhancing Partially Relevant Video Retrieval with Hyperbolic\n  Learning","summary":"  Partially Relevant Video Retrieval (PRVR) addresses the critical challenge of\nmatching untrimmed videos with text queries describing only partial content.\nExisting methods suffer from geometric distortion in Euclidean space that\nsometimes misrepresents the intrinsic hierarchical structure of videos and\noverlooks certain hierarchical semantics, ultimately leading to suboptimal\ntemporal modeling. To address this issue, we propose the first hyperbolic\nmodeling framework for PRVR, namely HLFormer, which leverages hyperbolic space\nlearning to compensate for the suboptimal hierarchical modeling capabilities of\nEuclidean space. Specifically, HLFormer integrates the Lorentz Attention Block\nand Euclidean Attention Block to encode video embeddings in hybrid spaces,\nusing the Mean-Guided Adaptive Interaction Module to dynamically fuse features.\nAdditionally, we introduce a Partial Order Preservation Loss to enforce \"text <\nvideo\" hierarchy through Lorentzian cone constraints. This approach further\nenhances cross-modal matching by reinforcing partial relevance between video\ncontent and text queries. Extensive experiments show that HLFormer outperforms\nstate-of-the-art methods. Code is released at\nhttps://github.com/lijun2005/ICCV25-HLFormer.\n","authors":["Jun Li","Jinpeng Wang","Chaolei Tan","Niu Lian","Long Chen","Yaowei Wang","Min Zhang","Shu-Tao Xia","Bin Chen"],"pdf_url":"https://arxiv.org/pdf/2507.17402v2.pdf","comment":"Accepted by ICCV'25. 13 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2507.20161v1","updated":"2025-07-27T07:28:27Z","published":"2025-07-27T07:28:27Z","title":"Practical Multi-Task Learning for Rare Conversions in Ad Tech","summary":"  We present a Multi-Task Learning (MTL) approach for improving predictions for\nrare (e.g., <1%) conversion events in online advertising. The conversions are\nclassified into \"rare\" or \"frequent\" types based on historical statistics. The\nmodel learns shared representations across all signals while specializing\nthrough separate task towers for each type. The approach was tested and fully\ndeployed to production, demonstrating consistent improvements in both offline\n(0.69% AUC lift) and online KPI performance metric (2% Cost per Action\nreduction).\n","authors":["Yuval Dishi","Ophir Friedler","Yonatan Karni","Natalia Silberstein","Yulia Stolin"],"pdf_url":"https://arxiv.org/pdf/2507.20161v1.pdf","comment":"Accepted to RecSys 2025"},{"id":"http://arxiv.org/abs/2404.15678v5","updated":"2025-07-27T07:23:00Z","published":"2024-04-24T06:16:09Z","title":"Retrieval and Distill: A Temporal Data Shift-Free Paradigm for Online\n  Recommendation System","summary":"  Current recommendation systems are significantly affected by a serious issue\nof temporal data shift, which is the inconsistency between the distribution of\nhistorical data and that of online data. Most existing models focus on\nutilizing updated data, overlooking the transferable, temporal data shift-free\ninformation that can be learned from shifting data. We propose the Temporal\nInvariance of Association theorem, which suggests that given a fixed search\nspace, the relationship between the data and the data in the search space keeps\ninvariant over time. Leveraging this principle, we designed a retrieval-based\nrecommendation system framework that can train a data shift-free relevance\nnetwork using shifting data, significantly enhancing the predictive performance\nof the original model in the recommendation system. However, retrieval-based\nrecommendation models face substantial inference time costs when deployed\nonline. To address this, we further designed a distill framework that can\ndistill information from the relevance network into a parameterized module\nusing shifting data. The distilled model can be deployed online alongside the\noriginal model, with only a minimal increase in inference time. Extensive\nexperiments on multiple real datasets demonstrate that our framework\nsignificantly improves the performance of the original model by utilizing\nshifting data.\n","authors":["Lei Zheng","Ning Li","Weinan Zhang","Yong Yu"],"pdf_url":"https://arxiv.org/pdf/2404.15678v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20147v1","updated":"2025-07-27T06:54:00Z","published":"2025-07-27T06:54:00Z","title":"Integrating LLM-Derived Multi-Semantic Intent into Graph Model for\n  Session-based Recommendation","summary":"  Session-based recommendation (SBR) is mainly based on anonymous user\ninteraction sequences to recommend the items that the next user is most likely\nto click. Currently, the most popular and high-performing SBR methods primarily\nleverage graph neural networks (GNNs), which model session sequences as\ngraph-structured data to effectively capture user intent. However, most\nGNNs-based SBR methods primarily focus on modeling the ID sequence information\nof session sequences, while neglecting the rich semantic information embedded\nwithin them. This limitation significantly hampers model's ability to\naccurately infer users' true intention. To address above challenge, this paper\nproposes a novel SBR approach called Integrating LLM-Derived Multi-Semantic\nIntent into Graph Model for Session-based Recommendation (LLM-DMsRec). The\nmethod utilizes a pre-trained GNN model to select the top-k items as candidate\nitem sets and designs prompts along with a large language model (LLM) to infer\nmulti-semantic intents from these candidate items. Specifically, we propose an\nalignment mechanism that effectively integrates the semantic intent inferred by\nthe LLM with the structural intent captured by GNNs. Extensive experiments\nconducted on the Beauty and ML-1M datasets demonstrate that the proposed method\ncan be seamlessly integrated into GNNs framework, significantly enhancing its\nrecommendation performance.\n","authors":["Shuo Zhang","Xiao Li","Jiayi Wu","Fan Yang","Xiang Li","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2507.20147v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20136v1","updated":"2025-07-27T05:45:45Z","published":"2025-07-27T05:45:45Z","title":"Multi-Stage Verification-Centric Framework for Mitigating Hallucination\n  in Multi-Modal RAG","summary":"  This paper presents the technical solution developed by team CRUISE for the\nKDD Cup 2025 Meta Comprehensive RAG Benchmark for Multi-modal, Multi-turn\n(CRAG-MM) challenge. The challenge aims to address a critical limitation of\nmodern Vision Language Models (VLMs): their propensity to hallucinate,\nespecially when faced with egocentric imagery, long-tail entities, and complex,\nmulti-hop questions. This issue is particularly problematic in real-world\napplications where users pose fact-seeking queries that demand high factual\naccuracy across diverse modalities. To tackle this, we propose a robust,\nmulti-stage framework that prioritizes factual accuracy and truthfulness over\ncompleteness. Our solution integrates a lightweight query router for\nefficiency, a query-aware retrieval and summarization pipeline, a dual-pathways\ngeneration and a post-hoc verification. This conservative strategy is designed\nto minimize hallucinations, which incur a severe penalty in the competition's\nscoring metric. Our approach achieved 3rd place in Task 1, demonstrating the\neffectiveness of prioritizing answer reliability in complex multi-modal RAG\nsystems. Our implementation is available at\nhttps://github.com/Breezelled/KDD-Cup-2025-Meta-CRAG-MM .\n","authors":["Baiyu Chen","Wilson Wongso","Xiaoqian Hu","Yue Tan","Flora Salim"],"pdf_url":"https://arxiv.org/pdf/2507.20136v1.pdf","comment":"KDD Cup 2025 Meta CRAG-MM Challenge"},{"id":"http://arxiv.org/abs/2502.12145v2","updated":"2025-07-27T00:10:15Z","published":"2025-02-17T18:56:20Z","title":"Fast or Better? Balancing Accuracy and Cost in Retrieval-Augmented\n  Generation with Flexible User Control","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to\nmitigate large language model (LLM) hallucinations by incorporating external\nknowledge retrieval. However, existing RAG frameworks often apply retrieval\nindiscriminately,leading to inefficiencies-over-retrieving when unnecessary or\nfailing to retrieve iteratively when required for complex reasoning. Recent\nadaptive retrieval strategies, though adaptively navigates these retrieval\nstrategies, predict only based on query complexity and lacks user-driven\nflexibility, making them infeasible for diverse user application needs. In this\npaper, we introduce a novel user-controllable RAG framework that enables\ndynamic adjustment of the accuracy-cost trade-off. Our approach leverages two\nclassifiers: one trained to prioritize accuracy and another to prioritize\nretrieval efficiency. Via an interpretable control parameter $\\alpha$, users\ncan seamlessly navigate between minimal-cost retrieval and high-accuracy\nretrieval based on their specific requirements. We empirically demonstrate that\nour approach effectively balances accuracy, retrieval cost, and user\ncontrollability, making it a practical and adaptable solution for real-world\napplications. Code is available at https://github.com/JinyanSu1/Flare-Aug.\n","authors":["Jinyan Su","Jennifer Healey","Preslav Nakov","Claire Cardie"],"pdf_url":"https://arxiv.org/pdf/2502.12145v2.pdf","comment":null}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2305.15612v5","updated":"2025-07-27T22:20:30Z","published":"2023-05-24T23:01:56Z","title":"Density Ratio Estimation-based Bayesian Optimization with\n  Semi-Supervised Learning","summary":"  Bayesian optimization has attracted huge attention from diverse research\nareas in science and engineering, since it is capable of efficiently finding a\nglobal optimum of an expensive-to-evaluate black-box function. In general, a\nprobabilistic regression model is widely used as a surrogate function to model\nan explicit distribution over function evaluations given an input to estimate\nand a training dataset. Beyond the probabilistic regression-based methods,\ndensity ratio estimation-based Bayesian optimization has been suggested in\norder to estimate a density ratio of the groups relatively close and relatively\nfar to a global optimum. Developing this line of research further, supervised\nclassifiers are employed to estimate a class probability for the two groups\ninstead of a density ratio. However, the supervised classifiers used in this\nstrategy are prone to be overconfident for known knowledge on global solution\ncandidates. Supposing that we have access to unlabeled points, e.g., predefined\nfixed-size pools, we propose density ratio estimation-based Bayesian\noptimization with semi-supervised learning to solve this challenge. Finally, we\nshow the empirical results of our methods and several baseline methods in two\ndistinct scenarios with unlabeled point sampling and a fixed-size pool, and\nanalyze the validity of our methods in diverse experiments.\n","authors":["Jungtaek Kim"],"pdf_url":"https://arxiv.org/pdf/2305.15612v5.pdf","comment":"Accepted at the 42nd International Conference on Machine Learning\n  (ICML 2025)"},{"id":"http://arxiv.org/abs/2506.16550v2","updated":"2025-07-27T20:04:17Z","published":"2025-06-19T19:13:02Z","title":"A Free Probabilistic Framework for Analyzing the Transformer-based\n  Language Models","summary":"  We present a formal operator-theoretic framework for analyzing\nTransformer-based language models using free probability theory. By modeling\ntoken embeddings and attention mechanisms as self-adjoint operators in a\ntracial \\( W^* \\)-probability space, we reinterpret attention as\nnon-commutative convolution and describe representation propagation via free\nadditive convolution. This leads to a spectral dynamic system interpretation of\ndeep Transformers. We derive entropy-based generalization bounds under freeness\nassumptions and provide insight into positional encoding, spectral evolution,\nand representational complexity. This work offers a principled, though\ntheoretical, perspective on structural dynamics in large language models.\n","authors":["Swagatam Das"],"pdf_url":"https://arxiv.org/pdf/2506.16550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00982v3","updated":"2025-07-27T19:31:09Z","published":"2023-02-02T10:02:01Z","title":"Stochastic optimal transport in Banach Spaces for regularized estimation\n  of multivariate quantiles","summary":"  We introduce a new stochastic algorithm for solving entropic optimal\ntransport (EOT) between two absolutely continuous probability measures $\\mu$\nand $\\nu$. Our work is motivated by the specific setting of Monge-Kantorovich\nquantiles where the source measure $\\mu$ is either the uniform distribution on\nthe unit hypercube or the spherical uniform distribution. Using the knowledge\nof the source measure, we propose to parametrize a Kantorovich dual potential\nby its Fourier coefficients. In this way, each iteration of our stochastic\nalgorithm reduces to two Fourier transforms that enables us to make use of the\nFast Fourier Transform (FFT) in order to implement a fast numerical method to\nsolve EOT. We study the almost sure convergence of our stochastic algorithm\nthat takes its values in an infinite-dimensional Banach space. Then, using\nnumerical experiments, we illustrate the performances of our approach on the\ncomputation of regularized Monge-Kantorovich quantiles. In particular, we\ninvestigate the potential benefits of entropic regularization for the smooth\nestimation of multivariate quantiles using data sampled from the target measure\n$\\nu$.\n","authors":["Bernard Bercu","Jérémie Bigot","Gauthier Thurin"],"pdf_url":"https://arxiv.org/pdf/2302.00982v3.pdf","comment":"32 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.20353v1","updated":"2025-07-27T16:56:01Z","published":"2025-07-27T16:56:01Z","title":"A Theory of $θ$-Expectations","summary":"  The canonical theory of stochastic calculus under ambiguity, founded on\nsub-additivity, is insensitive to non-convex uncertainty structures, leading to\nan identifiability impasse. This paper develops a mathematical framework for an\nidentifiable calculus sensitive to non-convex geometry. We introduce the\n$\\theta$-BSDE, a class of backward stochastic differential equations where the\ndriver is determined by a pointwise maximization over a primitive, possibly\nnon-convex, uncertainty set. The system's tractability is predicated not on\nconvexity, but on a global analytic hypothesis: the existence of a unique and\nglobally Lipschitz maximizer map for the driver function. Under this\nhypothesis, which carves out a tractable class of models, we establish\nwell-posedness via a fixed-point argument. For a distinct, geometrically\nregular class of models, we prove a result of independent interest: under\nnon-degeneracy conditions from Malliavin calculus, the maximizer is unique\nalong any solution path, ensuring the model's internal consistency. We clarify\nthe fundamental logical gap between this pathwise property and the global\nregularity required by our existence proof. The resulting valuation operator\ndefines a dynamically consistent expectation, and we establish its connection\nto fully nonlinear PDEs via a Feynman-Kac formula.\n","authors":["Qian Qi"],"pdf_url":"https://arxiv.org/pdf/2507.20353v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20333v1","updated":"2025-07-27T15:51:23Z","published":"2025-07-27T15:51:23Z","title":"The Blessing and Curse of Dimensionality in Safety Alignment","summary":"  The focus on safety alignment in large language models (LLMs) has increased\nsignificantly due to their widespread adoption across different domains. The\nscale of LLMs play a contributing role in their success, and the growth in\nparameter count follows larger hidden dimensions. In this paper, we hypothesize\nthat while the increase in dimensions has been a key advantage, it may lead to\nemergent problems as well. These problems emerge as the linear structures in\nthe activation space can be exploited, in the form of activation engineering,\nto circumvent its safety alignment. Through detailed visualizations of linear\nsubspaces associated with different concepts, such as safety, across various\nmodel scales, we show that the curse of high-dimensional representations\nuniquely impacts LLMs. Further substantiating our claim, we demonstrate that\nprojecting the representations of the model onto a lower dimensional subspace\ncan preserve sufficient information for alignment while avoiding those linear\nstructures. Empirical results confirm that such dimensional reduction\nsignificantly reduces susceptibility to jailbreaking through representation\nengineering. Building on our empirical validations, we provide theoretical\ninsights into these linear jailbreaking methods relative to a model's hidden\ndimensions. Broadly speaking, our work posits that the high dimensions of a\nmodel's internal representations can be both a blessing and a curse in safety\nalignment.\n","authors":["Rachel S. Y. Teo","Laziz U. Abdullaev","Tan M. Nguyen"],"pdf_url":"https://arxiv.org/pdf/2507.20333v1.pdf","comment":"Published as a conference paper at COLM 2025"},{"id":"http://arxiv.org/abs/2507.05297v6","updated":"2025-07-27T13:54:48Z","published":"2025-07-06T09:13:22Z","title":"Continuous Classification Aggregation","summary":"  We prove that any optimal, independent, and zero unanimous fuzzy\nclassification aggregation function of a continuum of individual\nclassifications of $m\\ge 3$ objects into $2\\le p\\le m$ types must be a weighted\narithmetic mean. We also provide a characterization for the case when $m=p=2$.\n","authors":["Zijun Meng"],"pdf_url":"https://arxiv.org/pdf/2507.05297v6.pdf","comment":"9 pages; 2 figures"},{"id":"http://arxiv.org/abs/2507.20272v1","updated":"2025-07-27T13:34:32Z","published":"2025-07-27T13:34:32Z","title":"Approximating Full Conformal Prediction for Neural Network Regression\n  with Gauss-Newton Influence","summary":"  Uncertainty quantification is an important prerequisite for the deployment of\ndeep learning models in safety-critical areas. Yet, this hinges on the\nuncertainty estimates being useful to the extent the prediction intervals are\nwell-calibrated and sharp. In the absence of inherent uncertainty estimates\n(e.g. pretrained models predicting only point estimates), popular approaches\nthat operate post-hoc include Laplace's method and split conformal prediction\n(split-CP). However, Laplace's method can be miscalibrated when the model is\nmisspecified and split-CP requires sample splitting, and thus comes at the\nexpense of statistical efficiency. In this work, we construct prediction\nintervals for neural network regressors post-hoc without held-out data. This is\nachieved by approximating the full conformal prediction method (full-CP).\nWhilst full-CP nominally requires retraining the model for every test point and\ncandidate label, we propose to train just once and locally perturb model\nparameters using Gauss-Newton influence to approximate the effect of\nretraining. Coupled with linearization of the network, we express the absolute\nresidual nonconformity score as a piecewise linear function of the candidate\nlabel allowing for an efficient procedure that avoids the exhaustive search\nover the output space. On standard regression benchmarks and bounding box\nlocalization, we show the resulting prediction intervals are locally-adaptive\nand often tighter than those of split-CP.\n","authors":["Dharmesh Tailor","Alvaro H. C. Correia","Eric Nalisnick","Christos Louizos"],"pdf_url":"https://arxiv.org/pdf/2507.20272v1.pdf","comment":"Accepted at the 13th International Conference on Learning\n  Representations (ICLR 2025)"},{"id":"http://arxiv.org/abs/2507.20268v1","updated":"2025-07-27T13:31:02Z","published":"2025-07-27T13:31:02Z","title":"Data-Efficient Prediction-Powered Calibration via Cross-Validation","summary":"  Calibration data are necessary to formally quantify the uncertainty of the\ndecisions produced by an existing artificial intelligence (AI) model. To\novercome the common issue of scarce calibration data, a promising approach is\nto employ synthetic labels produced by a (generally different) predictive\nmodel. However, fine-tuning the label-generating predictor on the inference\ntask of interest, as well as estimating the residual bias of the synthetic\nlabels, demand additional data, potentially exacerbating the calibration data\nscarcity problem. This paper introduces a novel approach that efficiently\nutilizes limited calibration data to simultaneously fine-tune a predictor and\nestimate the bias of the synthetic labels. The proposed method yields\nprediction sets with rigorous coverage guarantees for AI-generated decisions.\nExperimental results on an indoor localization problem validate the\neffectiveness and performance gains of our solution.\n","authors":["Seonghoon Yoo","Houssem Sifaou","Sangwoo Park","Joonhyuk Kang","Osvaldo Simeone"],"pdf_url":"https://arxiv.org/pdf/2507.20268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11174v2","updated":"2025-07-27T12:11:11Z","published":"2024-12-15T13:00:23Z","title":"Semi-Supervised Risk Control via Prediction-Powered Inference","summary":"  The risk-controlling prediction sets (RCPS) framework is a general tool for\ntransforming the output of any machine learning model to design a predictive\nrule with rigorous error rate control. The key idea behind this framework is to\nuse labeled hold-out calibration data to tune a hyper-parameter that affects\nthe error rate of the resulting prediction rule. However, the limitation of\nsuch a calibration scheme is that with limited hold-out data, the tuned\nhyper-parameter becomes noisy and leads to a prediction rule with an error rate\nthat is often unnecessarily conservative. To overcome this sample-size barrier,\nwe introduce a semi-supervised calibration procedure that leverages unlabeled\ndata to rigorously tune the hyper-parameter without compromising statistical\nvalidity. Our procedure builds upon the prediction-powered inference framework,\ncarefully tailoring it to risk-controlling tasks. We demonstrate the benefits\nand validity of our proposal through two real-data experiments: few-shot image\nclassification and early time series classification.\n","authors":["Bat-Sheva Einbinder","Liran Ringel","Yaniv Romano"],"pdf_url":"https://arxiv.org/pdf/2412.11174v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20126v1","updated":"2025-07-27T04:25:29Z","published":"2025-07-27T04:25:29Z","title":"An Automated Deep Segmentation and Spatial-Statistics Approach for\n  Post-Blast Rock Fragmentation Assessment","summary":"  We introduce an end-to-end pipeline that leverages a fine-tuned YOLO12l-seg\nmodel -- trained on over 500 annotated post-blast images -- to deliver\nreal-time instance segmentation (Box mAP@0.5 ~ 0.769, Mask mAP@0.5 ~ 0.800 at ~\n15 FPS). High-fidelity masks are converted into normalized 3D coordinates, from\nwhich we extract multi-metric spatial descriptors: principal component\ndirections, kernel density hotspots, size-depth regression, and Delaunay edge\nstatistics. We present four representative examples to illustrate key\nfragmentation patterns. Experimental results confirm the framework's accuracy,\nrobustness to small-object crowding, and feasibility for rapid, automated\nblast-effect assessment in field conditions.\n","authors":["Yukun Yang"],"pdf_url":"https://arxiv.org/pdf/2507.20126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00810v3","updated":"2025-07-27T04:22:52Z","published":"2025-03-02T09:32:06Z","title":"Minimax Optimal Reinforcement Learning with Quasi-Optimism","summary":"  In our quest for a reinforcement learning (RL) algorithm that is both\npractical and provably optimal, we introduce EQO (Exploration via\nQuasi-Optimism). Unlike existing minimax optimal approaches, EQO avoids\nreliance on empirical variances and employs a simple bonus term proportional to\nthe inverse of the state-action visit count. Central to EQO is the concept of\nquasi-optimism, where estimated values need not be fully optimistic, allowing\nfor a simpler yet effective exploration strategy. The algorithm achieves the\nsharpest known regret bound for tabular RL under the mildest assumptions,\nproving that fast convergence can be attained with a practical and\ncomputationally efficient approach. Empirical evaluations demonstrate that EQO\nconsistently outperforms existing algorithms in both regret performance and\ncomputational efficiency, providing the best of both theoretical soundness and\npractical effectiveness.\n","authors":["Harin Lee","Min-hwan Oh"],"pdf_url":"https://arxiv.org/pdf/2503.00810v3.pdf","comment":"Minor corrections to constant factors"},{"id":"http://arxiv.org/abs/2507.20112v1","updated":"2025-07-27T03:32:51Z","published":"2025-07-27T03:32:51Z","title":"Online Learning with Probing for Sequential User-Centric Selection","summary":"  We formalize sequential decision-making with information acquisition as the\nprobing-augmented user-centric selection (PUCS) framework, where a learner\nfirst probes a subset of arms to obtain side information on resources and\nrewards, and then assigns $K$ plays to $M$ arms. PUCS covers applications such\nas ridesharing, wireless scheduling, and content recommendation, in which both\nresources and payoffs are initially unknown and probing is costly. For the\noffline setting with known distributions, we present a greedy probing algorithm\nwith a constant-factor approximation guarantee $\\zeta = (e-1)/(2e-1)$. For the\nonline setting with unknown distributions, we introduce OLPA, a stochastic\ncombinatorial bandit algorithm that achieves a regret bound\n$\\mathcal{O}(\\sqrt{T} + \\ln^{2} T)$. We also prove a lower bound\n$\\Omega(\\sqrt{T})$, showing that the upper bound is tight up to logarithmic\nfactors. Experiments on real-world data demonstrate the effectiveness of our\nsolutions.\n","authors":["Tianyi Xu","Yiting Chen","Henger Li","Zheyong Bian","Emiliano Dall'Anese","Zizhan Zheng"],"pdf_url":"https://arxiv.org/pdf/2507.20112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20108v1","updated":"2025-07-27T02:34:08Z","published":"2025-07-27T02:34:08Z","title":"Graded Transformers: A Symbolic-Geometric Approach to Structured\n  Learning","summary":"  We introduce the Graded Transformer framework, a novel class of sequence\nmodels that embeds algebraic inductive biases through grading transformations\non vector spaces. Extending the theory of Graded Neural Networks (GNNs), we\npropose two architectures: the Linearly Graded Transformer (LGT) and the\nExponentially Graded Transformer (EGT). These models apply parameterized\nscaling operators-governed by fixed or learnable grading tuples and, for EGT,\nexponential factors to infuse hierarchical structure into attention and\nrepresentation layers, enhancing efficiency for structured data.\n  We derive rigorous theoretical guarantees, including universal approximation\ntheorems for continuous and Sobolev functions, reduced sample complexity via\neffective VC dimension bounds, Lipschitz continuity of graded operations, and\nrobustness to adversarial perturbations. A graded loss function ensures\ngradient stability and alignment with domain priors during optimization. By\ntreating grades as differentiable parameters, the framework enables adaptive\nfeature prioritization, overcoming limitations of fixed grades in prior work.\n  The Graded Transformer holds transformative potential for hierarchical\nlearning and neurosymbolic reasoning, with applications spanning algebraic\ngeometry (e.g., moduli spaces and zeta functions), physics (e.g., multiscale\nsimulations), natural language processing (e.g., syntactic parsing), biological\nsequence analysis (e.g., variant prediction), and emerging areas like graph\nneural networks and financial modeling. This work advances structured deep\nlearning by fusing geometric and algebraic principles with attention\nmechanisms, offering a mathematically grounded alternative to data-driven\nmodels and paving the way for interpretable, efficient systems in complex\ndomains.\n","authors":["Tony Shaska Sr"],"pdf_url":"https://arxiv.org/pdf/2507.20108v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20089v1","updated":"2025-07-27T00:50:29Z","published":"2025-07-27T00:50:29Z","title":"Meta Fusion: A Unified Framework For Multimodality Fusion with Mutual\n  Learning","summary":"  Developing effective multimodal data fusion strategies has become\nincreasingly essential for improving the predictive power of statistical\nmachine learning methods across a wide range of applications, from autonomous\ndriving to medical diagnosis. Traditional fusion methods, including early,\nintermediate, and late fusion, integrate data at different stages, each\noffering distinct advantages and limitations. In this paper, we introduce Meta\nFusion, a flexible and principled framework that unifies these existing\nstrategies as special cases. Motivated by deep mutual learning and ensemble\nlearning, Meta Fusion constructs a cohort of models based on various\ncombinations of latent representations across modalities, and further boosts\npredictive performance through soft information sharing within the cohort. Our\napproach is model-agnostic in learning the latent representations, allowing it\nto flexibly adapt to the unique characteristics of each modality.\nTheoretically, our soft information sharing mechanism reduces the\ngeneralization error. Empirically, Meta Fusion consistently outperforms\nconventional fusion strategies in extensive simulation studies. We further\nvalidate our approach on real-world applications, including Alzheimer's disease\ndetection and neural decoding.\n","authors":["Ziyi Liang","Annie Qu","Babak Shahbaba"],"pdf_url":"https://arxiv.org/pdf/2507.20089v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.18300v3","updated":"2025-07-27T00:40:47Z","published":"2025-05-23T18:46:10Z","title":"Beyond Self-Repellent Kernels: History-Driven Target Towards Efficient\n  Nonlinear MCMC on General Graphs","summary":"  We propose a history-driven target (HDT) framework in Markov Chain Monte\nCarlo (MCMC) to improve any random walk algorithm on discrete state spaces,\nsuch as general undirected graphs, for efficient sampling from target\ndistribution $\\boldsymbol{\\mu}$. With broad applications in network science and\ndistributed optimization, recent innovations like the self-repellent random\nwalk (SRRW) achieve near-zero variance by prioritizing under-sampled states\nthrough transition kernel modifications based on past visit frequencies.\nHowever, SRRW's reliance on explicit computation of transition probabilities\nfor all neighbors at each step introduces substantial computational overhead,\nwhile its strict dependence on time-reversible Markov chains excludes advanced\nnon-reversible MCMC methods. To overcome these limitations, instead of direct\nmodification of transition kernel, HDT introduces a history-dependent target\ndistribution $\\boldsymbol{\\pi}[\\mathbf{x}]$ to replace the original target\n$\\boldsymbol{\\mu}$ in any graph sampler, where $\\mathbf{x}$ represents the\nempirical measure of past visits. This design preserves lightweight\nimplementation by requiring only local information between the current and\nproposed states and achieves compatibility with both reversible and\nnon-reversible MCMC samplers, while retaining unbiased samples with target\ndistribution $\\boldsymbol{\\mu}$ and near-zero variance performance. Extensive\nexperiments in graph sampling demonstrate consistent performance gains, and a\nmemory-efficient Least Recently Used (LRU) cache ensures scalability to large\ngeneral graphs.\n","authors":["Jie Hu","Yi-Ting Ma","Do Young Eun"],"pdf_url":"https://arxiv.org/pdf/2505.18300v3.pdf","comment":"Accepted at ICML 2025 (Oral)"},{"id":"http://arxiv.org/abs/2507.20088v1","updated":"2025-07-27T00:35:15Z","published":"2025-07-27T00:35:15Z","title":"Feed-anywhere ANN (I) Steady Discrete $\\to$ Diffusing on Graph Hidden\n  States","summary":"  We propose a novel framework for learning hidden graph structures from data\nusing geometric analysis and nonlinear dynamics. Our approach: (1) Defines\ndiscrete Sobolev spaces on graphs for scalar/vector fields, establishing key\nfunctional properties; (2) Introduces gauge-equivalent nonlinear Schr\\\"odinger\nand Landau--Lifshitz dynamics with provable stable stationary solutions\nsmoothly dependent on input data and graph weights; (3) Develops a stochastic\ngradient algorithm over graph moduli spaces with sparsity regularization.\nTheoretically, we guarantee: topological correctness (homology recovery),\nmetric convergence (Gromov--Hausdorff), and efficient search space utilization.\nOur dynamics-based model achieves stronger generalization bounds than standard\nneural networks, with complexity dependent on the data manifold's topology.\n","authors":["Dmitry Pasechnyuk-Vilensky","Daniil Doroshenko"],"pdf_url":"https://arxiv.org/pdf/2507.20088v1.pdf","comment":"11 pages, 1 algorithm"}],"Computation":[{"id":"http://arxiv.org/abs/2507.20329v1","updated":"2025-07-27T15:45:17Z","published":"2025-07-27T15:45:17Z","title":"Clustering data with values missing at random using scale mixtures of\n  multivariate skew-normal distributions","summary":"  Handling missing data is a major challenge in model-based clustering,\nespecially when the data exhibit skewness and heavy tails. We address this by\nextending the finite mixture of scale mixtures of multivariate skew-normal\n(FMSMSN) family to accommodate incomplete data under a missing at random (MAR)\nmechanism. Unlike previous work that is limited to one of the special cases of\nthe FMSMSN family, our method offers a cluster analysis methodology for the\nentire family that accounts for skewness and excess kurtosis amidst data with\nmissing values. The multivariate skew-normal distribution, as parameterised by\n\\cite{azzalini1996} and \\cite{arnoldbeaver} includes the normal distribution as\na special case, which ensures that our method is flexible toward existing\nsymmetric model-based clustering techniques under a normality assumption. We\nderive the distributional properties of the missing components of the data and\npropose an augmented EM-type algorithm tailored for incomplete observations.\nThe modified E-step yields closed-form expressions for the conditional\nexpectations of the missing values. The simulation experiments showcase the\nflexibility of the FMSMSN family in both clustering performance and parameter\nrecovery for varying percentages of missing values, while incorporating the\neffects of sample size and cluster proximity. Finally, we illustrate the\npractical utility of the proposed method by applying special cases of the\nFMSMSN family to global CO2 emissions data.\n","authors":["Jason Pillay","Cristina Tortora","Antonio Punzo","Andriette Bekker"],"pdf_url":"https://arxiv.org/pdf/2507.20329v1.pdf","comment":"Keywords: Mixture Models, skew-normal distribution, missing values at\n  random. 32 pages, 14 figures"}]},"2025-07-26T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2302.10150v2","updated":"2025-07-26T21:01:03Z","published":"2023-02-20T18:32:57Z","title":"Information Retrieval in long documents: Word clustering approach for\n  improving Semantics","summary":"  In this paper, we propose an alternative to deep neural networks for semantic\ninformation retrieval for the case of long documents. This new approach\nexploiting clustering techniques to take into account the meaning of words in\nInformation Retrieval systems targeting long as well as short documents. This\napproach uses a specially designed clustering algorithm to group words with\nsimilar meanings into clusters. The dual representation (lexical and semantic)\nof documents and queries is based on the vector space model proposed by Gerard\nSalton in the vector space constituted by the formed clusters. The\noriginalities of our proposal are at several levels: first, we propose an\nefficient algorithm for the construction of clusters of semantically close\nwords using word embedding as input, then we define a formula for weighting\nthese clusters, and then we propose a function allowing to combine efficiently\nthe meanings of words with a lexical model widely used in Information\nRetrieval. The evaluation of our proposal in three contexts with two different\ndatasets SQuAD and TREC-CAR has shown that is significantly improves the\nclassical approaches only based on the keywords without degrading the lexical\naspect.\n","authors":["Paul Mbathe Mekontchou","Armel Fotsoh","Bernabe Batchakui","Eddy Ella"],"pdf_url":"https://arxiv.org/pdf/2302.10150v2.pdf","comment":"This replacement corrects a typographical error in one of the\n  authors' names in the PDF file. No other changes were made to the content"},{"id":"http://arxiv.org/abs/2507.20035v1","updated":"2025-07-26T18:38:27Z","published":"2025-07-26T18:38:27Z","title":"A Non-Parametric Choice Model That Learns How Users Choose Between\n  Recommended Options","summary":"  Choice models predict which items users choose from presented options. In\nrecommendation settings, they can infer user preferences while countering\nexposure bias. In contrast with traditional univariate recommendation models,\nchoice models consider which competitors appeared with the chosen item. This\nability allows them to distinguish whether a user chose an item due to\npreference, i.e., they liked it; or competition, i.e., it was the best\navailable option. Each choice model assumes specific user behavior, e.g., the\nmultinomial logit model. However, it is currently unclear how accurately these\nassumptions capture actual user behavior, how wrong assumptions impact\ninference, and whether better models exist.\n  In this work, we propose the learned choice model for recommendation\n(LCM4Rec), a non-parametric method for estimating the choice model. By applying\nkernel density estimation, LCM4Rec infers the most likely error distribution\nthat describes the effect of inter-item cannibalization and thereby\ncharacterizes the users' choice model. Thus, it simultaneously infers what\nusers prefer and how they make choices. Our experimental results indicate that\nour method (i) can accurately recover the choice model underlying a dataset;\n(ii) provides robust user preference inference, in contrast with existing\nchoice models that are only effective when their assumptions match user\nbehavior; and (iii) is more resistant against exposure bias than existing\nchoice models. Thereby, we show that learning choice models, instead of\nassuming them, can produce more robust predictions. We believe this work\nprovides an important step towards better understanding users' choice behavior.\n","authors":["Thorsten Krause","Harrie Oosterhuis"],"pdf_url":"https://arxiv.org/pdf/2507.20035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16708v2","updated":"2025-07-26T16:31:50Z","published":"2024-12-21T17:31:52Z","title":"Towards More Robust Retrieval-Augmented Generation: Evaluating RAG Under\n  Adversarial Poisoning Attacks","summary":"  Retrieval-Augmented Generation (RAG) systems have emerged as a promising\nsolution to mitigate LLM hallucinations and enhance their performance in\nknowledge-intensive domains. However, these systems are vulnerable to\nadversarial poisoning attacks, where malicious passages injected into the\nretrieval corpus can mislead models into producing factually incorrect outputs.\nIn this paper, we present a rigorously controlled empirical study of how RAG\nsystems behave under such attacks and how their robustness can be improved. On\nthe generation side, we introduce a structured taxonomy of context\ntypes-adversarial, untouched, and guiding-and systematically analyze their\nindividual and combined effects on model outputs. On the retrieval side, we\nevaluate several retrievers to measure how easily they expose LLMs to\nadversarial contexts. Our findings also reveal that \"skeptical prompting\" can\nactivate LLMs' internal reasoning, enabling partial self-defense against\nadversarial passages, though its effectiveness depends strongly on the model's\nreasoning capacity. Together, our experiments (code available at\nhttps://github.com/JinyanSu1/eval_PoisonRaG) and analysis provide actionable\ninsights for designing safer and more resilient RAG systems, paving the way for\nmore reliable real-world deployments.\n","authors":["Jinyan Su","Jin Peng Zhou","Zhengxin Zhang","Preslav Nakov","Claire Cardie"],"pdf_url":"https://arxiv.org/pdf/2412.16708v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19990v1","updated":"2025-07-26T15:59:25Z","published":"2025-07-26T15:59:25Z","title":"Improving the Performance of Sequential Recommendation Systems with an\n  Extended Large Language Model","summary":"  Recently, competition in the field of artificial intelligence (AI) has\nintensified among major technological companies, resulting in the continuous\nrelease of new large-language models (LLMs) that exhibit improved language\nunderstanding and context-based reasoning capabilities. It is expected that\nthese advances will enable more efficient personalized recommendations in\nLLM-based recommendation systems through improved quality of training data and\narchitectural design. However, many studies have not considered these recent\ndevelopments. In this study, it was proposed to improve LLM-based\nrecommendation systems by replacing Llama2 with Llama3 in the LlamaRec\nframework. To ensure a fair comparison, random seed values were set and\nidentical input data was provided during preprocessing and training. The\nexperimental results show average performance improvements of 38.65\\%, 8.69\\%,\nand 8.19\\% for the ML-100K, Beauty, and Games datasets, respectively, thus\nconfirming the practicality of this method. Notably, the significant\nimprovements achieved by model replacement indicate that the recommendation\nquality can be improved cost-effectively without the need to make structural\nchanges to the system. Based on these results, it is our contention that the\nproposed approach is a viable solution for improving the performance of current\nrecommendation systems.\n","authors":["Sinnyum Choi","Woong Kim"],"pdf_url":"https://arxiv.org/pdf/2507.19990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19973v1","updated":"2025-07-26T15:02:32Z","published":"2025-07-26T15:02:32Z","title":"Leveraging Fine-Tuned Large Language Models for Interpretable Pancreatic\n  Cystic Lesion Feature Extraction and Risk Categorization","summary":"  Background: Manual extraction of pancreatic cystic lesion (PCL) features from\nradiology reports is labor-intensive, limiting large-scale studies needed to\nadvance PCL research. Purpose: To develop and evaluate large language models\n(LLMs) that automatically extract PCL features from MRI/CT reports and assign\nrisk categories based on guidelines. Materials and Methods: We curated a\ntraining dataset of 6,000 abdominal MRI/CT reports (2005-2024) from 5,134\npatients that described PCLs. Labels were generated by GPT-4o using\nchain-of-thought (CoT) prompting to extract PCL and main pancreatic duct\nfeatures. Two open-source LLMs were fine-tuned using QLoRA on GPT-4o-generated\nCoT data. Features were mapped to risk categories per institutional guideline\nbased on the 2017 ACR White Paper. Evaluation was performed on 285 held-out\nhuman-annotated reports. Model outputs for 100 cases were independently\nreviewed by three radiologists. Feature extraction was evaluated using exact\nmatch accuracy, risk categorization with macro-averaged F1 score, and\nradiologist-model agreement with Fleiss' Kappa. Results: CoT fine-tuning\nimproved feature extraction accuracy for LLaMA (80% to 97%) and DeepSeek (79%\nto 98%), matching GPT-4o (97%). Risk categorization F1 scores also improved\n(LLaMA: 0.95; DeepSeek: 0.94), closely matching GPT-4o (0.97), with no\nstatistically significant differences. Radiologist inter-reader agreement was\nhigh (Fleiss' Kappa = 0.888) and showed no statistically significant difference\nwith the addition of DeepSeek-FT-CoT (Fleiss' Kappa = 0.893) or GPT-CoT\n(Fleiss' Kappa = 0.897), indicating that both models achieved agreement levels\non par with radiologists. Conclusion: Fine-tuned open-source LLMs with CoT\nsupervision enable accurate, interpretable, and efficient phenotyping for\nlarge-scale PCL research, achieving performance comparable to GPT-4o.\n","authors":["Ebrahim Rasromani","Stella K. Kang","Yanqi Xu","Beisong Liu","Garvit Luhadia","Wan Fung Chui","Felicia L. Pasadyn","Yu Chih Hung","Julie Y. An","Edwin Mathieu","Zehui Gu","Carlos Fernandez-Granda","Ammar A. Javed","Greg D. Sacks","Tamas Gonda","Chenchan Huang","Yiqiu Shen"],"pdf_url":"https://arxiv.org/pdf/2507.19973v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02951v2","updated":"2025-07-26T10:50:24Z","published":"2024-05-05T14:39:06Z","title":"iSEARLE: Improving Textual Inversion for Zero-Shot Composed Image\n  Retrieval","summary":"  Given a query consisting of a reference image and a relative caption,\nComposed Image Retrieval (CIR) aims to retrieve target images visually similar\nto the reference one while incorporating the changes specified in the relative\ncaption. The reliance of supervised methods on labor-intensive manually labeled\ndatasets hinders their broad applicability. In this work, we introduce a new\ntask, Zero-Shot CIR (ZS-CIR), that addresses CIR without the need for a labeled\ntraining dataset. We propose an approach named iSEARLE (improved zero-Shot\ncomposEd imAge Retrieval with textuaL invErsion) that involves mapping the\nvisual information of the reference image into a pseudo-word token in CLIP\ntoken embedding space and combining it with the relative caption. To foster\nresearch on ZS-CIR, we present an open-domain benchmarking dataset named CIRCO\n(Composed Image Retrieval on Common Objects in context), the first CIR dataset\nwhere each query is labeled with multiple ground truths and a semantic\ncategorization. The experimental results illustrate that iSEARLE obtains\nstate-of-the-art performance on three different CIR datasets -- FashionIQ,\nCIRR, and the proposed CIRCO -- and two additional evaluation settings, namely\ndomain conversion and object composition. The dataset, the code, and the model\nare publicly available at https://github.com/miccunifi/SEARLE.\n","authors":["Lorenzo Agnolucci","Alberto Baldrati","Alberto Del Bimbo","Marco Bertini"],"pdf_url":"https://arxiv.org/pdf/2405.02951v2.pdf","comment":"Accepted at TPAMI, extended version of the ICCV2023 paper\n  arXiv:2303.15247"},{"id":"http://arxiv.org/abs/2507.09331v2","updated":"2025-07-26T10:37:50Z","published":"2025-07-12T16:16:11Z","title":"Correcting the LogQ Correction: Revisiting Sampled Softmax for\n  Large-Scale Retrieval","summary":"  Two-tower neural networks are a popular architecture for the retrieval stage\nin recommender systems. These models are typically trained with a softmax loss\nover the item catalog. However, in web-scale settings, the item catalog is\noften prohibitively large, making full softmax infeasible. A common solution is\nsampled softmax, which approximates the full softmax using a small number of\nsampled negatives.\n  One practical and widely adopted approach is to use in-batch negatives, where\nnegatives are drawn from items in the current mini-batch. However, this\nintroduces a bias: items that appear more frequently in the batch (i.e.,\npopular items) are penalized more heavily.\n  To mitigate this issue, a popular industry technique known as logQ correction\nadjusts the logits during training by subtracting the log-probability of an\nitem appearing in the batch. This correction is derived by analyzing the bias\nin the gradient and applying importance sampling, effectively twice, using the\nin-batch distribution as a proposal distribution. While this approach improves\nmodel quality, it does not fully eliminate the bias.\n  In this work, we revisit the derivation of logQ correction and show that it\noverlooks a subtle but important detail: the positive item in the denominator\nis not Monte Carlo-sampled - it is always present with probability 1. We\npropose a refined correction formula that accounts for this. Notably, our loss\nintroduces an interpretable sample weight that reflects the model's uncertainty\n- the probability of misclassification under the current parameters. We\nevaluate our method on both public and proprietary datasets, demonstrating\nconsistent improvements over the standard logQ correction.\n","authors":["Kirill Khrylchenko","Vladimir Baikalov","Sergei Makeev","Artem Matveev","Sergei Liamaev"],"pdf_url":"https://arxiv.org/pdf/2507.09331v2.pdf","comment":"Accepted at ACM RecSys 2025. Author's version. To appear in the\n  Proceedings of the 18th ACM Conference on Recommender Systems"},{"id":"http://arxiv.org/abs/2507.19846v1","updated":"2025-07-26T07:42:12Z","published":"2025-07-26T07:42:12Z","title":"A Scalable and High Availability Solution for Recommending Resolutions\n  to Problem Tickets","summary":"  Resolution of incidents or problem tickets is a common theme in service\nindustries in any sector, including billing and charging systems in telecom\ndomain. Machine learning can help to identify patterns and suggest resolutions\nfor the problem tickets, based on patterns in the historical data of the\ntickets. However, this process may be complicated due to a variety of phenomena\nsuch as data drift and issues such as missing data, lack of data pertaining to\nresolutions of past incidents, too many similar sounding resolutions due to\nfree text and similar sounding text. This paper proposes a robust ML-driven\nsolution employing clustering, supervised learning, and advanced NLP models to\ntackle these challenges effectively. Building on previous work, we demonstrate\nclustering-based resolution identification, supervised classification with LDA,\nSiamese networks, and One-shot learning, Index embedding. Additionally, we\npresent a real-time dashboard and a highly available Kubernetes-based\nproduction deployment. Our experiments with both the open-source Bitext\ncustomer-support dataset and proprietary telecom datasets demonstrate high\nprediction accuracy.\n","authors":["Harish S","Chetana K Nayak","Joy Bose"],"pdf_url":"https://arxiv.org/pdf/2507.19846v1.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.19802v1","updated":"2025-07-26T05:27:32Z","published":"2025-07-26T05:27:32Z","title":"CleANN: Efficient Full Dynamism in Graph-based Approximate Nearest\n  Neighbor Search","summary":"  Approximate nearest neighbor search (ANNS) has become a quintessential\nalgorithmic problem for various other foundational data tasks for AI workloads.\nGraph-based ANNS indexes have superb empirical trade-offs in indexing cost,\nquery efficiency, and query approximation quality. Most existing graph-based\nindexes are designed for the static scenario, where there are no updates to the\ndata after the index is constructed. However, full dynamism (insertions,\ndeletions, and searches) is crucial to providing up-to-date responses in\napplications using vector databases. It is desirable that the index efficiently\nsupports updates and search queries concurrently. Existing dynamic graph-based\nindexes suffer from at least one of the following problems: (1) the query\nquality degrades as updates happen; and (2) the graph structure updates used to\nmaintain the index quality upon updates are global and thus expensive. To solve\nthese problems, we propose the CleANN system which consists of three main\ncomponents: (1) workload-aware linking of diverse search tree descendants to\ncombat distribution shift; (2)query-adaptive on-the-fly neighborhood\nconsolidation to efficiently handle deleted nodes; and (3) semi-lazy memory\ncleaning to clean up stale information in the data structure and reduce the\nwork spent by the first two components. We evaluate CleANN on 7 diverse\ndatasets on fully dynamic workloads and find that CleANN has query quality at\nleast as good as if the index had been built statically using the corresponding\ndata. In the in-memory setting using 56 hyper-threads, with all types of\nqueries running concurrently, at the same recall level, CleANN achieves 7-1200x\nthroughput improvement on million-scale real-world datasets. To the best of our\nknowledge, CleANN is the first concurrent ANNS index to achieve such efficiency\nwhile maintaining quality under full dynamism.\n","authors":["Ziyu Zhang","Yuanhao Wei","Joshua Engels","Julian Shun"],"pdf_url":"https://arxiv.org/pdf/2507.19802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19798v1","updated":"2025-07-26T05:05:29Z","published":"2025-07-26T05:05:29Z","title":"Analyzing and Mitigating Repetitions in Trip Recommendation","summary":"  Trip recommendation has emerged as a highly sought-after service over the\npast decade. Although current studies significantly understand human intention\nconsistency, they struggle with undesired repetitive outcomes that need\nresolution. We make two pivotal discoveries using statistical analyses and\nexperimental designs: (1) The occurrence of repetitions is intricately linked\nto the models and decoding strategies. (2) During training and decoding, adding\nperturbations to logits can reduce repetition. Motivated by these observations,\nwe introduce AR-Trip (Anti Repetition for Trip Recommendation), which\nincorporates a cycle-aware predictor comprising three mechanisms to avoid\nduplicate Points-of-Interest (POIs) and demonstrates their effectiveness in\nalleviating repetition. Experiments on four public datasets illustrate that\nAR-Trip successfully mitigates repetition issues while enhancing precision.\n","authors":["Wenzheng Shu","Kangqi Xu","Wenxin Tai","Ting Zhong","Yong Wang","Fan Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.19798v1.pdf","comment":"Accepted by ACM SIGIR 2024 Short Paper Track"},{"id":"http://arxiv.org/abs/2507.19750v1","updated":"2025-07-26T02:47:09Z","published":"2025-07-26T02:47:09Z","title":"A Unified Framework for Interactive Visual Graph Matching via\n  Attribute-Structure Synchronization","summary":"  In traditional graph retrieval tools, graph matching is commonly used to\nretrieve desired graphs from extensive graph datasets according to their\nstructural similarities. However, in real applications, graph nodes have\nnumerous attributes which also contain valuable information for evaluating\nsimilarities between graphs. Thus, to achieve superior graph matching results,\nit is crucial for graph retrieval tools to make full use of the attribute\ninformation in addition to structural information. We propose a novel framework\nfor interactive visual graph matching. In the proposed framework, an\nattribute-structure synchronization method is developed for representing\nstructural and attribute features in a unified embedding space based on\nCanonical Correlation Analysis (CCA). To support fast and interactive matching,\n\\revise{our method} provides users with intuitive visual query interfaces for\ntraversing, filtering and searching for the target graph in the embedding space\nconveniently. With the designed interfaces, the users can also specify a new\ntarget graph with desired structural and semantic features. Besides, evaluation\nviews are designed for easy validation and interpretation of the matching\nresults. Case studies and quantitative comparisons on real-world datasets have\ndemonstrated the superiorities of our proposed framework in graph matching and\nlarge graph exploration.\n","authors":["Yuhua Liu","Haoxuan Wang","Jiajia Kou","Ling Sun","Heyu Wang","Yongheng Wang","Yigang Wang","Jinchang Lic","Zhiguang Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.19750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.15551v3","updated":"2025-07-26T02:01:33Z","published":"2025-07-21T12:28:55Z","title":"RankMixer: Scaling Up Ranking Models in Industrial Recommenders","summary":"  Recent progress on large language models (LLMs) has spurred interest in\nscaling up recommendation systems, yet two practical obstacles remain. First,\ntraining and serving cost on industrial Recommenders must respect strict\nlatency bounds and high QPS demands. Second, most human-designed\nfeature-crossing modules in ranking models were inherited from the CPU era and\nfail to exploit modern GPUs, resulting in low Model Flops Utilization (MFU) and\npoor scalability. We introduce RankMixer, a hardware-aware model design\ntailored towards a unified and scalable feature-interaction architecture.\nRankMixer retains the transformer's high parallelism while replacing quadratic\nself-attention with multi-head token mixing module for higher efficiency.\nBesides, RankMixer maintains both the modeling for distinct feature subspaces\nand cross-feature-space interactions with Per-token FFNs. We further extend it\nto one billion parameters with a Sparse-MoE variant for higher ROI. A dynamic\nrouting strategy is adapted to address the inadequacy and imbalance of experts\ntraining. Experiments show RankMixer's superior scaling abilities on a\ntrillion-scale production dataset. By replacing previously diverse handcrafted\nlow-MFU modules with RankMixer, we boost the model MFU from 4.5\\% to 45\\%, and\nscale our ranking model parameters by 100x while maintaining roughly the same\ninference latency. We verify RankMixer's universality with online A/B tests\nacross two core application scenarios (Recommendation and Advertisement).\nFinally, we launch 1B Dense-Parameters RankMixer for full traffic serving\nwithout increasing the serving cost, which improves user active days by 0.3\\%\nand total in-app usage duration by 1.08\\%.\n","authors":["Jie Zhu","Zhifang Fan","Xiaoxie Zhu","Yuchen Jiang","Hangyu Wang","Xintian Han","Haoran Ding","Xinmin Wang","Wenlin Zhao","Zhen Gong","Huizhi Yang","Zheng Chai","Zhe Chen","Yuchao Zheng","Qiwei Chen","Feng Zhang","Xun Zhou","Peng Xu","Xiao Yang","Di Wu","Zuotao Liu"],"pdf_url":"https://arxiv.org/pdf/2507.15551v3.pdf","comment":null}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2507.20079v1","updated":"2025-07-26T23:19:17Z","published":"2025-07-26T23:19:17Z","title":"Lasso Penalization for High-Dimensional Beta Regression Models:\n  Computation, Analysis, and Inference","summary":"  Beta regression is commonly employed when the outcome variable is a\nproportion. Since its conception, the approach has been widely used in\napplications spanning various scientific fields. A series of extensions have\nbeen proposed over time, several of which address variable selection and\npenalized estimation, e.g., with an $\\ell_1$-penalty (LASSO). However, a\ntheoretical analysis of this popular approach in the context of Beta regression\nwith high-dimensional predictors is lacking. In this paper, we aim to close\nthis gap. A particular challenge arises from the non-convexity of the\nassociated negative log-likelihood, which we address by resorting to a\nframework for analyzing stationary points in a neighborhood of the target\nparameter. Leveraging this framework, we derive a non-asymptotic bound on the\n$\\ell_1$-error of such stationary points. In addition, we propose a debiasing\napproach to construct confidence intervals for the regression parameters. A\nproximal gradient algorithm is devised for optimizing the resulting penalized\nnegative log-likelihood function. Our theoretical analysis is corroborated via\nsimulation studies, and a real data example concerning the prediction of\ncounty-level proportions of incarceration is presented to showcase the\npractical utility of our methodology.\n","authors":["Niloofar Ramezani","Martin Slawski"],"pdf_url":"https://arxiv.org/pdf/2507.20079v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20068v1","updated":"2025-07-26T21:51:15Z","published":"2025-07-26T21:51:15Z","title":"PERRY: Policy Evaluation with Confidence Intervals using Auxiliary Data","summary":"  Off-policy evaluation (OPE) methods aim to estimate the value of a new\nreinforcement learning (RL) policy prior to deployment. Recent advances have\nshown that leveraging auxiliary datasets, such as those synthesized by\ngenerative models, can improve the accuracy of these value estimates.\nUnfortunately, such auxiliary datasets may also be biased, and existing methods\nfor using data augmentation for OPE in RL lack principled uncertainty\nquantification. In high stakes settings like healthcare, reliable uncertainty\nestimates are important for comparing policy value estimates. In this work, we\npropose two approaches to construct valid confidence intervals for OPE when\nusing data augmentation. The first provides a confidence interval over the\npolicy performance conditioned on a particular initial state $V^{\\pi}(s_0)$--\nsuch intervals are particularly important for human-centered applications. To\ndo so we introduce a new conformal prediction method for high dimensional state\nMDPs. Second, we consider the more common task of estimating the average policy\nperformance over many initial states; to do so we draw on ideas from doubly\nrobust estimation and prediction powered inference. Across simulators spanning\nrobotics, healthcare and inventory management, and a real healthcare dataset\nfrom MIMIC-IV, we find that our methods can use augmented data and still\nconsistently produce intervals that cover the ground truth values, unlike\npreviously proposed methods.\n","authors":["Aishwarya Mandyam","Jason Meng","Ge Gao","Jiankai Sun","Mac Schwager","Barbara E. Engelhardt","Emma Brunskill"],"pdf_url":"https://arxiv.org/pdf/2507.20068v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20058v1","updated":"2025-07-26T20:56:32Z","published":"2025-07-26T20:56:32Z","title":"Predicting Parkinson's Disease Progression Using Statistical and Neural\n  Mixed Effects Models: A Comparative Study on Longitudinal Biomarkers","summary":"  Predicting Parkinson's Disease (PD) progression is crucial, and voice\nbiomarkers offer a non-invasive method for tracking symptom severity (UPDRS\nscores) through telemonitoring. Analyzing this longitudinal data is challenging\ndue to within-subject correlations and complex, nonlinear patient-specific\nprogression patterns. This study benchmarks LMMs against two advanced hybrid\napproaches: the Generalized Neural Network Mixed Model (GNMM) (Mandel 2021),\nwhich embeds a neural network within a GLMM structure, and the Neural Mixed\nEffects (NME) model (Wortwein 2023), allowing nonlinear subject-specific\nparameters throughout the network. Using the Oxford Parkinson's telemonitoring\nvoice dataset, we evaluate these models' performance in predicting Total UPDRS\nto offer practical guidance for PD research and clinical applications.\n","authors":["Ran Tong","Lanruo Wang","Tong Wang","Wei Yan"],"pdf_url":"https://arxiv.org/pdf/2507.20058v1.pdf","comment":"20pages,3 figures,currently under review"},{"id":"http://arxiv.org/abs/2507.20048v1","updated":"2025-07-26T19:59:37Z","published":"2025-07-26T19:59:37Z","title":"Irredundant $k$-Fold Cross-Validation","summary":"  In traditional k-fold cross-validation, each instance is used ($k-1$) times\nfor training and once for testing, leading to redundancy that lets many\ninstances disproportionately influence the learning phase. We introduce\nIrredundant $k$-fold cross-validation, a novel method that guarantees each\ninstance is used exactly once for training and once for testing across the\nentire validation procedure. This approach ensures a more balanced utilization\nof the dataset, mitigates overfitting due to instance repetition, and enables\nsharper distinctions in comparative model analysis. The method preserves\nstratification and remains model-agnostic, i.e., compatible with any\nclassifier. Experimental results demonstrate that it delivers consistent\nperformance estimates across diverse datasets -- comparable to $k$-fold\ncross-validation -- while providing less optimistic variance estimates because\ntraining partitions are non-overlapping, and significantly reducing the overall\ncomputational cost.\n","authors":["Jesus S. Aguilar-Ruiz"],"pdf_url":"https://arxiv.org/pdf/2507.20048v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20039v1","updated":"2025-07-26T18:53:39Z","published":"2025-07-26T18:53:39Z","title":"Dependency Network-Based Portfolio Design with Forecasting and VaR\n  Constraints","summary":"  This study proposes a novel portfolio optimization framework that integrates\nstatistical social network analysis with time series forecasting and risk\nmanagement. Using daily stock data from the S&P 500 (2020-2024), we construct\ndependency networks via Vector Autoregression (VAR) and Forecast Error Variance\nDecomposition (FEVD), transforming influence relationships into a cost-based\nnetwork. Specifically, FEVD breaks down the VAR's forecast error variance to\nquantify how much each stock's shocks contribute to another's uncertainty\ninformation we invert to form influence-based edge weights in our network. By\napplying the Minimum Spanning Tree (MST) algorithm, we extract the core\ninter-stock structure and identify central stocks through degree centrality. A\ndynamic portfolio is constructed using the top-ranked stocks, with capital\nallocated based on Value at Risk (VaR). To refine stock selection, we\nincorporate forecasts from ARIMA and Neural Network Autoregressive (NNAR)\nmodels. Trading simulations over a one-year period demonstrate that the\nMST-based strategies outperform a buy-and-hold benchmark, with the tuned\nNNAR-enhanced strategy achieving a 63.74% return versus 18.00% for the\nbenchmark. Our results highlight the potential of combining network structures,\npredictive modeling, and risk metrics to improve adaptive financial\ndecision-making.\n","authors":["Zihan Lin","Haojie Liu","Randall R. Rojas"],"pdf_url":"https://arxiv.org/pdf/2507.20039v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20024v1","updated":"2025-07-26T17:43:31Z","published":"2025-07-26T17:43:31Z","title":"Discrete Gaussian Vector Fields On Meshes","summary":"  Though the underlying fields associated with vector-valued environmental data\nare continuous, observations themselves are discrete. For example, climate\nmodels typically output grid-based representations of wind fields or ocean\ncurrents, and these are often downscaled to a discrete set of points. By\ntreating the area of interest as a two-dimensional manifold that can be\nrepresented as a triangular mesh and embedded in Euclidean space, this work\nshows that discrete intrinsic Gaussian processes for vector-valued data can be\ndeveloped from discrete differential operators defined with respect to a mesh.\nThese Gaussian processes account for the geometry and curvature of the manifold\nwhilst also providing a flexible and practical formulation that can be readily\napplied to any two-dimensional mesh. We show that these models can capture\nharmonic flows, incorporate boundary conditions, and model non-stationary data.\nFinally, we apply these models to downscaling stationary and non-stationary\ngridded wind data on the globe, and to inference of ocean currents from sparse\nobservations in bounded domains.\n","authors":["Michael Gillan","Stefan Siegert","Ben Youngman"],"pdf_url":"https://arxiv.org/pdf/2507.20024v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.10505v2","updated":"2025-07-26T17:40:08Z","published":"2025-02-14T19:01:34Z","title":"Preference learning made easy: Everything should be understood through\n  win rate","summary":"  Preference learning, or the task of aligning generative models to preference\ncomparison data, has yet to reach the conceptual maturity of classification,\ndensity estimation, etc. To close this gap, this work presents a framework to\nunderstand preference learning starting from the sampling distribution of\npairwise preference data. First, we prove that the only evaluation of a\ngenerative model that respects both preferences and prevalences in the data\ndistribution is a form of win rate, justifying win rate as the focal point to\nunderstand preference learning. We then analyze preference learning methods as\nwin rate optimization (WRO) or non-WRO. We present novel instances of WRO\nbeyond existing examples (RLHF, NLHF) and identify two key theoretical benefits\nof all such methods. We prove that common non-WRO methods like DPO and SFT on\npreferred samples lack these properties and suggest ways to mitigate such\ntheoretical limitations. We also show that WRO underperforms in practice due\noptimization difficulties and that optimization success predicts performance\nbetter than choices which affect the objective's solution. Our analysis\nhighlights best practices for existing methods and provides recommendations for\nfuture research, guided by the principle that one should either align non-WRO\nmethods more closely with WRO or improve the optimization of WRO objectives.\n","authors":["Lily H. Zhang","Rajesh Ranganath"],"pdf_url":"https://arxiv.org/pdf/2502.10505v2.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2411.16715v3","updated":"2025-07-26T17:12:08Z","published":"2024-11-22T22:08:57Z","title":"PaRCE: Probabilistic and Reconstruction-based Competency Estimation for\n  CNN-based Image Classification","summary":"  Convolutional neural networks (CNNs) are extremely popular and effective for\nimage classification tasks but tend to be overly confident in their\npredictions. Various works have sought to quantify uncertainty associated with\nthese models, detect out-of-distribution (OOD) inputs, or identify anomalous\nregions in an image, but limited work has sought to develop a holistic approach\nthat can accurately estimate perception model confidence across various sources\nof uncertainty. We develop a probabilistic and reconstruction-based competency\nestimation (PaRCE) method and compare it to existing approaches for uncertainty\nquantification and OOD detection. We find that our method can best distinguish\nbetween correctly classified, misclassified, and OOD samples with anomalous\nregions, as well as between samples with visual image modifications resulting\nin high, medium, and low prediction accuracy. We describe how to extend our\napproach for anomaly localization tasks and demonstrate the ability of our\napproach to distinguish between regions in an image that are familiar to the\nperception model from those that are unfamiliar. We find that our method\ngenerates interpretable scores that most reliably capture a holistic notion of\nperception model confidence.\n","authors":["Sara Pohland","Claire Tomlin"],"pdf_url":"https://arxiv.org/pdf/2411.16715v3.pdf","comment":"arXiv admin note: text overlap with arXiv:2409.06111"},{"id":"http://arxiv.org/abs/2408.06642v3","updated":"2025-07-26T16:13:34Z","published":"2024-08-13T05:23:55Z","title":"Quantifying uncertainty in climate projections with conformal ensembles","summary":"  Ensembles of General Circulation Models (GCMs) are the primary tools for\ninvestigating climate sensitivity, projecting future climate states, and\nquantifying uncertainty. GCM ensembles are subject to substantial uncertainty\ndue to model inadequacies, resolution limits, internal variability, and\ninter-model variability, meaning rigorous climate risk assessments and informed\ndecision-making require reliable and accurate uncertainty quantification (UQ).\nWe introduce conformal ensembles (CE), a new approach to climate UQ that\nquantifies and constrains projection uncertainty with conformal prediction sets\nand observational data. CE seamlessly integrates climate model ensembles and\nobservational data across a range of scales to generate statistically rigorous,\neasy-to-interpret uncertainty estimates. CE can be applied to any climatic\nvariable using any ensemble analysis method and outperforms existing\ninter-model variability methods in uncertainty quantification across all time\nhorizons and most spatial locations under SSP2-4.5. CE is also computationally\nefficient, requires minimal assumptions, and is highly robust to the conformity\nmeasure. Experiments show that it is effective when conditioning future\nprojections on historical reanalysis data compared with standard ensemble\naveraging approaches, yielding more physically consistent projections.\n","authors":["Trevor Harris","Ryan Sriver"],"pdf_url":"https://arxiv.org/pdf/2408.06642v3.pdf","comment":"25 pages, 8 figures, 2 tables"},{"id":"http://arxiv.org/abs/2507.19978v1","updated":"2025-07-26T15:28:36Z","published":"2025-07-26T15:28:36Z","title":"Extreme value theory for singular subspace estimation in the matrix\n  denoising model","summary":"  This paper studies fine-grained singular subspace estimation in the matrix\ndenoising model where a deterministic low-rank signal matrix is additively\nperturbed by a stochastic matrix of Gaussian noise. We establish that the\nmaximum Euclidean row norm (i.e., the two-to-infinity norm) of the aligned\ndifference between the leading sample and population singular vectors\napproaches the Gumbel distribution in the large-matrix limit, under suitable\nsignal-to-noise conditions and after appropriate centering and scaling. We\napply our novel asymptotic distributional theory to test hypotheses of low-rank\nsignal structure encoded in the leading singular vectors and their\ncorresponding principal subspace. We provide de-biased estimators for the\ncorresponding nuisance signal singular values and show that our proposed\nplug-in test statistic has desirable properties. Notably, compared to using the\nFrobenius norm subspace distance, our test statistic based on the\ntwo-to-infinity norm has higher power to detect structured alternatives that\ndiffer from the null in only a few matrix entries or rows. Our main results are\nobtained by a novel synthesis of and technical analysis involving entrywise\nmatrix perturbation analysis, extreme value theory, saddle point approximation\nmethods, and random matrix theory. Our contributions complement the existing\nliterature for matrix denoising focused on minimaxity, mean squared error\nanalysis, unitarily invariant distances between subspaces, component-wise\nasymptotic distributional theory, and row-wise uniform error bounds. Numerical\nsimulations illustrate our main results and demonstrate the robustness\nproperties of our testing procedure to non-Gaussian noise distributions.\n","authors":["Junhyung Chang","Joshua Cape"],"pdf_url":"https://arxiv.org/pdf/2507.19978v1.pdf","comment":"64 pages, 8 figures"},{"id":"http://arxiv.org/abs/2507.19968v1","updated":"2025-07-26T14:57:32Z","published":"2025-07-26T14:57:32Z","title":"Dimer-Enhanced Optimization: A First-Order Approach to Escaping Saddle\n  Points in Neural Network Training","summary":"  First-order optimization methods, such as SGD and Adam, are widely used for\ntraining large-scale deep neural networks due to their computational efficiency\nand robust performance. However, relying solely on gradient information, these\nmethods often struggle to navigate complex loss landscapes with flat regions,\nplateaus, and saddle points. Second-order methods, which use curvature\ninformation from the Hessian matrix, can address these challenges but are\ncomputationally infeasible for large models. The Dimer method, a first-order\ntechnique that constructs two closely spaced points to probe the local geometry\nof a potential energy surface, efficiently estimates curvature using only\ngradient information. Inspired by its use in molecular dynamics simulations for\nlocating saddle points, we propose Dimer-Enhanced Optimization (DEO), a novel\nframework to escape saddle points in neural network training. DEO adapts the\nDimer method to explore a broader region of the loss landscape, approximating\nthe Hessian's smallest eigenvector without computing the full matrix. By\nperiodically projecting the gradient onto the subspace orthogonal to the\nminimum curvature direction, DEO guides the optimizer away from saddle points\nand flat regions, enhancing training efficiency with non-stepwise updates.\nPreliminary experiments on a Transformer toy model show DEO achieves\ncompetitive performance compared to standard first-order methods, improving\nnavigation of complex loss landscapes. Our work repurposes physics-inspired,\nfirst-order curvature estimation to enhance neural network training in\nhigh-dimensional spaces.\n","authors":["Yue Hu","Zanxia Cao","Yingchao Liu"],"pdf_url":"https://arxiv.org/pdf/2507.19968v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2502.07285v2","updated":"2025-07-26T13:40:20Z","published":"2025-02-11T06:04:49Z","title":"Negative Dependence as a toolbox for machine learning : review and new\n  developments","summary":"  Negative dependence is becoming a key driver in advancing learning\ncapabilities beyond the limits of traditional independence. Recent developments\nhave evidenced support towards negatively dependent systems as a learning\nparadigm in a broad range of fundamental machine learning challenges including\noptimization, sampling, dimensionality reduction and sparse signal recovery,\noften surpassing the performance of current methods based on statistical\nindependence. The most popular negatively dependent model has been that of\ndeterminantal point processes (DPPs), which have their origins in quantum\ntheory. However, other models, such as perturbed lattice models, strongly\nRayleigh measures, zeros of random functions have gained salience in various\nlearning applications. In this article, we review this burgeoning field of\nresearch, as it has developed over the past two decades or so. We also present\nnew results on applications of DPPs to the parsimonious representation of\nneural networks. In the limited scope of the article, we mostly focus on\naspects of this area to which the authors contributed over the recent years,\nincluding applications to Monte Carlo methods, coresets and stochastic gradient\ndescent, stochastic networks, signal processing and connections to quantum\ncomputation. However, starting from basics of negative dependence for the\nuninitiated reader, extensive references are provided to a broad swath of\nrelated developments which could not be covered within our limited scope. While\nexisting works and reviews generally focus on specific negatively dependent\nmodels (e.g. DPPs), a notable feature of this article is that it addresses\nnegative dependence as a machine learning methodology as a whole. In this vein,\nit covers within its span an array of negatively dependent models and their\napplications well beyond DPPs, thereby putting forward a very general and\nrather unique perspective.\n","authors":["Hoang-Son Tran","Vladimir Petrovic","Remi Bardenet","Subhroshekhar Ghosh"],"pdf_url":"https://arxiv.org/pdf/2502.07285v2.pdf","comment":"Dedicated to the memory of Prof K.R. Parthasarathy: visionary, guru,\n  and scientist par excellence"},{"id":"http://arxiv.org/abs/2410.03229v3","updated":"2025-07-26T10:48:52Z","published":"2024-10-04T08:34:14Z","title":"Elucidating the Design Choice of Probability Paths in Flow Matching for\n  Forecasting","summary":"  Flow matching has recently emerged as a powerful paradigm for generative\nmodeling and has been extended to probabilistic time series forecasting in\nlatent spaces. However, the impact of the specific choice of probability path\nmodel on forecasting performance remains under-explored. In this work, we\ndemonstrate that forecasting spatio-temporal data with flow matching is highly\nsensitive to the selection of the probability path model. Motivated by this\ninsight, we propose a novel probability path model designed to improve\nforecasting performance. Our empirical results across various dynamical system\nbenchmarks show that our model achieves faster convergence during training and\nimproved predictive performance compared to existing probability path models.\nImportantly, our approach is efficient during inference, requiring only a few\nsampling steps. This makes our proposed model practical for real-world\napplications and opens new avenues for probabilistic forecasting.\n","authors":["Soon Hoe Lim","Yijin Wang","Annan Yu","Emma Hart","Michael W. Mahoney","Xiaoye S. Li","N. Benjamin Erichson"],"pdf_url":"https://arxiv.org/pdf/2410.03229v3.pdf","comment":"35 pages"},{"id":"http://arxiv.org/abs/2507.19898v1","updated":"2025-07-26T09:58:26Z","published":"2025-07-26T09:58:26Z","title":"TS-Insight: Visualizing Thompson Sampling for Verification and XAI","summary":"  Thompson Sampling (TS) and its variants are powerful Multi-Armed Bandit\nalgorithms used to balance exploration and exploitation strategies in active\nlearning. Yet, their probabilistic nature often turns them into a ``black\nbox'', hindering debugging and trust. We introduce TS-Insight, a visual\nanalytics tool explicitly designed to shed light on the internal decision\nmechanisms of Thompson Sampling-based algorithms, for model developers. It\ncomprises multiple plots, tracing for each arm the evolving posteriors,\nevidence counts, and sampling outcomes, enabling the verification, diagnosis,\nand explainability of exploration/exploitation dynamics. This tool aims at\nfostering trust and facilitating effective debugging and deployment in complex\nbinary decision-making scenarios especially in sensitive domains requiring\ninterpretable decision-making.\n","authors":["Parsa Vares","Éloi Durant","Jun Pang","Nicolas Médoc","Mohammad Ghoniem"],"pdf_url":"https://arxiv.org/pdf/2507.19898v1.pdf","comment":"Accepted as a poster at IEEE VIS 2025 (\"TS-Insight: Visual\n  Fingerprinting of Multi-Armed Bandits\"). Open-source tool available at\n  https://github.com/parsavares/ts-insight"},{"id":"http://arxiv.org/abs/2507.19873v1","updated":"2025-07-26T09:03:13Z","published":"2025-07-26T09:03:13Z","title":"RestoreAI -- Pattern-based Risk Estimation Of Remaining Explosives","summary":"  Landmine removal is a slow, resource-intensive process affecting over 60\ncountries. While AI has been proposed to enhance explosive ordnance (EO)\ndetection, existing methods primarily focus on object recognition, with limited\nattention to prediction of landmine risk based on spatial pattern information.\nThis work aims to answer the following research question: How can AI be used to\npredict landmine risk from landmine patterns to improve clearance time\nefficiency? To that effect, we introduce RestoreAI, an AI system for\npattern-based risk estimation of remaining explosives. RestoreAI is the first\nAI system that leverages landmine patterns for risk prediction, improving the\naccuracy of estimating the residual risk of missing EO prior to land release.\nWe particularly focus on the implementation of three instances of RestoreAI,\nrespectively, linear, curved and Bayesian pattern deminers. First, the linear\npattern deminer uses linear landmine patterns from a principal component\nanalysis (PCA) for the landmine risk prediction. Second, the curved pattern\ndeminer uses curved landmine patterns from principal curves. Finally, the\nBayesian pattern deminer incorporates prior expert knowledge by using a\nBayesian pattern risk prediction. Evaluated on real-world landmine data,\nRestoreAI significantly boosts clearance efficiency. The top-performing\npattern-based deminers achieved a 14.37 percentage point increase in the\naverage share of cleared landmines per timestep and required 24.45% less time\nthan the best baseline deminer to locate all landmines. Interestingly, linear\nand curved pattern deminers showed no significant performance difference,\nsuggesting that more efficient linear patterns are a viable option for risk\nprediction.\n","authors":["Björn Kischelewski","Benjamin Guedj","David Wahl"],"pdf_url":"https://arxiv.org/pdf/2507.19873v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16459v3","updated":"2025-07-26T07:11:11Z","published":"2024-03-25T06:42:02Z","title":"On the rates of convergence for learning with convolutional neural\n  networks","summary":"  We study approximation and learning capacities of convolutional neural\nnetworks (CNNs) with one-side zero-padding and multiple channels. Our first\nresult proves a new approximation bound for CNNs with certain constraint on the\nweights. Our second result gives new analysis on the covering number of\nfeed-forward neural networks with CNNs as special cases. The analysis carefully\ntakes into account the size of the weights and hence gives better bounds than\nthe existing literature in some situations. Using these two results, we are\nable to derive rates of convergence for estimators based on CNNs in many\nlearning problems. In particular, we establish minimax optimal convergence\nrates of the least squares based on CNNs for learning smooth functions in the\nnonparametric regression setting. For binary classification, we derive\nconvergence rates for CNN classifiers with hinge loss and logistic loss. It is\nalso shown that the obtained rates for classification are minimax optimal in\nsome common settings.\n","authors":["Yunfei Yang","Han Feng","Ding-Xuan Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.16459v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.18826v5","updated":"2025-07-26T04:49:04Z","published":"2025-02-26T05:01:11Z","title":"Adversarial Combinatorial Semi-bandits with Graph Feedback","summary":"  In combinatorial semi-bandits, a learner repeatedly selects from a\ncombinatorial decision set of arms, receives the realized sum of rewards, and\nobserves the rewards of the individual selected arms as feedback. In this\npaper, we extend this framework to include \\emph{graph feedback}, where the\nlearner observes the rewards of all neighboring arms of the selected arms in a\nfeedback graph $G$. We establish that the optimal regret over a time horizon\n$T$ scales as $\\widetilde{\\Theta}(S\\sqrt{T}+\\sqrt{\\alpha ST})$, where $S$ is\nthe size of the combinatorial decisions and $\\alpha$ is the independence number\nof $G$. This result interpolates between the known regrets\n$\\widetilde\\Theta(S\\sqrt{T})$ under full information (i.e., $G$ is complete)\nand $\\widetilde\\Theta(\\sqrt{KST})$ under the semi-bandit feedback (i.e., $G$\nhas only self-loops), where $K$ is the total number of arms. A key technical\ningredient is to realize a convexified action using a random decision vector\nwith negative correlations. We also show that online stochastic mirror descent\n(OSMD) that only realizes convexified actions in expectation is suboptimal. In\naddition, we describe the problem of \\emph{combinatorial semi-bandits with\ngeneral capacity} and apply our results to derive an improved regret upper\nbound, which may be of independent interest.\n","authors":["Yuxiao Wen"],"pdf_url":"https://arxiv.org/pdf/2502.18826v5.pdf","comment":"To appear in ICML 2025"},{"id":"http://arxiv.org/abs/2507.19787v1","updated":"2025-07-26T04:24:40Z","published":"2025-07-26T04:24:40Z","title":"Sparse-mode Dynamic Mode Decomposition for Disambiguating Local and\n  Global Structures","summary":"  The dynamic mode decomposition (DMD) is a data-driven approach that extracts\nthe dominant features from spatiotemporal data. In this work, we introduce\nsparse-mode DMD, a new variant of the optimized DMD framework that specifically\nleverages sparsity-promoting regularization in order to approximate DMD modes\nwhich have localized spatial structure. The algorithm maintains the\nnoise-robust properties of optimized DMD while disambiguating between modes\nwhich are spatially local versus global in nature. In many applications, such\nmodes are associated with discrete and continuous spectra respectively, thus\nallowing the algorithm to explicitly construct, in an unsupervised manner, the\ndistinct portions of the spectrum. We demonstrate this by analyzing synthetic\nand real-world systems, including examples from optical waveguides, quantum\nmechanics, and sea surface temperature data.\n","authors":["Sara M. Ichinaga","Steven L. Brunton","Aleksandr Y. Aravkin","J. Nathan Kutz"],"pdf_url":"https://arxiv.org/pdf/2507.19787v1.pdf","comment":null}],"Computation":[{"id":"http://arxiv.org/abs/2502.20608v2","updated":"2025-07-26T20:50:01Z","published":"2025-02-28T00:18:07Z","title":"Analysis of multivariate event times under informative censoring using\n  vine copula","summary":"  The study of times to nonterminal events of different types and their\ninterrelation is a compelling area of interest. The primary challenge in\nanalyzing such multivariate event times is the presence of informative\ncensoring by the terminal event. While numerous statistical methods have been\nproposed for a single nonterminal event, i.e., semi-competing risks data, there\nremains a dearth of tools for analyzing times to multiple nonterminal events.\nThis article introduces a novel analysis framework that leverages the vine\ncopula to directly estimate the joint density of multivariate times to\nnonterminal and terminal events. Unlike the few existing methods based on\nmultivariate or nested copulas, the developed approach excels in capturing the\nheterogeneous dependence between each pair of event times (nonterminal-terminal\nand between-nonterminal) in terms of strength and structure. We propose a\nlikelihood-based estimation and inference procedure, which can be implemented\nefficiently in sequential stages. Through extensive simulation studies, we\ndemonstrate the satisfactory finite-sample performance of our proposed\nstage-wise estimators and analytical variance estimators, as well as their\nadvantages over existing methods. We apply the developed approach to data from\na crowdfunding platform to investigate the relationship between various types\nof creator-backer interactions and a creator's lifetime on the platform.\n","authors":["Xinyuan Chen","Yiwei Li","Qian M. Zhou"],"pdf_url":"https://arxiv.org/pdf/2502.20608v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20001v1","updated":"2025-07-26T16:40:20Z","published":"2025-07-26T16:40:20Z","title":"Computation of Optimal Type-II Progressing Censoring Scheme Using\n  Genetic Algorithm Approach","summary":"  The experimenter must perform a legitimate search in the entire set of\nfeasible censoring schemes to identify the optimal type II progressive\ncensoring scheme, when applied to a life-testing experiment. Current\nrecommendations are limited to small sample sizes. Exhaustive search strategies\nare not practically feasible for large sample sizes. This paper proposes a\nmeta-heuristic algorithm based on the genetic algorithm for large sample sizes.\nThe algorithm is found to provide optimal or near-optimal solutions for small\nsample sizes and large sample sizes. Our suggested optimal criterion is based\non the cost function and is scale-invariant for both location-scale and\nlog-location-scale distribution families. To investigate how inaccurate\nparameter values or cost coefficients may affect the optimal solution, a\nsensitivity analysis is also taken into account.\n","authors":["Ujjwal Roy","Ritwik Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2507.20001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19915v1","updated":"2025-07-26T11:18:15Z","published":"2025-07-26T11:18:15Z","title":"Effective Bayesian Modeling of Large Spatiotemporal Count Data Using\n  Autoregressive Gamma Processes","summary":"  We put forward a new Bayesian modeling strategy for spatiotemporal count data\nthat enables efficient posterior sampling. Most previous models for such data\ndecompose logarithms of the response Poisson rates into fixed effects and\nspatial random effects, where the latter is typically assumed to follow a\nlatent Gaussian process, the conditional autoregressive model, or the intrinsic\nconditional autoregressive model. Since log-Gaussian is not conjugate to\nPoisson, such implementations must resort to either approximation methods like\nINLA or Metropolis moves on latent states in MCMC algorithms for model fitting\nand exhibit several approximation and posterior sampling challenges. Instead of\nmodeling logarithms of spatiotemporal frailties jointly as a Gaussian process,\nwe construct a spatiotemporal autoregressive gamma process guaranteed\nstationary across the time dimension. We decompose latent Poisson variables to\npermit fully conjugate Gibbs sampling of spatiotemporal frailties and design a\nsparse spatial dependence structure to get a linear computational complexity\nthat facilitates efficient posterior computation. Our model permits convenient\nBayesian predictive machinery based on posterior samples that delivers\nsatisfactory performance in predicting at new spatial locations and time\nintervals. We have performed extensive simulation experiments and real data\nanalyses, which corroborated our model's accurate parameter estimation, model\nfitting, and out-of-sample prediction capabilities.\n","authors":["Yifan Cheng","Cheng Li"],"pdf_url":"https://arxiv.org/pdf/2507.19915v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.04115v3","updated":"2025-07-26T09:33:20Z","published":"2023-10-06T09:29:42Z","title":"Markov chain entropy games and the geometry of their Nash equilibria","summary":"  We introduce and study a two-player zero-sum game between a probabilist and\nNature defined by a convex function $f$, a finite collection $\\mathcal{B}$ of\nMarkov generators (or its convex hull), and a target distribution $\\pi$. The\nprobabilist selects a mixed strategy $\\mu \\in \\mathcal{P}(\\mathcal{B})$, the\nset of probability measures on $\\mathcal{B}$, while Nature adopts a pure\nstrategy and selects a $\\pi$-reversible Markov generator $M$. The probabilist\nreceives a payoff equal to the $f$-divergence $D_f(M \\| L)$, where $L$ is drawn\naccording to $\\mu$. We prove that this game always admits a mixed strategy Nash\nequilibrium and satisfies a minimax identity. In contrast, a pure strategy\nequilibrium may fail to exist. We develop a projected subgradient method to\ncompute approximate mixed strategy equilibria with provable convergence\nguarantees. Connections to information centroids, Chebyshev centers, and Bayes\nrisk are discussed. This paper extends earlier minimax results on\n$f$-divergences to the context of Markov generators.\n","authors":["Michael C. H. Choi","Geoffrey Wolfer"],"pdf_url":"https://arxiv.org/pdf/2310.04115v3.pdf","comment":"29 pages, 2 figures"},{"id":"http://arxiv.org/abs/2508.00888v1","updated":"2025-07-26T16:24:25Z","published":"2025-07-26T16:24:25Z","title":"A Dynamic, Context-Aware Framework for Risky Driving Prediction Using\n  Naturalistic Data","summary":"  Naturalistic driving studies offer a powerful means for observing and\nquantifying real-world driving behaviour. One of their prominent applications\nin traffic safety is the continuous monitoring and classification of risky\ndriving behaviour. However, many existing frameworks rely on fixed time windows\nand static thresholds for distinguishing between safe and risky behaviour -\nlimiting their ability to respond to the stochastic nature of real-world\ndriving. This study proposes a dynamic and individualised framework for\nidentifying risky driving behaviour using Belgian naturalistic driving data.\nThe approach leverages a rolling time window and bi-level optimisation to\ndynamically calibrate both risk thresholds and model hyperparameters, capturing\nsubtle behavioural shifts. Two safety indicators, speed-weighted headway and\nharsh driving events, were evaluated using three data-driven models: Random\nForest, XGBoost, and Deep Neural Network (DNN). The DNN demonstrated strong\ncapability in capturing subtle changes in driving behaviour, particularly\nexcelling in high-recall tasks, making it promising for early-stage risk\ndetection. XGBoost provided the most balanced and stable performance across\ndifferent thresholds and evaluation metrics. While random forest showed more\nvariability, it responded sensitively to dynamic threshold adjustments, which\nmay be advantageous during model adaptation or tuning. Speed-weighted headway\nemerged as a more stable and context-sensitive risk indicator than harsh\ndriving events, likely due to its robustness to label sparsity and contextual\nvariation. Overall, the findings support the value of adaptive, personalised\nrisk detection approaches for enhancing real-time safety feedback and tailoring\ndriver support in intelligent transport systems.\n","authors":["Amir Hossein Kalantari","Eleonora Papadimitriou","Amir Pooyan Afghari"],"pdf_url":"https://arxiv.org/pdf/2508.00888v1.pdf","comment":"32 pages"}]},"2025-07-29T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2507.22062v1","updated":"2025-07-29T17:59:58Z","published":"2025-07-29T17:59:58Z","title":"MetaCLIP 2: A Worldwide Scaling Recipe","summary":"  Contrastive Language-Image Pretraining (CLIP) is a popular foundation model,\nsupporting from zero-shot classification, retrieval to encoders for multimodal\nlarge language models (MLLMs). Although CLIP is successfully trained on\nbillion-scale image-text pairs from the English world, scaling CLIP's training\nfurther to learning from the worldwide web data is still challenging: (1) no\ncuration method is available to handle data points from non-English world; (2)\nthe English performance from existing multilingual CLIP is worse than its\nEnglish-only counterpart, i.e., \"curse of multilinguality\" that is common in\nLLMs. Here, we present MetaCLIP 2, the first recipe training CLIP from scratch\non worldwide web-scale image-text pairs. To generalize our findings, we conduct\nrigorous ablations with minimal changes that are necessary to address the above\nchallenges and present a recipe enabling mutual benefits from English and\nnon-English world data. In zero-shot ImageNet classification, MetaCLIP 2\nViT-H/14 surpasses its English-only counterpart by 0.8% and mSigLIP by 0.7%,\nand surprisingly sets new state-of-the-art without system-level confounding\nfactors (e.g., translation, bespoke architecture changes) on multilingual\nbenchmarks, such as CVQA with 57.4%, Babel-ImageNet with 50.2% and XM3600 with\n64.3% on image-to-text retrieval.\n","authors":["Yung-Sung Chuang","Yang Li","Dong Wang","Ching-Feng Yeh","Kehan Lyu","Ramya Raghavendra","James Glass","Lifei Huang","Jason Weston","Luke Zettlemoyer","Xinlei Chen","Zhuang Liu","Saining Xie","Wen-tau Yih","Shang-Wen Li","Hu Xu"],"pdf_url":"https://arxiv.org/pdf/2507.22062v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2507.22050v1","updated":"2025-07-29T17:55:23Z","published":"2025-07-29T17:55:23Z","title":"DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router","summary":"  Large Language Models (LLMs) excel at many reasoning tasks but struggle with\nknowledge-intensive queries due to their inability to dynamically access\nup-to-date or domain-specific information. Retrieval-Augmented Generation (RAG)\nhas emerged as a promising solution, enabling LLMs to ground their responses in\nexternal sources. However, existing RAG methods lack fine-grained control over\nboth the query and source sides, often resulting in noisy retrieval and shallow\nreasoning. In this work, we introduce DeepSieve, an agentic RAG framework that\nincorporates information sieving via LLM-as-a-knowledge-router. DeepSieve\ndecomposes complex queries into structured sub-questions and recursively routes\neach to the most suitable knowledge source, filtering irrelevant information\nthrough a multi-stage distillation process. Our design emphasizes modularity,\ntransparency, and adaptability, leveraging recent advances in agentic system\ndesign. Experiments on multi-hop QA tasks across heterogeneous sources\ndemonstrate improved reasoning depth, retrieval precision, and interpretability\nover conventional RAG approaches.\n","authors":["Minghao Guo","Qingcheng Zeng","Xujiang Zhao","Yanchi Liu","Wenchao Yu","Mengnan Du","Haifeng Chen","Wei Cheng"],"pdf_url":"https://arxiv.org/pdf/2507.22050v1.pdf","comment":"22 pages, work in progress"},{"id":"http://arxiv.org/abs/2503.01751v2","updated":"2025-07-29T17:41:30Z","published":"2025-03-03T17:20:29Z","title":"SAKE: Steering Activations for Knowledge Editing","summary":"  As Large Langue Models have been shown to memorize real-world facts, the need\nto update this knowledge in a controlled and efficient manner arises. Designed\nwith these constraints in mind, Knowledge Editing (KE) approaches propose to\nalter specific facts in pretrained models. However, they have been shown to\nsuffer from several limitations, including their lack of contextual robustness\nand their failure to generalize to logical implications related to the fact. To\novercome these issues, we propose SAKE, a steering activation method that\nmodels a fact to be edited as a distribution rather than a single prompt.\nLeveraging Optimal Transport, SAKE alters the LLM behavior over a whole\nfact-related distribution, defined as paraphrases and logical implications.\nSeveral numerical experiments demonstrate the effectiveness of this method:\nSAKE is thus able to perform more robust edits than its existing counterparts.\n","authors":["Marco Scialanga","Thibault Laugel","Vincent Grari","Marcin Detyniecki"],"pdf_url":"https://arxiv.org/pdf/2503.01751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22034v1","updated":"2025-07-29T17:34:12Z","published":"2025-07-29T17:34:12Z","title":"UserBench: An Interactive Gym Environment for User-Centric Agents","summary":"  Large Language Models (LLMs)-based agents have made impressive progress in\nreasoning and tool use, enabling them to solve complex tasks. However, their\nability to proactively collaborate with users, especially when goals are vague,\nevolving, or indirectly expressed, remains underexplored. To address this gap,\nwe introduce UserBench, a user-centric benchmark designed to evaluate agents in\nmulti-turn, preference-driven interactions. UserBench features simulated users\nwho start with underspecified goals and reveal preferences incrementally,\nrequiring agents to proactively clarify intent and make grounded decisions with\ntools. Our evaluation of leading open- and closed-source LLMs reveals a\nsignificant disconnect between task completion and user alignment. For\ninstance, models provide answers that fully align with all user intents only\n20% of the time on average, and even the most advanced models uncover fewer\nthan 30% of all user preferences through active interaction. These results\nhighlight the challenges of building agents that are not just capable task\nexecutors, but true collaborative partners. UserBench offers an interactive\nenvironment to measure and advance this critical capability.\n","authors":["Cheng Qian","Zuxin Liu","Akshara Prabhakar","Zhiwei Liu","Jianguo Zhang","Haolin Chen","Heng Ji","Weiran Yao","Shelby Heinecke","Silvio Savarese","Caiming Xiong","Huan Wang"],"pdf_url":"https://arxiv.org/pdf/2507.22034v1.pdf","comment":"25 Pages, 17 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2507.22025v1","updated":"2025-07-29T17:22:07Z","published":"2025-07-29T17:22:07Z","title":"UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and\n  Precise Inference-Time Grounding","summary":"  The emergence of Multimodal Large Language Models (MLLMs) has driven\nsignificant advances in Graphical User Interface (GUI) agent capabilities.\nNevertheless, existing GUI agent training and inference techniques still suffer\nfrom a dilemma for reasoning designs, ineffective reward, and visual noise. To\naddress these issues, we introduce UI-AGILE, a comprehensive framework\nenhancing GUI agents at both the training and inference stages. For training,\nwe propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:\n1) a Continuous Reward function to incentivize high-precision grounding; 2) a\n\"Simple Thinking\" reward to balance planning with speed and grounding accuracy;\nand 3) a Cropping-based Resampling strategy to mitigate the sparse reward\nproblem and improve learning on complex tasks. For inference, we present\nDecomposed Grounding with Selection, a novel method that dramatically improves\ngrounding accuracy on high-resolution displays by breaking the image into\nsmaller, manageable parts. Experiments show that UI-AGILE achieves the\nstate-of-the-art performance on two benchmarks ScreenSpot-Pro and\nScreenSpot-v2. For instance, using both our proposed training and inference\nenhancement methods brings 23% grounding accuracy improvement over the best\nbaseline on ScreenSpot-Pro.\n","authors":["Shuquan Lian","Yuhang Wu","Jia Ma","Zihan Song","Bingqi Chen","Xiawu Zheng","Hui Li"],"pdf_url":"https://arxiv.org/pdf/2507.22025v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.23966v3","updated":"2025-07-29T17:19:06Z","published":"2025-05-29T19:42:35Z","title":"FLAT-LLM: Fine-grained Low-rank Activation Space Transformation for\n  Large Language Model Compression","summary":"  Large Language Models (LLMs) have enabled remarkable progress in natural\nlanguage processing, yet their high computational and memory demands pose\nchallenges for deployment in resource-constrained environments. Although recent\nlow-rank decomposition methods offer a promising path for structural\ncompression, they often suffer from accuracy degradation, expensive calibration\nprocedures, and result in inefficient model architectures that hinder\nreal-world inference speedups. In this paper, we propose FLAT-LLM, a fast and\naccurate, training-free structural compression method based on fine-grained\nlow-rank transformations in the activation space. Specifically, we reduce the\nhidden dimension by transforming the weights using truncated eigenvectors\ncomputed via head-wise Principal Component Analysis, and employ a greedy budget\nredistribution strategy to adaptively allocate ranks across decoders. FLAT-LLM\nachieves efficient and effective weight compression without recovery\nfine-tuning, which could complete the calibration within a few minutes.\nEvaluated across 5 models and 11 datasets, FLAT-LLM outperforms structural\npruning baselines in generalization and downstream performance, while\ndelivering inference speedups over decomposition-based methods.\n","authors":["Jiayi Tian","Ryan Solgi","Jinming Lu","Yifan Yang","Hai Li","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2505.23966v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20527v2","updated":"2025-07-29T17:02:27Z","published":"2025-07-28T05:17:48Z","title":"SAND-Math: Using LLMs to Generate Novel, Difficult and Useful\n  Mathematics Questions and Answers","summary":"  The demand for Large Language Models (LLMs) capable of sophisticated\nmathematical reasoning is growing across industries. However, the development\nof performant mathematical LLMs is critically bottlenecked by the scarcity of\ndifficult, novel training data. We introduce \\textbf{SAND-Math} (Synthetic\nAugmented Novel and Difficult Mathematics problems and solutions), a pipeline\nthat addresses this by first generating high-quality problems from scratch and\nthen systematically elevating their complexity via a new \\textbf{Difficulty\nHiking} step. We demonstrate the effectiveness of our approach through two key\nfindings. First, augmenting a strong baseline with SAND-Math data significantly\nboosts performance, outperforming the next-best synthetic dataset by\n\\textbf{$\\uparrow$ 17.85 absolute points} on the AIME25 benchmark. Second, in a\ndedicated ablation study, we show our Difficulty Hiking process is highly\neffective: by increasing average problem difficulty from 5.02 to 5.98, this\nstep lifts AIME25 performance from 46.38\\% to 49.23\\%. The full generation\npipeline, final dataset, and a fine-tuned model form a practical and scalable\ntoolkit for building more capable and efficient mathematical reasoning LLMs.\nSAND-Math dataset is released here:\n\\href{https://huggingface.co/datasets/amd/SAND-MATH}{https://huggingface.co/datasets/amd/SAND-MATH}\n","authors":["Chaitanya Manem","Pratik Prabhanjan Brahma","Prakamya Mishra","Zicheng Liu","Emad Barsoum"],"pdf_url":"https://arxiv.org/pdf/2507.20527v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21980v1","updated":"2025-07-29T16:32:45Z","published":"2025-07-29T16:32:45Z","title":"Predicting Microbial Ontology and Pathogen Risk from Environmental\n  Metadata with Large Language Models","summary":"  Traditional machine learning models struggle to generalize in microbiome\nstudies where only metadata is available, especially in small-sample settings\nor across studies with heterogeneous label formats. In this work, we explore\nthe use of large language models (LLMs) to classify microbial samples into\nontology categories such as EMPO 3 and related biological labels, as well as to\npredict pathogen contamination risk, specifically the presence of E. Coli,\nusing environmental metadata alone. We evaluate LLMs such as ChatGPT-4o, Claude\n3.7 Sonnet, Grok-3, and LLaMA 4 in zero-shot and few-shot settings, comparing\ntheir performance against traditional models like Random Forests across\nmultiple real-world datasets. Our results show that LLMs not only outperform\nbaselines in ontology classification, but also demonstrate strong predictive\nability for contamination risk, generalizing across sites and metadata\ndistributions. These findings suggest that LLMs can effectively reason over\nsparse, heterogeneous biological metadata and offer a promising metadata-only\napproach for environmental microbiology and biosurveillance applications.\n","authors":["Hyunwoo Yoo","Gail L. Rosen"],"pdf_url":"https://arxiv.org/pdf/2507.21980v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.03387v3","updated":"2025-07-29T16:23:02Z","published":"2025-02-05T17:23:45Z","title":"LIMO: Less is More for Reasoning","summary":"  We challenge the prevailing assumption that complex reasoning in large\nlanguage models (LLMs) necessitates massive training data. We demonstrate that\nsophisticated mathematical reasoning can emerge with only a few examples.\nSpecifically, through simple supervised fine-tuning, our model, LIMO, achieves\n63.3\\% accuracy on AIME24 and 95.6\\% on MATH500, surpassing previous fine-tuned\nmodels (6.5\\% on AIME24, 59.2\\% on MATH500) while using only 1\\% of the\ntraining data required by prior approaches. Furthermore, LIMO exhibits strong\nout-of-distribution generalization, achieving a 45.8\\% absolute improvement\nacross diverse benchmarks, outperforming models trained on 100x more data.\nSynthesizing these findings, we propose the Less-Is-More Reasoning Hypothesis\n(LIMO Hypothesis): In foundation models where domain knowledge has been\ncomprehensively encoded during pre-training, sophisticated reasoning can emerge\nthrough minimal but strategically designed demonstrations of cognitive\nprocesses. This hypothesis suggests that the threshold for eliciting complex\nreasoning is not dictated by task complexity but rather by two key factors: (1)\nthe completeness of the model's pre-trained knowledge base and (2) the\neffectiveness of post-training examples in serving as \"cognitive templates\"\nthat guide reasoning.\n","authors":["Yixin Ye","Zhen Huang","Yang Xiao","Ethan Chern","Shijie Xia","Pengfei Liu"],"pdf_url":"https://arxiv.org/pdf/2502.03387v3.pdf","comment":"COLM 2025"},{"id":"http://arxiv.org/abs/2507.21934v1","updated":"2025-07-29T15:48:12Z","published":"2025-07-29T15:48:12Z","title":"Culinary Crossroads: A RAG Framework for Enhancing Diversity in\n  Cross-Cultural Recipe Adaptation","summary":"  In cross-cultural recipe adaptation, the goal is not only to ensure cultural\nappropriateness and retain the original dish's essence, but also to provide\ndiverse options for various dietary needs and preferences. Retrieval Augmented\nGeneration (RAG) is a promising approach, combining the retrieval of real\nrecipes from the target cuisine for cultural adaptability with large language\nmodels (LLMs) for relevance. However, it remains unclear whether RAG can\ngenerate diverse adaptation results. Our analysis shows that RAG tends to\noverly rely on a limited portion of the context across generations, failing to\nproduce diverse outputs even when provided with varied contextual inputs. This\nreveals a key limitation of RAG in creative tasks with multiple valid answers:\nit fails to leverage contextual diversity for generating varied responses. To\naddress this issue, we propose CARRIAGE, a plug-and-play RAG framework for\ncross-cultural recipe adaptation that enhances diversity in both retrieval and\ncontext organization. To our knowledge, this is the first RAG framework that\nexplicitly aims to generate highly diverse outputs to accommodate multiple user\npreferences. Our experiments show that CARRIAGE achieves Pareto efficiency in\nterms of diversity and quality of recipe adaptation compared to closed-book\nLLMs.\n","authors":["Tianyi Hu","Andrea Morales-Garzón","Jingyi Zheng","Maria Maistro","Daniel Hershcovich"],"pdf_url":"https://arxiv.org/pdf/2507.21934v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19980v2","updated":"2025-07-29T15:46:47Z","published":"2025-07-26T15:33:05Z","title":"Exploring LLM Autoscoring Reliability in Large-Scale Writing Assessments\n  Using Generalizability Theory","summary":"  This study investigates the estimation of reliability for large language\nmodels (LLMs) in scoring writing tasks from the AP Chinese Language and Culture\nExam. Using generalizability theory, the research evaluates and compares score\nconsistency between human and AI raters across two types of AP Chinese\nfree-response writing tasks: story narration and email response. These essays\nwere independently scored by two trained human raters and seven AI raters. Each\nessay received four scores: one holistic score and three analytic scores\ncorresponding to the domains of task completion, delivery, and language use.\nResults indicate that although human raters produced more reliable scores\noverall, LLMs demonstrated reasonable consistency under certain conditions,\nparticularly for story narration tasks. Composite scoring that incorporates\nboth human and AI raters improved reliability, which supports that hybrid\nscoring models may offer benefits for large-scale writing assessments.\n","authors":["Dan Song","Won-Chan Lee","Hong Jiao"],"pdf_url":"https://arxiv.org/pdf/2507.19980v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.20797v2","updated":"2025-07-29T15:46:39Z","published":"2025-03-23T02:32:25Z","title":"\"Whose Side Are You On?\" Estimating Ideology of Political and News\n  Content Using Large Language Models and Few-shot Demonstration Selection","summary":"  The rapid growth of social media platforms has led to concerns about\nradicalization, filter bubbles, and content bias. Existing approaches to\nclassifying ideology are limited in that they require extensive human effort,\nthe labeling of large datasets, and are not able to adapt to evolving\nideological contexts. This paper explores the potential of Large Language\nModels (LLMs) for classifying the political ideology of online content in the\ncontext of the two-party US political spectrum through in-context learning\n(ICL). Our extensive experiments involving demonstration selection in\nlabel-balanced fashion, conducted on three datasets comprising news articles\nand YouTube videos, reveal that our approach significantly outperforms\nzero-shot and traditional supervised methods. Additionally, we evaluate the\ninfluence of metadata (e.g., content source and descriptions) on ideological\nclassification and discuss its implications. Finally, we show how providing the\nsource for political and non-political content influences the LLM's\nclassification.\n","authors":["Muhammad Haroon","Magdalena Wojcieszak","Anshuman Chhabra"],"pdf_url":"https://arxiv.org/pdf/2503.20797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21931v1","updated":"2025-07-29T15:46:26Z","published":"2025-07-29T15:46:26Z","title":"Post-Training Large Language Models via Reinforcement Learning from\n  Self-Feedback","summary":"  Large Language Models (LLMs) often produce plausible but poorly-calibrated\nanswers, limiting their reliability on reasoning-intensive tasks. We present\nReinforcement Learning from Self-Feedback (RLSF), a post-training stage that\nuses the model's own confidence as an intrinsic reward, mimicking how humans\nlearn in the absence of external feedback. After a frozen LLM generates several\nchain-of-thought solutions, we define and compute the confidence of each final\nanswer span and rank the traces accordingly. These synthetic preferences are\nthen used to fine-tune the policy with standard preference optimization,\nsimilar to RLHF yet requiring no human labels, gold answers, or externally\ncurated rewards.\n  RLSF simultaneously (i) refines the model's probability estimates --\nrestoring well-behaved calibration -- and (ii) strengthens step-by-step\nreasoning, yielding improved performance on arithmetic reasoning and\nmultiple-choice question answering.\n  By turning a model's own uncertainty into useful self-feedback, RLSF affirms\nreinforcement learning on intrinsic model behaviour as a principled and\ndata-efficient component of the LLM post-training pipeline and warrents further\nresearch in intrinsic rewards for LLM post-training.\n","authors":["Carel van Niekerk","Renato Vukovic","Benjamin Matthias Ruppik","Hsien-chin Lin","Milica Gašić"],"pdf_url":"https://arxiv.org/pdf/2507.21931v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21919v1","updated":"2025-07-29T15:33:20Z","published":"2025-07-29T15:33:20Z","title":"Training language models to be warm and empathetic makes them less\n  reliable and more sycophantic","summary":"  Artificial intelligence (AI) developers are increasingly building language\nmodels with warm and empathetic personas that millions of people now use for\nadvice, therapy, and companionship. Here, we show how this creates a\nsignificant trade-off: optimizing language models for warmth undermines their\nreliability, especially when users express vulnerability. We conducted\ncontrolled experiments on five language models of varying sizes and\narchitectures, training them to produce warmer, more empathetic responses, then\nevaluating them on safety-critical tasks. Warm models showed substantially\nhigher error rates (+10 to +30 percentage points) than their original\ncounterparts, promoting conspiracy theories, providing incorrect factual\ninformation, and offering problematic medical advice. They were also\nsignificantly more likely to validate incorrect user beliefs, particularly when\nuser messages expressed sadness. Importantly, these effects were consistent\nacross different model architectures, and occurred despite preserved\nperformance on standard benchmarks, revealing systematic risks that current\nevaluation practices may fail to detect. As human-like AI systems are deployed\nat an unprecedented scale, our findings indicate a need to rethink how we\ndevelop and oversee these systems that are reshaping human relationships and\nsocial interaction.\n","authors":["Lujain Ibrahim","Franziska Sofia Hafner","Luc Rocher"],"pdf_url":"https://arxiv.org/pdf/2507.21919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.20779v4","updated":"2025-07-29T15:30:36Z","published":"2025-05-27T06:36:04Z","title":"CHIMERA: A Knowledge Base of Scientific Idea Recombinations for Research\n  Analysis and Ideation","summary":"  A hallmark of human innovation is recombination -- the creation of novel\nideas by integrating elements from existing concepts and mechanisms. In this\nwork, we introduce CHIMERA, a large-scale Knowledge Base (KB) of over 28K\nrecombination examples automatically mined from the scientific literature.\nCHIMERA enables large-scale empirical analysis of how scientists recombine\nconcepts and draw inspiration from different areas, and enables training models\nthat propose novel, cross-disciplinary research directions. To construct this\nKB, we define a new information extraction task: identifying recombination\ninstances in scientific abstracts. We curate a high-quality, expert-annotated\ndataset and use it to fine-tune a large language model, which we apply to a\nbroad corpus of AI papers. We showcase the utility of CHIMERA through two\napplications. First, we analyze patterns of recombination across AI subfields.\nSecond, we train a scientific hypothesis generation model using the KB, showing\nthat it can propose novel research directions that researchers rate as\ninspiring. We release our data and code at\nhttps://github.com/noy-sternlicht/CHIMERA-KB.\n","authors":["Noy Sternlicht","Tom Hope"],"pdf_url":"https://arxiv.org/pdf/2505.20779v4.pdf","comment":"Project page: https://noy-sternlicht.github.io/CHIMERA-Web"},{"id":"http://arxiv.org/abs/2507.21914v1","updated":"2025-07-29T15:28:41Z","published":"2025-07-29T15:28:41Z","title":"Rote Learning Considered Useful: Generalizing over Memorized Data in\n  LLMs","summary":"  Rote learning is a memorization technique based on repetition. It is commonly\nbelieved to hinder generalization by encouraging verbatim memorization rather\nthan deeper understanding. This insight holds for even learning factual\nknowledge that inevitably requires a certain degree of memorization. In this\nwork, we demonstrate that LLMs can be trained to generalize from rote memorized\ndata. We introduce a two-phase memorize-then-generalize framework, where the\nmodel first rote memorizes factual subject-object associations using a\nsemantically meaningless token and then learns to generalize by fine-tuning on\na small set of semantically meaningful prompts. Extensive experiments over 8\nLLMs show that the models can reinterpret rote memorized data through the\nsemantically meaningful prompts, as evidenced by the emergence of structured,\nsemantically aligned latent representations between the two. This surprising\nfinding opens the door to both effective and efficient knowledge injection and\npossible risks of repurposing the memorized data for malicious usage.\n","authors":["Qinyuan Wu","Soumi Das","Mahsa Amani","Bishwamittra Ghosh","Mohammad Aflah Khan","Krishna P. Gummadi","Muhammad Bilal Zafar"],"pdf_url":"https://arxiv.org/pdf/2507.21914v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2506.05413v2","updated":"2025-07-29T15:28:07Z","published":"2025-06-04T19:07:45Z","title":"SmoothRot: Combining Channel-Wise Scaling and Rotation for\n  Quantization-Friendly LLMs","summary":"  We present SmoothRot, a novel post-training quantization technique to enhance\nthe efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot\naddresses the critical challenge of massive activation outliers, by integrating\nchannel-wise scaling with Hadamard transformations. Our technique effectively\ntransforms extreme outliers into quantization-friendly activations,\nsignificantly improving quantization accuracy. Experiments conducted on popular\nLLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot\nconsistently reduces the performance gap between quantized and FP16 models by\napproximately 10-30\\% across language generation and zero-shot reasoning tasks,\nwithout introducing additional inference latency. Code is available at\nhttps://github.com/czakop/smoothrot.\n","authors":["Patrik Czakó","Gábor Kertész","Sándor Szénási"],"pdf_url":"https://arxiv.org/pdf/2506.05413v2.pdf","comment":"6 pages, 3 figures, 5 tables. Accepted to IEEE SMC 2025 conference\n  proceedings"},{"id":"http://arxiv.org/abs/2506.15787v3","updated":"2025-07-29T15:26:05Z","published":"2025-06-18T18:10:30Z","title":"SLR: Automated Synthesis for Scalable Logical Reasoning","summary":"  We introduce SLR, an end-to-end framework for systematic evaluation and\ntraining of Large Language Models (LLMs) via Scalable Logical Reasoning. Given\na user's task specification, SLR automatically synthesizes (i) an instruction\nprompt for an inductive reasoning task, (ii) a validation program, executable\non model outputs to provide verifiable rewards, and (iii) the latent\nground-truth rule. This process is fully automated, scalable, requires no human\nannotations, and offers precise control over task difficulty. Using SLR, we\ncreate SLR-Bench, a benchmark comprising 19k prompts organized into 20\ncurriculum levels that progressively increase in relational, arithmetic, and\nrecursive complexity. Large-scale evaluation reveals that contemporary LLMs\nreadily produce syntactically valid rules, yet often fail at correct logical\ninference. Recent reasoning LLMs demonstrate improved performance but incur\nvery high test-time computation, with costs exceeding $300 for just 1,000\nprompts. Finally, curriculum learning via SLR doubles Llama-3-8B accuracy on\nSLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of\ncomputational cost. Moreover, these reasoning capabilities generalize to a wide\nrange of established benchmarks, underscoring the effectiveness of SLR for\ndownstream reasoning.\n","authors":["Lukas Helff","Ahmad Omar","Felix Friedrich","Antonia Wüst","Hikaru Shindo","Rupert Mitchell","Tim Woydt","Patrick Schramowski","and Wolfgang Stammer Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2506.15787v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21903v1","updated":"2025-07-29T15:14:39Z","published":"2025-07-29T15:14:39Z","title":"Who's important? -- SUnSET: Synergistic Understanding of Stakeholder,\n  Events and Time for Timeline Generation","summary":"  As news reporting becomes increasingly global and decentralized online,\ntracking related events across multiple sources presents significant\nchallenges. Existing news summarization methods typically utilizes Large\nLanguage Models and Graphical methods on article-based summaries. However, this\nis not effective since it only considers the textual content of similarly dated\narticles to understand the gist of the event. To counteract the lack of\nanalysis on the parties involved, it is essential to come up with a novel\nframework to gauge the importance of stakeholders and the connection of related\nevents through the relevant entities involved. Therefore, we present SUnSET:\nSynergistic Understanding of Stakeholder, Events and Time for the task of\nTimeline Summarization (TLS). We leverage powerful Large Language Models (LLMs)\nto build SET triplets and introduced the use of stakeholder-based ranking to\nconstruct a $Relevancy$ metric, which can be extended into general situations.\nOur experimental results outperform all prior baselines and emerged as the new\nState-of-the-Art, highlighting the impact of stakeholder information within\nnews article.\n","authors":["Tiviatis Sim","Kaiwen Yang","Shen Xin","Kenji Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2507.21903v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21892v1","updated":"2025-07-29T15:01:26Z","published":"2025-07-29T15:01:26Z","title":"Graph-R1: Towards Agentic GraphRAG Framework via End-to-end\n  Reinforcement Learning","summary":"  Retrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by\nincorporating external knowledge, but relies on chunk-based retrieval that\nlacks structural semantics. GraphRAG methods improve RAG by modeling knowledge\nas entity-relation graphs, but still face challenges in high construction cost,\nfixed one-time retrieval, and reliance on long-context reasoning and prompt\ndesign. To address these challenges, we propose Graph-R1, an agentic GraphRAG\nframework via end-to-end reinforcement learning (RL). It introduces lightweight\nknowledge hypergraph construction, models retrieval as a multi-turn\nagent-environment interaction, and optimizes the agent process via an\nend-to-end reward mechanism. Experiments on standard RAG datasets show that\nGraph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in\nreasoning accuracy, retrieval efficiency, and generation quality.\n","authors":["Haoran Luo","Haihong E","Guanting Chen","Qika Lin","Yikai Guo","Fangzhi Xu","Zemin Kuang","Meina Song","Xiaobao Wu","Yifan Zhu","Luu Anh Tuan"],"pdf_url":"https://arxiv.org/pdf/2507.21892v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2507.07634v2","updated":"2025-07-29T14:39:09Z","published":"2025-07-10T11:02:13Z","title":"FrugalRAG: Learning to retrieve and reason for multi-hop QA","summary":"  We consider the problem of answering complex questions, given access to a\nlarge unstructured document corpus. The de facto approach to solving the\nproblem is to leverage language models that (iteratively) retrieve and reason\nthrough the retrieved documents, until the model has sufficient information to\ngenerate an answer. Attempts at improving this approach focus on\nretrieval-augmented generation (RAG) metrics such as accuracy and recall and\ncan be categorized into two types: (a) fine-tuning on large question answering\n(QA) datasets augmented with chain-of-thought traces, and (b) leveraging\nRL-based fine-tuning techniques that rely on question-document relevance\nsignals. However, efficiency in the number of retrieval searches is an equally\nimportant metric, which has received less attention. In this work, we show\nthat: (1) Large-scale fine-tuning is not needed to improve RAG metrics,\ncontrary to popular claims in recent literature. Specifically, a standard ReAct\npipeline with improved prompts can outperform state-of-the-art methods on\nbenchmarks such as HotPotQA. (2) Supervised and RL-based fine-tuning can help\nRAG from the perspective of frugality, i.e., the latency due to number of\nsearches at inference time. For example, we show that we can achieve\ncompetitive RAG metrics at nearly half the cost (in terms of number of\nsearches) on popular RAG benchmarks, using the same base model, and at a small\ntraining cost (1000 examples).\n","authors":["Abhinav Java","Srivathsan Koundinyan","Nagarajan Natarajan","Amit Sharma"],"pdf_url":"https://arxiv.org/pdf/2507.07634v2.pdf","comment":"Accepted at ICML Workshop: Efficient Systems for Foundation Models"},{"id":"http://arxiv.org/abs/2507.16199v3","updated":"2025-07-29T14:18:28Z","published":"2025-07-22T03:21:48Z","title":"WakenLLM: Evaluating Reasoning Potential and Stability in LLMs via\n  Fine-Grained Benchmarking","summary":"  Large Language Models (LLMs) frequently output the label Unknown in reasoning\ntasks, where two scenarios may appear: (i) an input sample is genuinely\nunverifiable, but the model cannot understand why; and (ii) a verifiable\nproblem that the model fails to solve, thus outputs Unknown. We refer to these\ncases collectively as the Vague Perception phenomenon. Current evaluations\nfocus on whether such answers are honest, rather than analyzing the limits of\nLLM reasoning.\n  To address this, we introduce WakenLLM, a framework that quantifies the\nportion of Unknown output attributable to model incapacity and evaluates\nwhether stimulation can convert them into either correct answers (verifiable)\nor justified (unverifiable) responses with valid reasoning. Our method offers a\nclearer picture of the limits of LLM reasoning and the potential for\ncorrections across various datasets. Comprehensive experiments on six LLMs\nsuggest that, without any training or parameter revision, LLMs can achieve up\nto a 68.53% accuracy improvement on Vague Perception samples through guided\nunderstanding.\n  Our work reveals that current baseline methods only activate a small portion\nof LLMs' reasoning potential, indicating considerable unexplored capacity. This\nextends the theoretical upper bounds of reasoning accuracy in LLMs.\nConsequently, this study deepens our understanding of the latent reasoning\ncapacity of LLMs and offers a new perspective on addressing the Vague\nPerception phenomenon.\n","authors":["Zipeng Ling","Yuehao Tang","Shuliang Liu","Junqi Yang","Shenghong Fu","Chen Huang","Kejia Huang","Yao Wan","Zhichao Hou","Xuming Hu"],"pdf_url":"https://arxiv.org/pdf/2507.16199v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.17206v2","updated":"2025-07-29T14:14:03Z","published":"2025-05-22T18:31:52Z","title":"FB-RAG: Improving RAG with Forward and Backward Lookup","summary":"  Traditional Retrieval-Augmented Generation (RAG) struggles with complex\nqueries that lack strong signals to retrieve the most relevant context, forcing\na trade-off between choosing a small context that misses key information and a\nlarge context that confuses the LLM. To address this, we propose\nForward-Backward RAG (FB-RAG), a new training-free framework based on a simple\nyet powerful forward-looking strategy. FB-RAG employs a light-weight LLM to\npeek into potential future generations, using evidence from multiple sampled\noutputs to precisely identify the most relevant context for a final, more\npowerful generator. This improves performance without complex finetuning or\nReinforcement Learning common in prior work. Across 9 datasets, FB-RAG\nconsistently delivers strong results. Further, the performance gains can be\nachieved with reduced latency due to a shorter, more focused prompt for the\npowerful generator. On EN.QA dataset, FB-RAG matches the leading baseline with\nover 48% latency reduction or achieves an 8% performance improvement with a 10%\nlatency reduction. Our analysis finds cases where even when the forward-looking\nLLM fails to generate correct answers, its attempts are sufficient to guide the\nfinal model to an accurate response, demonstrating how smaller LLMs can\nsystematically improve the performance and efficiency of larger ones.\n","authors":["Kushal Chawla","Alfy Samuel","Anoop Kumar","Daben Liu"],"pdf_url":"https://arxiv.org/pdf/2505.17206v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21836v1","updated":"2025-07-29T14:12:28Z","published":"2025-07-29T14:12:28Z","title":"AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement\n  Learning","summary":"  Large Language Models (LLMs), when enhanced through reasoning-oriented\npost-training, evolve into powerful Large Reasoning Models (LRMs).\nTool-Integrated Reasoning (TIR) further extends their capabilities by\nincorporating external tools, but existing methods often rely on rigid,\npredefined tool-use patterns that risk degrading core language competence.\nInspired by the human ability to adaptively select tools, we introduce AutoTIR,\na reinforcement learning framework that enables LLMs to autonomously decide\nwhether and which tool to invoke during the reasoning process, rather than\nfollowing static tool-use strategies. AutoTIR leverages a hybrid reward\nmechanism that jointly optimizes for task-specific answer correctness,\nstructured output adherence, and penalization of incorrect tool usage, thereby\nencouraging both precise reasoning and efficient tool integration. Extensive\nevaluations across diverse knowledge-intensive, mathematical, and general\nlanguage modeling tasks demonstrate that AutoTIR achieves superior overall\nperformance, significantly outperforming baselines and exhibits superior\ngeneralization in tool-use behavior. These results highlight the promise of\nreinforcement learning in building truly generalizable and scalable TIR\ncapabilities in LLMs. The code and data are available at\nhttps://github.com/weiyifan1023/AutoTIR.\n","authors":["Yifan Wei","Xiaoyan Yu","Yixuan Weng","Tengfei Pan","Angsheng Li","Li Du"],"pdf_url":"https://arxiv.org/pdf/2507.21836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21831v1","updated":"2025-07-29T14:10:31Z","published":"2025-07-29T14:10:31Z","title":"Introducing HALC: A general pipeline for finding optimal prompting\n  strategies for automated coding with LLMs in the computational social\n  sciences","summary":"  LLMs are seeing widespread use for task automation, including automated\ncoding in the social sciences. However, even though researchers have proposed\ndifferent prompting strategies, their effectiveness varies across LLMs and\ntasks. Often trial and error practices are still widespread. We propose\nHALC$-$a general pipeline that allows for the systematic and reliable\nconstruction of optimal prompts for any given coding task and model, permitting\nthe integration of any prompting strategy deemed relevant. To investigate LLM\ncoding and validate our pipeline, we sent a total of 1,512 individual prompts\nto our local LLMs in over two million requests. We test prompting strategies\nand LLM task performance based on few expert codings (ground truth). When\ncompared to these expert codings, we find prompts that code reliably for single\nvariables (${\\alpha}$climate = .76; ${\\alpha}$movement = .78) and across two\nvariables (${\\alpha}$climate = .71; ${\\alpha}$movement = .74) using the LLM\nMistral NeMo. Our prompting strategies are set up in a way that aligns the LLM\nto our codebook$-$we are not optimizing our codebook for LLM friendliness. Our\npaper provides insights into the effectiveness of different prompting\nstrategies, crucial influencing factors, and the identification of reliable\nprompts for each coding task and model.\n","authors":["Andreas Reich","Claudia Thoms","Tobias Schrimpf"],"pdf_url":"https://arxiv.org/pdf/2507.21831v1.pdf","comment":"48 pages, 9 figures and 8 tables"},{"id":"http://arxiv.org/abs/2503.16531v2","updated":"2025-07-29T14:09:40Z","published":"2025-03-18T11:12:15Z","title":"EEG-CLIP : Learning EEG representations from natural language\n  descriptions","summary":"  Deep networks for electroencephalogram (EEG) decoding are often only trained\nto solve one specific task, such as pathology or age decoding. A more general\ntask-agnostic approach is to train deep networks to match a (clinical) EEG\nrecording to its corresponding textual medical report and vice versa. This\napproach was pioneered in the computer vision domain matching images and their\ntext captions and subsequently allowed to do successful zero-shot decoding\nusing textual class prompts. In this work, we follow this approach and develop\na contrastive learning framework, EEG-CLIP, that aligns the EEG time series and\nthe descriptions of the corresponding clinical text in a shared embedding\nspace. We investigated its potential for versatile EEG decoding, evaluating\nperformance in a range of few-shot and zero-shot settings. Overall, we show\nthat EEG-CLIP manages to non-trivially align text and EEG representations. Our\nwork presents a promising approach to learn general EEG representations, which\ncould enable easier analyses of diverse decoding questions through zero-shot\ndecoding or training task-specific models from fewer training examples. The\ncode for reproducing our results is available at\nhttps://github.com/tidiane-camaret/EEGClip\n","authors":["Tidiane Camaret Ndir","Robin Tibor Schirrmeister","Tonio Ball"],"pdf_url":"https://arxiv.org/pdf/2503.16531v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21828v1","updated":"2025-07-29T14:06:19Z","published":"2025-07-29T14:06:19Z","title":"Modelling Adjectival Modification Effects on Semantic Plausibility","summary":"  While the task of assessing the plausibility of events such as ''news is\nrelevant'' has been addressed by a growing body of work, less attention has\nbeen paid to capturing changes in plausibility as triggered by event\nmodification. Understanding changes in plausibility is relevant for tasks such\nas dialogue generation, commonsense reasoning, and hallucination detection as\nit allows to correctly model, for example, ''gentle sarcasm'' as a sign of\ncloseness rather than unkindness among friends [9]. In this work, we tackle the\nADEPT challenge benchmark [6] consisting of 16K English sentence pairs\ndiffering by exactly one adjectival modifier. Our modeling experiments provide\na conceptually novel method by using sentence transformers, and reveal that\nboth they and transformer-based models struggle with the task at hand, and\nsentence transformers - despite their conceptual alignment with the task - even\nunder-perform in comparison to models like RoBERTa. Furthermore, an in-depth\ncomparison with prior work highlights the importance of a more realistic,\nbalanced evaluation method: imbalances distort model performance and evaluation\nmetrics, and weaken result trustworthiness.\n","authors":["Anna Golub","Beate Zywietz","Annerose Eichel"],"pdf_url":"https://arxiv.org/pdf/2507.21828v1.pdf","comment":"Accepted at ESSLLI 2025 Student Session"},{"id":"http://arxiv.org/abs/2507.21815v1","updated":"2025-07-29T13:47:17Z","published":"2025-07-29T13:47:17Z","title":"HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to\n  Support People Who Use Drugs","summary":"  Millions of individuals' well-being are challenged by the harms of substance\nuse. Harm reduction as a public health strategy is designed to improve their\nhealth outcomes and reduce safety risks. Some large language models (LLMs) have\ndemonstrated a decent level of medical knowledge, promising to address the\ninformation needs of people who use drugs (PWUD). However, their performance in\nrelevant tasks remains largely unexplored. We introduce HRIPBench, a benchmark\ndesigned to evaluate LLM's accuracy and safety risks in harm reduction\ninformation provision. The benchmark dataset HRIP-Basic has 2,160\nquestion-answer-evidence pairs. The scope covers three tasks: checking safety\nboundaries, providing quantitative values, and inferring polysubstance use\nrisks. We build the Instruction and RAG schemes to evaluate model behaviours\nbased on their inherent knowledge and the integration of domain knowledge. Our\nresults indicate that state-of-the-art LLMs still struggle to provide accurate\nharm reduction information, and sometimes, carry out severe safety risks to\nPWUD. The use of LLMs in harm reduction contexts should be cautiously\nconstrained to avoid inducing negative health outcomes. WARNING: This paper\ncontains illicit content that potentially induces harms.\n","authors":["Kaixuan Wang","Chenxin Diao","Jason T. Jacques","Zhongliang Guo","Shuai Zhao"],"pdf_url":"https://arxiv.org/pdf/2507.21815v1.pdf","comment":"15 pages, 5 figures, 12 tables, a dataset"},{"id":"http://arxiv.org/abs/2507.21813v1","updated":"2025-07-29T13:45:08Z","published":"2025-07-29T13:45:08Z","title":"Overview of ADoBo at IberLEF 2025: Automatic Detection of Anglicisms in\n  Spanish","summary":"  This paper summarizes the main findings of ADoBo 2025, the shared task on\nanglicism identification in Spanish proposed in the context of IberLEF 2025.\nParticipants of ADoBo 2025 were asked to detect English lexical borrowings (or\nanglicisms) from a collection of Spanish journalistic texts. Five teams\nsubmitted their solutions for the test phase. Proposed systems included LLMs,\ndeep learning models, Transformer-based models and rule-based systems. The\nresults range from F1 scores of 0.17 to 0.99, which showcases the variability\nin performance different systems can have for this task.\n","authors":["Elena Alvarez-Mellado","Jordi Porta-Zamorano","Constantine Lignos","Julio Gonzalo"],"pdf_url":"https://arxiv.org/pdf/2507.21813v1.pdf","comment":"Accepted in the journal Procesamiento del Lenguaje Natural 75"},{"id":"http://arxiv.org/abs/2507.21810v1","updated":"2025-07-29T13:44:40Z","published":"2025-07-29T13:44:40Z","title":"ChartMark: A Structured Grammar for Chart Annotation","summary":"  Chart annotations enhance visualization accessibility but suffer from\nfragmented, non-standardized representations that limit cross-platform reuse.\nWe propose ChartMark, a structured grammar that separates annotation semantics\nfrom visualization implementations. ChartMark features a hierarchical framework\nmapping onto annotation dimensions (e.g., task, chart context), supporting both\nabstract intents and precise visual details. Our toolkit demonstrates\nconverting ChartMark specifications into Vega-Lite visualizations, highlighting\nits flexibility, expressiveness, and practical applicability.\n","authors":["Yiyu Chen","Yifan Wu","Shuyu Shen","Yupeng Xie","Leixian Shen","Hui Xiong","Yuyu Luo"],"pdf_url":"https://arxiv.org/pdf/2507.21810v1.pdf","comment":"IEEE VIS 2025"},{"id":"http://arxiv.org/abs/2409.11274v3","updated":"2025-07-29T13:37:58Z","published":"2024-09-17T15:25:11Z","title":"Task Arithmetic for Language Expansion in Speech Translation","summary":"  Recent progress in large language models (LLMs) has gained interest in\nspeech-text multimodal foundation models, achieving strong performance on\ninstruction-tuned speech translation (ST). However, expanding language pairs is\ncostly due to re-training on combined new and previous datasets. To address\nthis, we aim to build a one-to-many ST system from existing one-to-one ST\nsystems using task arithmetic without re-training. Direct application of task\narithmetic in ST leads to language confusion; therefore, we introduce an\naugmented task arithmetic method incorporating a language control model to\nensure correct target language generation. Our experiments on MuST-C and\nCoVoST-2 show BLEU score improvements of up to 4.66 and 4.92, with COMET gains\nof 8.87 and 11.83. In addition, we demonstrate our framework can extend to\nlanguage pairs lacking paired ST training data or pre-trained ST models by\nsynthesizing ST models based on existing machine translation (MT) and ST models\nvia task analogies.\n","authors":["Yao-Fei Cheng","Hayato Futami","Yosuke Kashiwagi","Emiru Tsunoo","Wen Shen Teo","Siddhant Arora","Shinji Watanabe"],"pdf_url":"https://arxiv.org/pdf/2409.11274v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21782v1","updated":"2025-07-29T13:09:40Z","published":"2025-07-29T13:09:40Z","title":"The Problem with Safety Classification is not just the Models","summary":"  Studying the robustness of Large Language Models (LLMs) to unsafe behaviors\nis an important topic of research today. Building safety classification models\nor guard models, which are fine-tuned models for input/output safety\nclassification for LLMs, is seen as one of the solutions to address the issue.\nAlthough there is a lot of research on the safety testing of LLMs themselves,\nthere is little research on evaluating the effectiveness of such safety\nclassifiers or the evaluation datasets used for testing them, especially in\nmultilingual scenarios. In this position paper, we demonstrate how multilingual\ndisparities exist in 5 safety classification models by considering datasets\ncovering 18 languages. At the same time, we identify potential issues with the\nevaluation datasets, arguing that the shortcomings of current safety\nclassifiers are not only because of the models themselves. We expect that these\nfindings will contribute to the discussion on developing better methods to\nidentify harmful content in LLM inputs across languages.\n","authors":["Sowmya Vajjala"],"pdf_url":"https://arxiv.org/pdf/2507.21782v1.pdf","comment":"Pre-print, Short paper"},{"id":"http://arxiv.org/abs/2507.11230v2","updated":"2025-07-29T13:09:21Z","published":"2025-07-15T12:00:30Z","title":"Sparse Autoencoders Can Capture Language-Specific Concepts Across\n  Diverse Languages","summary":"  Understanding the multilingual mechanisms of large language models (LLMs)\nprovides insight into how they process different languages, yet this remains\nchallenging. Existing studies often focus on individual neurons, but their\npolysemantic nature makes it difficult to isolate language-specific units from\ncross-lingual representations. To address this, we explore sparse autoencoders\n(SAEs) for their ability to learn monosemantic features that represent concrete\nand abstract concepts across languages in LLMs. While some of these features\nare language-independent, the presence of language-specific features remains\nunderexplored. In this work, we introduce SAE-LAPE, a method based on feature\nactivation probability, to identify language-specific features within the\nfeed-forward network. We find that many such features predominantly appear in\nthe middle to final layers of the model and are interpretable. These features\ninfluence the model's multilingual performance and language output and can be\nused for language identification with performance comparable to fastText along\nwith more interpretability. Our code is available at\nhttps://github.com/LyzanderAndrylie/language-specific-features\n","authors":["Lyzander Marciano Andrylie","Inaya Rahmanisa","Mahardika Krisna Ihsani","Alfan Farizki Wicaksono","Haryo Akbarianto Wibowo","Alham Fikri Aji"],"pdf_url":"https://arxiv.org/pdf/2507.11230v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21773v1","updated":"2025-07-29T12:58:27Z","published":"2025-07-29T12:58:27Z","title":"AgriEval: A Comprehensive Chinese Agricultural Benchmark for Large\n  Language Models","summary":"  In the agricultural domain, the deployment of large language models (LLMs) is\nhindered by the lack of training data and evaluation benchmarks. To mitigate\nthis issue, we propose AgriEval, the first comprehensive Chinese agricultural\nbenchmark with three main characteristics: (1) Comprehensive Capability\nEvaluation. AgriEval covers six major agriculture categories and 29\nsubcategories within agriculture, addressing four core cognitive scenarios:\nmemorization, understanding, inference, and generation. (2) High-Quality Data.\nThe dataset is curated from university-level examinations and assignments,\nproviding a natural and robust benchmark for assessing the capacity of LLMs to\napply knowledge and make expert-like decisions. (3) Diverse Formats and\nExtensive Scale. AgriEval comprises 14,697 multiple-choice questions and 2,167\nopen-ended question-and-answer questions, establishing it as the most extensive\nagricultural benchmark available to date. We also present comprehensive\nexperimental results over 51 open-source and commercial LLMs. The experimental\nresults reveal that most existing LLMs struggle to achieve 60% accuracy,\nunderscoring the developmental potential in agricultural LLMs. Additionally, we\nconduct extensive experiments to investigate factors influencing model\nperformance and propose strategies for enhancement. AgriEval is available at\nhttps://github.com/YanPioneer/AgriEval/.\n","authors":["Lian Yan","Haotian Wang","Chen Tang","Haifeng Liu","Tianyang Sun","Liangliang Liu","Yi Guan","Jingchi Jiang"],"pdf_url":"https://arxiv.org/pdf/2507.21773v1.pdf","comment":"36 pages, 22 figures"},{"id":"http://arxiv.org/abs/2507.21750v1","updated":"2025-07-29T12:31:26Z","published":"2025-07-29T12:31:26Z","title":"Adversarial Defence without Adversarial Defence: Enhancing Language\n  Model Robustness via Instance-level Principal Component Removal","summary":"  Pre-trained language models (PLMs) have driven substantial progress in\nnatural language processing but remain vulnerable to adversarial attacks,\nraising concerns about their robustness in real-world applications. Previous\nstudies have sought to mitigate the impact of adversarial attacks by\nintroducing adversarial perturbations into the training process, either\nimplicitly or explicitly. While both strategies enhance robustness, they often\nincur high computational costs. In this work, we propose a simple yet effective\nadd-on module that enhances the adversarial robustness of PLMs by removing\ninstance-level principal components, without relying on conventional\nadversarial defences or perturbing the original training data. Our approach\ntransforms the embedding space to approximate Gaussian properties, thereby\nreducing its susceptibility to adversarial perturbations while preserving\nsemantic relationships. This transformation aligns embedding distributions in a\nway that minimises the impact of adversarial noise on decision boundaries,\nenhancing robustness without requiring adversarial examples or costly\ntraining-time augmentation. Evaluations on eight benchmark datasets show that\nour approach improves adversarial robustness while maintaining comparable\nbefore-attack accuracy to baselines, achieving a balanced trade-off between\nrobustness and generalisation.\n","authors":["Yang Wang","Chenghao Xiao","Yizhi Li","Stuart E. Middleton","Noura Al Moubayed","Chenghua Lin"],"pdf_url":"https://arxiv.org/pdf/2507.21750v1.pdf","comment":"This paper was accepted with an A-decision to Transactions of the\n  Association for Computational Linguistics. This version is the\n  pre-publication version prior to MIT Press production"},{"id":"http://arxiv.org/abs/2201.01984v2","updated":"2025-07-29T10:32:39Z","published":"2022-01-06T09:23:18Z","title":"Image Captioning via Compact Bidirectional Architecture","summary":"  Most current image captioning models typically generate captions from\nleft-to-right. This unidirectional property makes them can only leverage past\ncontext but not future context. Though refinement-based models can exploit both\npast and future context by generating a new caption in the second stage based\non pre-retrieved or pre-generated captions in the first stage, the decoder of\nthese models generally consists of two networks~(i.e. a retriever or captioner\nin the first stage and a captioner in the second stage), which can only be\nexecuted sequentially. In this paper, we introduce a Compact Bidirectional\nTransformer model for image captioning that can leverage bidirectional context\nimplicitly and explicitly while the decoder can be executed parallelly.\nSpecifically, it is implemented by tightly coupling left-to-right(L2R) and\nright-to-left(R2L) flows into a single compact model to serve as a\nregularization for implicitly exploiting bidirectional context and optionally\nallowing explicit interaction of the bidirectional flows, while the final\ncaption is chosen from either L2R or R2L flow in a sentence-level ensemble\nmanner. We conduct extensive ablation studies on MSCOCO benchmark and find that\nthe compact bidirectional architecture and the sentence-level ensemble play\nmore important roles than the explicit interaction mechanism. By combining with\nword-level ensemble seamlessly, the effect of sentence-level ensemble is\nfurther enlarged. We further extend the conventional one-flow self-critical\ntraining to the two-flows version under this architecture and achieve new\nstate-of-the-art results in comparison with non-vision-language-pretraining\nmodels. Finally, we verify the generality of this compact bidirectional\narchitecture by extending it to LSTM backbone. Source code is available at\nhttps://github.com/YuanEZhou/cbtic.\n","authors":["Zijie Song","Yuanen Zhou","Zhenzhen Hu","Daqing Liu","Huixia Ben","Richang Hong","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2201.01984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.04142v2","updated":"2025-07-29T10:30:24Z","published":"2025-04-05T11:26:48Z","title":"My Life in Artificial Intelligence: People, anecdotes, and some lessons\n  learnt","summary":"  In this very personal workography, I relate my 40-year experiences as a\nresearcher and educator in and around Artificial Intelligence (AI), more\nspecifically Natural Language Processing. I describe how curiosity, and the\ncircumstances of the day, led me to work in both industry and academia, and in\nvarious countries, including The Netherlands (Amsterdam, Eindhoven, and\nUtrecht), the USA (Stanford), England (Brighton), Scotland (Aberdeen), and\nChina (Beijing and Harbin). People and anecdotes play a large role in my story;\nthe history of AI forms its backdrop. I focus on things that might be of\ninterest to (even) younger colleagues, given the choices they face in their own\nwork and life at a time when AI is finally emerging from the shadows.\n","authors":["Kees van Deemter"],"pdf_url":"https://arxiv.org/pdf/2504.04142v2.pdf","comment":"34 pages"},{"id":"http://arxiv.org/abs/2507.18013v3","updated":"2025-07-29T10:30:18Z","published":"2025-07-24T01:00:48Z","title":"Technical Report of TeleChat2, TeleChat2.5 and T1","summary":"  We introduce the latest series of TeleChat models: \\textbf{TeleChat2},\n\\textbf{TeleChat2.5}, and \\textbf{T1}, offering a significant upgrade over\ntheir predecessor, TeleChat. Despite minimal changes to the model architecture,\nthe new series achieves substantial performance gains through enhanced training\nstrategies in both pre-training and post-training stages. The series begins\nwith \\textbf{TeleChat2}, which undergoes pretraining on 10 trillion\nhigh-quality and diverse tokens. This is followed by Supervised Fine-Tuning\n(SFT) and Direct Preference Optimization (DPO) to further enhance its\ncapabilities. \\textbf{TeleChat2.5} and \\textbf{T1} expand the pipeline by\nincorporating a continual pretraining phase with domain-specific datasets,\ncombined with reinforcement learning (RL) to improve performance in code\ngeneration and mathematical reasoning tasks. The \\textbf{T1} variant is\ndesigned for complex reasoning, supporting long Chain-of-Thought (CoT)\nreasoning and demonstrating substantial improvements in mathematics and coding.\nIn contrast, \\textbf{TeleChat2.5} prioritizes speed, delivering rapid\ninference. Both flagship models of \\textbf{T1} and \\textbf{TeleChat2.5} are\ndense Transformer-based architectures with 115B parameters, showcasing\nsignificant advancements in reasoning and general task performance compared to\nthe original TeleChat. Notably, \\textbf{T1-115B} outperform proprietary models\nsuch as OpenAI's o1-mini and GPT-4o. We publicly release \\textbf{TeleChat2},\n\\textbf{TeleChat2.5} and \\textbf{T1}, including post-trained versions with 35B\nand 115B parameters, to empower developers and researchers with\nstate-of-the-art language models tailored for diverse applications.\n","authors":["Zihan Wang","Xinzhang Liu","Yitong Yao","Chao Wang","Yu Zhao","Zhihao Yang","Wenmin Deng","Kaipeng Jia","Jiaxin Peng","Yuyao Huang","Sishi Xiong","Zhuo Jiang","Kaidong Yu","Xiaohui Hu","Fubei Yao","Ruiyu Fang","Zhuoru Jiang","Ruiting Song","Qiyi Xie","Rui Xue","Xuewei He","Yanlei Xue","Zhu Yuan","Zhaoxi Zhang","Zilu Huang","Shiquan Wang","Xin Wang","Hanming Wu","Mingyuan Wang","Xufeng Zhan","Yuhan Sun","Zhaohu Xing","Yuhao Jiang","Bingkai Yang","Shuangyong Song","Yongxiang Li","Zhongjiang He","Xuelong Li"],"pdf_url":"https://arxiv.org/pdf/2507.18013v3.pdf","comment":"32 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.21652v1","updated":"2025-07-29T10:08:52Z","published":"2025-07-29T10:08:52Z","title":"UnsafeChain: Enhancing Reasoning Model Safety via Hard Cases","summary":"  As large reasoning models (LRMs) grow more capable, chain-of-thought (CoT)\nreasoning introduces new safety challenges. Existing SFT-based safety alignment\nstudies dominantly focused on filtering prompts with safe, high-quality\nresponses, while overlooking hard prompts that always elicit harmful outputs.\nTo fill this gap, we introduce UnsafeChain, a safety alignment dataset\nconstructed from hard prompts with diverse sources, where unsafe completions\nare identified and explicitly corrected into safe responses. By exposing models\nto unsafe behaviors and guiding their correction, UnsafeChain enhances safety\nwhile preserving general reasoning ability. We fine-tune three LRMs on\nUnsafeChain and compare them against recent SafeChain and STAR-1 across six\nout-of-distribution and five in-distribution benchmarks. UnsafeChain\nconsistently outperforms prior datasets, with even a 1K subset matching or\nsurpassing baseline performance, demonstrating the effectiveness and\ngeneralizability of correction-based supervision. We release our dataset and\ncode at https://github.com/mbzuai-nlp/UnsafeChain\n","authors":["Raj Vardhan Tomar","Preslav Nakov","Yuxia Wang"],"pdf_url":"https://arxiv.org/pdf/2507.21652v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21645v1","updated":"2025-07-29T10:02:43Z","published":"2025-07-29T10:02:43Z","title":"Libra: Assessing and Improving Reward Model by Learning to Think","summary":"  Reinforcement learning (RL) has significantly improved the reasoning ability\nof large language models. However, current reward models underperform in\nchallenging reasoning scenarios and predominant RL training paradigms rely on\nrule-based or reference-based rewards, which impose two critical limitations:\n1) the dependence on finely annotated reference answer to attain rewards; and\n2) the requirement for constrained output format. These limitations\nfundamentally hinder further RL data scaling and sustained enhancement of model\nreasoning performance. To address these limitations, we propose a comprehensive\nframework for evaluating and improving the performance of reward models in\ncomplex reasoning scenarios. We first present a reasoning-oriented benchmark\n(Libra Bench), systematically constructed from a diverse collection of\nchallenging mathematical problems and advanced reasoning models, to address the\nlimitations of existing reward model benchmarks in reasoning scenarios. We\nfurther introduce a novel approach for improving the generative reward model\nvia learning-to-think methodologies. Based on the proposed approach, we develop\nLibra-RM series, a collection of generative reward models with reasoning\ncapabilities that achieve state-of-the-art results on various benchmarks.\nComprehensive downstream experiments are conducted and the experimental results\ndemonstrate the correlation between our Libra Bench and downstream application,\nand the potential of Libra-RM to further improve reasoning models with\nunlabeled data.\n","authors":["Meng Zhou","Bei Li","Jiahao Liu","Xiaowen Shi","Yang Bai","Rongxiang Weng","Jingang Wang","Xunliang Cai"],"pdf_url":"https://arxiv.org/pdf/2507.21645v1.pdf","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2504.10227v2","updated":"2025-07-29T09:46:02Z","published":"2025-04-14T13:46:35Z","title":"Probing then Editing Response Personality of Large Language Models","summary":"  Large Language Models (LLMs) have demonstrated promising capabilities to\ngenerate responses that simulate consistent personality traits. Despite the\nmajor attempts to analyze personality expression through output-based\nevaluations, little is known about how such traits are internally encoded\nwithin LLM parameters. In this paper, we introduce a layer-wise probing\nframework to systematically investigate the layer-wise capability of LLMs in\nsimulating personality for responding. We conduct probing experiments on 11\nopen-source LLMs over the PersonalityEdit benchmark and find that LLMs\npredominantly simulate personality for responding in their middle and upper\nlayers, with instruction-tuned models demonstrating a slightly clearer\nseparation of personality traits. Furthermore, by interpreting the trained\nprobing hyperplane as a layer-wise boundary for each personality category, we\npropose a layer-wise perturbation method to edit the personality expressed by\nLLMs during inference. Our results show that even when the prompt explicitly\nspecifies a particular personality, our method can still successfully alter the\nresponse personality of LLMs. Interestingly, the difficulty of converting\nbetween certain personality traits varies substantially, which aligns with the\nrepresentational distances in our probing experiments. Finally, we conduct a\ncomprehensive MMLU benchmark evaluation and time overhead analysis,\ndemonstrating that our proposed personality editing method incurs only minimal\ndegradation in general capabilities while maintaining low training costs and\nacceptable inference latency. Our code is publicly available at\nhttps://github.com/universe-sky/probing-then-editing-personality.\n","authors":["Tianjie Ju","Zhenyu Shao","Bowen Wang","Yujia Chen","Zhuosheng Zhang","Hao Fei","Mong-Li Lee","Wynne Hsu","Sufeng Duan","Gongshen Liu"],"pdf_url":"https://arxiv.org/pdf/2504.10227v2.pdf","comment":"Accepted at COLM 2025"},{"id":"http://arxiv.org/abs/2408.10635v3","updated":"2025-07-29T09:42:39Z","published":"2024-08-20T08:22:04Z","title":"Strategist: Self-improvement of LLM Decision Making via Bi-Level Tree\n  Search","summary":"  Traditional reinforcement learning and planning typically requires vast\namounts of data and training to develop effective policies. In contrast, large\nlanguage models (LLMs) exhibit strong generalization and zero-shot\ncapabilities, but struggle with tasks that require detailed planning and\ndecision-making in complex action spaces. We introduce STRATEGIST, a novel\napproach that integrates the strengths of both methods. Our approach leverages\nLLMs to search and update high-level strategies (as text), which are then\nrefined and executed by low-level Monte Carlo Tree Search (MCTS). STRATEGIST is\na generalizable framework to optimize the strategy through population-based\nself-play simulations without the need for any training data. We demonstrate\nthe effectiveness of STRATEGIST in learning optimal strategies for competitive,\nmulti-turn games with partial information, including Game of Pure Strategy\n(GOPS) and multi-agent, hidden-identity discussion games like The Resistance:\nAvalon. Our results show that agents equipped with STRATEGIST outperform those\ntrained with traditional RL methods, other LLM-based skill acquisition\ntechniques, pre-existing LLM agents across both game environments and achieves\ncomparable performance against human players.\n","authors":["Jonathan Light","Min Cai","Weiqin Chen","Guanzhi Wang","Xiusi Chen","Wei Cheng","Yisong Yue","Ziniu Hu"],"pdf_url":"https://arxiv.org/pdf/2408.10635v3.pdf","comment":"website: https://llm-strategist.github.io"},{"id":"http://arxiv.org/abs/2407.15549v3","updated":"2025-07-29T09:37:22Z","published":"2024-07-22T11:19:14Z","title":"Latent Adversarial Training Improves Robustness to Persistent Harmful\n  Behaviors in LLMs","summary":"  Large language models (LLMs) can often be made to behave in undesirable ways\nthat they are explicitly fine-tuned not to. For example, the LLM red-teaming\nliterature has produced a wide variety of 'jailbreaking' techniques to elicit\nharmful text from models that were fine-tuned to be harmless. Recent work on\nred-teaming, model editing, and interpretability suggests that this challenge\nstems from how (adversarial) fine-tuning largely serves to suppress rather than\nremove undesirable capabilities from LLMs. Prior work has introduced latent\nadversarial training (LAT) as a way to improve robustness to broad classes of\nfailures. These prior works have considered untargeted latent space attacks\nwhere the adversary perturbs latent activations to maximize loss on examples of\ndesirable behavior. Untargeted LAT can provide a generic type of robustness but\ndoes not leverage information about specific failure modes. Here, we experiment\nwith targeted LAT where the adversary seeks to minimize loss on a specific\ncompeting task. We find that it can augment a wide variety of state-of-the-art\nmethods. First, we use targeted LAT to improve robustness to jailbreaks,\noutperforming a strong R2D2 baseline with orders of magnitude less compute.\nSecond, we use it to more effectively remove backdoors with no knowledge of the\ntrigger. Finally, we use it to more effectively unlearn knowledge for specific\nundesirable tasks in a way that is also more robust to re-learning. Overall,\nour results suggest that targeted LAT can be an effective tool for defending\nagainst harmful behaviors from LLMs.\n","authors":["Abhay Sheshadri","Aidan Ewart","Phillip Guo","Aengus Lynch","Cindy Wu","Vivek Hebbar","Henry Sleight","Asa Cooper Stickland","Ethan Perez","Dylan Hadfield-Menell","Stephen Casper"],"pdf_url":"https://arxiv.org/pdf/2407.15549v3.pdf","comment":"Code at https://github.com/aengusl/latent-adversarial-training.\n  Models at https://huggingface.co/LLM-LAT"},{"id":"http://arxiv.org/abs/2507.21609v1","updated":"2025-07-29T09:06:09Z","published":"2025-07-29T09:06:09Z","title":"Multilingual JobBERT for Cross-Lingual Job Title Matching","summary":"  We introduce JobBERT-V3, a contrastive learning-based model for cross-lingual\njob title matching. Building on the state-of-the-art monolingual JobBERT-V2,\nour approach extends support to English, German, Spanish, and Chinese by\nleveraging synthetic translations and a balanced multilingual dataset of over\n21 million job titles. The model retains the efficiency-focused architecture of\nits predecessor while enabling robust alignment across languages without\nrequiring task-specific supervision. Extensive evaluations on the TalentCLEF\n2025 benchmark demonstrate that JobBERT-V3 outperforms strong multilingual\nbaselines and achieves consistent performance across both monolingual and\ncross-lingual settings. While not the primary focus, we also show that the\nmodel can be effectively used to rank relevant skills for a given job title,\ndemonstrating its broader applicability in multilingual labor market\nintelligence. The model is publicly available:\nhttps://huggingface.co/TechWolf/JobBERT-v3.\n","authors":["Jens-Joris Decorte","Matthias De Lange","Jeroen Van Hautte"],"pdf_url":"https://arxiv.org/pdf/2507.21609v1.pdf","comment":"Accepted to the TalentCLEF 2025 Workshop as part of CLEF 2025"},{"id":"http://arxiv.org/abs/2411.19096v2","updated":"2025-07-29T08:49:05Z","published":"2024-11-28T12:17:24Z","title":"Pralekha: Cross-Lingual Document Alignment for Indic Languages","summary":"  Mining parallel document pairs for document-level machine translation (MT)\nremains challenging due to the limitations of existing Cross-Lingual Document\nAlignment (CLDA) techniques. Most approaches rely on metadata such as URLs,\nwhich is often unavailable in low-resource language settings, while others\nrepresent documents using pooled sentence embeddings, which fail to capture\nfine-grained alignment cues. Moreover, current sentence embedding models have\nlimited context windows, hindering their ability to represent document-level\ninformation effectively. To address these challenges for Indic languages, we\nintroduce PRALEKHA, a large-scale benchmark for evaluating document-level\nalignment techniques. It contains over 3 million aligned document pairs across\n11 Indic languages and English, of which 1.5 million are English--Indic pairs.\nFurthermore, we propose Document Alignment Coefficient (DAC), a novel metric\nfor fine-grained document alignment. Unlike pooling-based approaches, DAC\naligns documents by matching smaller chunks and computes similarity as the\nratio of aligned chunks to the average number of chunks in a pair. Intrinsic\nevaluation shows that DAC achieves substantial improvements over pooling-based\nbaselines, particularly in noisy scenarios. Extrinsic evaluation further\ndemonstrates that document MT models trained on DAC-aligned pairs consistently\noutperform those using baseline alignment methods. These results highlight\nDAC's effectiveness for parallel document mining. The PRALEKHA dataset and CLDA\nevaluation framework will be made publicly available.\n","authors":["Sanjay Suryanarayanan","Haiyue Song","Mohammed Safi Ur Rahman Khan","Anoop Kunchukuttan","Raj Dabre"],"pdf_url":"https://arxiv.org/pdf/2411.19096v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.22493v2","updated":"2025-07-29T08:42:14Z","published":"2025-06-24T20:33:51Z","title":"A Detailed Factor Analysis for the Political Compass Test: Navigating\n  Ideologies of Large Language Models","summary":"  Political Compass Test (PCT) or similar questionnaires have been used to\nquantify LLM's political leanings. Building on a recent line of work that\nexamines the validity of PCT tests, we demonstrate that variation in standard\ngeneration parameters does not significantly impact the models' PCT scores.\nHowever, external factors such as prompt variations and fine-tuning\nindividually and in combination affect the same. Finally, we demonstrate that\nwhen models are fine-tuned on text datasets with higher political content than\nothers, the PCT scores are not differentially affected. This calls for a\nthorough investigation into the validity of PCT and similar tests, as well as\nthe mechanism by which political leanings are encoded in LLMs.\n","authors":["Sadia Kamal","Lalu Prasad Yadav Prakash","S M Rafiuddin","Mohammed Rakib","Arunkumar Bagavathi","Atriya Sen","Sagnik Ray Choudhury"],"pdf_url":"https://arxiv.org/pdf/2506.22493v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03248v2","updated":"2025-07-29T08:19:36Z","published":"2024-12-04T11:47:57Z","title":"AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and\n  Pruning","summary":"  Large language models (LLMs) have enabled the creation of multi-modal LLMs\nthat exhibit strong comprehension of visual data such as images and videos.\nHowever, these models usually rely on extensive visual tokens from visual\nencoders, leading to high computational demands, which limits their\napplicability in resource-constrained environments and for long-context tasks.\nIn this work, we propose a training-free adaptive inference method for\nmulti-modal LLMs that can accommodate a broad range of efficiency requirements\nwith a minimum performance drop. Our method consists of a) iterative token\nmerging based on embedding similarity before LLMs, and b) progressive token\npruning within LLM layers based on multi-modal importance. With a minimalist\ndesign, our method can be applied to both video and image LLMs. Extensive\nexperiments on diverse video and image benchmarks demonstrate that our method\nsubstantially reduces computation load (e.g., a $\\textbf{7-fold}$ reduction in\nFLOPs) while preserving the performance of video and image LLMs. Further, at a\nsimilar computational cost, our method outperforms the state-of-the-art methods\nin long video understanding (e.g., $\\textbf{+4.6}$ on MLVU). Additionally, our\nin-depth analysis provides insights into token redundancy and LLM layer\nbehaviors, offering guidance for future research in designing efficient\nmulti-modal LLMs. Our code is available at https://github.com/LaVi-Lab/AIM.\n","authors":["Yiwu Zhong","Zhuoming Liu","Yin Li","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2412.03248v2.pdf","comment":"Accepted to ICCV 2025"},{"id":"http://arxiv.org/abs/2507.21568v1","updated":"2025-07-29T07:59:20Z","published":"2025-07-29T07:59:20Z","title":"Multi-Hypothesis Distillation of Multilingual Neural Translation Models\n  for Low-Resource Languages","summary":"  This paper explores sequence-level knowledge distillation (KD) of\nmultilingual pre-trained encoder-decoder translation models. We argue that the\nteacher model's output distribution holds valuable insights for the student,\nbeyond the approximated mode obtained through beam search (the standard\ndecoding method), and present Multi-Hypothesis Distillation (MHD), a\nsequence-level KD method that generates multiple translations for each source\nsentence. This provides a larger representation of the teacher model\ndistribution and exposes the student model to a wider range of target-side\nprefixes. We leverage $n$-best lists from beam search to guide the student's\nlearning and examine alternative decoding methods to address issues like low\nvariability and the under-representation of infrequent tokens. For low-resource\nlanguages, our research shows that while sampling methods may slightly\ncompromise translation quality compared to beam search based approaches, they\nenhance the generated corpora with greater variability and lexical richness.\nThis ultimately improves student model performance and mitigates the gender\nbias amplification often associated with KD.\n","authors":["Aarón Galiano-Jiménez","Juan Antonio Pérez-Ortiz","Felipe Sánchez-Martínez","Víctor M. Sánchez-Cartagena"],"pdf_url":"https://arxiv.org/pdf/2507.21568v1.pdf","comment":"17 pages, 12 figures"},{"id":"http://arxiv.org/abs/2507.21556v1","updated":"2025-07-29T07:40:32Z","published":"2025-07-29T07:40:32Z","title":"Evaluating the cognitive reality of Spanish irregular morphomic\n  patterns: Humans vs. Transformers","summary":"  This study investigates the cognitive plausibility of the Spanish irregular\nmorphomic pattern by directly comparing transformer-based neural networks to\nhuman behavioral data from \\citet{Nevins2015TheRA}. Using the same analytical\nframework as the original human study, we evaluate whether transformer models\ncan replicate human-like sensitivity to a complex linguistic phenomena, the\nmorphome, under controlled input conditions. Our experiments focus on three\nfrequency conditions: natural, low-frequency, and high-frequency distributions\nof verbs exhibiting irregular morphomic patterns. While the models outperformed\nhumans in stem and suffix accuracy, a clear divergence emerged in response\npreferences. Unlike humans, who consistently favored natural responses across\nall test items, models' preferred irregular responses and were influenced by\nthe proportion of irregular verbs in their training data. Additionally, models\ntrained on the natural and low-frequency distributions, but not the\nhigh-frequency distribution, were sensitive to the phonological similarity\nbetween test items and real Spanish L-shaped verbs.\n","authors":["Akhilesh Kakolu Ramarao","Kevin Tang","Dinah Baer-Henney"],"pdf_url":"https://arxiv.org/pdf/2507.21556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.16518v2","updated":"2025-07-29T07:40:20Z","published":"2025-07-22T12:27:08Z","title":"C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving\n  Reasoning","summary":"  Recent advances in multimodal large language models (MLLMs) have shown\nimpressive reasoning capabilities. However, further enhancing existing MLLMs\nnecessitates high-quality vision-language datasets with carefully curated task\ncomplexities, which are both costly and challenging to scale. Although recent\nself-improving models that iteratively refine themselves offer a feasible\nsolution, they still suffer from two core challenges: (i) most existing methods\naugment visual or textual data separately, resulting in discrepancies in data\ncomplexity (e.g., over-simplified diagrams paired with redundant textual\ndescriptions); and (ii) the evolution of data and models is also separated,\nleading to scenarios where models are exposed to tasks with mismatched\ndifficulty levels. To address these issues, we propose C2-Evo, an automatic,\nclosed-loop self-improving framework that jointly evolves both training data\nand model capabilities. Specifically, given a base dataset and a base model,\nC2-Evo enhances them by a cross-modal data evolution loop and a data-model\nevolution loop. The former loop expands the base dataset by generating complex\nmultimodal problems that combine structured textual sub-problems with\niteratively specified geometric diagrams, while the latter loop adaptively\nselects the generated problems based on the performance of the base model, to\nconduct supervised fine-tuning and reinforcement learning alternately.\nConsequently, our method continuously refines its model and training data, and\nconsistently obtains considerable performance gains across multiple\nmathematical reasoning benchmarks. Our code, models, and datasets will be\nreleased.\n","authors":["Xiuwei Chen","Wentao Hu","Hanhui Li","Jun Zhou","Zisheng Chen","Meng Cao","Yihan Zeng","Kui Zhang","Yu-Jie Yuan","Jianhua Han","Hang Xu","Xiaodan Liang"],"pdf_url":"https://arxiv.org/pdf/2507.16518v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2507.22019v1","updated":"2025-07-29T17:12:16Z","published":"2025-07-29T17:12:16Z","title":"Not Here, Go There: Analyzing Redirection Patterns on the Web","summary":"  URI redirections are integral to web management, supporting structural\nchanges, SEO optimization, and security. However, their complexities affect\nusability, SEO performance, and digital preservation. This study analyzed 11\nmillion unique redirecting URIs, following redirections up to 10 hops per URI,\nto uncover patterns and implications of redirection practices. Our findings\nrevealed that 50% of the URIs terminated successfully, while 50% resulted in\nerrors, including 0.06% exceeding 10 hops. Canonical redirects, such as HTTP to\nHTTPS transitions, were prevalent, reflecting adherence to SEO best practices.\nNon-canonical redirects, often involving domain or path changes, highlighted\nsignificant web migrations, rebranding, and security risks. Notable patterns\nincluded \"sink\" URIs, where multiple redirects converged, ranging from traffic\nconsolidation by global websites to deliberate \"Rickrolling.\" The study also\nidentified 62,000 custom 404 URIs, almost half being soft 404s, which could\ncompromise SEO and user experience. These findings underscore the critical role\nof URI redirects in shaping the web while exposing challenges such as outdated\nURIs, server instability, and improper error handling. This research offers a\ndetailed analysis of URI redirection practices, providing insights into their\nprevalence, types, and outcomes. By examining a large dataset, we highlight\ninefficiencies in redirection chains and examine patterns such as the use of\n\"sink\" URIs and custom error pages. This information can help webmasters,\nresearchers, and digital archivists improve web usability, optimize resource\nallocation, and safeguard valuable online content.\n","authors":["Kritika Garg","Sawood Alam","Dietrich Ayala","Michele C. Weigle","Michael L. Nelson"],"pdf_url":"https://arxiv.org/pdf/2507.22019v1.pdf","comment":"Extended version of the paper accepted at the 2025 ACM Web Science\n  Conference (WebSci 2025)"},{"id":"http://arxiv.org/abs/2507.21989v1","updated":"2025-07-29T16:39:54Z","published":"2025-07-29T16:39:54Z","title":"Benchmarking Filtered Approximate Nearest Neighbor Search Algorithms on\n  Transformer-based Embedding Vectors","summary":"  Advances in embedding models for text, image, audio, and video drive progress\nacross multiple domains, including retrieval-augmented generation,\nrecommendation systems, vehicle/person reidentification, and face recognition.\nMany applications in these domains require an efficient method to retrieve\nitems that are close to a given query in the embedding space while satisfying a\nfilter condition based on the item's attributes, a problem known as Filtered\nApproximate Nearest Neighbor Search (FANNS). In this work, we present a\ncomprehensive survey and taxonomy of FANNS methods and analyze how they are\nbenchmarked in the literature. By doing so, we identify a key challenge in the\ncurrent FANNS landscape: the lack of diverse and realistic datasets,\nparticularly ones derived from the latest transformer-based text embedding\nmodels. To address this, we introduce a novel dataset consisting of embedding\nvectors for the abstracts of over 2.7 million research articles from the arXiv\nrepository, accompanied by 11 real-world attributes such as authors and\ncategories. We benchmark a wide range of FANNS methods on our novel dataset and\nfind that each method has distinct strengths and limitations; no single\napproach performs best across all scenarios. ACORN, for example, supports\nvarious filter types and performs reliably across dataset scales but is often\noutperformed by more specialized methods. SeRF shows excellent performance for\nrange filtering on ordered attributes but cannot handle categorical attributes.\nFiltered-DiskANN and UNG excel on the medium-scale dataset but fail on the\nlarge-scale dataset, highlighting the challenge posed by transformer-based\nembeddings, which are often more than an order of magnitude larger than earlier\nembeddings. We conclude that no universally best method exists.\n","authors":["Patrick Iff","Paul Bruegger","Marcin Chrapek","Maciej Besta","Torsten Hoefler"],"pdf_url":"https://arxiv.org/pdf/2507.21989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21939v1","updated":"2025-07-29T15:51:44Z","published":"2025-07-29T15:51:44Z","title":"The Curious Case of High-Dimensional Indexing as a File Structure: A\n  Case Study of eCP-FS","summary":"  Modern analytical pipelines routinely deploy multiple deep learning and\nretrieval models that rely on approximate nearest-neighbor (ANN) indexes to\nsupport efficient similarity-based search. While many state-of-the-art\nANN-indexes are memory-based (e.g., HNSW and IVF), using multiple ANN indexes\ncreates a competition for limited GPU/CPU memory resources, which in turn\nnecessitates disk-based index structures (e.g., DiskANN or eCP). In typical\nindex implementations, the main component is a complex data structure that is\nserialized to disk and is read either fully at startup time, for memory-based\nindexes, or incrementally at query time, for disk-based indexes. To visualize\nthe index structure, or analyze its quality, complex coding is needed that is\neither embedded in the index implementation or replicates the code that reads\nthe data structure. In this paper, we consider an alternative approach that\nmaps the data structure to a file structure, using a file library, making the\nindex easily readable for any programming language and even human-readable. The\ndisadvantage is that the serialized index is verbose, leading to overhead of\nsearching through the index. The question addressed in this paper is how severe\nthis performance penalty is. To that end, this paper presents eCP-FS, a\nfile-based implementation of eCP, a well-known disk-based ANN index. A\ncomparison with state-of-the-art indexes shows that while eCP-FS is slower, the\nimplementation is nevertheless somewhat competitive even when memory is not\nconstrained. In a memory-constrained scenario, eCP-FS offers a minimal memory\nfootprint, making it ideal for resource-constrained or multi-index\nenvironments.\n","authors":["Omar Shahbaz Khan","Gylfi Þór Guðmundsson","Björn Þór Jónsson"],"pdf_url":"https://arxiv.org/pdf/2507.21939v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21903v1","updated":"2025-07-29T15:14:39Z","published":"2025-07-29T15:14:39Z","title":"Who's important? -- SUnSET: Synergistic Understanding of Stakeholder,\n  Events and Time for Timeline Generation","summary":"  As news reporting becomes increasingly global and decentralized online,\ntracking related events across multiple sources presents significant\nchallenges. Existing news summarization methods typically utilizes Large\nLanguage Models and Graphical methods on article-based summaries. However, this\nis not effective since it only considers the textual content of similarly dated\narticles to understand the gist of the event. To counteract the lack of\nanalysis on the parties involved, it is essential to come up with a novel\nframework to gauge the importance of stakeholders and the connection of related\nevents through the relevant entities involved. Therefore, we present SUnSET:\nSynergistic Understanding of Stakeholder, Events and Time for the task of\nTimeline Summarization (TLS). We leverage powerful Large Language Models (LLMs)\nto build SET triplets and introduced the use of stakeholder-based ranking to\nconstruct a $Relevancy$ metric, which can be extended into general situations.\nOur experimental results outperform all prior baselines and emerged as the new\nState-of-the-Art, highlighting the impact of stakeholder information within\nnews article.\n","authors":["Tiviatis Sim","Kaiwen Yang","Shen Xin","Kenji Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2507.21903v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21884v1","updated":"2025-07-29T14:57:26Z","published":"2025-07-29T14:57:26Z","title":"Exploration on Demand: From Algorithmic Control to User Empowerment","summary":"  Recommender systems often struggle with over-specialization, which severely\nlimits users' exposure to diverse content and creates filter bubbles that\nreduce serendipitous discovery. To address this fundamental limitation, this\npaper introduces an adaptive clustering framework with user-controlled\nexploration that effectively balances personalization and diversity in movie\nrecommendations. Our approach leverages sentence-transformer embeddings to\ngroup items into semantically coherent clusters through an online algorithm\nwith dynamic thresholding, thereby creating a structured representation of the\ncontent space. Building upon this clustering foundation, we propose a novel\nexploration mechanism that empowers users to control recommendation diversity\nby strategically sampling from less-engaged clusters, thus expanding their\ncontent horizons while preserving relevance. Experiments on the MovieLens\ndataset demonstrate the system's effectiveness, showing that exploration\nsignificantly reduces intra-list similarity from 0.34 to 0.26 while\nsimultaneously increasing unexpectedness to 0.73. Furthermore, our Large\nLanguage Model-based A/B testing methodology, conducted with 300 simulated\nusers, reveals that 72.7% of long-term users prefer exploratory recommendations\nover purely exploitative ones, providing strong evidence for the system's\nability to promote meaningful content discovery without sacrificing user\nsatisfaction.\n","authors":["Edoardo Bianchi"],"pdf_url":"https://arxiv.org/pdf/2507.21884v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21770v1","updated":"2025-07-29T12:55:45Z","published":"2025-07-29T12:55:45Z","title":"Proposing a Semantic Movie Recommendation System Enhanced by ChatGPT's\n  NLP Results","summary":"  The importance of recommender systems on the web has grown, especially in the\nmovie industry, with a vast selection of options to watch. To assist users in\ntraversing available items and finding relevant results, recommender systems\nanalyze operational data and investigate users' tastes and habits. Providing\nhighly individualized suggestions can boost user engagement and satisfaction,\nwhich is one of the fundamental goals of the movie industry, significantly in\nonline platforms. According to recent studies and research, using\nknowledge-based techniques and considering the semantic ideas of the textual\ndata is a suitable way to get more appropriate results. This study provides a\nnew method for building a knowledge graph based on semantic information. It\nuses the ChatGPT, as a large language model, to assess the brief descriptions\nof movies and extract their tone of voice. Results indicated that using the\nproposed method may significantly enhance accuracy rather than employing the\nexplicit genres supplied by the publishers.\n","authors":["Ali Fallahi","Azam Bastanfard","Amineh Amini","Hadi Saboohi"],"pdf_url":"https://arxiv.org/pdf/2507.21770v1.pdf","comment":"May 2023, 6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2504.10541v2","updated":"2025-07-29T12:44:24Z","published":"2025-04-13T09:12:35Z","title":"Multi-Modal Hypergraph Enhanced LLM Learning for Recommendation","summary":"  The burgeoning presence of Large Language Models (LLM) is propelling the\ndevelopment of personalized recommender systems. Most existing LLM-based\nmethods fail to sufficiently explore the multi-view graph structure\ncorrelations inherent in recommendation scenarios. To this end, we propose a\nnovel framework, Hypergraph Enhanced LLM Learning for multimodal Recommendation\n(HeLLM), designed to equip LLMs with the capability to capture intricate\nhigher-order semantic correlations by fusing graph-level contextual signals\nwith sequence-level behavioral patterns. In the recommender pre-training phase,\nwe design a user hypergraph to uncover shared interest preferences among users\nand an item hypergraph to capture correlations within multimodal similarities\namong items. The hypergraph convolution and synergistic contrastive learning\nmechanism are introduced to enhance the distinguishability of learned\nrepresentations. In the LLM fine-tuning phase, we inject the learned\ngraph-structured embeddings directly into the LLM's architecture and integrate\nsequential features capturing each user's chronological behavior. This process\nenables hypergraphs to leverage graph-structured information as global context,\nenhancing the LLM's ability to perceive complex relational patterns and\nintegrate multimodal information, while also modeling local temporal dynamics.\nExtensive experiments demonstrate the superiority of our proposed method over\nstate-of-the-art baselines, confirming the advantages of fusing\nhypergraph-based context with sequential user behavior in LLMs for\nrecommendation.\n","authors":["Xu Guo","Tong Zhang","Yuanzhi Wang","Chenxu Wang","Fuyun Wang","Xudong Wang","Xiaoya Zhang","Xin Liu","Zhen Cui"],"pdf_url":"https://arxiv.org/pdf/2504.10541v2.pdf","comment":"12 pages, 4 figures, submitted to IEEE Transactions on Knowledge and\n  Data Engineering"},{"id":"http://arxiv.org/abs/2507.18365v2","updated":"2025-07-29T12:22:41Z","published":"2025-07-24T12:46:30Z","title":"RecPS: Privacy Risk Scoring for Recommender Systems","summary":"  Recommender systems (RecSys) have become an essential component of many web\napplications. The core of the system is a recommendation model trained on\nhighly sensitive user-item interaction data. While privacy-enhancing techniques\nare actively studied in the research community, the real-world model\ndevelopment still depends on minimal privacy protection, e.g., via controlled\naccess. Users of such systems should have the right to choose \\emph{not} to\nshare highly sensitive interactions. However, there is no method allowing the\nuser to know which interactions are more sensitive than others. Thus,\nquantifying the privacy risk of RecSys training data is a critical step to\nenabling privacy-aware RecSys model development and deployment. We propose a\nmembership-inference attack (MIA)- based privacy scoring method, RecPS, to\nmeasure privacy risks at both the interaction and user levels. The RecPS\ninteraction-level score definition is motivated and derived from differential\nprivacy, which is then extended to the user-level scoring method. A critical\ncomponent is the interaction-level MIA method RecLiRA, which gives high-quality\nmembership estimation. We have conducted extensive experiments on well-known\nbenchmark datasets and RecSys models to show the unique features and benefits\nof RecPS scoring in risk assessment and RecSys model unlearning.\n","authors":["Jiajie He","Yuechun Gu","Keke Chen"],"pdf_url":"https://arxiv.org/pdf/2507.18365v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.10381v4","updated":"2025-07-29T09:19:23Z","published":"2024-10-14T11:10:15Z","title":"Collaborative filtering based on nonnegative/binary matrix factorization","summary":"  Collaborative filtering generates recommendations by exploiting user-item\nsimilarities based on rating data, which often contains numerous unrated items.\nTo predict scores for unrated items, matrix factorization techniques such as\nnonnegative matrix factorization (NMF) are often employed. Nonnegative/binary\nmatrix factorization (NBMF), which is an extension of NMF, approximates a\nnonnegative matrix as the product of nonnegative and binary matrices. While\nprevious studies have applied NBMF primarily to dense data such as images, this\npaper proposes a modified NBMF algorithm tailored for collaborative filtering\nwith sparse data. In the modified method, unrated entries in the rating matrix\nare masked, enhancing prediction accuracy. Furthermore, utilizing a low-latency\nIsing machine in NBMF is advantageous in terms of the computation time, making\nthe proposed method beneficial.\n","authors":["Yukino Terui","Yuka Inoue","Yohei Hamakawa","Kosuke Tatsumura","Kazue Kudo"],"pdf_url":"https://arxiv.org/pdf/2410.10381v4.pdf","comment":"12 pages, 8 figures"},{"id":"http://arxiv.org/abs/2504.03524v2","updated":"2025-07-29T09:14:58Z","published":"2025-04-04T15:22:02Z","title":"RANa: Retrieval-Augmented Navigation","summary":"  Methods for navigation based on large-scale learning typically treat each\nepisode as a new problem, where the agent is spawned with a clean memory in an\nunknown environment. While these generalization capabilities to an unknown\nenvironment are extremely important, we claim that, in a realistic setting, an\nagent should have the capacity of exploiting information collected during\nearlier robot operations. We address this by introducing a new\nretrieval-augmented agent, trained with RL, capable of querying a database\ncollected from previous episodes in the same environment and learning how to\nintegrate this additional context information. We introduce a unique agent\narchitecture for the general navigation task, evaluated on ImageNav,\nInstance-ImageNav and ObjectNav. Our retrieval and context encoding methods are\ndata-driven and employ vision foundation models (FM) for both semantic and\ngeometric understanding. We propose new benchmarks for these settings and we\nshow that retrieval allows zero-shot transfer across tasks and environments\nwhile significantly improving performance.\n","authors":["Gianluca Monaci","Rafael S. Rezende","Romain Deffayet","Gabriela Csurka","Guillaume Bono","Hervé Déjean","Stéphane Clinchant","Christian Wolf"],"pdf_url":"https://arxiv.org/pdf/2504.03524v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20227v2","updated":"2025-07-29T08:21:20Z","published":"2025-07-27T11:13:03Z","title":"CTR-Driven Ad Text Generation via Online Feedback Preference\n  Optimization","summary":"  Advertising text plays a critical role in determining click-through rates\n(CTR) in online advertising. Large Language Models (LLMs) offer significant\nefficiency advantages over manual ad text creation. However, LLM-generated ad\ntexts do not guarantee higher CTR performance compared to human-crafted texts,\nrevealing a gap between generation quality and online performance of ad texts.\nIn this work, we propose a novel ad text generation method which optimizes for\nCTR through preference optimization from online feedback. Our approach adopts\nan innovative two-stage framework: (1) diverse ad text sampling via one-shot\nin-context learning, using retrieval-augmented generation (RAG) to provide\nexemplars with chain-of-thought (CoT) reasoning; (2) CTR-driven preference\noptimization from online feedback, which weighs preference pairs according to\ntheir CTR gains and confidence levels. Through our method, the resulting model\nenables end-to-end generation of high-CTR ad texts. Extensive experiments have\ndemonstrated the effectiveness of our method in both offline and online\nmetrics. Notably, we have applied our method on a large-scale online shopping\nplatform and achieved significant CTR improvements, showcasing its strong\napplicability and effectiveness in advertising systems.\n","authors":["Yanda Chen","Zihui Ren","Qixiang Gao","Jiale Chen","Si Chen","Xubin Li","Tiezheng Ge","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2507.20227v2.pdf","comment":"9 pages, 6 figures, 5 tables"},{"id":"http://arxiv.org/abs/2507.21563v1","updated":"2025-07-29T07:51:56Z","published":"2025-07-29T07:51:56Z","title":"Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank\n  Augmentation","summary":"  Recommendation systems often suffer from data sparsity caused by limited\nuser-item interactions, which degrade their performance and amplify popularity\nbias in real-world scenarios. This paper proposes a novel data augmentation\nframework that leverages Large Language Models (LLMs) and item textual\ndescriptions to enrich interaction data. By few-shot prompting LLMs multiple\ntimes to rerank items and aggregating the results via majority voting, we\ngenerate high-confidence synthetic user-item interactions, supported by\ntheoretical guarantees based on the concentration of measure. To effectively\nleverage the augmented data in the context of a graph recommendation system, we\nintegrate it into a graph contrastive learning framework to mitigate\ndistributional shift and alleviate popularity bias. Extensive experiments show\nthat our method improves accuracy and reduces popularity bias, outperforming\nstrong baselines.\n","authors":["Minh-Anh Nguyen","Bao Nguyen","Ha Lan N. T.","Tuan Anh Hoang","Duc-Trong Le","Dung D. Le"],"pdf_url":"https://arxiv.org/pdf/2507.21563v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19846v2","updated":"2025-07-29T06:26:46Z","published":"2025-07-26T07:42:12Z","title":"A Scalable and High Availability Solution for Recommending Resolutions\n  to Problem Tickets","summary":"  Resolution of incidents or problem tickets is a common theme in service\nindustries in any sector, including billing and charging systems in telecom\ndomain. Machine learning can help to identify patterns and suggest resolutions\nfor the problem tickets, based on patterns in the historical data of the\ntickets. However, this process may be complicated due to a variety of phenomena\nsuch as data drift and issues such as missing data, lack of data pertaining to\nresolutions of past incidents, too many similar sounding resolutions due to\nfree text and similar sounding text. This paper proposes a robust ML-driven\nsolution employing clustering, supervised learning, and advanced NLP models to\ntackle these challenges effectively. Building on previous work, we demonstrate\nclustering-based resolution identification, supervised classification with LDA,\nSiamese networks, and One-shot learning, Index embedding. Additionally, we\npresent a real-time dashboard and a highly available Kubernetes-based\nproduction deployment. Our experiments with both the open-source Bitext\ncustomer-support dataset and proprietary telecom datasets demonstrate high\nprediction accuracy.\n","authors":["Harish Saragadam","Chetana K Nayak","Joy Bose"],"pdf_url":"https://arxiv.org/pdf/2507.19846v2.pdf","comment":"9 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.21520v1","updated":"2025-07-29T06:07:59Z","published":"2025-07-29T06:07:59Z","title":"Solution for Meta KDD Cup'25: A Comprehensive Three-Step Framework for\n  Vision Question Answering","summary":"  Vision Large Language Models (VLLMs) have improved multi-modal understanding\nand visual question answering (VQA), but still suffer from hallucinated\nanswers. Multi-modal Retrieval-Augmented Generation (RAG) helps address these\nissues by incorporating external information, yet challenges remain in visual\ncontext comprehension, multi-source retrieval, and multi-turn interactions. To\naddress these challenges, Meta constructed the CRAG-MM benchmark and launched\nthe CRAG-MM Challenge at KDD Cup 2025, which consists of three tasks. This\npaper describes the solutions of all tasks in Meta KDD Cup'25 from BlackPearl\nteam. We use a single model for each task, with key methods including data\naugmentation, RAG, reranking, and multi-task fine-tuning. Our solution achieve\nautomatic evaluation rankings of 3rd, 3rd, and 1st on the three tasks, and win\nsecond place in Task3 after human evaluation.\n","authors":["Zijian Zhang","Xiaocheng Zhang","Yang Zhou","Zhimin Lin","Peng Yan"],"pdf_url":"https://arxiv.org/pdf/2507.21520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21490v1","updated":"2025-07-29T04:16:21Z","published":"2025-07-29T04:16:21Z","title":"Conversations over Clicks: Impact of Chatbots on Information Search in\n  Interdisciplinary Learning","summary":"  This full research paper investigates the impact of generative AI (GenAI) on\nthe learner experience, with a focus on how learners engage with and utilize\nthe information it provides. In e-learning environments, learners often need to\nnavigate a complex information space on their own. This challenge is further\ncompounded in interdisciplinary fields like bioinformatics, due to the varied\nprior knowledge and backgrounds. In this paper, we studied how GenAI influences\ninformation search in bioinformatics research: (1) How do interactions with a\nGenAI chatbot influence learner orienteering behaviors?; and (2) How do\nlearners identify information scent in GenAI chatbot responses? We adopted an\nautoethnographic approach to investigate these questions. GenAI was found to\nsupport orienteering once a learning plan was established, but it was\ncounterproductive prior to that. Moreover, traditionally value-rich information\nsources such as bullet points and related terms proved less effective when\napplied to GenAI responses. Information scents were primarily recognized\nthrough the presence or absence of prior knowledge of the domain. These\nfindings suggest that GenAI should be adopted into e-learning environments with\ncaution, particularly in interdisciplinary learning contexts.\n","authors":["Hannah Kim","Sergei L. Kosakovsky Pond","Stephen MacNeil"],"pdf_url":"https://arxiv.org/pdf/2507.21490v1.pdf","comment":"9 pages, 2 tables, 3 figures, 2025 ASEE/IEEE Frontiers in Education\n  (FIE) Conference preprint"},{"id":"http://arxiv.org/abs/2502.07327v2","updated":"2025-07-29T03:43:44Z","published":"2025-02-11T07:43:47Z","title":"Generative Ghost: Investigating Ranking Bias Hidden in AI-Generated\n  Videos","summary":"  With the rapid development of AI-generated content (AIGC), the creation of\nhigh-quality AI-generated videos has become faster and easier, resulting in the\nInternet being flooded with all kinds of video content. However, the impact of\nthese videos on the content ecosystem remains largely unexplored. Video\ninformation retrieval remains a fundamental approach for accessing video\ncontent. Building on the observation that retrieval models often favor\nAI-generated content in ad-hoc and image retrieval tasks, we investigate\nwhether similar biases emerge in the context of challenging video retrieval,\nwhere temporal and visual factors may further influence model behavior. To\nexplore this, we first construct a comprehensive benchmark dataset containing\nboth real and AI-generated videos, along with a set of fair and rigorous\nmetrics to assess bias. This benchmark consists of 13,000 videos generated by\ntwo state-of-the-art open-source video generation models. We meticulously\ndesign a suite of rigorous metrics to accurately measure this preference,\naccounting for potential biases arising from the limited frame rate and\nsuboptimal quality of AIGC videos. We then applied three off-the-shelf video\nretrieval models to perform retrieval tasks on this hybrid dataset. Our\nfindings reveal a clear preference for AI-generated videos in retrieval.\nFurther investigation shows that incorporating AI-generated videos into the\ntraining set of retrieval models exacerbates this bias. Unlike the preference\nobserved in image modalities, we find that video retrieval bias arises from\nboth unseen visual and temporal information, making the root causes of video\nbias a complex interplay of these two factors. To mitigate this bias, we\nfine-tune the retrieval models using a contrastive learning approach. The\nresults of this study highlight the potential implications of AI-generated\nvideos on retrieval systems.\n","authors":["Haowen Gao","Liang Pang","Shicheng Xu","Leigang Qu","Tat-Seng Chua","Huawei Shen","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2502.07327v2.pdf","comment":"13 pages, Accepted at ACMMM2025"},{"id":"http://arxiv.org/abs/2408.11557v5","updated":"2025-07-29T03:37:44Z","published":"2024-08-21T12:09:37Z","title":"Enhancing Spectral Knowledge Interrogation: A Reliable\n  Retrieval-Augmented Generative Framework on Large Language Models","summary":"  Large Language Model (LLM) has demonstrated significant success in a range of\nnatural language processing (NLP) tasks within general domain. The emergence of\nLLM has introduced innovative methodologies across diverse fields, including\nthe natural sciences. Researchers aim to implement automated, concurrent\nprocess driven by LLM to supplant conventional manual, repetitive and\nlabor-intensive work. In the domain of spectral analysis and detection, it is\nimperative for researchers to autonomously acquire pertinent knowledge across\nvarious research objects, which encompasses the spectroscopic techniques and\nthe chemometric methods that are employed in experiments and analysis.\nParadoxically, despite the recognition of spectroscopic detection as an\neffective analytical method, the fundamental process of knowledge retrieval\nremains both time-intensive and repetitive. In response to this challenge, we\nfirst introduced the Spectral Detection and Analysis Based Paper(SDAAP)\ndataset, which is the first open-source textual knowledge dataset for spectral\nanalysis and detection and contains annotated literature data as well as\ncorresponding knowledge instruction data. Subsequently, we also designed an\nautomated Q\\&A framework based on the SDAAP dataset, which can retrieve\nrelevant knowledge and generate high-quality responses by extracting entities\nin the input as retrieval parameters. It is worth noting that: within this\nframework, LLM is only used as a tool to provide generalizability, while RAG\ntechnique is used to accurately capture the source of the knowledge.This\napproach not only improves the quality of the generated responses, but also\nensures the traceability of the knowledge. Experimental results show that our\nframework generates responses with more reliable expertise compared to the\nbaseline.\n","authors":["Jiheng Liang","Zujie Xie","Ziru Yu","Xiangyang Yu"],"pdf_url":"https://arxiv.org/pdf/2408.11557v5.pdf","comment":"16 pages,10 figures,3 tables"},{"id":"http://arxiv.org/abs/2507.21474v1","updated":"2025-07-29T03:34:32Z","published":"2025-07-29T03:34:32Z","title":"Hebbian Memory-Augmented Recurrent Networks: Engram Neurons in Deep\n  Learning","summary":"  Despite success across diverse tasks, current artificial recurrent network\narchitectures rely primarily on implicit hidden-state memories, limiting their\ninterpretability and ability to model long-range dependencies. In contrast,\nbiological neural systems employ explicit, associative memory traces (i.e.,\nengrams) strengthened through Hebbian synaptic plasticity and activated\nsparsely during recall. Motivated by these neurobiological insights, we\nintroduce the Engram Neural Network (ENN), a novel recurrent architecture\nincorporating an explicit, differentiable memory matrix with Hebbian plasticity\nand sparse, attention-driven retrieval mechanisms. The ENN explicitly models\nmemory formation and recall through dynamic Hebbian traces, improving\ntransparency and interpretability compared to conventional RNN variants. We\nevaluate the ENN architecture on three canonical benchmarks: MNIST digit\nclassification, CIFAR-10 image sequence modeling, and WikiText-103 language\nmodeling. Our empirical results demonstrate that the ENN achieves accuracy and\ngeneralization performance broadly comparable to classical RNN, GRU, and LSTM\narchitectures, with all models converging to similar accuracy and perplexity on\nthe large-scale WikiText-103 task. At the same time, the ENN offers significant\nenhancements in interpretability through observable memory dynamics. Hebbian\ntrace visualizations further reveal biologically plausible, structured memory\nformation processes, validating the potential of neuroscience-inspired\nmechanisms to inform the development of more interpretable and robust deep\nlearning models.\n","authors":["Daniel Szelogowski"],"pdf_url":"https://arxiv.org/pdf/2507.21474v1.pdf","comment":"20 pages, 11 figures, 4 tables"},{"id":"http://arxiv.org/abs/2507.21467v1","updated":"2025-07-29T03:13:41Z","published":"2025-07-29T03:13:41Z","title":"Efficient Data Retrieval and Comparative Bias Analysis of Recommendation\n  Algorithms for YouTube Shorts and Long-Form Videos","summary":"  The growing popularity of short-form video content, such as YouTube Shorts,\nhas transformed user engagement on digital platforms, raising critical\nquestions about the role of recommendation algorithms in shaping user\nexperiences. These algorithms significantly influence content consumption, yet\nconcerns about biases, echo chambers, and content diversity persist. This study\ndevelops an efficient data collection framework to analyze YouTube's\nrecommendation algorithms for both short-form and long-form videos, employing\nparallel computing and advanced scraping techniques to overcome limitations of\nYouTube's API. The analysis uncovers distinct behavioral patterns in\nrecommendation algorithms across the two formats, with short-form videos\nshowing a more immediate shift toward engaging yet less diverse content\ncompared to long-form videos. Furthermore, a novel investigation into biases in\npolitically sensitive topics, such as the South China Sea dispute, highlights\nthe role of these algorithms in shaping narratives and amplifying specific\nviewpoints. By providing actionable insights for designing equitable and\ntransparent recommendation systems, this research underscores the importance of\nresponsible AI practices in the evolving digital media landscape.\n","authors":["Selimhan Dagtas","Mert Can Cakmak","Nitin Agarwal"],"pdf_url":"https://arxiv.org/pdf/2507.21467v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22268v1","updated":"2025-07-29T22:38:39Z","published":"2025-07-29T22:38:39Z","title":"Multi-modal Relational Item Representation Learning for Inferring\n  Substitutable and Complementary Items","summary":"  We introduce a novel self-supervised multi-modal relational item\nrepresentation learning framework designed to infer substitutable and\ncomplementary items. Existing approaches primarily focus on modeling item-item\nassociations deduced from user behaviors using graph neural networks (GNNs) or\nleveraging item content information. However, these methods often overlook\ncritical challenges, such as noisy user behavior data and data sparsity due to\nthe long-tailed distribution of these behaviors. In this paper, we propose\nMMSC, a self-supervised multi-modal relational item representation learning\nframework to address these challenges. Specifically, MMSC consists of three\nmain components: (1) a multi-modal item representation learning module that\nleverages a multi-modal foundational model and learns from item metadata, (2) a\nself-supervised behavior-based representation learning module that denoises and\nlearns from user behavior data, and (3) a hierarchical representation\naggregation mechanism that integrates item representations at both the semantic\nand task levels. Additionally, we leverage LLMs to generate augmented training\ndata, further enhancing the denoising process during training. We conduct\nextensive experiments on five real-world datasets, showing that MMSC\noutperforms existing baselines by 26.1% for substitutable recommendation and\n39.2% for complementary recommendation. In addition, we empirically show that\nMMSC is effective in modeling cold-start items.\n","authors":["Junting Wang","Chenghuan Guo","Jiao Yang","Yanhui Guo","Yan Gao","Hari Sundaram"],"pdf_url":"https://arxiv.org/pdf/2507.22268v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22224v1","updated":"2025-07-29T20:41:51Z","published":"2025-07-29T20:41:51Z","title":"Generative Recommendation with Semantic IDs: A Practitioner's Handbook","summary":"  Generative recommendation (GR) has gained increasing attention for its\npromising performance compared to traditional models. A key factor contributing\nto the success of GR is the semantic ID (SID), which converts continuous\nsemantic representations (e.g., from large language models) into discrete ID\nsequences. This enables GR models with SIDs to both incorporate semantic\ninformation and learn collaborative filtering signals, while retaining the\nbenefits of discrete decoding. However, varied modeling techniques,\nhyper-parameters, and experimental setups in existing literature make direct\ncomparisons between GR proposals challenging. Furthermore, the absence of an\nopen-source, unified framework hinders systematic benchmarking and extension,\nslowing model iteration. To address this challenge, our work introduces and\nopen-sources a framework for Generative Recommendation with semantic ID, namely\nGRID, specifically designed for modularity to facilitate easy component\nswapping and accelerate idea iteration. Using GRID, we systematically\nexperiment with and ablate different components of GR models with SIDs on\npublic benchmarks. Our comprehensive experiments with GRID reveal that many\noverlooked architectural components in GR models with SIDs substantially impact\nperformance. This offers both novel insights and validates the utility of an\nopen-source platform for robust benchmarking and GR research advancement. GRID\nis open-sourced at https://github.com/snap-research/GRID.\n","authors":["Clark Mingxuan Ju","Liam Collins","Leonardo Neves","Bhuvesh Kumar","Louis Yufeng Wang","Tong Zhao","Neil Shah"],"pdf_url":"https://arxiv.org/pdf/2507.22224v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22213v1","updated":"2025-07-29T20:20:07Z","published":"2025-07-29T20:20:07Z","title":"Intent-Aware Neural Query Reformulation for Behavior-Aligned Product\n  Search","summary":"  Understanding and modeling buyer intent is a foundational challenge in\noptimizing search query reformulation within the dynamic landscape of\ne-commerce search systems. This work introduces a robust data pipeline designed\nto mine and analyze large-scale buyer query logs, with a focus on extracting\nfine-grained intent signals from both explicit interactions and implicit\nbehavioral cues. Leveraging advanced sequence mining techniques and supervised\nlearning models, the pipeline systematically captures patterns indicative of\nlatent purchase intent, enabling the construction of a high-fidelity,\nintent-rich dataset. The proposed framework facilitates the development of\nadaptive query rewrite strategies by grounding reformulations in inferred user\nintent rather than surface-level lexical signals. This alignment between query\nrewriting and underlying user objectives enhances both retrieval relevance and\ndownstream engagement metrics. Empirical evaluations across multiple product\nverticals demonstrate measurable gains in precision-oriented relevance metrics,\nunderscoring the efficacy of intent-aware reformulation. Our findings highlight\nthe value of intent-centric modeling in bridging the gap between sparse user\ninputs and complex product discovery goals, and establish a scalable foundation\nfor future research in user-aligned neural retrieval and ranking systems.\n","authors":["Jayanth Yetukuri","Ishita Khan"],"pdf_url":"https://arxiv.org/pdf/2507.22213v1.pdf","comment":"Accepted at SIGIR eCom'25.\n  https://sigir-ecom.github.io/eCom25Papers/paper_23.pdf"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2507.22053v1","updated":"2025-07-29T17:56:38Z","published":"2025-07-29T17:56:38Z","title":"Foundation Models for Demand Forecasting via Dual-Strategy Ensembling","summary":"  Accurate demand forecasting is critical for supply chain optimization, yet\nremains difficult in practice due to hierarchical complexity, domain shifts,\nand evolving external factors. While recent foundation models offer strong\npotential for time series forecasting, they often suffer from architectural\nrigidity and limited robustness under distributional change. In this paper, we\npropose a unified ensemble framework that enhances the performance of\nfoundation models for sales forecasting in real-world supply chains. Our method\ncombines two complementary strategies: (1) Hierarchical Ensemble (HE), which\npartitions training and inference by semantic levels (e.g., store, category,\ndepartment) to capture localized patterns; and (2) Architectural Ensemble (AE),\nwhich integrates predictions from diverse model backbones to mitigate bias and\nimprove stability. We conduct extensive experiments on the M5 benchmark and\nthree external sales datasets, covering both in-domain and zero-shot\nforecasting. Results show that our approach consistently outperforms strong\nbaselines, improves accuracy across hierarchical levels, and provides a simple\nyet effective mechanism for boosting generalization in complex forecasting\nenvironments.\n","authors":["Wei Yang","Defu Cao","Yan Liu"],"pdf_url":"https://arxiv.org/pdf/2507.22053v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20114v3","updated":"2025-07-29T17:50:49Z","published":"2025-06-25T04:06:37Z","title":"Extracting Interpretable Models from Tree Ensembles: Computational and\n  Statistical Perspectives","summary":"  Tree ensembles are non-parametric methods widely recognized for their\naccuracy and ability to capture complex interactions. While these models excel\nat prediction, they are difficult to interpret and may fail to uncover useful\nrelationships in the data. We propose an estimator to extract compact sets of\ndecision rules from tree ensembles. The extracted models are accurate and can\nbe manually examined to reveal relationships between the predictors and the\nresponse. A key novelty of our estimator is the flexibility to jointly control\nthe number of rules extracted and the interaction depth of each rule, which\nimproves accuracy. We develop a tailored exact algorithm to efficiently solve\noptimization problems underlying our estimator and an approximate algorithm for\ncomputing regularization paths, sequences of solutions that correspond to\nvarying model sizes. We also establish novel non-asymptotic prediction error\nbounds for our proposed approach, comparing it to an oracle that chooses the\nbest data-dependent linear combination of the rules in the ensemble subject to\nthe same complexity constraint as our estimator. The bounds illustrate that the\nlarge-sample predictive performance of our estimator is on par with that of the\noracle. Through experiments, we demonstrate that our estimator outperforms\nexisting algorithms for rule extraction.\n","authors":["Brian Liu","Rahul Mazumder","Peter Radchenko"],"pdf_url":"https://arxiv.org/pdf/2506.20114v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22045v1","updated":"2025-07-29T17:49:43Z","published":"2025-07-29T17:49:43Z","title":"Weight-Parameterization in Continuous Time Deep Neural Networks for\n  Surrogate Modeling","summary":"  Continuous-time deep learning models, such as neural ordinary differential\nequations (ODEs), offer a promising framework for surrogate modeling of complex\nphysical systems. A central challenge in training these models lies in learning\nexpressive yet stable time-varying weights, particularly under computational\nconstraints. This work investigates weight parameterization strategies that\nconstrain the temporal evolution of weights to a low-dimensional subspace\nspanned by polynomial basis functions. We evaluate both monomial and Legendre\npolynomial bases within neural ODE and residual network (ResNet) architectures\nunder discretize-then-optimize and optimize-then-discretize training paradigms.\nExperimental results across three high-dimensional benchmark problems show that\nLegendre parameterizations yield more stable training dynamics, reduce\ncomputational cost, and achieve accuracy comparable to or better than both\nmonomial parameterizations and unconstrained weight models. These findings\nelucidate the role of basis choice in time-dependent weight parameterization\nand demonstrate that using orthogonal polynomial bases offers a favorable\ntradeoff between model expressivity and training efficiency.\n","authors":["Haley Rosso","Lars Ruthotto","Khachik Sargsyan"],"pdf_url":"https://arxiv.org/pdf/2507.22045v1.pdf","comment":"34 pages, 6 figures, submitted to the MoRE24 special issue of\n  Computational Science and Engineering"},{"id":"http://arxiv.org/abs/2504.15458v2","updated":"2025-07-29T17:47:58Z","published":"2025-04-21T21:56:49Z","title":"Compton Form Factor Extraction using Quantum Deep Neural Networks","summary":"  We present an extraction of Compton Form Factors (CFFs) from Deeply Virtual\nCompton Scattering (DVCS) experiments conducted at Thomas Jefferson National\nAccelerator Facility, utilizing Quantum Deep Neural Networks (QDNNs). The\nanalysis employs the standard Belitsky, Kirchner, and M\\\"uller formalism at\ntwist-two, complemented by a fitting procedure designed to minimize model\ndependence in a manner analogous to conventional local fits. A pseudodata\nextraction test of the CFFs is performed using both Classical Deep Neural\nNetworks (CDNNs) and QDNNs, with a detailed comparative analysis. Results\nindicate that QDNNs can outperform CDNNs in particular cases, offering enhanced\npredictive accuracy and precision even with limited model complexity. Motivated\nby this, we develop a metric to quantify the extent of the quantum advantage\nbased on characteristics of DVCS experimental data. These findings underscore\nthe promising role of QDNNs in advancing future investigations into\nmultidimensional parton distributions and hadronic physics.\n","authors":["Brandon B. Le","Dustin Keller"],"pdf_url":"https://arxiv.org/pdf/2504.15458v2.pdf","comment":"36 pages, 17 figures. v2: major revisions"},{"id":"http://arxiv.org/abs/2507.22040v1","updated":"2025-07-29T17:41:45Z","published":"2025-07-29T17:41:45Z","title":"Structure-Informed Deep Reinforcement Learning for Inventory Management","summary":"  This paper investigates the application of Deep Reinforcement Learning (DRL)\nto classical inventory management problems, with a focus on practical\nimplementation considerations. We apply a DRL algorithm based on DirectBackprop\nto several fundamental inventory management scenarios including multi-period\nsystems with lost sales (with and without lead times), perishable inventory\nmanagement, dual sourcing, and joint inventory procurement and removal. The DRL\napproach learns policies across products using only historical information that\nwould be available in practice, avoiding unrealistic assumptions about demand\ndistributions or access to distribution parameters. We demonstrate that our\ngeneric DRL implementation performs competitively against or outperforms\nestablished benchmarks and heuristics across these diverse settings, while\nrequiring minimal parameter tuning. Through examination of the learned\npolicies, we show that the DRL approach naturally captures many known\nstructural properties of optimal policies derived from traditional operations\nresearch methods. To further improve policy performance and interpretability,\nwe propose a Structure-Informed Policy Network technique that explicitly\nincorporates analytically-derived characteristics of optimal policies into the\nlearning process. This approach can help interpretability and add robustness to\nthe policy in out-of-sample performance, as we demonstrate in an example with\nrealistic demand data. Finally, we provide an illustrative application of DRL\nin a non-stationary setting. Our work bridges the gap between data-driven\nlearning and analytical insights in inventory management while maintaining\npractical applicability.\n","authors":["Alvaro Maggiar","Sohrab Andaz","Akhil Bagaria","Carson Eisenach","Dean Foster","Omer Gottesman","Dominique Perrault-Joncas"],"pdf_url":"https://arxiv.org/pdf/2507.22040v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.01751v2","updated":"2025-07-29T17:41:30Z","published":"2025-03-03T17:20:29Z","title":"SAKE: Steering Activations for Knowledge Editing","summary":"  As Large Langue Models have been shown to memorize real-world facts, the need\nto update this knowledge in a controlled and efficient manner arises. Designed\nwith these constraints in mind, Knowledge Editing (KE) approaches propose to\nalter specific facts in pretrained models. However, they have been shown to\nsuffer from several limitations, including their lack of contextual robustness\nand their failure to generalize to logical implications related to the fact. To\novercome these issues, we propose SAKE, a steering activation method that\nmodels a fact to be edited as a distribution rather than a single prompt.\nLeveraging Optimal Transport, SAKE alters the LLM behavior over a whole\nfact-related distribution, defined as paraphrases and logical implications.\nSeveral numerical experiments demonstrate the effectiveness of this method:\nSAKE is thus able to perform more robust edits than its existing counterparts.\n","authors":["Marco Scialanga","Thibault Laugel","Vincent Grari","Marcin Detyniecki"],"pdf_url":"https://arxiv.org/pdf/2503.01751v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22039v1","updated":"2025-07-29T17:40:59Z","published":"2025-07-29T17:40:59Z","title":"Supervised Quantum Image Processing","summary":"  In the era of big data and artificial intelligence, the increasing volume of\ndata and the demand to solve more and more complex computational challenges are\ntwo driving forces for improving the efficiency of data storage, processing and\nanalysis. Quantum image processing (QIP) is an interdisciplinary field between\nquantum information science and image processing, which has the potential to\nalleviate some of these challenges by leveraging the power of quantum\ncomputing. In this work, we compare and examine the compression properties of\nfour different Quantum Image Representations (QImRs): namely, Tensor Network\nRepresentation (TNR), Flexible Representation of Quantum Image (FRQI), Novel\nEnhanced Quantum Representation NEQR, and Quantum Probability Image Encoding\n(QPIE). Our simulations show that FRQI performs a higher compression of image\ninformation than TNR, NEQR, and QPIE. Furthermore, we investigate the trade-off\nbetween accuracy and memory in binary classification problems, evaluating the\nperformance of quantum kernels based on QImRs compared to the classical linear\nkernel. Our results indicate that quantum kernels provide comparable\nclassification average accuracy but require exponentially fewer resources for\nimage storage.\n","authors":["Marco Parigi","Mehran Khosrojerdi","Filippo Caruso","Leonardo Banchi"],"pdf_url":"https://arxiv.org/pdf/2507.22039v1.pdf","comment":"13 pages, 11 figures"},{"id":"http://arxiv.org/abs/2507.22034v1","updated":"2025-07-29T17:34:12Z","published":"2025-07-29T17:34:12Z","title":"UserBench: An Interactive Gym Environment for User-Centric Agents","summary":"  Large Language Models (LLMs)-based agents have made impressive progress in\nreasoning and tool use, enabling them to solve complex tasks. However, their\nability to proactively collaborate with users, especially when goals are vague,\nevolving, or indirectly expressed, remains underexplored. To address this gap,\nwe introduce UserBench, a user-centric benchmark designed to evaluate agents in\nmulti-turn, preference-driven interactions. UserBench features simulated users\nwho start with underspecified goals and reveal preferences incrementally,\nrequiring agents to proactively clarify intent and make grounded decisions with\ntools. Our evaluation of leading open- and closed-source LLMs reveals a\nsignificant disconnect between task completion and user alignment. For\ninstance, models provide answers that fully align with all user intents only\n20% of the time on average, and even the most advanced models uncover fewer\nthan 30% of all user preferences through active interaction. These results\nhighlight the challenges of building agents that are not just capable task\nexecutors, but true collaborative partners. UserBench offers an interactive\nenvironment to measure and advance this critical capability.\n","authors":["Cheng Qian","Zuxin Liu","Akshara Prabhakar","Zhiwei Liu","Jianguo Zhang","Haolin Chen","Heng Ji","Weiran Yao","Shelby Heinecke","Silvio Savarese","Caiming Xiong","Huan Wang"],"pdf_url":"https://arxiv.org/pdf/2507.22034v1.pdf","comment":"25 Pages, 17 Figures, 6 Tables"},{"id":"http://arxiv.org/abs/2507.22032v1","updated":"2025-07-29T17:27:31Z","published":"2025-07-29T17:27:31Z","title":"Classification of Honey Botanical and Geographical Sources using Mineral\n  Profiles and Machine Learning","summary":"  This paper proposes a machine learning-based approach for identifying honey\nfloral and geographical sources using mineral element profiles. The proposed\nmethod comprises two steps: preprocessing and classification. The preprocessing\nphase involves missing-value treatment and data normalization. In the\nclassification phase, we employ various supervised classification models for\ndiscriminating between six botanical sources and 13 geographical origins of\nhoney. We test the classifiers' performance on a publicly available honey\nmineral element dataset. The dataset contains mineral element profiles of\nhoneys from various floral and geographical origins. Results show that mineral\nelement content in honey provides discriminative information useful for\nclassifying honey botanical and geographical sources. Results also show that\nthe Random Forests (RF) classifier obtains the best performance on this\ndataset, achieving a cross-validation accuracy of 99.30% for classifying honey\nbotanical origins and 98.01% for classifying honey geographical origins.\n","authors":["Mokhtar Al-Awadhi","Ratnadeep Deshmukh"],"pdf_url":"https://arxiv.org/pdf/2507.22032v1.pdf","comment":"13 pages, 7 figures, conference paper"},{"id":"http://arxiv.org/abs/2409.13864v3","updated":"2025-07-29T17:24:25Z","published":"2024-09-20T19:28:48Z","title":"Persistent Backdoor Attacks in Continual Learning","summary":"  Backdoor attacks pose a significant threat to neural networks, enabling\nadversaries to manipulate model outputs on specific inputs, often with\ndevastating consequences, especially in critical applications. While backdoor\nattacks have been studied in various contexts, little attention has been given\nto their practicality and persistence in continual learning, particularly in\nunderstanding how the continual updates to model parameters, as new data\ndistributions are learned and integrated, impact the effectiveness of these\nattacks over time. To address this gap, we introduce two persistent backdoor\nattacks-Blind Task Backdoor and Latent Task Backdoor-each leveraging minimal\nadversarial influence. Our blind task backdoor subtly alters the loss\ncomputation without direct control over the training process, while the latent\ntask backdoor influences only a single task's training, with all other tasks\ntrained benignly. We evaluate these attacks under various configurations,\ndemonstrating their efficacy with static, dynamic, physical, and semantic\ntriggers. Our results show that both attacks consistently achieve high success\nrates across different continual learning algorithms, while effectively evading\nstate-of-the-art defenses, such as SentiNet and I-BAU.\n","authors":["Zhen Guo","Abhinav Kumar","Reza Tourani"],"pdf_url":"https://arxiv.org/pdf/2409.13864v3.pdf","comment":"19 pages, 20 figures, 6 tables"},{"id":"http://arxiv.org/abs/2507.22010v1","updated":"2025-07-29T17:00:33Z","published":"2025-07-29T17:00:33Z","title":"Exploring the Stratified Space Structure of an RL Game with the Volume\n  Growth Transform","summary":"  In this work, we explore the structure of the embedding space of a\ntransformer model trained for playing a particular reinforcement learning (RL)\ngame. Specifically, we investigate how a transformer-based Proximal Policy\nOptimization (PPO) model embeds visual inputs in a simple environment where an\nagent must collect \"coins\" while avoiding dynamic obstacles consisting of\n\"spotlights.\" By adapting Robinson et al.'s study of the volume growth\ntransform for LLMs to the RL setting, we find that the token embedding space\nfor our visual coin collecting game is also not a manifold, and is better\nmodeled as a stratified space, where local dimension can vary from point to\npoint. We further strengthen Robinson's method by proving that fairly general\nvolume growth curves can be realized by stratified spaces. Finally, we carry\nout an analysis that suggests that as an RL agent acts, its latent\nrepresentation alternates between periods of low local dimension, while\nfollowing a fixed sub-strategy, and bursts of high local dimension, where the\nagent achieves a sub-goal (e.g., collecting an object) or where the\nenvironmental complexity increases (e.g., more obstacles appear). Consequently,\nour work suggests that the distribution of dimensions in a stratified latent\nspace may provide a new geometric indicator of complexity for RL games.\n","authors":["Justin Curry","Brennan Lagasse","Ngoc B. Lam","Gregory Cox","David Rosenbluth","Alberto Speranzon"],"pdf_url":"https://arxiv.org/pdf/2507.22010v1.pdf","comment":"17 pages and 8 figures. Preliminary report. Feedback welcome!"},{"id":"http://arxiv.org/abs/2505.06581v2","updated":"2025-07-29T16:55:08Z","published":"2025-05-10T09:51:25Z","title":"An $\\tilde{O}$ptimal Differentially Private Learner for Concept Classes\n  with VC Dimension 1","summary":"  We present the first nearly optimal differentially private PAC learner for\nany concept class with VC dimension 1 and Littlestone dimension $d$. Our\nalgorithm achieves the sample complexity of\n$\\tilde{O}_{\\varepsilon,\\delta,\\alpha,\\delta}(\\log^* d)$, nearly matching the\nlower bound of $\\Omega(\\log^* d)$ proved by Alon et al. [STOC19]. Prior to our\nwork, the best known upper bound is $\\tilde{O}(VC\\cdot d^5)$ for general VC\nclasses, as shown by Ghazi et al. [STOC21].\n","authors":["Chao Yan"],"pdf_url":"https://arxiv.org/pdf/2505.06581v2.pdf","comment":"Add proper learner"},{"id":"http://arxiv.org/abs/2507.22000v1","updated":"2025-07-29T16:47:34Z","published":"2025-07-29T16:47:34Z","title":"Staining and locking computer vision models without retraining","summary":"  We introduce new methods of staining and locking computer vision models, to\nprotect their owners' intellectual property. Staining, also known as\nwatermarking, embeds secret behaviour into a model which can later be used to\nidentify it, while locking aims to make a model unusable unless a secret\ntrigger is inserted into input images. Unlike existing methods, our algorithms\ncan be used to stain and lock pre-trained models without requiring fine-tuning\nor retraining, and come with provable, computable guarantees bounding their\nworst-case false positive rates. The stain and lock are implemented by directly\nmodifying a small number of the model's weights and have minimal impact on the\n(unlocked) model's performance. Locked models are unlocked by inserting a small\n`trigger patch' into the corner of the input image. We present experimental\nresults showing the efficacy of our methods and demonstrating their practical\nperformance on a variety of computer vision models.\n","authors":["Oliver J. Sutton","Qinghua Zhou","George Leete","Alexander N. Gorban","Ivan Y. Tyukin"],"pdf_url":"https://arxiv.org/pdf/2507.22000v1.pdf","comment":"10 pages, 9 pages of appendices, 10 figures"},{"id":"http://arxiv.org/abs/2507.21992v1","updated":"2025-07-29T16:43:54Z","published":"2025-07-29T16:43:54Z","title":"Teach Me to Trick: Exploring Adversarial Transferability via Knowledge\n  Distillation","summary":"  We investigate whether knowledge distillation (KD) from multiple\nheterogeneous teacher models can enhance the generation of transferable\nadversarial examples. A lightweight student model is trained using two KD\nstrategies: curriculum-based switching and joint optimization, with ResNet50\nand DenseNet-161 as teachers. The trained student is then used to generate\nadversarial examples using FG, FGS, and PGD attacks, which are evaluated\nagainst a black-box target model (GoogLeNet). Our results show that student\nmodels distilled from multiple teachers achieve attack success rates comparable\nto ensemble-based baselines, while reducing adversarial example generation time\nby up to a factor of six. An ablation study further reveals that lower\ntemperature settings and the inclusion of hard-label supervision significantly\nenhance transferability. These findings suggest that KD can serve not only as a\nmodel compression technique but also as a powerful tool for improving the\nefficiency and effectiveness of black-box adversarial attacks.\n","authors":["Siddhartha Pradhan","Shikshya Shiwakoti","Neha Bathuri"],"pdf_url":"https://arxiv.org/pdf/2507.21992v1.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.21984v1","updated":"2025-07-29T16:35:52Z","published":"2025-07-29T16:35:52Z","title":"Higher-Order Kuramoto Oscillator Network for Dense Associative Memory","summary":"  Networks of phase oscillators can serve as dense associative memories if they\nincorporate higher-order coupling beyond the classical Kuramoto model's\npairwise interactions. Here we introduce a generalized Kuramoto model with\ncombined second-harmonic (pairwise) and fourth-harmonic (quartic) coupling,\ninspired by dense Hopfield memory theory. Using mean-field theory and its\ndynamical approximation, we obtain a phase diagram for dense associative memory\nmodel that exhibits a tricritical point at which the continuous onset of memory\nretrieval is supplanted by a discontinuous, hysteretic transition. In the\nquartic-dominated regime, the system supports bistable phase-locked states\ncorresponding to stored memory patterns, with a sizable energy barrier between\nmemory and incoherent states. We analytically determine this bistable region\nand show that the escape time from a memory state (due to noise) grows\nexponentially with network size, indicating robust storage. Extending the\ntheory to finite memory load, we show that higher-order couplings achieve\nsuperlinear scaling of memory capacity with system size, far exceeding the\nlimit of pairwise-only oscillators. Large-scale simulations of the oscillator\nnetwork confirm our theoretical predictions, demonstrating rapid pattern\nretrieval and robust storage of many phase patterns. These results bridge the\nKuramoto synchronization with modern Hopfield memories, pointing toward\nexperimental realization of high-capacity, analog associative memory in\noscillator systems.\n","authors":["Jona Nagerl","Natalia G. Berloff"],"pdf_url":"https://arxiv.org/pdf/2507.21984v1.pdf","comment":"13 pages, 7 figures"},{"id":"http://arxiv.org/abs/2507.21983v1","updated":"2025-07-29T16:34:02Z","published":"2025-07-29T16:34:02Z","title":"Improving Generative Ad Text on Facebook using Reinforcement Learning","summary":"  Generative artificial intelligence (AI), in particular large language models\n(LLMs), is poised to drive transformative economic change. LLMs are pre-trained\non vast text data to learn general language patterns, but a subsequent\npost-training phase is critical to align them for specific real-world tasks.\nReinforcement learning (RL) is the leading post-training technique, yet its\neconomic impact remains largely underexplored and unquantified. We examine this\nquestion through the lens of the first deployment of an RL-trained LLM for\ngenerative advertising on Facebook. Integrated into Meta's Text Generation\nfeature, our model, \"AdLlama,\" powers an AI tool that helps advertisers create\nnew variations of human-written ad text. To train this model, we introduce\nreinforcement learning with performance feedback (RLPF), a post-training method\nthat uses historical ad performance data as a reward signal. In a large-scale\n10-week A/B test on Facebook spanning nearly 35,000 advertisers and 640,000 ad\nvariations, we find that AdLlama improves click-through rates by 6.7%\n(p=0.0296) compared to a supervised imitation model trained on curated ads.\nThis represents a substantial improvement in advertiser return on investment on\nFacebook. We also find that advertisers who used AdLlama generated more ad\nvariations, indicating higher satisfaction with the model's outputs. To our\nknowledge, this is the largest study to date on the use of generative AI in an\necologically valid setting, offering an important data point quantifying the\ntangible impact of RL post-training. Furthermore, the results show that RLPF is\na promising and generalizable approach for metric-driven post-training that\nbridges the gap between highly capable language models and tangible outcomes.\n","authors":["Daniel R. Jiang","Alex Nikulkov","Yu-Chia Chen","Yang Bai","Zheqing Zhu"],"pdf_url":"https://arxiv.org/pdf/2507.21983v1.pdf","comment":"D.J. and A.N. contributed equally, 41 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.15857v3","updated":"2025-07-29T16:19:10Z","published":"2025-07-21T17:59:57Z","title":"Diffusion Beats Autoregressive in Data-Constrained Settings","summary":"  Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.\n","authors":["Mihir Prabhudesai","Mengning Wu","Amir Zadeh","Katerina Fragkiadaki","Deepak Pathak"],"pdf_url":"https://arxiv.org/pdf/2507.15857v3.pdf","comment":"Project Webpage: https://diffusion-scaling.github.io"},{"id":"http://arxiv.org/abs/2507.21964v1","updated":"2025-07-29T16:13:10Z","published":"2025-07-29T16:13:10Z","title":"Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart\n  Homes via Language Modeling of Sensor Data & Activities","summary":"  Developing zero-shot human activity recognition (HAR) methods is a critical\ndirection in smart home research -- considering its impact on making HAR\nsystems work across smart homes having diverse sensing modalities, layouts, and\nactivities of interest. The state-of-the-art solutions along this direction are\nbased on generating natural language descriptions of the sensor data and\nfeeding it via a carefully crafted prompt to the LLM to perform classification.\nDespite their performance guarantees, such ``prompt-the-LLM'' approaches carry\nseveral risks, including privacy invasion, reliance on an external service, and\ninconsistent predictions due to version changes, making a case for alternative\nzero-shot HAR methods that do not require prompting the LLMs. In this paper, we\npropose one such solution that models sensor data and activities using natural\nlanguage, leveraging its embeddings to perform zero-shot classification and\nthereby bypassing the need to prompt the LLMs for activity predictions. The\nimpact of our work lies in presenting a detailed case study on six datasets,\nhighlighting how language modeling can bolster HAR systems in zero-shot\nrecognition.\n","authors":["Sourish Gunesh Dhekane","Thomas Ploetz"],"pdf_url":"https://arxiv.org/pdf/2507.21964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21963v1","updated":"2025-07-29T16:12:37Z","published":"2025-07-29T16:12:37Z","title":"SLA-Centric Automated Algorithm Selection Framework for Cloud\n  Environments","summary":"  Cloud computing offers on-demand resource access, regulated by Service-Level\nAgreements (SLAs) between consumers and Cloud Service Providers (CSPs). SLA\nviolations can impact efficiency and CSP profitability. In this work, we\npropose an SLA-aware automated algorithm-selection framework for combinatorial\noptimization problems in resource-constrained cloud environments. The framework\nuses an ensemble of machine learning models to predict performance and rank\nalgorithm-hardware pairs based on SLA constraints. We also apply our framework\nto the 0-1 knapsack problem. We curate a dataset comprising instance specific\nfeatures along with memory usage, runtime, and optimality gap for 6 algorithms.\nAs an empirical benchmark, we evaluate the framework on both classification and\nregression tasks. Our ablation study explores the impact of hyperparameters,\nlearning approaches, and large language models effectiveness in regression, and\nSHAP-based interpretability.\n","authors":["Siana Rizwan","Tasnim Ahmed","Salimur Choudhury"],"pdf_url":"https://arxiv.org/pdf/2507.21963v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.13818v2","updated":"2025-07-29T16:04:56Z","published":"2025-01-23T16:39:09Z","title":"Ensuring Medical AI Safety: Interpretability-Driven Detection and\n  Mitigation of Spurious Model Behavior and Associated Data","summary":"  Deep neural networks are increasingly employed in high-stakes medical\napplications, despite their tendency for shortcut learning in the presence of\nspurious correlations, which can have potentially fatal consequences in\npractice. Whereas a multitude of works address either the detection or\nmitigation of such shortcut behavior in isolation, the Reveal2Revise approach\nprovides a comprehensive bias mitigation framework combining these steps.\nHowever, effectively addressing these biases often requires substantial\nlabeling efforts from domain experts. In this work, we review the steps of the\nReveal2Revise framework and enhance it with semi-automated\ninterpretability-based bias annotation capabilities. This includes methods for\nthe sample- and feature-level bias annotation, providing valuable information\nfor bias mitigation methods to unlearn the undesired shortcut behavior. We show\nthe applicability of the framework using four medical datasets across two\nmodalities, featuring controlled and real-world spurious correlations caused by\ndata artifacts. We successfully identify and mitigate these biases in VGG16,\nResNet50, and contemporary Vision Transformer models, ultimately increasing\ntheir robustness and applicability for real-world medical tasks. Our code is\navailable at https://github.com/frederikpahde/medical-ai-safety.\n","authors":["Frederik Pahde","Thomas Wiegand","Sebastian Lapuschkin","Wojciech Samek"],"pdf_url":"https://arxiv.org/pdf/2501.13818v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21952v1","updated":"2025-07-29T16:02:59Z","published":"2025-07-29T16:02:59Z","title":"DeepGo: Predictive Directed Greybox Fuzzing","summary":"  The state-of-the-art DGF techniques redefine and optimize the fitness metric\nto reach the target sites precisely and quickly. However, optimizations for\nfitness metrics are mainly based on heuristic algorithms, which usually rely on\nhistorical execution information and lack foresight on paths that have not been\nexercised yet. Thus, those hard-to-execute paths with complex constraints would\nhinder DGF from reaching the targets, making DGF less efficient. In this paper,\nwe propose DeepGo, a predictive directed grey-box fuzzer that can combine\nhistorical and predicted information to steer DGF to reach the target site via\nan optimal path. We first propose the path transition model, which models DGF\nas a process of reaching the target site through specific path transition\nsequences. The new seed generated by mutation would cause the path transition,\nand the path corresponding to the high-reward path transition sequence\nindicates a high likelihood of reaching the target site through it. Then, to\npredict the path transitions and the corresponding rewards, we use deep neural\nnetworks to construct a Virtual Ensemble Environment (VEE), which gradually\nimitates the path transition model and predicts the rewards of path transitions\nthat have not been taken yet. To determine the optimal path, we develop a\nReinforcement Learning for Fuzzing (RLF) model to generate the transition\nsequences with the highest sequence rewards. The RLF model can combine\nhistorical and predicted path transitions to generate the optimal path\ntransition sequences, along with the policy to guide the mutation strategy of\nfuzzing. Finally, to exercise the high-reward path transition sequence, we\npropose the concept of an action group, which comprehensively optimizes the\ncritical steps of fuzzing to realize the optimal path to reach the target\nefficiently.\n","authors":["Peihong Lin","Pengfei Wang","Xu Zhou","Wei Xie","Gen Zhang","Kai Lu"],"pdf_url":"https://arxiv.org/pdf/2507.21952v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21938v1","updated":"2025-07-29T15:51:26Z","published":"2025-07-29T15:51:26Z","title":"Multi-state Protein Design with DynamicMPNN","summary":"  Structural biology has long been dominated by the one sequence, one\nstructure, one function paradigm, yet many critical biological processes - from\nenzyme catalysis to membrane transport - depend on proteins that adopt multiple\nconformational states. Existing multi-state design approaches rely on post-hoc\naggregation of single-state predictions, achieving poor experimental success\nrates compared to single-state design. We introduce DynamicMPNN, an inverse\nfolding model explicitly trained to generate sequences compatible with multiple\nconformations through joint learning across conformational ensembles. Trained\non 46,033 conformational pairs covering 75% of CATH superfamilies and evaluated\nusing AlphaFold initial guess, DynamicMPNN outperforms ProteinMPNN by up to 13%\non structure-normalized RMSD across our challenging multi-state protein\nbenchmark.\n","authors":["Alex Abrudan","Sebastian Pujalte Ojeda","Chaitanya K. Joshi","Matthew Greenig","Felipe Engelberger","Alena Khmelinskaia","Jens Meiler","Michele Vendruscolo","Tuomas P. J. Knowles"],"pdf_url":"https://arxiv.org/pdf/2507.21938v1.pdf","comment":"ICML 2025 GenBio Workshop"},{"id":"http://arxiv.org/abs/2408.15393v2","updated":"2025-07-29T15:41:36Z","published":"2024-08-27T20:33:16Z","title":"Linear Stability Analysis of Physics-Informed Random Projection Neural\n  Networks for ODEs","summary":"  We present a linear stability analysis of physics-informed random projection\nneural networks (PI-RPNNs), for the numerical solution of {the initial value\nproblem (IVP)} of (stiff) ODEs. We begin by proving that PI-RPNNs are uniform\napproximators of the solution to ODEs. We then provide a constructive proof\ndemonstrating that PI-RPNNs offer consistent and asymptotically stable\nnumerical schemes, thus convergent schemes. In particular, we prove that\nmulti-collocation PI-RPNNs guarantee asymptotic stability. Our theoretical\nresults are illustrated via numerical solutions of benchmark examples including\nindicative comparisons with the backward Euler method, the midpoint method, the\ntrapezoidal rule, the 2-stage Gauss scheme, and the 2- and 3-stage Radau\nschemes.\n","authors":["Gianluca Fabiani","Erik Bollt","Constantinos Siettos","Athanasios N. Yannacopoulos"],"pdf_url":"https://arxiv.org/pdf/2408.15393v2.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2506.05413v2","updated":"2025-07-29T15:28:07Z","published":"2025-06-04T19:07:45Z","title":"SmoothRot: Combining Channel-Wise Scaling and Rotation for\n  Quantization-Friendly LLMs","summary":"  We present SmoothRot, a novel post-training quantization technique to enhance\nthe efficiency of 4-bit quantization in Large Language Models (LLMs). SmoothRot\naddresses the critical challenge of massive activation outliers, by integrating\nchannel-wise scaling with Hadamard transformations. Our technique effectively\ntransforms extreme outliers into quantization-friendly activations,\nsignificantly improving quantization accuracy. Experiments conducted on popular\nLLMs (LLaMA2 7B, LLaMA3.1 8B, and Mistral 7B) demonstrate that SmoothRot\nconsistently reduces the performance gap between quantized and FP16 models by\napproximately 10-30\\% across language generation and zero-shot reasoning tasks,\nwithout introducing additional inference latency. Code is available at\nhttps://github.com/czakop/smoothrot.\n","authors":["Patrik Czakó","Gábor Kertész","Sándor Szénási"],"pdf_url":"https://arxiv.org/pdf/2506.05413v2.pdf","comment":"6 pages, 3 figures, 5 tables. Accepted to IEEE SMC 2025 conference\n  proceedings"},{"id":"http://arxiv.org/abs/2506.15787v3","updated":"2025-07-29T15:26:05Z","published":"2025-06-18T18:10:30Z","title":"SLR: Automated Synthesis for Scalable Logical Reasoning","summary":"  We introduce SLR, an end-to-end framework for systematic evaluation and\ntraining of Large Language Models (LLMs) via Scalable Logical Reasoning. Given\na user's task specification, SLR automatically synthesizes (i) an instruction\nprompt for an inductive reasoning task, (ii) a validation program, executable\non model outputs to provide verifiable rewards, and (iii) the latent\nground-truth rule. This process is fully automated, scalable, requires no human\nannotations, and offers precise control over task difficulty. Using SLR, we\ncreate SLR-Bench, a benchmark comprising 19k prompts organized into 20\ncurriculum levels that progressively increase in relational, arithmetic, and\nrecursive complexity. Large-scale evaluation reveals that contemporary LLMs\nreadily produce syntactically valid rules, yet often fail at correct logical\ninference. Recent reasoning LLMs demonstrate improved performance but incur\nvery high test-time computation, with costs exceeding $300 for just 1,000\nprompts. Finally, curriculum learning via SLR doubles Llama-3-8B accuracy on\nSLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of\ncomputational cost. Moreover, these reasoning capabilities generalize to a wide\nrange of established benchmarks, underscoring the effectiveness of SLR for\ndownstream reasoning.\n","authors":["Lukas Helff","Ahmad Omar","Felix Friedrich","Antonia Wüst","Hikaru Shindo","Rupert Mitchell","Tim Woydt","Patrick Schramowski","and Wolfgang Stammer Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2506.15787v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15064v2","updated":"2025-07-29T15:25:46Z","published":"2025-06-18T02:12:24Z","title":"HiPreNets: High-Precision Neural Networks through Progressive Training","summary":"  Deep neural networks are powerful tools for solving nonlinear problems in\nscience and engineering, but training highly accurate models becomes\nchallenging as problem complexity increases. Non-convex optimization and\nnumerous hyperparameters to tune make performance improvement difficult, and\ntraditional approaches often prioritize minimizing mean squared error (MSE)\nwhile overlooking $L^{\\infty}$ error, which is the critical focus in many\napplications. To address these challenges, we present a progressive framework\nfor training and tuning high-precision neural networks (HiPreNets). Our\napproach refines a previously explored staged training technique for neural\nnetworks that improves an existing fully connected neural network by\nsequentially learning its prediction residuals using additional networks,\nleading to improved overall accuracy. We discuss how to take advantage of the\nstructure of the residuals to guide the choice of loss function, number of\nparameters to use, and ways to introduce adaptive data sampling techniques. We\nvalidate our framework's effectiveness through several benchmark problems.\n","authors":["Ethan Mulle","Wei Kang","Qi Gong"],"pdf_url":"https://arxiv.org/pdf/2506.15064v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22296v5","updated":"2025-07-29T15:25:10Z","published":"2024-10-29T17:45:57Z","title":"Generalists vs. Specialists: Evaluating LLMs on Highly-Constrained\n  Biophysical Sequence Optimization Tasks","summary":"  Although large language models (LLMs) have shown promise in biomolecule\noptimization problems, they incur heavy computational costs and struggle to\nsatisfy precise constraints. On the other hand, specialized solvers like\nLaMBO-2 offer efficiency and fine-grained control but require more domain\nexpertise. Comparing these approaches is challenging due to expensive\nlaboratory validation and inadequate synthetic benchmarks. We address this by\nintroducing Ehrlich functions, a synthetic test suite that captures the\ngeometric structure of biophysical sequence optimization problems. With\nprompting alone, off-the-shelf LLMs struggle to optimize Ehrlich functions. In\nresponse, we propose LLOME (Language Model Optimization with Margin\nExpectation), a bilevel optimization routine for online black-box optimization.\nWhen combined with a novel preference learning loss, we find LLOME can not only\nlearn to solve some Ehrlich functions, but can even perform as well as or\nbetter than LaMBO-2 on moderately difficult Ehrlich variants. However, LLMs\nalso exhibit some likelihood-reward miscalibration and struggle without\nexplicit rewards. Our results indicate LLMs can occasionally provide\nsignificant benefits, but specialized solvers are still competitive and incur\nless overhead.\n","authors":["Angelica Chen","Samuel D. Stanton","Frances Ding","Robert G. Alberstein","Andrew M. Watkins","Richard Bonneau","Vladimir Gligorijević","Kyunghyun Cho","Nathan C. Frey"],"pdf_url":"https://arxiv.org/pdf/2410.22296v5.pdf","comment":"Supercedes arXiv:2407.00236v1. arXiv admin note: text overlap with\n  arXiv:2407.00236"},{"id":"http://arxiv.org/abs/2506.20380v3","updated":"2025-07-29T15:23:52Z","published":"2025-06-25T12:46:26Z","title":"TESSERA: Temporal Embeddings of Surface Spectra for Earth Representation\n  and Analysis","summary":"  Satellite remote sensing from repeated observations and multiple sensors\nenables a wide range of downstream applications, including climate modeling,\ncarbon accounting, and strategies for conservation and sustainable land use.\nHowever, satellite time series are voluminous, often corrupted by sensor noise,\nclouds, and atmospheric conditions, and unevenly spaced in time, making them\nchallenging to use. We present TESSERA, an open, global, land-oriented remote\nsensing foundation model that uses self-supervised learning to generate\n`ready-to-use' embeddings at 10~m scale from pixel-level satellite time series\ndata. TESSERA uses two parallel Transformer-based encoders to combine optical\ndata from ten Sentinel-2 spectral bands at 10-60~m spatial resolution and two\nSentinel-1 synthetic aperture radar backscatter coefficients at 10~m resolution\nto create embeddings that are subsequently fused with a multilayer perceptron\nto create annual global embedding maps. We compare our work with\nstate-of-the-art task-specific models and other foundation models in five\ndiverse downstream tasks and find that TESSERA closely matches or outperforms\nthese baselines. We believe that TESSERA's ease of use, openness, computation-,\nlabel-, and data-efficiency, and high performance will prove transformative in\na wide range of vegetation-oriented ecological and agricultural applications.\n","authors":["Zhengpeng Feng","Clement Atzberger","Sadiq Jaffer","Jovana Knezevic","Silja Sormunen","Robin Young","Madeline C Lisaius","Markus Immitzer","David A. Coomes","Anil Madhavapeddy","Andrew Blake","Srinivasan Keshav"],"pdf_url":"https://arxiv.org/pdf/2506.20380v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21905v1","updated":"2025-07-29T15:17:00Z","published":"2025-07-29T15:17:00Z","title":"Evaluating Deepfake Detectors in the Wild","summary":"  Deepfakes powered by advanced machine learning models present a significant\nand evolving threat to identity verification and the authenticity of digital\nmedia. Although numerous detectors have been developed to address this problem,\ntheir effectiveness has yet to be tested when applied to real-world data. In\nthis work we evaluate modern deepfake detectors, introducing a novel testing\nprocedure designed to mimic real-world scenarios for deepfake detection. Using\nstate-of-the-art deepfake generation methods, we create a comprehensive dataset\ncontaining more than 500,000 high-quality deepfake images. Our analysis shows\nthat detecting deepfakes still remains a challenging task. The evaluation shows\nthat in fewer than half of the deepfake detectors tested achieved an AUC score\ngreater than 60%, with the lowest being 50%. We demonstrate that basic image\nmanipulations, such as JPEG compression or image enhancement, can significantly\nreduce model performance. All code and data are publicly available at\nhttps://github.com/messlav/Deepfake-Detectors-in-the-Wild.\n","authors":["Viacheslav Pirogov","Maksim Artemev"],"pdf_url":"https://arxiv.org/pdf/2507.21905v1.pdf","comment":"Accepted to the ICML 2025 Workshop 'DataWorld: Unifying Data Curation\n  Frameworks Across Domains'"},{"id":"http://arxiv.org/abs/2411.01297v3","updated":"2025-07-29T15:15:31Z","published":"2024-11-02T16:06:29Z","title":"Receding Hamiltonian-Informed Optimal Neural Control and State\n  Estimation for Closed-Loop Dynamical Systems","summary":"  This paper formalizes Hamiltonian-Informed Optimal Neural (Hion) controllers,\na novel class of neural network-based controllers for dynamical systems and\nexplicit non-linear model-predictive control. Hion controllers estimate future\nstates and develop an optimal control strategy using Pontryagin's Maximum\nPrinciple. The proposed framework, along with our Taylored Multi-Faceted\nApproach for Neural ODE and Optimal Control (T-mano) architecture, allows for\ncustom transient behavior, predictive control, and closed-loop feedback,\naddressing limitations of existing methods. Comparative analyses with\nestablished model-predictive controllers revealed Hion controllers' superior\noptimality and tracking capabilities. Optimal control strategies are also\ndemonstrated for both linear and non-linear dynamical systems.\n","authors":["Josue N. Rivera","Dengfeng Sun"],"pdf_url":"https://arxiv.org/pdf/2411.01297v3.pdf","comment":"27 pages. Source code: https://github.com/wzjoriv/Hion"},{"id":"http://arxiv.org/abs/2410.11468v3","updated":"2025-07-29T15:13:08Z","published":"2024-10-15T10:16:01Z","title":"Can sparse autoencoders make sense of gene expression latent variable\n  models?","summary":"  Sparse autoencoders (SAEs) have lately been used to uncover interpretable\nlatent features in large language models. By projecting dense embeddings into a\nmuch higher-dimensional and sparse space, learned features become disentangled\nand easier to interpret. This work explores the potential of SAEs for\ndecomposing embeddings in complex and high-dimensional biological data. Using\nsimulated data, it outlines the efficacy, hyperparameter landscape, and\nlimitations of SAEs when it comes to extracting ground truth generative\nvariables from latent space. The application to embeddings from pretrained\nsingle-cell models shows that SAEs can find and steer key biological processes\nand even uncover subtle biological signals that might otherwise be missed. This\nwork further introduces scFeatureLens, an automated interpretability approach\nfor linking SAE features and biological concepts from gene sets to enable\nlarge-scale analysis and hypothesis generation in single-cell gene expression\nmodels.\n","authors":["Viktoria Schuster"],"pdf_url":"https://arxiv.org/pdf/2410.11468v3.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2507.21902v1","updated":"2025-07-29T15:12:40Z","published":"2025-07-29T15:12:40Z","title":"Reducing Data Requirements for Sequence-Property Prediction in Copolymer\n  Compatibilizers via Deep Neural Network Tuning","summary":"  Synthetic sequence-controlled polymers promise to transform polymer science\nby combining the chemical versatility of synthetic polymers with the precise\nsequence-mediated functionality of biological proteins. However, design of\nthese materials has proven extraordinarily challenging, because they lack the\nmassive datasets of closely related evolved molecules that accelerate design of\nproteins. Here we report on a new Artifical Intelligence strategy to\ndramatically reduce the amount of data necessary to accelerate these materials'\ndesign. We focus on data connecting the repeat-unit-sequence of a\n\\emph{compatibilizer} molecule to its ability to reduce the interfacial tension\nbetween distinct polymer domains. The optimal sequence of these molecules,\nwhich are essential for applications such as mixed-waste polymer recycling,\ndepends strongly on variables such as concentration and chemical details of the\npolymer. With current methods, this would demand an entirely distinct dataset\nto enable design at each condition. Here we show that a deep neural network\ntrained on low-fidelity data for sequence/interfacial tension relations at one\nset of conditions can be rapidly tuned to make higher-fidelity predictions at a\ndistinct set of conditions, requiring far less data that would ordinarily be\nneeded. This priming-and-tuning approach should allow a single low-fidelity\nparent dataset to dramatically accelerate prediction and design in an entire\nconstellation of related systems. In the long run, it may also provide an\napproach to bootstrapping quantitative atomistic design with AI insights from\nfast, coarse simulations.\n","authors":["Md Mushfiqul Islam","Nishat N. Labiba","Lawrence O. Hall","David S. Simmons"],"pdf_url":"https://arxiv.org/pdf/2507.21902v1.pdf","comment":"23 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.21899v1","updated":"2025-07-29T15:09:38Z","published":"2025-07-29T15:09:38Z","title":"LLM-based Content Classification Approach for GitHub Repositories by the\n  README Files","summary":"  GitHub is the world's most popular platform for storing, sharing, and\nmanaging code. Every GitHub repository has a README file associated with it.\nThe README files should contain project-related information as per the\nrecommendations of GitHub to support the usage and improvement of repositories.\nHowever, GitHub repository owners sometimes neglected these recommendations.\nThis prevents a GitHub repository from reaching its full potential. This\nresearch posits that the comprehensiveness of a GitHub repository's README file\nsignificantly influences its adoption and utilization, with a lack of detail\npotentially hindering its full potential for widespread engagement and impact\nwithin the research community. Large Language Models (LLMs) have shown great\nperformance in many text-based tasks including text classification, text\ngeneration, text summarization and text translation. In this study, an approach\nis developed to fine-tune LLMs for automatically classifying different sections\nof GitHub README files. Three encoder-only LLMs are utilized, including BERT,\nDistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a\ngold-standard dataset consisting of 4226 README file sections. This approach\noutperforms current state-of-the-art methods and has achieved an overall F1\nscore of 0.98. Moreover, we have also investigated the use of\nParameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation\n(LoRA) and shown an economical alternative to full fine-tuning without\ncompromising much performance. The results demonstrate the potential of using\nLLMs in designing an automatic classifier for categorizing the content of\nGitHub README files. Consequently, this study contributes to the development of\nautomated tools for GitHub repositories to improve their identifications and\npotential usages.\n","authors":["Malik Uzair Mehmood","Shahid Hussain","Wen Li Wang","Muhammad Usama Malik"],"pdf_url":"https://arxiv.org/pdf/2507.21899v1.pdf","comment":"8 pages, 4 Figures"},{"id":"http://arxiv.org/abs/2507.21898v1","updated":"2025-07-29T15:07:32Z","published":"2025-07-29T15:07:32Z","title":"Cardiovascular Disease Prediction using Machine Learning: A Comparative\n  Analysis","summary":"  Cardiovascular diseases (CVDs) are a main cause of mortality globally,\naccounting for 31% of all deaths. This study involves a cardiovascular disease\n(CVD) dataset comprising 68,119 records to explore the influence of numerical\n(age, height, weight, blood pressure, BMI) and categorical gender, cholesterol,\nglucose, smoking, alcohol, activity) factors on CVD occurrence. We have\nperformed statistical analyses, including t-tests, Chi-square tests, and ANOVA,\nto identify strong associations between CVD and elderly people, hypertension,\nhigher weight, and abnormal cholesterol levels, while physical activity (a\nprotective factor). A logistic regression model highlights age, blood pressure,\nand cholesterol as primary risk factors, with unexpected negative associations\nfor smoking and alcohol, suggesting potential data issues. Model performance\ncomparisons reveal CatBoost as the top performer with an accuracy of 0.734 and\nan ECE of 0.0064 and excels in probabilistic prediction (Brier score = 0.1824).\nData challenges, including outliers and skewed distributions, indicate a need\nfor improved preprocessing to enhance predictive reliability.\n","authors":["Risshab Srinivas Ramesh","Roshani T S Udupa","Monisha J","Kushi K K S"],"pdf_url":"https://arxiv.org/pdf/2507.21898v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15196v2","updated":"2025-07-29T15:06:38Z","published":"2025-01-25T12:25:31Z","title":"A Review on Self-Supervised Learning for Time Series Anomaly Detection:\n  Recent Advances and Open Challenges","summary":"  Time series anomaly detection presents various challenges due to the\nsequential and dynamic nature of time-dependent data. Traditional unsupervised\nmethods frequently encounter difficulties in generalization, often overfitting\nto known normal patterns observed during training and struggling to adapt to\nunseen normality. In response to this limitation, self-supervised techniques\nfor time series have garnered attention as a potential solution to undertake\nthis obstacle and enhance the performance of anomaly detectors. This paper\npresents a comprehensive review of the recent methods that make use of\nself-supervised learning for time series anomaly detection. A taxonomy is\nproposed to categorize these methods based on their primary characteristics,\nfacilitating a clear understanding of their diversity within this field. The\ninformation contained in this survey, along with additional details that will\nbe periodically updated, is available on the following GitHub repository:\nhttps://github.com/Aitorzan3/Awesome-Self-Supervised-Time-Series-Anomaly-Detection.\n","authors":["Aitor Sánchez-Ferrera","Borja Calvo","Jose A. Lozano"],"pdf_url":"https://arxiv.org/pdf/2501.15196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21890v1","updated":"2025-07-29T15:00:56Z","published":"2025-07-29T15:00:56Z","title":"Data-driven quantum Koopman method for simulating nonlinear dynamics","summary":"  Quantum computation offers potential exponential speedups for simulating\ncertain physical systems, but its application to nonlinear dynamics is\ninherently constrained by the requirement of unitary evolution. We propose the\nquantum Koopman method (QKM), a data-driven framework that bridges this gap\nthrough transforming nonlinear dynamics into linear unitary evolution in\nhigher-dimensional observable spaces. Leveraging the Koopman operator theory to\nachieve a global linearization, our approach maps system states into a\nhierarchy of Hilbert spaces using a deep autoencoder. Within the linearized\nembedding spaces, the state representation is decomposed into modulus and phase\ncomponents, and the evolution is governed by a set of unitary Koopman operators\nthat act exclusively on the phase. These operators are constructed from\ndiagonal Hamiltonians with coefficients learned from data, a structure designed\nfor efficient implementation on quantum hardware. This architecture enables\ndirect multi-step prediction, and the operator's computational complexity\nscales logarithmically with the observable space dimension. The QKM is\nvalidated across diverse nonlinear systems. Its predictions maintain relative\nerrors below 6% for reaction-diffusion systems and shear flows, and capture key\nstatistics in 2D turbulence. This work establishes a practical pathway for\nquantum-accelerated simulation of nonlinear phenomena, exploring a framework\nbuilt on the synergy between deep learning for global linearization and quantum\nalgorithms for unitary dynamics evolution.\n","authors":["Baoyang Zhang","Zhen Lu","Yaomin Zhao","Yue Yang"],"pdf_url":"https://arxiv.org/pdf/2507.21890v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21886v1","updated":"2025-07-29T14:58:29Z","published":"2025-07-29T14:58:29Z","title":"Efficient Pain Recognition via Respiration Signals: A Single\n  Cross-Attention Transformer Multi-Window Fusion Pipeline","summary":"  Pain is a complex condition affecting a large portion of the population.\nAccurate and consistent evaluation is essential for individuals experiencing\npain, and it supports the development of effective and advanced management\nstrategies. Automatic pain assessment systems provide continuous monitoring and\nsupport clinical decision-making, aiming to reduce distress and prevent\nfunctional decline. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed method introduces a pipeline that leverages respiration as the input\nsignal and incorporates a highly efficient cross-attention transformer\nalongside a multi-windowing strategy. Extensive experiments demonstrate that\nrespiration is a valuable physiological modality for pain assessment. Moreover,\nexperiments revealed that compact and efficient models, when properly\noptimized, can achieve strong performance, often surpassing larger\ncounterparts. The proposed multi-window approach effectively captures both\nshort-term and long-term features, as well as global characteristics, thereby\nenhancing the model's representational capacity.\n","authors":["Stefanos Gkikas","Ioannis Kyprakis","Manolis Tsiknakis"],"pdf_url":"https://arxiv.org/pdf/2507.21886v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17489v3","updated":"2025-07-29T14:56:41Z","published":"2024-11-26T14:57:30Z","title":"Puzzle Similarity: A Perceptually-guided Cross-Reference Metric for\n  Artifact Detection in 3D Scene Reconstructions","summary":"  Modern reconstruction techniques can effectively model complex 3D scenes from\nsparse 2D views. However, automatically assessing the quality of novel views\nand identifying artifacts is challenging due to the lack of ground truth images\nand the limitations of no-reference image metrics in predicting reliable\nartifact maps. The absence of such metrics hinders assessment of the quality of\nnovel views and limits the adoption of post-processing techniques, such as\ninpainting, to enhance reconstruction quality. To tackle this, recent work has\nestablished a new category of metrics (cross-reference), predicting image\nquality solely by leveraging context from alternate viewpoint captures\n(arXiv:2404.14409). In this work, we propose a new cross-reference metric,\nPuzzle Similarity, which is designed to localize artifacts in novel views. Our\napproach utilizes image patch statistics from the training views to establish a\nscene-specific distribution, later used to identify poorly reconstructed\nregions in the novel views. Given the lack of good measures to evaluate\ncross-reference methods in the context of 3D reconstruction, we collected a\nnovel human-labeled dataset of artifact and distortion maps in unseen\nreconstructed views. Through this dataset, we demonstrate that our method\nachieves state-of-the-art localization of artifacts in novel views, correlating\nwith human assessment, even without aligned references. We can leverage our new\nmetric to enhance applications like automatic image restoration, guided\nacquisition, or 3D reconstruction from sparse inputs. Find the project page at\nhttps://nihermann.github.io/puzzlesim/ .\n","authors":["Nicolai Hermann","Jorge Condor","Piotr Didyk"],"pdf_url":"https://arxiv.org/pdf/2411.17489v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.15566v2","updated":"2025-07-29T14:48:39Z","published":"2025-07-21T12:46:18Z","title":"Prediction accuracy versus rescheduling flexibility in elective surgery\n  management","summary":"  The availability of downstream resources plays is critical in planning the\nadmission of elective surgery patients. The most crucial one is inpatient beds.\nTo ensure bed availability, hospitals may use machine learning (ML) models to\npredict patients' length-of-stay (LOS) in the admission planning stage.\nHowever, the real value of the LOS for each patient may differ from the\npredicted one, potentially making the schedule infeasible. To address such\ninfeasibilities, it is possible to implement rescheduling strategies that take\nadvantage of operational flexibility. For example, planners may postpone\nadmission dates, relocate patients to different wards, or even transfer\npatients who are already admitted among wards. A straightforward assumption is\nthat better LOS predictions can help reduce the impact of rescheduling.\nHowever, the training process of ML models that can make such accurate\npredictions can be very costly. Building on previous work that proposed\nsimulated ML for evaluating data-driven approaches, this paper explores the\nrelationship between LOS prediction accuracy and rescheduling flexibility\nacross various corrective policies. Specifically, we examine the most effective\npatient rescheduling strategies under LOS prediction errors to prevent bed\noverflows while optimizing resource utilization\n","authors":["Pieter Smet","Martina Doneda","Ettore Lanzarone","Giuliana Carello"],"pdf_url":"https://arxiv.org/pdf/2507.15566v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.10774v2","updated":"2025-07-29T14:43:48Z","published":"2025-05-16T01:23:53Z","title":"Context-Aware Probabilistic Modeling with LLM for Multimodal Time Series\n  Forecasting","summary":"  Time series forecasting is important for applications spanning energy\nmarkets, climate analysis, and traffic management. However, existing methods\nstruggle to effectively integrate exogenous texts and align them with the\nprobabilistic nature of large language models (LLMs). Current approaches either\nemploy shallow text-time series fusion via basic prompts or rely on\ndeterministic numerical decoding that conflict with LLMs' token-generation\nparadigm, which limits contextual awareness and distribution modeling. To\naddress these limitations, we propose CAPTime, a context-aware probabilistic\nmultimodal time series forecasting method that leverages text-informed\nabstraction and autoregressive LLM decoding. Our method first encodes temporal\npatterns using a pretrained time series encoder, then aligns them with textual\ncontexts via learnable interactions to produce joint multimodal\nrepresentations. By combining a mixture of distribution experts with frozen\nLLMs, we enable context-aware probabilistic forecasting while preserving LLMs'\ninherent distribution modeling capabilities. Experiments on diverse time series\nforecasting tasks demonstrate the superior accuracy and generalization of\nCAPTime, particularly in multimodal scenarios. Additional analysis highlights\nits robustness in data-scarce scenarios through hybrid probabilistic decoding.\n","authors":["Yueyang Yao","Jiajun Li","Xingyuan Dai","MengMeng Zhang","Xiaoyan Gong","Fei-Yue Wang","Yisheng Lv"],"pdf_url":"https://arxiv.org/pdf/2505.10774v2.pdf","comment":"13 pages, 2 figures"},{"id":"http://arxiv.org/abs/2507.21871v1","updated":"2025-07-29T14:42:31Z","published":"2025-07-29T14:42:31Z","title":"Representations in vision and language converge in a shared,\n  multidimensional space of perceived similarities","summary":"  Humans can effortlessly describe what they see, yet establishing a shared\nrepresentational format between vision and language remains a significant\nchallenge. Emerging evidence suggests that human brain representations in both\nvision and language are well predicted by semantic feature spaces obtained from\nlarge language models (LLMs). This raises the possibility that sensory systems\nconverge in their inherent ability to transform their inputs onto shared,\nembedding-like representational space. However, it remains unclear how such a\nspace manifests in human behaviour. To investigate this, sixty-three\nparticipants performed behavioural similarity judgements separately on 100\nnatural scene images and 100 corresponding sentence captions from the Natural\nScenes Dataset. We found that visual and linguistic similarity judgements not\nonly converge at the behavioural level but also predict a remarkably similar\nnetwork of fMRI brain responses evoked by viewing the natural scene images.\nFurthermore, computational models trained to map images onto LLM-embeddings\noutperformed both category-trained and AlexNet controls in explaining the\nbehavioural similarity structure. These findings demonstrate that human visual\nand linguistic similarity judgements are grounded in a shared,\nmodality-agnostic representational structure that mirrors how the visual system\nencodes experience. The convergence between sensory and artificial systems\nsuggests a common capacity of how conceptual representations are formed-not as\narbitrary products of first order, modality-specific input, but as structured\nrepresentations that reflect the stable, relational properties of the external\nworld.\n","authors":["Katerina Marie Simkova","Adrien Doerig","Clayton Hickey","Ian Charest"],"pdf_url":"https://arxiv.org/pdf/2507.21871v1.pdf","comment":"51 pages, 15 figures"},{"id":"http://arxiv.org/abs/2507.21841v1","updated":"2025-07-29T14:19:59Z","published":"2025-07-29T14:19:59Z","title":"Discovering Interpretable Ordinary Differential Equations from Noisy\n  Data","summary":"  The data-driven discovery of interpretable models approximating the\nunderlying dynamics of a physical system has gained attraction in the past\ndecade. Current approaches employ pre-specified functional forms or basis\nfunctions and often result in models that lack physical meaning and\ninterpretability, let alone represent the true physics of the system. We\npropose an unsupervised parameter estimation methodology that first finds an\napproximate general solution, followed by a spline transformation to linearly\nestimate the coefficients of the governing ordinary differential equation\n(ODE). The approximate general solution is postulated using the same functional\nform as the analytical solution of a general homogeneous, linear,\nconstant-coefficient ODE. An added advantage is its ability to produce a\nhigh-fidelity, smooth functional form even in the presence of noisy data. The\nspline approximation obtains gradient information from the functional form\nwhich are linearly independent and creates the basis of the gradient matrix.\nThis gradient matrix is used in a linear system to find the coefficients of the\nODEs. From the case studies, we observed that our modeling approach discovers\nODEs with high accuracy and also promotes sparsity in the solution without\nusing any regularization techniques. The methodology is also robust to noisy\ndata and thus allows the integration of data-driven techniques into real\nexperimental setting for data-driven learning of physical phenomena.\n","authors":["Rahul Golder","M. M. Faruque Hasan"],"pdf_url":"https://arxiv.org/pdf/2507.21841v1.pdf","comment":"20 pages, 11 figures, 7 tables"},{"id":"http://arxiv.org/abs/2507.21833v1","updated":"2025-07-29T14:10:46Z","published":"2025-07-29T14:10:46Z","title":"Analysis of Fourier Neural Operators via Effective Field Theory","summary":"  Fourier Neural Operators (FNOs) have emerged as leading surrogates for\nhigh-dimensional partial-differential equations, yet their stability,\ngeneralization and frequency behavior lack a principled explanation. We present\nthe first systematic effective-field-theory analysis of FNOs in an\ninfinite-dimensional function space, deriving closed recursion relations for\nthe layer kernel and four-point vertex and then examining three practically\nimportant settings-analytic activations, scale-invariant cases and\narchitectures with residual connections. The theory shows that nonlinear\nactivations inevitably couple frequency inputs to high-frequency modes that are\notherwise discarded by spectral truncation, and experiments confirm this\nfrequency transfer. For wide networks we obtain explicit criticality conditions\non the weight-initialization ensemble that keep small input perturbations to\nhave uniform scale across depth, and empirical tests validate these\npredictions. Taken together, our results quantify how nonlinearity enables\nneural operators to capture non-trivial features, supply criteria for\nhyper-parameter selection via criticality analysis, and explain why\nscale-invariant activations and residual connections enhance feature learning\nin FNOs.\n","authors":["Taeyoung Kim"],"pdf_url":"https://arxiv.org/pdf/2507.21833v1.pdf","comment":"37 pages, 10 figures"},{"id":"http://arxiv.org/abs/2507.21831v1","updated":"2025-07-29T14:10:31Z","published":"2025-07-29T14:10:31Z","title":"Introducing HALC: A general pipeline for finding optimal prompting\n  strategies for automated coding with LLMs in the computational social\n  sciences","summary":"  LLMs are seeing widespread use for task automation, including automated\ncoding in the social sciences. However, even though researchers have proposed\ndifferent prompting strategies, their effectiveness varies across LLMs and\ntasks. Often trial and error practices are still widespread. We propose\nHALC$-$a general pipeline that allows for the systematic and reliable\nconstruction of optimal prompts for any given coding task and model, permitting\nthe integration of any prompting strategy deemed relevant. To investigate LLM\ncoding and validate our pipeline, we sent a total of 1,512 individual prompts\nto our local LLMs in over two million requests. We test prompting strategies\nand LLM task performance based on few expert codings (ground truth). When\ncompared to these expert codings, we find prompts that code reliably for single\nvariables (${\\alpha}$climate = .76; ${\\alpha}$movement = .78) and across two\nvariables (${\\alpha}$climate = .71; ${\\alpha}$movement = .74) using the LLM\nMistral NeMo. Our prompting strategies are set up in a way that aligns the LLM\nto our codebook$-$we are not optimizing our codebook for LLM friendliness. Our\npaper provides insights into the effectiveness of different prompting\nstrategies, crucial influencing factors, and the identification of reliable\nprompts for each coding task and model.\n","authors":["Andreas Reich","Claudia Thoms","Tobias Schrimpf"],"pdf_url":"https://arxiv.org/pdf/2507.21831v1.pdf","comment":"48 pages, 9 figures and 8 tables"},{"id":"http://arxiv.org/abs/2503.16531v2","updated":"2025-07-29T14:09:40Z","published":"2025-03-18T11:12:15Z","title":"EEG-CLIP : Learning EEG representations from natural language\n  descriptions","summary":"  Deep networks for electroencephalogram (EEG) decoding are often only trained\nto solve one specific task, such as pathology or age decoding. A more general\ntask-agnostic approach is to train deep networks to match a (clinical) EEG\nrecording to its corresponding textual medical report and vice versa. This\napproach was pioneered in the computer vision domain matching images and their\ntext captions and subsequently allowed to do successful zero-shot decoding\nusing textual class prompts. In this work, we follow this approach and develop\na contrastive learning framework, EEG-CLIP, that aligns the EEG time series and\nthe descriptions of the corresponding clinical text in a shared embedding\nspace. We investigated its potential for versatile EEG decoding, evaluating\nperformance in a range of few-shot and zero-shot settings. Overall, we show\nthat EEG-CLIP manages to non-trivially align text and EEG representations. Our\nwork presents a promising approach to learn general EEG representations, which\ncould enable easier analyses of diverse decoding questions through zero-shot\ndecoding or training task-specific models from fewer training examples. The\ncode for reproducing our results is available at\nhttps://github.com/tidiane-camaret/EEGClip\n","authors":["Tidiane Camaret Ndir","Robin Tibor Schirrmeister","Tonio Ball"],"pdf_url":"https://arxiv.org/pdf/2503.16531v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21807v1","updated":"2025-07-29T13:42:38Z","published":"2025-07-29T13:42:38Z","title":"MIBoost: A Gradient Boosting Algorithm for Variable Selection After\n  Multiple Imputation","summary":"  Statistical learning methods for automated variable selection, such as LASSO,\nelastic nets, or gradient boosting, have become increasingly popular tools for\nbuilding powerful prediction models. Yet, in practice, analyses are often\ncomplicated by missing data. The most widely used approach to address\nmissingness is multiple imputation, which creates several completed datasets.\nHowever, there is an ongoing debate on how to perform model selection in the\npresence of multiple imputed datasets. Simple strategies, such as pooling\nmodels across datasets, have been shown to have suboptimal properties. Although\nmore sophisticated methods exist, they are often difficult to implement and\ntherefore not widely applied. In contrast, two recent approaches modify the\nregularization methods LASSO and elastic nets by defining a single loss\nfunction, resulting in a unified set of coefficients across imputations. Our\nkey contribution is to extend this principle to the framework of component-wise\ngradient boosting by proposing MIBoost, a novel algorithm that employs a\nuniform variable-selection mechanism across imputed datasets. Simulation\nstudies suggest that our approach yields prediction performance comparable to\nthat of these recently proposed methods.\n","authors":["Robert Kuchen"],"pdf_url":"https://arxiv.org/pdf/2507.21807v1.pdf","comment":"21 pages, 2 algorithms, includes a simulation study"},{"id":"http://arxiv.org/abs/2507.21803v1","updated":"2025-07-29T13:40:46Z","published":"2025-07-29T13:40:46Z","title":"Bayesian Neural Network Surrogates for Bayesian Optimization of Carbon\n  Capture and Storage Operations","summary":"  Carbon Capture and Storage (CCS) stands as a pivotal technology for fostering\na sustainable future. The process, which involves injecting supercritical\nCO$_2$ into underground formations, a method already widely used for Enhanced\nOil Recovery, serves a dual purpose: it not only curbs CO$_2$ emissions and\naddresses climate change but also extends the operational lifespan and\nsustainability of oil fields and platforms, easing the shift toward greener\npractices. This paper delivers a thorough comparative evaluation of strategies\nfor optimizing decision variables in CCS project development, employing a\nderivative-free technique known as Bayesian Optimization. In addition to\nGaussian Processes, which usually serve as the gold standard in BO, various\nnovel stochastic models were examined and compared within a BO framework. This\nresearch investigates the effectiveness of utilizing more exotic stochastic\nmodels than GPs for BO in environments where GPs have been shown to\nunderperform, such as in cases with a large number of decision variables or\nmultiple objective functions that are not similarly scaled. By incorporating\nNet Present Value (NPV) as a key objective function, the proposed framework\ndemonstrates its potential to improve economic viability while ensuring the\nsustainable deployment of CCS technologies. Ultimately, this study represents\nthe first application in the reservoir engineering industry of the growing body\nof BO research, specifically in the search for more appropriate stochastic\nmodels, highlighting its potential as a preferred method for enhancing\nsustainability in the energy sector.\n","authors":["Sofianos Panagiotis Fotias","Vassilis Gaganis"],"pdf_url":"https://arxiv.org/pdf/2507.21803v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21799v1","updated":"2025-07-29T13:35:51Z","published":"2025-07-29T13:35:51Z","title":"Unlocking Interpretability for RF Sensing: A Complex-Valued White-Box\n  Transformer","summary":"  The empirical success of deep learning has spurred its application to the\nradio-frequency (RF) domain, leading to significant advances in Deep Wireless\nSensing (DWS). However, most existing DWS models function as black boxes with\nlimited interpretability, which hampers their generalizability and raises\nconcerns in security-sensitive physical applications. In this work, inspired by\nthe remarkable advances of white-box transformers, we present RF-CRATE, the\nfirst mathematically interpretable deep network architecture for RF sensing,\ngrounded in the principles of complex sparse rate reduction. To accommodate the\nunique RF signals, we conduct non-trivial theoretical derivations that extend\nthe original real-valued white-box transformer to the complex domain. By\nleveraging the CR-Calculus framework, we successfully construct a fully\ncomplex-valued white-box transformer with theoretically derived self-attention\nand residual multi-layer perceptron modules. Furthermore, to improve the\nmodel's ability to extract discriminative features from limited wireless data,\nwe introduce Subspace Regularization, a novel regularization strategy that\nenhances feature diversity, resulting in an average performance improvement of\n19.98% across multiple sensing tasks. We extensively evaluate RF-CRATE against\nseven baselines with multiple public and self-collected datasets involving\ndifferent RF signals. The results show that RF-CRATE achieves performance on\npar with thoroughly engineered black-box models, while offering full\nmathematical interpretability. More importantly, by extending CRATE to the\ncomplex domain, RF-CRATE yields substantial improvements, achieving an average\nclassification gain of 5.08% and reducing regression error by 10.34% across\ndiverse sensing tasks compared to CRATE. RF-CRATE is fully open-sourced at:\nhttps://github.com/rfcrate/RF_CRATE.\n","authors":["Xie Zhang","Yina Wang","Chenshu Wu"],"pdf_url":"https://arxiv.org/pdf/2507.21799v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.03443v2","updated":"2025-07-29T13:18:56Z","published":"2025-03-05T12:24:12Z","title":"Conceptualizing Uncertainty: A Concept-based Approach to Explaining\n  Uncertainty","summary":"  Uncertainty in machine learning refers to the degree of confidence or lack\nthereof in a model's predictions. While uncertainty quantification methods\nexist, explanations of uncertainty, especially in high-dimensional settings,\nremain an open challenge. Existing work focuses on feature attribution\napproaches which are restricted to local explanations. Understanding\nuncertainty, its origins, and characteristics on a global scale is crucial for\nenhancing interpretability and trust in a model's predictions. In this work, we\npropose to explain the uncertainty in high-dimensional data classification\nsettings by means of concept activation vectors which give rise to local and\nglobal explanations of uncertainty. We demonstrate the utility of the generated\nexplanations by leveraging them to refine and improve our model.\n","authors":["Isaac Roberts","Alexander Schulz","Sarah Schroeder","Fabian Hinder","Barbara Hammer"],"pdf_url":"https://arxiv.org/pdf/2503.03443v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14078v2","updated":"2025-07-29T13:13:35Z","published":"2024-05-23T00:52:38Z","title":"A finite time analysis of distributed Q-learning","summary":"  Multi-agent reinforcement learning (MARL) has witnessed a remarkable surge in\ninterest, fueled by the empirical success achieved in applications of\nsingle-agent reinforcement learning (RL). In this study, we consider a\ndistributed Q-learning scenario, wherein a number of agents cooperatively solve\na sequential decision making problem without access to the central reward\nfunction which is an average of the local rewards. In particular, we study\nfinite-time analysis of a distributed Q-learning algorithm, and provide a new\nsample complexity result of $\\tilde{\\mathcal{O}}\\left(\n\\min\\left\\{\\frac{1}{\\epsilon^2}\\frac{t_{\\text{mix}}}{(1-\\gamma)^6 d_{\\min}^4 }\n,\\frac{1}{\\epsilon}\\frac{\\sqrt{|\\gS||\\gA|}}{(1-\\sigma_2(\\boldsymbol{W}))(1-\\gamma)^4\nd_{\\min}^3} \\right\\}\\right)$ under tabular lookup\n","authors":["Han-Dong Lim","Donghwan Lee"],"pdf_url":"https://arxiv.org/pdf/2405.14078v2.pdf","comment":"Published at RLC2025"}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2506.20114v3","updated":"2025-07-29T17:50:49Z","published":"2025-06-25T04:06:37Z","title":"Extracting Interpretable Models from Tree Ensembles: Computational and\n  Statistical Perspectives","summary":"  Tree ensembles are non-parametric methods widely recognized for their\naccuracy and ability to capture complex interactions. While these models excel\nat prediction, they are difficult to interpret and may fail to uncover useful\nrelationships in the data. We propose an estimator to extract compact sets of\ndecision rules from tree ensembles. The extracted models are accurate and can\nbe manually examined to reveal relationships between the predictors and the\nresponse. A key novelty of our estimator is the flexibility to jointly control\nthe number of rules extracted and the interaction depth of each rule, which\nimproves accuracy. We develop a tailored exact algorithm to efficiently solve\noptimization problems underlying our estimator and an approximate algorithm for\ncomputing regularization paths, sequences of solutions that correspond to\nvarying model sizes. We also establish novel non-asymptotic prediction error\nbounds for our proposed approach, comparing it to an oracle that chooses the\nbest data-dependent linear combination of the rules in the ensemble subject to\nthe same complexity constraint as our estimator. The bounds illustrate that the\nlarge-sample predictive performance of our estimator is on par with that of the\noracle. Through experiments, we demonstrate that our estimator outperforms\nexisting algorithms for rule extraction.\n","authors":["Brian Liu","Rahul Mazumder","Peter Radchenko"],"pdf_url":"https://arxiv.org/pdf/2506.20114v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.03458v3","updated":"2025-07-29T17:44:50Z","published":"2025-02-05T18:55:54Z","title":"The Performance Of The Unadjusted Langevin Algorithm Without Smoothness\n  Assumptions","summary":"  In this article, we study the problem of sampling from distributions whose\ndensities are not necessarily smooth nor logconcave. We propose a simple\nLangevin-based algorithm that does not rely on popular but computationally\nchallenging techniques, such as the Moreau-Yosida envelope or Gaussian\nsmoothing, and show consequently that the performance of samplers like ULA does\nnot necessarily degenerate arbitrarily with low regularity. In particular, we\nshow that the Lipschitz or H\\\"older continuity assumption can be replaced by a\ngeometric one-sided Lipschitz condition that allows even for discontinuous\nlog-gradients. We derive non-asymptotic guarantees for the convergence of the\nalgorithm to the target distribution in Wasserstein distances. Non-asymptotic\nbounds are also provided for the performance of the algorithm as an optimizer,\nspecifically for the solution of associated excess risk optimization problems.\n","authors":["Tim Johnston","Iosif Lytras","Nikolaos Makras","Sotirios Sabanis"],"pdf_url":"https://arxiv.org/pdf/2502.03458v3.pdf","comment":"24pages"},{"id":"http://arxiv.org/abs/2507.22004v1","updated":"2025-07-29T16:53:44Z","published":"2025-07-29T16:53:44Z","title":"Horseshoe Forests for High-Dimensional Causal Survival Analysis","summary":"  We develop a Bayesian tree ensemble model to estimate heterogeneous treatment\neffects in censored survival data with high-dimensional covariates. Instead of\nimposing sparsity through the tree structure, we place a horseshoe prior\ndirectly on the step heights to achieve adaptive global-local shrinkage. This\nstrategy allows flexible regularisation and reduces noise. We develop a\nreversible jump Gibbs sampler to accommodate the non-conjugate horseshoe prior\nwithin the tree ensemble framework. We show through extensive simulations that\nthe method accurately estimates treatment effects in high-dimensional covariate\nspaces, at various sparsity levels, and under non-linear treatment effect\nfunctions. We further illustrate the practical utility of the proposed approach\nby a re-analysis of pancreatic ductal adenocarcinoma (PDAC) survival data from\nThe Cancer Genome Atlas.\n","authors":["Tijn Jacobs","Wessel N. van Wieringen","Stéphanie L. van der Pas"],"pdf_url":"https://arxiv.org/pdf/2507.22004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21982v1","updated":"2025-07-29T16:33:43Z","published":"2025-07-29T16:33:43Z","title":"Preconditioned Discrete-HAMS: A Second-order Irreversible Discrete\n  Sampler","summary":"  Gradient-based Markov Chain Monte Carlo methods have recently received much\nattention for sampling discrete distributions, with notable examples such as\nNorm Constrained Gradient (NCG), Auxiliary Variable Gradient (AVG), and\nDiscrete Hamiltonian Assisted Metropolis Sampling (DHAMS). In this work, we\npropose the Preconditioned Discrete-HAMS (PDHAMS) algorithm, which extends\nDHAMS by incorporating a second-order, quadratic approximation of the potential\nfunction, and uses Gaussian integral trick to avoid directly sampling a\npairwise Markov random field. The PDHAMS sampler not only satisfies generalized\ndetailed balance, hence enabling irreversible sampling, but also is a\nrejection-free property for a target distribution with a quadratic potential\nfunction. In various numerical experiments, PDHAMS algorithms consistently\nyield superior performance compared with other methods.\n","authors":["Yuze Zhou","Zhiqiang Tan"],"pdf_url":"https://arxiv.org/pdf/2507.21982v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.15196v2","updated":"2025-07-29T15:06:38Z","published":"2025-01-25T12:25:31Z","title":"A Review on Self-Supervised Learning for Time Series Anomaly Detection:\n  Recent Advances and Open Challenges","summary":"  Time series anomaly detection presents various challenges due to the\nsequential and dynamic nature of time-dependent data. Traditional unsupervised\nmethods frequently encounter difficulties in generalization, often overfitting\nto known normal patterns observed during training and struggling to adapt to\nunseen normality. In response to this limitation, self-supervised techniques\nfor time series have garnered attention as a potential solution to undertake\nthis obstacle and enhance the performance of anomaly detectors. This paper\npresents a comprehensive review of the recent methods that make use of\nself-supervised learning for time series anomaly detection. A taxonomy is\nproposed to categorize these methods based on their primary characteristics,\nfacilitating a clear understanding of their diversity within this field. The\ninformation contained in this survey, along with additional details that will\nbe periodically updated, is available on the following GitHub repository:\nhttps://github.com/Aitorzan3/Awesome-Self-Supervised-Time-Series-Anomaly-Detection.\n","authors":["Aitor Sánchez-Ferrera","Borja Calvo","Jose A. Lozano"],"pdf_url":"https://arxiv.org/pdf/2501.15196v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21807v1","updated":"2025-07-29T13:42:38Z","published":"2025-07-29T13:42:38Z","title":"MIBoost: A Gradient Boosting Algorithm for Variable Selection After\n  Multiple Imputation","summary":"  Statistical learning methods for automated variable selection, such as LASSO,\nelastic nets, or gradient boosting, have become increasingly popular tools for\nbuilding powerful prediction models. Yet, in practice, analyses are often\ncomplicated by missing data. The most widely used approach to address\nmissingness is multiple imputation, which creates several completed datasets.\nHowever, there is an ongoing debate on how to perform model selection in the\npresence of multiple imputed datasets. Simple strategies, such as pooling\nmodels across datasets, have been shown to have suboptimal properties. Although\nmore sophisticated methods exist, they are often difficult to implement and\ntherefore not widely applied. In contrast, two recent approaches modify the\nregularization methods LASSO and elastic nets by defining a single loss\nfunction, resulting in a unified set of coefficients across imputations. Our\nkey contribution is to extend this principle to the framework of component-wise\ngradient boosting by proposing MIBoost, a novel algorithm that employs a\nuniform variable-selection mechanism across imputed datasets. Simulation\nstudies suggest that our approach yields prediction performance comparable to\nthat of these recently proposed methods.\n","authors":["Robert Kuchen"],"pdf_url":"https://arxiv.org/pdf/2507.21807v1.pdf","comment":"21 pages, 2 algorithms, includes a simulation study"},{"id":"http://arxiv.org/abs/2507.21783v1","updated":"2025-07-29T13:09:41Z","published":"2025-07-29T13:09:41Z","title":"Domain Generalization and Adaptation in Intensive Care with Anchor\n  Regression","summary":"  The performance of predictive models in clinical settings often degrades when\ndeployed in new hospitals due to distribution shifts. This paper presents a\nlarge-scale study of causality-inspired domain generalization on heterogeneous\nmulti-center intensive care unit (ICU) data. We apply anchor regression and\nintroduce anchor boosting, a novel, tree-based nonlinear extension, to a large\ndataset comprising 400,000 patients from nine distinct ICU databases. The\nanchor regularization consistently improves out-of-distribution performance,\nparticularly for the most dissimilar target domains. The methods appear robust\nto violations of theoretical assumptions, such as anchor exogeneity.\nFurthermore, we propose a novel conceptual framework to quantify the utility of\nlarge external data datasets. By evaluating performance as a function of\navailable target-domain data, we identify three regimes: (i) a domain\ngeneralization regime, where only the external model should be used, (ii) a\ndomain adaptation regime, where refitting the external model is optimal, and\n(iii) a data-rich regime, where external data provides no additional value.\n","authors":["Malte Londschien","Manuel Burger","Gunnar Rätsch","Peter Bühlmann"],"pdf_url":"https://arxiv.org/pdf/2507.21783v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.18627v2","updated":"2025-07-29T12:28:13Z","published":"2023-05-29T21:32:15Z","title":"Quantize Once, Train Fast: Allreduce-Compatible Compression with\n  Provable Guarantees","summary":"  Distributed training enables large-scale deep learning, but suffers from high\ncommunication overhead, especially as models and datasets grow. Gradient\ncompression, particularly quantization, is a promising approach to mitigate\nthis bottleneck. However, existing quantization schemes are often incompatible\nwith Allreduce, the dominant communication primitive in distributed deep\nlearning, and many prior solutions rely on heuristics without theoretical\nguarantees. We introduce Global-QSGD, an Allreduce-compatible gradient\nquantization method that leverages global norm scaling to reduce communication\noverhead while preserving accuracy. Global-QSGD is backed by rigorous\ntheoretical analysis, extending standard unbiased compressor frameworks to\nestablish formal convergence guarantees. Additionally, we develop a performance\nmodel to evaluate its impact across different hardware configurations.\nExtensive experiments on NVLink, PCIe, and large-scale cloud environments show\nthat Global-QSGD accelerates distributed training by up to 3.51% over baseline\nquantization methods, making it a practical and efficient solution for\nlarge-scale deep learning workloads.\n","authors":["Jihao Xin","Marco Canini","Peter Richtárik","Samuel Horváth"],"pdf_url":"https://arxiv.org/pdf/2305.18627v2.pdf","comment":"ECAI'25"},{"id":"http://arxiv.org/abs/2412.20802v2","updated":"2025-07-29T11:54:33Z","published":"2024-12-30T08:49:41Z","title":"Robust Matrix Completion for Discrete Rating-Scale Data: Coping with\n  Fake Profiles in Recommender Systems","summary":"  Recommender systems are essential tools in the digital landscape for\nconnecting users with content that more closely aligns with their preferences.\nMatrix completion is a widely used statistical framework for such systems,\naiming to predict a user's preferences for items they have not yet rated by\nleveraging the observed ratings in a partially filled user-item rating matrix.\nRealistic applications of matrix completion in recommender systems must address\nseveral challenges that are too often neglected: (i) the discrete nature of\nrating-scale data, (ii) the presence of malicious users who manipulate the\nsystem to their advantage through the creation of fake profiles, and (iii)\nmissing-not-at-random patterns, where users are more likely to rate items they\nexpect to enjoy. Our goal in this paper is twofold. First, we propose a novel\nmatrix completion method, robust discrete matrix completion (RDMC), designed\nspecifically to handle the discrete nature of sparse rating-scale data and to\nremain reliable in the presence of adversarial manipulation. We evaluate RDMC\nthrough carefully designed experiments and realistic case studies. Our work\ntherefore, secondly, offers a statistically-sound blueprint for future studies\non how to evaluate matrix completion methods for recommender systems under\nrealistic scenarios.\n","authors":["Aurore Archimbaud","Andreas Alfons","Ines Wilms"],"pdf_url":"https://arxiv.org/pdf/2412.20802v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21712v1","updated":"2025-07-29T11:39:13Z","published":"2025-07-29T11:39:13Z","title":"An Equal-Probability Partition of the Sample Space: A Non-parametric\n  Inference from Finite Samples","summary":"  This paper investigates what can be inferred about an arbitrary continuous\nprobability distribution from a finite sample of $N$ observations drawn from\nit. The central finding is that the $N$ sorted sample points partition the real\nline into $N+1$ segments, each carrying an expected probability mass of exactly\n$1/(N+1)$. This non-parametric result, which follows from fundamental\nproperties of order statistics, holds regardless of the underlying\ndistribution's shape. This equal-probability partition yields a discrete\nentropy of $\\log_2(N+1)$ bits, which quantifies the information gained from the\nsample and contrasts with Shannon's results for continuous variables. I compare\nthis partition-based framework to the conventional ECDF and discuss its\nimplications for robust non-parametric inference, particularly in density and\ntail estimation.\n","authors":["Urban Eriksson"],"pdf_url":"https://arxiv.org/pdf/2507.21712v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2206.04841v2","updated":"2025-07-29T11:09:33Z","published":"2022-06-10T02:03:18Z","title":"Hierarchical mixtures of Gaussians for combined dimensionality reduction\n  and clustering","summary":"  We introduce hierarchical mixtures of Gaussians (HMoGs), which unify\ndimensionality reduction and clustering into a single probabilistic model.\nHMoGs provide closed-form expressions for the model likelihood, exact inference\nover latent states and cluster membership, and exact algorithms for\nmaximum-likelihood optimization. The novel exponential family parameterization\nof HMoGs greatly reduces their computational complexity relative to similar\nmodel-based methods, allowing them to efficiently model hundreds of latent\ndimensions, and thereby capture additional structure in high-dimensional data.\nWe demonstrate HMoGs on synthetic experiments and MNIST, and show how joint\noptimization of dimensionality reduction and clustering facilitates increased\nmodel performance. We also explore how sparsity-constrained dimensionality\nreduction can further improve clustering performance while encouraging\ninterpretability. By bridging classical statistical modelling with the scale of\nmodern data and compute, HMoGs offer a practical approach to high-dimensional\nclustering that preserves statistical rigour, interpretability, and uncertainty\nquantification that is often missing from embedding-based, variational, and\nself-supervised methods.\n","authors":["Sacha Sokoloski","Philipp Berens"],"pdf_url":"https://arxiv.org/pdf/2206.04841v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.16299v2","updated":"2025-07-29T09:24:24Z","published":"2025-02-22T17:10:45Z","title":"A calibration test for evaluating set-based epistemic uncertainty\n  representations","summary":"  The accurate representation of epistemic uncertainty is a challenging yet\nessential task in machine learning. A widely used representation corresponds to\nconvex sets of probabilistic predictors, also known as credal sets. One popular\nway of constructing these credal sets is via ensembling or specialized\nsupervised learning methods, where the epistemic uncertainty can be quantified\nthrough measures such as the set size or the disagreement among members. In\nprinciple, these sets should contain the true data-generating distribution. As\na necessary condition for this validity, we adopt the strongest notion of\ncalibration as a proxy. Concretely, we propose a novel statistical test to\ndetermine whether there is a convex combination of the set's predictions that\nis calibrated in distribution. In contrast to previous methods, our framework\nallows the convex combination to be instance dependent, recognizing that\ndifferent ensemble members may be better calibrated in different regions of the\ninput space. Moreover, we learn this combination via proper scoring rules,\nwhich inherently optimize for calibration. Building on differentiable,\nkernel-based estimators of calibration errors, we introduce a nonparametric\ntesting procedure and demonstrate the benefits of capturing instance-level\nvariability on of synthetic and real-world experiments.\n","authors":["Mira Jürgens","Thomas Mortier","Eyke Hüllermeier","Viktor Bengs","Willem Waegeman"],"pdf_url":"https://arxiv.org/pdf/2502.16299v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.12422v2","updated":"2025-07-29T06:31:29Z","published":"2025-05-18T13:46:35Z","title":"Opening the Black Box of Local Projections","summary":"  Local projections (LPs) are widely used in empirical macroeconomics to\nestimate impulse responses to policy interventions. Yet, in many ways, they are\nblack boxes. It is often unclear what mechanism or historical episodes drive a\nparticular estimate. We introduce a new decomposition of LP estimates into the\nsum of contributions of historical events, which is the product, for each time\nstamp, of a weight and the realization of the response variable. In the least\nsquares case, we show that these weights admit two interpretations. First, they\nrepresent purified and standardized shocks. Second, they serve as proximity\nscores between the projected policy intervention and past interventions in the\nsample. Notably, this second interpretation extends naturally to machine\nlearning methods, many of which yield impulse responses that, while nonlinear\nin predictors, still aggregate past outcomes linearly via proximity-based\nweights. Applying this framework to shocks in monetary and fiscal policy,\nglobal temperature, and the excess bond premium, we find that easily\nidentifiable events-such as Nixon's interference with the Fed, stagflation,\nWorld War II, and the Mount Agung volcanic eruption-emerge as dominant drivers\nof often heavily concentrated impulse response estimates.\n","authors":["Philippe Goulet Coulombe","Karin Klieber"],"pdf_url":"https://arxiv.org/pdf/2505.12422v2.pdf","comment":"Keywords: Local projections, Impulse response functions, Monetary\n  policy, Inflation, Fiscal multipliers, Climate, Financial shocks,\n  Econometrics, Time Series, Macroeconomics"},{"id":"http://arxiv.org/abs/2507.01918v2","updated":"2025-07-29T04:20:02Z","published":"2025-07-02T17:27:29Z","title":"End-to-End Large Portfolio Optimization for Variance Minimization with\n  Neural Networks through Covariance Cleaning","summary":"  We develop a rotation-invariant neural network that provides the global\nminimum-variance portfolio by jointly learning how to lag-transform historical\nreturns and how to regularise both the eigenvalues and the marginal\nvolatilities of large equity covariance matrices. This explicit mathematical\nmapping offers clear interpretability of each module's role, so the model\ncannot be regarded as a pure black-box. The architecture mirrors the analytical\nform of the global minimum-variance solution yet remains agnostic to dimension,\nso a single model can be calibrated on panels of a few hundred stocks and\napplied, without retraining, to one thousand US equities-a cross-sectional jump\nthat demonstrates robust out-of-sample generalisation. The loss function is the\nfuture realized minimum portfolio variance and is optimized end-to-end on real\ndaily returns. In out-of-sample tests from January 2000 to December 2024 the\nestimator delivers systematically lower realised volatility, smaller maximum\ndrawdowns, and higher Sharpe ratios than the best analytical competitors,\nincluding state-of-the-art non-linear shrinkage. Furthermore, although the\nmodel is trained end-to-end to produce an unconstrained (long-short)\nminimum-variance portfolio, we show that its learned covariance representation\ncan be used in general optimizers under long-only constraints with virtually no\nloss in its performance advantage over competing estimators. These gains\npersist when the strategy is executed under a highly realistic implementation\nframework that models market orders at the auctions, empirical slippage,\nexchange fees, and financing charges for leverage, and they remain stable\nduring episodes of acute market stress.\n","authors":["Christian Bongiorno","Efstratios Manolakis","Rosario Nunzio Mantegna"],"pdf_url":"https://arxiv.org/pdf/2507.01918v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21486v1","updated":"2025-07-29T04:04:23Z","published":"2025-07-29T04:04:23Z","title":"Stochastic forest transition model dynamics and parameter estimation via\n  deep learning","summary":"  Forest transitions, characterized by dynamic shifts between forest,\nagricultural, and abandoned lands, are complex phenomena. This study developed\na stochastic differential equation model to capture the intricate dynamics of\nthese transitions. We established the existence of global positive solutions\nfor the model and conducted numerical analyses to assess the impact of model\nparameters on deforestation incentives. To address the challenge of parameter\nestimation, we proposed a novel deep learning approach that estimates all model\nparameters from a single sample containing time-series observations of forest\nand agricultural land proportions. This innovative approach enables us to\nunderstand forest transition dynamics and deforestation trends at any future\ntime.\n","authors":["Satoshi Kumabe","Tianyu Song","Ton Viet Ta"],"pdf_url":"https://arxiv.org/pdf/2507.21486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21479v1","updated":"2025-07-29T03:47:22Z","published":"2025-07-29T03:47:22Z","title":"Capacity-Constrained Continual Learning","summary":"  Any agents we can possibly build are subject to capacity constraints, as\nmemory and compute resources are inherently finite. However, comparatively\nlittle attention has been dedicated to understanding how agents with limited\ncapacity should allocate their resources for optimal performance. The goal of\nthis paper is to shed some light on this question by studying a simple yet\nrelevant continual learning problem: the capacity-constrained\nlinear-quadratic-Gaussian (LQG) sequential prediction problem. We derive a\nsolution to this problem under appropriate technical conditions. Moreover, for\nproblems that can be decomposed into a set of sub-problems, we also demonstrate\nhow to optimally allocate capacity across these sub-problems in the steady\nstate. We view the results of this paper as a first step in the systematic\ntheoretical study of learning under capacity constraints.\n","authors":["Zheng Wen","Doina Precup","Benjamin Van Roy","Satinder Singh"],"pdf_url":"https://arxiv.org/pdf/2507.21479v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21449v1","updated":"2025-07-29T02:38:57Z","published":"2025-07-29T02:38:57Z","title":"From Global to Local: A Scalable Benchmark for Local Posterior Sampling","summary":"  Degeneracy is an inherent feature of the loss landscape of neural networks,\nbut it is not well understood how stochastic gradient MCMC (SGMCMC) algorithms\ninteract with this degeneracy. In particular, current global convergence\nguarantees for common SGMCMC algorithms rely on assumptions which are likely\nincompatible with degenerate loss landscapes. In this paper, we argue that this\ngap requires a shift in focus from global to local posterior sampling, and, as\na first step, we introduce a novel scalable benchmark for evaluating the local\nsampling performance of SGMCMC algorithms. We evaluate a number of common\nalgorithms, and find that RMSProp-preconditioned SGLD is most effective at\nfaithfully representing the local geometry of the posterior distribution.\nAlthough we lack theoretical guarantees about global sampler convergence, our\nempirical results show that we are able to extract non-trivial local\ninformation in models with up to O(100M) parameters.\n","authors":["Rohan Hitchcock","Jesse Hoogland"],"pdf_url":"https://arxiv.org/pdf/2507.21449v1.pdf","comment":"25 pages"},{"id":"http://arxiv.org/abs/2405.07432v3","updated":"2025-07-29T02:34:46Z","published":"2024-05-13T02:18:49Z","title":"Nonparametric Sparse Online Learning of the Koopman Operator","summary":"  The Koopman operator provides a powerful framework for representing the\ndynamics of general nonlinear dynamical systems. However, existing data-driven\napproaches to learning the Koopman operator rely on batch data. In this work,\nwe present a sparse online learning algorithm that learns the Koopman operator\niteratively via stochastic approximation, with explicit control over model\ncomplexity and provable convergence guarantees. Specifically, we study the\nKoopman operator via its action on the reproducing kernel Hilbert space (RKHS),\nand address the mis-specified scenario where the dynamics may escape the chosen\nRKHS. In this mis-specified setting, we relate the Koopman operator to the\nconditional mean embeddings (CME) operator. We further establish both\nasymptotic and finite-time convergence guarantees for our learning algorithm in\nmis-specified setting, with trajectory-based sampling where the data arrive\nsequentially over time. Numerical experiments demonstrate the algorithm's\ncapability to learn unknown nonlinear dynamics.\n","authors":["Boya Hou","Sina Sanjari","Nathan Dahlin","Alec Koppel","Subhonmesh Bose"],"pdf_url":"https://arxiv.org/pdf/2405.07432v3.pdf","comment":"47 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.21434v1","updated":"2025-07-29T02:11:45Z","published":"2025-07-29T02:11:45Z","title":"Measuring Sample Quality with Copula Discrepancies","summary":"  The scalable Markov chain Monte Carlo (MCMC) algorithms that underpin modern\nBayesian machine learning, such as Stochastic Gradient Langevin Dynamics\n(SGLD), sacrifice asymptotic exactness for computational speed, creating a\ncritical diagnostic gap: traditional sample quality measures fail\ncatastrophically when applied to biased samplers. While powerful Stein-based\ndiagnostics can detect distributional mismatches, they provide no direct\nassessment of dependence structure, often the primary inferential target in\nmultivariate problems. We introduce the Copula Discrepancy (CD), a principled\nand computationally efficient diagnostic that leverages Sklar's theorem to\nisolate and quantify the fidelity of a sample's dependence structure\nindependent of its marginals. Our theoretical framework provides the first\nstructure-aware diagnostic specifically designed for the era of approximate\ninference. Empirically, we demonstrate that a moment-based CD dramatically\noutperforms standard diagnostics like effective sample size for hyperparameter\nselection in biased MCMC, correctly identifying optimal configurations where\ntraditional methods fail. Furthermore, our robust MLE-based variant can detect\nsubtle but critical mismatches in tail dependence that remain invisible to rank\ncorrelation-based approaches, distinguishing between samples with identical\nKendall's tau but fundamentally different extreme-event behavior. With\ncomputational overhead orders of magnitude lower than existing Stein\ndiscrepancies, the CD provides both immediate practical value for MCMC\npractitioners and a theoretical foundation for the next generation of\nstructure-aware sample quality assessment.\n","authors":["Agnideep Aich","Ashit Baran Aich","Bruce Wade"],"pdf_url":"https://arxiv.org/pdf/2507.21434v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21429v1","updated":"2025-07-29T01:49:16Z","published":"2025-07-29T01:49:16Z","title":"From Sublinear to Linear: Fast Convergence in Deep Networks via Locally\n  Polyak-Lojasiewicz Regions","summary":"  The convergence of gradient descent (GD) on the non-convex loss landscapes of\ndeep neural networks (DNNs) presents a fundamental theoretical challenge. While\nrecent work has established that GD converges to a stationary point at a\nsublinear rate within locally quasi-convex regions (LQCRs), this fails to\nexplain the exponential convergence rates consistently observed in practice. In\nthis paper, we resolve this discrepancy by proving that under a mild assumption\non Neural Tangent Kernel (NTK) stability, these same regions satisfy a local\nPolyak-Lojasiewicz (PL) condition. We introduce the concept of a Locally\nPolyak-Lojasiewicz Region (LPLR), where the squared gradient norm lower-bounds\nthe suboptimality gap, prove that properly initialized finite-width networks\nadmit such regions around initialization, and establish that GD achieves linear\nconvergence within an LPLR, providing the first finite-width guarantee that\nmatches empirically observed rates. We validate our theory across diverse\nsettings, from controlled experiments on fully-connected networks to modern\nResNet architectures trained with stochastic methods, demonstrating that LPLR\nstructure emerges robustly in practical deep learning scenarios. By rigorously\nconnecting local landscape geometry to fast optimization through the NTK\nframework, our work provides a definitive theoretical explanation for the\nremarkable efficiency of gradient-based optimization in deep learning.\n","authors":["Agnideep Aich","Ashit Baran Aich","Bruce Wade"],"pdf_url":"https://arxiv.org/pdf/2507.21429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03616v3","updated":"2025-07-29T01:49:06Z","published":"2024-06-05T20:23:52Z","title":"BEACON: A Bayesian Optimization Strategy for Novelty Search in Expensive\n  Black-Box Systems","summary":"  Novelty search (NS) refers to a class of exploration algorithms that seek to\nuncover diverse system behaviors through simulations or experiments. Such\ndiversity is central to many AI-driven discovery and design tasks, including\nmaterial and drug development, neural architecture search, and reinforcement\nlearning. However, existing NS methods typically rely on evolutionary\nstrategies and other meta-heuristics that require dense sampling of the input\nspace, making them impractical for expensive black-box systems. In this work,\nwe introduce BEACON, a sample-efficient, Bayesian optimization-inspired\napproach to NS that is tailored for settings where the input-to-behavior\nrelationship is opaque and costly to evaluate. BEACON models this mapping using\nmulti-output Gaussian processes (MOGPs) and selects new inputs by maximizing a\nnovelty metric computed from posterior samples of the MOGP, effectively\nbalancing the exploration-exploitation trade-off. By leveraging recent advances\nin posterior sampling and high-dimensional GP modeling, our method remains\nscalable to large input spaces and datasets. We evaluate BEACON across ten\nsynthetic benchmarks and eight real-world tasks, including the design of\ndiverse materials for clean energy applications. Our results show that BEACON\nsignificantly outperforms existing NS baselines, consistently discovering a\nbroader set of behaviors under tight evaluation budgets.\n","authors":["Wei-Ting Tang","Ankush Chakrabarty","Joel A. Paulson"],"pdf_url":"https://arxiv.org/pdf/2406.03616v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.12225v2","updated":"2025-07-29T01:42:42Z","published":"2025-05-18T04:00:35Z","title":"Mining Intrinsic Rewards from LLM Hidden States for Efficient Best-of-N\n  Sampling","summary":"  Enhancing Large Language Model (LLM)'s performance with best-of-N sampling is\neffective and has attracted significant attention. However, it is\ncomputationally prohibitive due to massive, data-hungry text-based reward\nmodels. By changing the data source from text to hidden states, we introduce\nSWIFT (Simple Weighted Intrinsic Feedback Technique), a novel, lightweight\ntechnique that leverages the rich information embedded in LLM hidden states to\naddress these issues, which operates on token-level and consists of only linear\nlayers. Extensive experiments show that SWIFT outperforms baselines with less\nthan 0.005% of the parameters of baselines, requiring only a few samples for\ntraining, demonstrating significant efficiency improvement. SWIFT's robust\nscalability, applicability to some closed-source models via logits, and ability\nto be combined with traditional reward models to yield further performance\ngains underscore its practical value.\n","authors":["Jizhou Guo","Zhaomin Wu","Hanchen Yang","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2505.12225v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11673v2","updated":"2025-07-29T01:40:18Z","published":"2025-01-20T18:55:51Z","title":"Randomized Kaczmarz Methods with Beyond-Krylov Convergence","summary":"  Randomized Kaczmarz methods form a family of linear system solvers which\nconverge by repeatedly projecting their iterates onto randomly sampled\nequations. While effective in some contexts, such as highly over-determined\nleast squares, Kaczmarz methods are traditionally deemed secondary to Krylov\nsubspace methods, since this latter family of solvers can exploit outliers in\nthe input's singular value distribution to attain fast convergence on\nill-conditioned systems.\n  In this paper, we introduce Kaczmarz++, an accelerated randomized block\nKaczmarz algorithm that exploits outlying singular values in the input to\nattain a fast Krylov-style convergence. Moreover, we show that Kaczmarz++\ncaptures large outlying singular values provably faster than popular Krylov\nmethods, for both over- and under-determined systems. We also develop an\noptimized variant for positive semidefinite systems, called CD++, demonstrating\nempirically that it is competitive in arithmetic operations with both CG and\nGMRES on a collection of benchmark problems. To attain these results, we\nintroduce several novel algorithmic improvements to the Kaczmarz framework,\nincluding adaptive momentum acceleration, Tikhonov-regularized projections, and\na memoization scheme for reusing information from previously sampled equation\nblocks.\n","authors":["Michał Dereziński","Deanna Needell","Elizaveta Rebrova","Jiaming Yang"],"pdf_url":"https://arxiv.org/pdf/2501.11673v2.pdf","comment":"SIMAX"},{"id":"http://arxiv.org/abs/2507.14795v3","updated":"2025-07-29T01:17:07Z","published":"2025-07-20T02:55:15Z","title":"A DPI-PAC-Bayesian Framework for Generalization Bounds","summary":"  We develop a unified Data Processing Inequality PAC-Bayesian framework --\nabbreviated DPI-PAC-Bayesian -- for deriving generalization error bounds in the\nsupervised learning setting. By embedding the Data Processing Inequality (DPI)\ninto the change-of-measure technique, we obtain explicit bounds on the binary\nKullback-Leibler generalization gap for both R\\'enyi divergence and any\n$f$-divergence measured between a data-independent prior distribution and an\nalgorithm-dependent posterior distribution. We present three bounds derived\nunder our framework using R\\'enyi, Hellinger \\(p\\) and Chi-Squared divergences.\nAdditionally, our framework also demonstrates a close connection with other\nwell-known bounds. When the prior distribution is chosen to be uniform, our\nbounds recover the classical Occam's Razor bound and, crucially, eliminate the\nextraneous \\(\\log(2\\sqrt{n})/n\\) slack present in the PAC-Bayes bound, thereby\nachieving tighter results. The framework thus bridges data-processing and\nPAC-Bayesian perspectives, providing a flexible, information-theoretic tool to\nconstruct generalization guarantees.\n","authors":["Muhan Guan","Farhad Farokhi","Jingge Zhu"],"pdf_url":"https://arxiv.org/pdf/2507.14795v3.pdf","comment":"7 pages, 1 figures, the final version with full proofs"},{"id":"http://arxiv.org/abs/2503.22745v2","updated":"2025-07-29T20:14:47Z","published":"2025-03-26T21:54:19Z","title":"Graph-Based Uncertainty-Aware Self-Training with Stochastic Node\n  Labeling","summary":"  Self-training has become a popular semi-supervised learning technique for\nleveraging unlabeled data. However, the over-confidence of pseudo-labels\nremains a key challenge. In this paper, we propose a novel \\emph{graph-based\nuncertainty-aware self-training} (GUST) framework to combat over-confidence in\nnode classification. Drawing inspiration from the uncertainty integration idea\nintroduced by Wang \\emph{et al.}~\\cite{wang2024uncertainty}, our method largely\ndiverges from previous self-training approaches by focusing on \\emph{stochastic\nnode labeling} grounded in the graph topology. Specifically, we deploy a\nBayesian-inspired module to estimate node-level uncertainty, incorporate these\nestimates into the pseudo-label generation process via an\nexpectation-maximization (EM)-like step, and iteratively update both node\nembeddings and adjacency-based transformations. Experimental results on several\nbenchmark graph datasets demonstrate that our GUST framework achieves\nstate-of-the-art performance, especially in settings where labeled data is\nextremely sparse.\n","authors":["Tom Liu","Anna Wu","Chao Li"],"pdf_url":"https://arxiv.org/pdf/2503.22745v2.pdf","comment":"arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship and affiliation"},{"id":"http://arxiv.org/abs/2503.22744v2","updated":"2025-07-29T20:14:32Z","published":"2025-03-26T21:52:21Z","title":"Uncertainty-Aware Graph Self-Training with Expectation-Maximization\n  Regularization","summary":"  In this paper, we propose a novel \\emph{uncertainty-aware graph\nself-training} approach for semi-supervised node classification. Our method\nintroduces an Expectation-Maximization (EM) regularization scheme to\nincorporate an uncertainty mechanism during pseudo-label generation and model\nretraining. Unlike conventional graph self-training pipelines that rely on\nfixed pseudo-labels, our approach iteratively refines label confidences with an\nEM-inspired uncertainty measure. This ensures that the predictive model focuses\non reliable graph regions while gradually incorporating ambiguous nodes.\nInspired by prior work on uncertainty-aware self-training\ntechniques~\\cite{wang2024uncertainty}, our framework is designed to handle\nnoisy graph structures and feature spaces more effectively. Through extensive\nexperiments on several benchmark graph datasets, we demonstrate that our method\noutperforms strong baselines by a margin of up to 2.5\\% in accuracy while\nmaintaining lower variance in performance across multiple runs.\n","authors":["Emily Wang","Michael Chen","Chao Li"],"pdf_url":"https://arxiv.org/pdf/2503.22744v2.pdf","comment":"arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship and affiliation"},{"id":"http://arxiv.org/abs/2507.22207v1","updated":"2025-07-29T20:11:02Z","published":"2025-07-29T20:11:02Z","title":"Better Together: Cross and Joint Covariances Enhance Signal\n  Detectability in Undersampled Data","summary":"  Many data-science applications involve detecting a shared signal between two\nhigh-dimensional variables. Using random matrix theory methods, we determine\nwhen such signal can be detected and reconstructed from sample correlations,\ndespite the background of sampling noise induced correlations. We consider\nthree different covariance matrices constructed from two high-dimensional\nvariables: their individual self covariance, their cross covariance, and the\nself covariance of the concatenated (joint) variable, which incorporates the\nself and the cross correlation blocks. We observe the expected Baik, Ben Arous,\nand P\\'ech\\'e detectability phase transition in all these covariance matrices,\nand we show that joint and cross covariance matrices always reconstruct the\nshared signal earlier than the self covariances. Whether the joint or the cross\napproach is better depends on the mismatch of dimensionalities between the\nvariables. We discuss what these observations mean for choosing the right\nmethod for detecting linear correlations in data and how these findings may\ngeneralize to nonlinear statistical dependencies.\n","authors":["Arabind Swain","Sean Alexander Ridout","Ilya Nemenman"],"pdf_url":"https://arxiv.org/pdf/2507.22207v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22170v1","updated":"2025-07-29T19:03:01Z","published":"2025-07-29T19:03:01Z","title":"Stacked SVD or SVD stacked? A Random Matrix Theory perspective on data\n  integration","summary":"  Modern data analysis increasingly requires identifying shared latent\nstructure across multiple high-dimensional datasets. A commonly used model\nassumes that the data matrices are noisy observations of low-rank matrices with\na shared singular subspace. In this case, two primary methods have emerged for\nestimating this shared structure, which vary in how they integrate information\nacross datasets. The first approach, termed Stack-SVD, concatenates all the\ndatasets, and then performs a singular value decomposition (SVD). The second\napproach, termed SVD-Stack, first performs an SVD separately for each dataset,\nthen aggregates the top singular vectors across these datasets, and finally\ncomputes a consensus amongst them. While these methods are widely used, they\nhave not been rigorously studied in the proportional asymptotic regime, which\nis of great practical relevance in today's world of increasing data size and\ndimensionality. This lack of theoretical understanding has led to uncertainty\nabout which method to choose and limited the ability to fully exploit their\npotential. To address these challenges, we derive exact expressions for the\nasymptotic performance and phase transitions of these two methods and develop\noptimal weighting schemes to further improve both methods. Our analysis reveals\nthat while neither method uniformly dominates the other in the unweighted case,\noptimally weighted Stack-SVD dominates optimally weighted SVD-Stack. We extend\nour analysis to accommodate multiple shared components, and provide practical\nalgorithms for estimating optimal weights from data, offering theoretical\nguidance for method selection in practical data integration problems. Extensive\nnumerical simulations and semi-synthetic experiments on genomic data\ncorroborate our theoretical findings.\n","authors":["Tavor Z. Baharav","Phillip B. Nicol","Rafael A. Irizarry","Rong Ma"],"pdf_url":"https://arxiv.org/pdf/2507.22170v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.15112v2","updated":"2025-07-29T18:47:25Z","published":"2025-07-20T20:21:23Z","title":"Distributional Unlearning: Forgetting Distributions, Not Just Samples","summary":"  Machine unlearning seeks to remove unwanted information from trained models,\ninitially at the individual-sample level, but increasingly at the level of\nentire sub-populations. In many deployments, models must delete whole topical\ndomains to satisfy privacy, legal, or quality requirements, e.g., removing\nseveral users' posts under GDPR or copyrighted web content. Existing unlearning\ntools remain largely sample-oriented, and straightforward point deletion often\nleaves enough residual signal for downstream learners to recover the unwanted\ndomain. We introduce distributional unlearning, a data-centric, model-agnostic\nframework that asks: Given examples from an unwanted distribution and a\nretained distribution, what is the smallest set of points whose removal makes\nthe edited dataset far from the unwanted domain yet close to the retained one?\nUsing Kullback-Leibler divergence to quantify removal and preservation, we\nderive the exact Pareto frontier in the Gaussian case and prove that any model\nretrained on the edited data incurs log-loss shifts bounded by the divergence\nthresholds. We propose a simple distance-based selection rule satisfying these\nconstraints with a quadratic reduction in deletion budget compared to random\nremoval. Experiments on synthetic Gaussians, Jigsaw Toxic Comments, SMS spam,\nand CIFAR-10 show 15-72% fewer deletions than random, with negligible impact on\nretained performance.\n","authors":["Youssef Allouah","Rachid Guerraoui","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2507.15112v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08030v2","updated":"2025-07-29T18:17:10Z","published":"2025-06-02T03:20:12Z","title":"MOSS: Multi-Objective Optimization for Stable Rule Sets","summary":"  We present MOSS, a multi-objective optimization framework for constructing\nstable sets of decision rules. MOSS incorporates three important criteria for\ninterpretability: sparsity, accuracy, and stability, into a single\nmulti-objective optimization framework. Importantly, MOSS allows a practitioner\nto rapidly evaluate the trade-off between accuracy and stability in sparse rule\nsets in order to select an appropriate model. We develop a specialized cutting\nplane algorithm in our framework to rapidly compute the Pareto frontier between\nthese two objectives, and our algorithm scales to problem instances beyond the\ncapabilities of commercial optimization solvers. Our experiments show that MOSS\noutperforms state-of-the-art rule ensembles in terms of both predictive\nperformance and stability.\n","authors":["Brian Liu","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2506.08030v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22095v1","updated":"2025-07-29T15:54:34Z","published":"2025-07-29T15:54:34Z","title":"Simulating Posterior Bayesian Neural Networks with Dependent Weights","summary":"  In this paper we consider posterior Bayesian fully connected and feedforward\ndeep neural networks with dependent weights. Particularly, if the likelihood is\nGaussian, we identify the distribution of the wide width limit and provide an\nalgorithm to sample from the network. In the shallow case we explicitly compute\nthe distribution of the output, proving that it is a Gaussian mixture. All the\ntheoretical results are numerically validated.\n","authors":["Nicola Apollonio","Giovanni Franzina","Giovanni Luca Torrisi"],"pdf_url":"https://arxiv.org/pdf/2507.22095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22256v1","updated":"2025-07-29T22:10:50Z","published":"2025-07-29T22:10:50Z","title":"Spatiodynamic inference using vision-based generative modelling","summary":"  Biological systems commonly exhibit complex spatiotemporal patterns whose\nunderlying generative mechanisms pose a significant analytical challenge.\nTraditional approaches to spatiodynamic inference rely on dimensionality\nreduction through summary statistics, which sacrifice complexity and\ninterdependent structure intrinsic to these data in favor of parameter\nidentifiability. This imposes a fundamental constraint on reliably extracting\nmechanistic insights from spatiotemporal data, highlighting the need for\nanalytical frameworks that preserve the full richness of these dynamical\nsystems. To address this, we developed a simulation-based inference framework\nthat employs vision transformer-driven variational encoding to generate compact\nrepresentations of the data, exploiting the inherent contextual dependencies.\nThese representations are subsequently integrated into a likelihood-free\nBayesian approach for parameter inference. The central idea is to construct a\nfine-grained, structured mesh of latent representations from simulated dynamics\nthrough systematic exploration of the parameter space. This encoded mesh of\nlatent embeddings then serves as a reference map for retrieving parameter\nvalues that correspond to observed data. By integrating generative modeling\nwith Bayesian principles, our approach provides a unified inference framework\nto identify both spatial and temporal patterns that manifest in multivariate\ndynamical systems.\n","authors":["Jun Won Park","Kangyu Zhao","Sanket Rane"],"pdf_url":"https://arxiv.org/pdf/2507.22256v1.pdf","comment":null}],"Computation":[{"id":"http://arxiv.org/abs/2502.03458v3","updated":"2025-07-29T17:44:50Z","published":"2025-02-05T18:55:54Z","title":"The Performance Of The Unadjusted Langevin Algorithm Without Smoothness\n  Assumptions","summary":"  In this article, we study the problem of sampling from distributions whose\ndensities are not necessarily smooth nor logconcave. We propose a simple\nLangevin-based algorithm that does not rely on popular but computationally\nchallenging techniques, such as the Moreau-Yosida envelope or Gaussian\nsmoothing, and show consequently that the performance of samplers like ULA does\nnot necessarily degenerate arbitrarily with low regularity. In particular, we\nshow that the Lipschitz or H\\\"older continuity assumption can be replaced by a\ngeometric one-sided Lipschitz condition that allows even for discontinuous\nlog-gradients. We derive non-asymptotic guarantees for the convergence of the\nalgorithm to the target distribution in Wasserstein distances. Non-asymptotic\nbounds are also provided for the performance of the algorithm as an optimizer,\nspecifically for the solution of associated excess risk optimization problems.\n","authors":["Tim Johnston","Iosif Lytras","Nikolaos Makras","Sotirios Sabanis"],"pdf_url":"https://arxiv.org/pdf/2502.03458v3.pdf","comment":"24pages"},{"id":"http://arxiv.org/abs/2507.22038v1","updated":"2025-07-29T17:40:23Z","published":"2025-07-29T17:40:23Z","title":"Sample Complexity of Branch-length Estimation by Maximum Likelihood","summary":"  We consider the branch-length estimation problem on a bifurcating tree: a\ncharacter evolves along the edges of a binary tree according to a two-state\nsymmetric Markov process, and we seek to recover the edge transition\nprobabilities from repeated observations at the leaves. This problem arises in\nphylogenetics, and is related to latent tree graphical model inference. In\ngeneral, the log-likelihood function is non-concave and may admit many critical\npoints. Nevertheless, simple coordinate maximization has been known to perform\nwell in practice, defying the complexity of the likelihood landscape. In this\nwork, we provide the first theoretical guarantee as to why this might be the\ncase. We show that deep inside the Kesten-Stigum reconstruction regime,\nprovided with polynomially many $m$ samples (assuming the tree is balanced),\nthere exists a universal parameter regime (independent of the size of the tree)\nwhere the log-likelihood function is strongly concave and smooth with high\nprobability. On this high-probability likelihood landscape event, we show that\nthe standard coordinate maximization algorithm converges exponentially fast to\nthe maximum likelihood estimator, which is within $O(1/\\sqrt{m})$ from the true\nparameter, provided a sufficiently close initial point.\n","authors":["David Clancy Jr.","Hanbaek Lyu","Sebastien Roch"],"pdf_url":"https://arxiv.org/pdf/2507.22038v1.pdf","comment":"22 pages, 2 figures"},{"id":"http://arxiv.org/abs/2507.07660v3","updated":"2025-07-29T17:10:17Z","published":"2025-07-10T11:36:23Z","title":"Scalable Signed Exponential Random Graph Models under Local Dependence","summary":"  Traditional network analysis focuses on binary edges, while real-world\nrelationships are more nuanced, encompassing cooperation, neutrality, and\nconflict. The rise of negative edges in social media discussions spurred\ninterest in analyzing signed interactions, especially in polarized debates.\nHowever, the vast data generated by digital networks presents challenges for\ntraditional methods like Stochastic Block Models (SBM) and Exponential Family\nRandom Graph Models (ERGM), particularly due to the homogeneity assumption and\nglobal dependence, which become increasingly unrealistic as network size grows.\nTo address this, we propose a novel method that combines the strengths of SBM\nand ERGM while mitigating their weaknesses by incorporating local dependence\nbased on non-overlapping blocks. Our approach involves a two-step process:\nfirst, decomposing the network into sub-networks using SBM approximation, and\nthen estimating parameters using ERGM methods. We validate our method on large\nsynthetic networks and apply it to a signed Wikipedia network of thousands of\neditors. Through the use of local dependence, we find patterns consistent with\nstructural balance theory.\n","authors":["Marc Schalberger","Cornelius Fritz"],"pdf_url":"https://arxiv.org/pdf/2507.07660v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.20802v2","updated":"2025-07-29T11:54:33Z","published":"2024-12-30T08:49:41Z","title":"Robust Matrix Completion for Discrete Rating-Scale Data: Coping with\n  Fake Profiles in Recommender Systems","summary":"  Recommender systems are essential tools in the digital landscape for\nconnecting users with content that more closely aligns with their preferences.\nMatrix completion is a widely used statistical framework for such systems,\naiming to predict a user's preferences for items they have not yet rated by\nleveraging the observed ratings in a partially filled user-item rating matrix.\nRealistic applications of matrix completion in recommender systems must address\nseveral challenges that are too often neglected: (i) the discrete nature of\nrating-scale data, (ii) the presence of malicious users who manipulate the\nsystem to their advantage through the creation of fake profiles, and (iii)\nmissing-not-at-random patterns, where users are more likely to rate items they\nexpect to enjoy. Our goal in this paper is twofold. First, we propose a novel\nmatrix completion method, robust discrete matrix completion (RDMC), designed\nspecifically to handle the discrete nature of sparse rating-scale data and to\nremain reliable in the presence of adversarial manipulation. We evaluate RDMC\nthrough carefully designed experiments and realistic case studies. Our work\ntherefore, secondly, offers a statistically-sound blueprint for future studies\non how to evaluate matrix completion methods for recommender systems under\nrealistic scenarios.\n","authors":["Aurore Archimbaud","Andreas Alfons","Ines Wilms"],"pdf_url":"https://arxiv.org/pdf/2412.20802v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.20152v6","updated":"2025-07-29T18:00:45Z","published":"2024-03-29T12:48:33Z","title":"Combinatorial Potential of Random Equations with Mixture Models:\n  Modeling and Simulation","summary":"  The goal of this paper is to demonstrate the general modeling and practical\nsimulation of random equations with mixture model parameter random variables.\nRandom equations, understood as stationary (non-dynamical) equations with\nparameters as random variables, have a long history and a broad range of\napplications. The specific novelty of this explorative study lies on the\ndemonstration of the combinatorial complexity of these equations and their\nsolutions with mixture model parameters. In a Bayesian argumentation framework,\nwe derive a likelihood function and posterior density of approximate solutions\nwhile avoiding significant restrictions about the type of nonlinearity of the\nequation or mixture models, and demonstrate their numerically efficient\nimplementation for the applied researcher. In the results section, we are\nspecifically focusing on expressive example simulations showcasing the\ncombinatorial potential of random linear equation systems and nonlinear systems\nof random conic section equations. Introductory applications to portfolio\noptimization, stochastic control and random matrix theory are provided in order\nto show the wide applicability of the presented methodology.\n","authors":["Wolfgang Hoegele"],"pdf_url":"https://arxiv.org/pdf/2403.20152v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2111.06871v3","updated":"2025-07-29T05:08:54Z","published":"2021-11-12T18:48:36Z","title":"Sampling from high-dimensional, multimodal distributions using\n  automatically tuned, tempered Hamiltonian Monte Carlo","summary":"  Hamiltonian Monte Carlo (HMC) is widely used for sampling from high\ndimensional target distributions with densities known up to proportionality.\nWhile HMC exhibits favorable scaling properties in high dimensions, it\nstruggles with strongly multimodal distributions. Tempering methods are\ncommonly used to address multimodality, but they can be difficult to tune,\nespecially in high dimensional settings. In this study, we propose a method\nthat combines tempering with HMC to enable efficient sampling from high\ndimensional, strongly multimodal distributions. Our approach simulates the\ndynamics of a time-varying Hamiltonian in which the temperature increases and\nthen decreases over time. In the first phase, the simulated trajectory\ngradually explores low-density regions farther from the mode; the second phase\nguides it back toward a local mode. We develop efficient tuning strategies\nbased on a time-scale transformation under which the Hamiltonian becomes\napproximately stationary. This leads to a tempered Hamiltonian Monte Carlo\n(THMC) algorithm with automatic tuning. We demonstrate numerically that our\nmethod scales more effectively with dimension than adaptive parallel tempering\nand tempered sequential Monte Carlo. Finally, we apply our THMC to sample from\nstrongly multimodal posterior distributions arising in Bayesian inference.\n","authors":["Joonha Park"],"pdf_url":"https://arxiv.org/pdf/2111.06871v3.pdf","comment":null}]},"2025-07-30T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2507.22887v1","updated":"2025-07-30T17:59:46Z","published":"2025-07-30T17:59:46Z","title":"Where to show Demos in Your Prompt: A Positional Bias of In-Context\n  Learning","summary":"  In-context learning (ICL) is a critical emerging capability of large language\nmodels (LLMs), enabling few-shot learning during inference by including a few\ndemonstrations (demos) in the prompt. However, it has been found that ICL's\nperformance can be sensitive to the choices of demos and their order. This\npaper investigates an unexplored new positional bias of ICL for the first time:\nwe observe that the predictions and accuracy can drift drastically when the\npositions of demos, the system prompt, and the user message in LLM input are\nvaried. We refer to this bias as DEMOS' POSITION IN PROMPT (DPP) bias. We\ndesign a systematic evaluation pipeline to study this type of positional bias\nacross classification, question answering, summarization, and reasoning tasks.\nWe introduce two metrics, ACCURACY-CHANGE and PREDICTION-CHANGE, to quantify\nnet gains and output volatility induced by changes in the demos' position.\nExtensive experiments on ten LLMs from four open-source model families (QWEN,\nLLAMA3, MISTRAL, COHERE) verify that the bias significantly affects their\naccuracy and predictions: placing demos at the start of the prompt yields the\nmost stable and accurate outputs with gains of up to +6 points. In contrast,\nplacing demos at the end of the user message flips over 30\\% of predictions\nwithout improving correctness on QA tasks. Smaller models are most affected by\nthis sensitivity, though even large models remain marginally affected on\ncomplex tasks.\n","authors":["Kwesi Cobbina","Tianyi Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.22887v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22879v1","updated":"2025-07-30T17:55:06Z","published":"2025-07-30T17:55:06Z","title":"RecGPT Technical Report","summary":"  Recommender systems are among the most impactful applications of artificial\nintelligence, serving as critical infrastructure connecting users, merchants,\nand platforms. However, most current industrial systems remain heavily reliant\non historical co-occurrence patterns and log-fitting objectives, i.e.,\noptimizing for past user interactions without explicitly modeling user intent.\nThis log-fitting approach often leads to overfitting to narrow historical\npreferences, failing to capture users' evolving and latent interests. As a\nresult, it reinforces filter bubbles and long-tail phenomena, ultimately\nharming user experience and threatening the sustainability of the whole\nrecommendation ecosystem.\n  To address these challenges, we rethink the overall design paradigm of\nrecommender systems and propose RecGPT, a next-generation framework that places\nuser intent at the center of the recommendation pipeline. By integrating large\nlanguage models (LLMs) into key stages of user interest mining, item retrieval,\nand explanation generation, RecGPT transforms log-fitting recommendation into\nan intent-centric process. To effectively align general-purpose LLMs to the\nabove domain-specific recommendation tasks at scale, RecGPT incorporates a\nmulti-stage training paradigm, which integrates reasoning-enhanced\npre-alignment and self-training evolution, guided by a Human-LLM cooperative\njudge system. Currently, RecGPT has been fully deployed on the Taobao App.\nOnline experiments demonstrate that RecGPT achieves consistent performance\ngains across stakeholders: users benefit from increased content diversity and\nsatisfaction, merchants and the platform gain greater exposure and conversions.\nThese comprehensive improvement results across all stakeholders validates that\nLLM-driven, intent-centric design can foster a more sustainable and mutually\nbeneficial recommendation ecosystem.\n","authors":["Chao Yi","Dian Chen","Gaoyang Guo","Jiakai Tang","Jian Wu","Jing Yu","Sunhao Dai","Wen Chen","Wenjun Yang","Yuning Jiang","Zhujin Gao","Bo Zheng","Chi Li","Dimin Wang","Dixuan Wang","Fan Li","Fan Zhang","Haibin Chen","Haozhuang Liu","Jialin Zhu","Jiamang Wang","Jiawei Wu","Jin Cui","Ju Huang","Kai Zhang","Kan Liu","Lang Tian","Liang Rao","Longbin Li","Lulu Zhao","Mao Zhang","Na He","Peiyang Wang","Qiqi Huang","Tao Luo","Wenbo Su","Xiaoxiao He","Xin Tong","Xu Chen","Xunke Xi","Yang Li","Yaxuan Wu","Yeqiu Yang","Yi Hu","Yinnan Song","Yuchen Li","Yujie Luo","Yujin Yuan","Yuliang Yan","Zhengyang Wang","Zhibo Xiao","Zhixin Ma","Zile Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.22879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22878v1","updated":"2025-07-30T17:54:38Z","published":"2025-07-30T17:54:38Z","title":"GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for\n  Multiresolution Power Outage Analysis","summary":"  Detecting, analyzing, and predicting power outages is crucial for grid risk\nassessment and disaster mitigation. Numerous outages occur each year,\nexacerbated by extreme weather events such as hurricanes. Existing outage data\nare typically reported at the county level, limiting their spatial resolution\nand making it difficult to capture localized patterns. However, it offers\nexcellent temporal granularity. In contrast, nighttime light satellite image\ndata provides significantly higher spatial resolution and enables a more\ncomprehensive spatial depiction of outages, enhancing the accuracy of assessing\nthe geographic extent and severity of power loss after disaster events.\nHowever, these satellite data are only available on a daily basis. Integrating\nspatiotemporal visual and time-series data sources into a unified knowledge\nrepresentation can substantially improve power outage detection, analysis, and\npredictive reasoning. In this paper, we propose GeoOutageKG, a multimodal\nknowledge graph that integrates diverse data sources, including nighttime light\nsatellite image data, high-resolution spatiotemporal power outage maps, and\ncounty-level timeseries outage reports in the U.S. We describe our method for\nconstructing GeoOutageKG by aligning source data with a developed ontology,\nGeoOutageOnto. Currently, GeoOutageKG includes over 10.6 million individual\noutage records spanning from 2014 to 2024, 300,000 NTL images spanning from\n2012 to 2024, and 15,000 outage maps. GeoOutageKG is a novel, modular and\nreusable semantic resource that enables robust multimodal data integration. We\ndemonstrate its use through multiresolution analysis of geospatiotemporal power\noutages.\n","authors":["Ethan Frakes","Yinghui Wu","Roger H. French","Mengjie Li"],"pdf_url":"https://arxiv.org/pdf/2507.22878v1.pdf","comment":"Accepted to the 24th International Semantic Web Conference Resource\n  Track (ISWC 2025)"},{"id":"http://arxiv.org/abs/2507.20930v2","updated":"2025-07-30T17:19:41Z","published":"2025-07-28T15:41:53Z","title":"FRED: Financial Retrieval-Enhanced Detection and Editing of\n  Hallucinations in Language Models","summary":"  Hallucinations in large language models pose a critical challenge for\napplications requiring factual reliability, particularly in high-stakes domains\nsuch as finance. This work presents an effective approach for detecting and\nediting factually incorrect content in model-generated responses based on the\nprovided context. Given a user-defined domain-specific error taxonomy, we\nconstruct a synthetic dataset by inserting tagged errors into financial\nquestion-answering corpora and then fine-tune four language models, Phi-4,\nPhi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual\ninaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%\nimprovement in binary F1 score and a 30% gain in overall detection performance\ncompared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having\nonly 4 billion parameters, maintains competitive performance with just a 2%\ndrop in binary detection and a 0.1% decline in overall detection compared to\nOpenAI-o3. Our work provides a practical solution for detecting and editing\nfactual inconsistencies in financial text generation while introducing a\ngeneralizable framework that can enhance the trustworthiness and alignment of\nlarge language models across diverse applications beyond finance. Our code and\ndata are available at https://github.com/pegasi-ai/shield.\n","authors":["Likun Tan","Kuan-Wei Huang","Kevin Wu"],"pdf_url":"https://arxiv.org/pdf/2507.20930v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.14820v2","updated":"2025-07-30T17:18:33Z","published":"2024-09-23T08:52:09Z","title":"Past Meets Present: Creating Historical Analogy with Large Language\n  Models","summary":"  Historical analogies, which compare known past events with contemporary but\nunfamiliar events, are important abilities that help people make decisions and\nunderstand the world. However, research in applied history suggests that people\nhave difficulty finding appropriate analogies. And previous studies in the AI\ncommunity have also overlooked historical analogies. To fill this gap, in this\npaper, we focus on the historical analogy acquisition task, which aims to\nacquire analogous historical events for a given event. We explore retrieval and\ngeneration methods for acquiring historical analogies based on different large\nlanguage models (LLMs). Furthermore, we propose a self-reflection method to\nmitigate hallucinations and stereotypes when LLMs generate historical\nanalogies. Through human evaluations and our specially designed automatic\nmulti-dimensional assessment, we find that LLMs generally have a good potential\nfor historical analogies. And the performance of the models can be further\nimproved by using our self-reflection method.\n","authors":["Nianqi Li","Siyu Yuan","Jiangjie Chen","Jiaqing Liang","Feng Wei","Zujie Liang","Deqing Yang","Yanghua Xiao"],"pdf_url":"https://arxiv.org/pdf/2409.14820v2.pdf","comment":"Accepted to ACL 2025 (Outstanding Paper Award)"},{"id":"http://arxiv.org/abs/2507.22847v1","updated":"2025-07-30T17:03:59Z","published":"2025-07-30T17:03:59Z","title":"The Incomplete Bridge: How AI Research (Mis)Engages with Psychology","summary":"  Social sciences have accumulated a rich body of theories and methodologies\nfor investigating the human mind and behaviors, while offering valuable\ninsights into the design and understanding of Artificial Intelligence (AI)\nsystems. Focusing on psychology as a prominent case, this study explores the\ninterdisciplinary synergy between AI and the field by analyzing 1,006\nLLM-related papers published in premier AI venues between 2023 and 2025, along\nwith the 2,544 psychology publications they cite. Through our analysis, we\nidentify key patterns of interdisciplinary integration, locate the psychology\ndomains most frequently referenced, and highlight areas that remain\nunderexplored. We further examine how psychology theories/frameworks are\noperationalized and interpreted, identify common types of misapplication, and\noffer guidance for more effective incorporation. Our work provides a\ncomprehensive map of interdisciplinary engagement between AI and psychology,\nthereby facilitating deeper collaboration and advancing AI systems.\n","authors":["Han Jiang","Pengda Wang","Xiaoyuan Yi","Xing Xie","Ziang Xiao"],"pdf_url":"https://arxiv.org/pdf/2507.22847v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.20992v2","updated":"2025-07-30T17:02:04Z","published":"2025-03-26T21:11:17Z","title":"ReverBERT: A State Space Model for Efficient Text-Driven Speech Style\n  Transfer","summary":"  Text-driven speech style transfer aims to mold the intonation, pace, and\ntimbre of a spoken utterance to match stylistic cues from text descriptions.\nWhile existing methods leverage large-scale neural architectures or pre-trained\nlanguage models, the computational costs often remain high. In this paper, we\npresent \\emph{ReverBERT}, an efficient framework for text-driven speech style\ntransfer that draws inspiration from a state space model (SSM) paradigm,\nloosely motivated by the image-based method of Wang and\nLiu~\\cite{wang2024stylemamba}. Unlike image domain techniques, our method\noperates in the speech space and integrates a discrete Fourier transform of\nlatent speech features to enable smooth and continuous style modulation. We\nalso propose a novel \\emph{Transformer-based SSM} layer for bridging textual\nstyle descriptors with acoustic attributes, dramatically reducing inference\ntime while preserving high-quality speech characteristics. Extensive\nexperiments on benchmark speech corpora demonstrate that \\emph{ReverBERT}\nsignificantly outperforms baselines in terms of naturalness, expressiveness,\nand computational efficiency. We release our model and code publicly to foster\nfurther research in text-driven speech style transfer.\n","authors":["Michael Brown","Sofia Martinez","Priya Singh"],"pdf_url":"https://arxiv.org/pdf/2503.20992v2.pdf","comment":"arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship and affiliation"},{"id":"http://arxiv.org/abs/2503.20988v2","updated":"2025-07-30T17:01:45Z","published":"2025-03-26T21:06:56Z","title":"Cross-Modal State-Space Graph Reasoning for Structured Summarization","summary":"  The ability to extract compact, meaningful summaries from large-scale and\nmultimodal data is critical for numerous applications, ranging from video\nanalytics to medical reports. Prior methods in cross-modal summarization have\noften suffered from high computational overheads and limited interpretability.\nIn this paper, we propose a \\textit{Cross-Modal State-Space Graph Reasoning}\n(\\textbf{CSS-GR}) framework that incorporates a state-space model with\ngraph-based message passing, inspired by prior work on efficient state-space\nmodels. Unlike existing approaches relying on purely sequential models, our\nmethod constructs a graph that captures inter- and intra-modal relationships,\nallowing more holistic reasoning over both textual and visual streams. We\ndemonstrate that our approach significantly improves summarization quality and\ninterpretability while maintaining computational efficiency, as validated on\nstandard multimodal summarization benchmarks. We also provide a thorough\nablation study to highlight the contributions of each component.\n","authors":["Hannah Kim","Sofia Martinez","Jason Lee"],"pdf_url":"https://arxiv.org/pdf/2503.20988v2.pdf","comment":"arXiv admin note: This paper has been withdrawn by arXiv due to\n  disputed and unverifiable authorship and affiliation"},{"id":"http://arxiv.org/abs/2507.07966v3","updated":"2025-07-30T16:55:33Z","published":"2025-07-10T17:47:40Z","title":"Scaling RL to Long Videos","summary":"  We introduce a full-stack framework that scales up reasoning in\nvision-language models (VLMs) to long videos, leveraging reinforcement\nlearning. We address the unique challenges of long video reasoning by\nintegrating three critical components: (1) a large-scale dataset,\nLongVideo-Reason, comprising 104K long video QA pairs with high-quality\nreasoning annotations across diverse domains such as sports, games, and vlogs;\n(2) a two-stage training pipeline that extends VLMs with chain-of-thought\nsupervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a\ntraining infrastructure for long video RL, named Multi-modal Reinforcement\nSequence Parallelism (MR-SP), which incorporates sequence parallelism and a\nvLLM-based engine tailored for long video, using cached video embeddings for\nefficient rollout and prefilling. In our experiments, LongVILA-R1-7B achieves\nstrong performance on video benchmarks, reaching 65.1% and 71.1% accuracy on\nVideoMME without and with subtitles, respectively, and consistently\noutperforming LongVILA-7B across multiple benchmarks. Moreover, LongVILA-R1-7B\nsupports processing up to 8,192 video frames per video, and configurable FPS\nsettings. Notably, our MR-SP system achieves up to 2.1x speedup on long video\nRL training. In addition, we release our training system for public\navailability that supports RL training on various modalities (video, text, and\naudio), various models (VILA and Qwen series), and even image and video\ngeneration models. On a single A100 node (8 GPUs), it supports RL training on\nhour-long videos (e.g., 3,600 frames).\n","authors":["Yukang Chen","Wei Huang","Baifeng Shi","Qinghao Hu","Hanrong Ye","Ligeng Zhu","Zhijian Liu","Pavlo Molchanov","Jan Kautz","Xiaojuan Qi","Sifei Liu","Hongxu Yin","Yao Lu","Song Han"],"pdf_url":"https://arxiv.org/pdf/2507.07966v3.pdf","comment":"Code at https://github.com/NVlabs/Long-RL and model at\n  https://huggingface.co/Efficient-Large-Model/LongVILA-R1-7B"},{"id":"http://arxiv.org/abs/2505.19959v2","updated":"2025-07-30T16:46:12Z","published":"2025-05-26T13:21:18Z","title":"MiniLongBench: The Low-cost Long Context Understanding Benchmark for\n  Large Language Models","summary":"  Long Context Understanding (LCU) is a critical area for exploration in\ncurrent large language models (LLMs). However, due to the inherently lengthy\nnature of long-text data, existing LCU benchmarks for LLMs often result in\nprohibitively high evaluation costs, like testing time and inference expenses.\nThrough extensive experimentation, we discover that existing LCU benchmarks\nexhibit significant redundancy, which means the inefficiency in evaluation. In\nthis paper, we propose a concise data compression method tailored for long-text\ndata with sparse information characteristics. By pruning the well-known LCU\nbenchmark LongBench, we create MiniLongBench. This benchmark includes only 237\ntest samples across six major task categories and 21 distinct tasks. Through\nempirical analysis of over 60 LLMs, MiniLongBench achieves an average\nevaluation cost reduced to only 4.5% of the original while maintaining an\naverage rank correlation coefficient of 0.97 with LongBench results. Therefore,\nour MiniLongBench, as a low-cost benchmark, holds great potential to\nsubstantially drive future research into the LCU capabilities of LLMs. See\nhttps://github.com/MilkThink-Lab/MiniLongBench for our code, data and tutorial.\n","authors":["Zhongzhan Huang","Guoming Ling","Shanshan Zhong","Hefeng Wu","Liang Lin"],"pdf_url":"https://arxiv.org/pdf/2505.19959v2.pdf","comment":"Accepted by ACL'25 main track"},{"id":"http://arxiv.org/abs/2507.22829v1","updated":"2025-07-30T16:42:19Z","published":"2025-07-30T16:42:19Z","title":"Beyond Natural Language Plans: Structure-Aware Planning for\n  Query-Focused Table Summarization","summary":"  Query-focused table summarization requires complex reasoning, often\napproached through step-by-step natural language (NL) plans. However, NL plans\nare inherently ambiguous and lack structure, limiting their conversion into\nexecutable programs like SQL and hindering scalability, especially for\nmulti-table tasks. To address this, we propose a paradigm shift to structured\nrepresentations. We introduce a new structured plan, TaSoF, inspired by\nformalism in traditional multi-agent systems, and a framework, SPaGe, that\nformalizes the reasoning process in three phases: 1) Structured Planning to\ngenerate TaSoF from a query, 2) Graph-based Execution to convert plan steps\ninto SQL and model dependencies via a directed cyclic graph for parallel\nexecution, and 3) Summary Generation to produce query-focused summaries. Our\nmethod explicitly captures complex dependencies and improves reliability.\nExperiments on three public benchmarks show that SPaGe consistently outperforms\nprior models in both single- and multi-table settings, demonstrating the\nadvantages of structured representations for robust and scalable summarization.\n","authors":["Weijia Zhang","Songgaojun Deng","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2507.22829v1.pdf","comment":"10 pages, 4 figures, and 5 tables"},{"id":"http://arxiv.org/abs/2507.07610v3","updated":"2025-07-30T16:42:00Z","published":"2025-07-10T10:27:20Z","title":"SpatialViz-Bench: Automatically Generated Spatial Visualization\n  Reasoning Tasks for MLLMs","summary":"  Humans can directly imagine and manipulate visual images in their minds, a\ncapability known as spatial visualization. While multi-modal Large Language\nModels (MLLMs) support imagination-based reasoning, spatial visualization\nremains insufficiently evaluated, typically embedded within broader\nmathematical and logical assessments. Existing evaluations often rely on IQ\ntests or math competitions that may overlap with training data, compromising\nassessment reliability. To this end, we introduce SpatialViz-Bench, a\ncomprehensive multi-modal benchmark for spatial visualization with 12 tasks\nacross 4 sub-abilities, comprising 1,180 automatically generated problems. Our\nevaluation of 33 state-of-the-art MLLMs not only reveals wide performance\nvariations and demonstrates the benchmark's strong discriminative power, but\nalso uncovers counter-intuitive findings: models show difficulty perception\nmisaligned with human intuition, exhibit dramatic 2Dto-3D performance cliffs,\ndefault to formulaic derivation over visualization, and paradoxically suffer\nperformance degradation from Chain-of-Thought prompting in open-source models.\nThrough statistical and qualitative analysis of error types, SpatialViz-Bench\ndemonstrates that state-of-the-art MLLMs continue to exhibit deficiencies in\nspatial visualization tasks, thereby addressing a significant lacuna in the\nfield. The benchmark data and evaluation code are publicly available.\n","authors":["Siting Wang","Luoyang Sun","Cheng Deng","Kun Shao","Minnan Pei","Zheng Tian","Haifeng Zhang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2507.07610v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22811v1","updated":"2025-07-30T16:29:47Z","published":"2025-07-30T16:29:47Z","title":"DBLPLink 2.0 -- An Entity Linker for the DBLP Scholarly Knowledge Graph","summary":"  In this work we present an entity linker for DBLP's 2025 version of RDF-based\nKnowledge Graph. Compared to the 2022 version, DBLP now considers publication\nvenues as a new entity type called dblp:Stream. In the earlier version of\nDBLPLink, we trained KG-embeddings and re-rankers on a dataset to produce\nentity linkings. In contrast, in this work, we develop a zero-shot entity\nlinker using LLMs using a novel method, where we re-rank candidate entities\nbased on the log-probabilities of the \"yes\" token output at the penultimate\nlayer of the LLM.\n","authors":["Debayan Banerjee","Tilahun Abedissa Taffa","Ricardo Usbeck"],"pdf_url":"https://arxiv.org/pdf/2507.22811v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.08450v2","updated":"2025-07-30T16:11:59Z","published":"2025-05-13T11:25:15Z","title":"IterKey: Iterative Keyword Generation with LLMs for Enhanced Retrieval\n  Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a way to complement the\nin-context knowledge of Large Language Models (LLMs) by integrating external\ndocuments. However, real-world applications demand not only accuracy but also\ninterpretability. While dense retrieval methods provide high accuracy, they\nlack interpretability; conversely, sparse retrieval methods offer transparency\nbut often fail to capture the full intent of queries due to their reliance on\nkeyword matching. To address these issues, we introduce IterKey, an LLM-driven\niterative keyword generation framework that enhances RAG via sparse retrieval.\nIterKey consists of three LLM-driven stages: generating keywords for retrieval,\ngenerating answers based on retrieved documents, and validating the answers. If\nvalidation fails, the process iteratively repeats with refined keywords. Across\nfour QA tasks, experimental results show that IterKey achieves 5% to 20%\naccuracy improvements over BM25-based RAG and simple baselines. Its performance\nis comparable to dense retrieval-based RAG and prior iterative query refinement\nmethods using dense models. In summary, IterKey is a novel BM25-based approach\nleveraging LLMs to iteratively refine RAG, effectively balancing accuracy with\ninterpretability.\n","authors":["Kazuki Hayashi","Hidetaka Kamigaito","Shinya Kouda","Taro Watanabe"],"pdf_url":"https://arxiv.org/pdf/2505.08450v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02744v2","updated":"2025-07-30T16:07:24Z","published":"2024-10-03T17:55:17Z","title":"Neutral Residues: Revisiting Adapters for Model Extension","summary":"  We address the problem of extending a pretrained large language model to a\nnew domain that was not seen during training. Standard techniques, such as\nfinetuning or low-rank adaptation (LoRA) are successful at domain adaptation,\nbut do not formally add capacity to the model. This often leads to a trade-off,\nbetween performing well on the new domain vs. degrading performance on the\noriginal domain. Here, we revisit and improve adapters to extend LLMs from\nthree angles: data, architecture and training procedure, which are\nadvantageously considered jointly. The resulting method, called neutral\nresidues, modifies adapters in a way that leads each new residual block to\noutput near-zeros on the original domain. This solution leads to strong results\nwhen adapting a state-of-the-art model originally trained on English to a new\nlanguage. Neutral residues significantly outperform competing approaches such\nas finetuning, LoRA or vanilla adapters in terms of the trade-off between\nlearning the new language and not forgetting English.\n","authors":["Franck Signe Talla","Edouard Grave","Hervé Jégou"],"pdf_url":"https://arxiv.org/pdf/2410.02744v2.pdf","comment":"Accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2311.07052v4","updated":"2025-07-30T16:00:53Z","published":"2023-11-13T03:36:18Z","title":"Towards the Law of Capacity Gap in Distilling Language Models","summary":"  Language model (LM) distillation aims at distilling the knowledge in a large\nteacher LM to a small student one. As a critical issue facing LM distillation,\na superior student often arises from a teacher of a relatively small scale\ninstead of a larger one, especially in the presence of substantial capacity gap\nbetween the teacher and student. This issue, often referred to as the\n\\textit{curse of capacity gap}, suggests that there is likely an optimal\nteacher yielding the best-performing student along the scaling course of the\nteacher. Consequently, distillation trials on teachers of a wide range of\nscales are called for to determine the optimal teacher, which becomes\ncomputationally intensive in the context of large LMs (LLMs). This paper\naddresses this critical bottleneck by providing the \\textit{law of capacity\ngap} inducted from a preliminary study on distilling a broad range of\nsmall-scale (<3B) LMs, where the optimal teacher consistently scales linearly\nwith the student scale across different model and data scales. By extending the\nlaw to LLM distillation on a larger scale (7B), we succeed in obtaining\nversatile LLMs that outperform a wide array of competitors.\n","authors":["Chen Zhang","Qiuchi Li","Dawei Song","Zheyu Ye","Yan Gao","Yan Hu"],"pdf_url":"https://arxiv.org/pdf/2311.07052v4.pdf","comment":"32 pages, 10 figures, 15 tables, accepted to ACL 2025. Code and\n  checkpoints are available at https://github.com/GeneZC/MiniMA"},{"id":"http://arxiv.org/abs/2506.19073v2","updated":"2025-07-30T15:54:38Z","published":"2025-06-23T19:44:21Z","title":"MFTCXplain: A Multilingual Benchmark Dataset for Evaluating the Moral\n  Reasoning of LLMs through Hate Speech Multi-hop Explanations","summary":"  Ensuring the moral reasoning capabilities of Large Language Models (LLMs) is\na growing concern as these systems are used in socially sensitive tasks.\nNevertheless, current evaluation benchmarks present two major shortcomings: a\nlack of annotations that justify moral classifications, which limits\ntransparency and interpretability; and a predominant focus on English, which\nconstrains the assessment of moral reasoning across diverse cultural settings.\nIn this paper, we introduce MFTCXplain, a multilingual benchmark dataset for\nevaluating the moral reasoning of LLMs via hate speech multi-hop explanation\nusing Moral Foundation Theory (MFT). The dataset comprises 3,000 tweets across\nPortuguese, Italian, Persian, and English, annotated with binary hate speech\nlabels, moral categories, and text span-level rationales. Empirical results\nhighlight a misalignment between LLM outputs and human annotations in moral\nreasoning tasks. While LLMs perform well in hate speech detection (F1 up to\n0.836), their ability to predict moral sentiments is notably weak (F1 < 0.35).\nFurthermore, rationale alignment remains limited mainly in underrepresented\nlanguages. These findings show the limited capacity of current LLMs to\ninternalize and reflect human moral reasoning.\n","authors":["Jackson Trager","Diego Alves","Matteo Guida","Mikel K. Ngueajio","Ameeta Agrawal","Flor Plaza-del-Arco","Yalda Daryanai","Farzan Karimi-Malekabadi","Francielle Vargas"],"pdf_url":"https://arxiv.org/pdf/2506.19073v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2507.22050v2","updated":"2025-07-30T15:51:29Z","published":"2025-07-29T17:55:23Z","title":"DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router","summary":"  Large Language Models (LLMs) excel at many reasoning tasks but struggle with\nknowledge-intensive queries due to their inability to dynamically access\nup-to-date or domain-specific information. Retrieval-Augmented Generation (RAG)\nhas emerged as a promising solution, enabling LLMs to ground their responses in\nexternal sources. However, existing RAG methods lack fine-grained control over\nboth the query and source sides, often resulting in noisy retrieval and shallow\nreasoning. In this work, we introduce DeepSieve, an agentic RAG framework that\nincorporates information sieving via LLM-as-a-knowledge-router. DeepSieve\ndecomposes complex queries into structured sub-questions and recursively routes\neach to the most suitable knowledge source, filtering irrelevant information\nthrough a multi-stage distillation process. Our design emphasizes modularity,\ntransparency, and adaptability, leveraging recent advances in agentic system\ndesign. Experiments on multi-hop QA tasks across heterogeneous sources\ndemonstrate improved reasoning depth, retrieval precision, and interpretability\nover conventional RAG approaches. Our codes are available at\nhttps://github.com/MinghoKwok/DeepSieve.\n","authors":["Minghao Guo","Qingcheng Zeng","Xujiang Zhao","Yanchi Liu","Wenchao Yu","Mengnan Du","Haifeng Chen","Wei Cheng"],"pdf_url":"https://arxiv.org/pdf/2507.22050v2.pdf","comment":"22 pages, work in progress"},{"id":"http://arxiv.org/abs/2410.15633v6","updated":"2025-07-30T15:50:58Z","published":"2024-10-21T04:30:53Z","title":"GATEAU: Selecting Influential Samples for Long Context Alignment","summary":"  Aligning large language models to handle instructions with extremely long\ncontexts has yet to be fully investigated. Previous studies have attempted to\nscale up the available data volume by synthesizing long instruction-following\nsamples, as constructing such a dataset tends to be challenging for annotators.\nHowever, a lack of a well-defined strategy for ensuring data quality may\nintroduce low-quality samples and restrict the model's performance. Thus, we\npropose GATEAU, a novel framework to address the unique challenge of long\ncontext alignment by identifying the influential samples enriched with\nlong-range dependency relations. Specifically, GATEAU measures the long-range\ndependencies from two essential aspects: the difficulty of generating target\nresponses due to the long-range dependencies, and the difficulty of\nunderstanding long inputs due to such dependencies. Comprehensive experiments\nindicate that GATEAU effectively identifies influential samples, and the model\ntrained on these selected samples exhibits better instruction-following and\nlong-context understanding capabilities.\n","authors":["Shuzheng Si","Haozhe Zhao","Gang Chen","Yunshui Li","Kangyang Luo","Chuancheng Lv","Kaikai An","Fanchao Qi","Baobao Chang","Maosong Sun"],"pdf_url":"https://arxiv.org/pdf/2410.15633v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22758v1","updated":"2025-07-30T15:19:38Z","published":"2025-07-30T15:19:38Z","title":"MASCA: LLM based-Multi Agents System for Credit Assessment","summary":"  Recent advancements in financial problem-solving have leveraged LLMs and\nagent-based systems, with a primary focus on trading and financial modeling.\nHowever, credit assessment remains an underexplored challenge, traditionally\ndependent on rule-based methods and statistical models. In this paper, we\nintroduce MASCA, an LLM-driven multi-agent system designed to enhance credit\nevaluation by mirroring real-world decision-making processes. The framework\nemploys a layered architecture where specialized LLM-based agents\ncollaboratively tackle sub-tasks. Additionally, we integrate contrastive\nlearning for risk and reward assessment to optimize decision-making. We further\npresent a signaling game theory perspective on hierarchical multi-agent\nsystems, offering theoretical insights into their structure and interactions.\nOur paper also includes a detailed bias analysis in credit assessment,\naddressing fairness concerns. Experimental results demonstrate that MASCA\noutperforms baseline approaches, highlighting the effectiveness of hierarchical\nLLM-based multi-agent systems in financial applications, particularly in credit\nscoring.\n","authors":["Gautam Jajoo","Pranjal A Chitale","Saksham Agarwal"],"pdf_url":"https://arxiv.org/pdf/2507.22758v1.pdf","comment":"Accepted at ACL REALM Workshop. Work in Progress"},{"id":"http://arxiv.org/abs/2507.22753v1","updated":"2025-07-30T15:12:12Z","published":"2025-07-30T15:12:12Z","title":"Opportunities and Challenges of LLMs in Education: An NLP Perspective","summary":"  Interest in the role of large language models (LLMs) in education is\nincreasing, considering the new opportunities they offer for teaching,\nlearning, and assessment. In this paper, we examine the impact of LLMs on\neducational NLP in the context of two main application scenarios: {\\em\nassistance} and {\\em assessment}, grounding them along the four dimensions --\nreading, writing, speaking, and tutoring. We then present the new directions\nenabled by LLMs, and the key challenges to address. We envision that this\nholistic overview would be useful for NLP researchers and practitioners\ninterested in exploring the role of LLMs in developing language-focused and\nNLP-enabled educational applications of the future.\n","authors":["Sowmya Vajjala","Bashar Alhafni","Stefano Bannò","Kaushal Kumar Maurya","Ekaterina Kochmar"],"pdf_url":"https://arxiv.org/pdf/2507.22753v1.pdf","comment":"Pre-print"},{"id":"http://arxiv.org/abs/2507.22752v1","updated":"2025-07-30T15:10:55Z","published":"2025-07-30T15:10:55Z","title":"CUS-QA: Local-Knowledge-Oriented Open-Ended Question Answering Dataset","summary":"  We introduce a benchmark for open-ended regional question answering that\nencompasses both textual and visual modalities. We also provide strong\nbaselines using state-of-the-art large language models (LLMs). Our dataset\nconsists of manually curated questions and answers grounded in Wikipedia,\ncreated by native speakers from Czechia, Slovakia, and Ukraine, with\naccompanying English translations. It includes both purely textual questions\nand those requiring visual understanding. As a baseline, we evaluate\nstate-of-the-art LLMs through prompting and complement this with human\njudgments of answer correctness. Using these human evaluations, we analyze the\nreliability of existing automatic evaluation metrics. Our baseline results\nhighlight a significant gap in regional knowledge among current LLMs. Moreover,\napart from LLM-based evaluation, there is minimal correlation between automated\nmetrics and human judgment. We release this dataset as a resource to (1) assess\nregional knowledge in LLMs, (2) study cross-lingual generation consistency in a\nchallenging setting, and (3) advance the development of evaluation metrics for\nopen-ended question answering.\n","authors":["Jindřich Libovický","Jindřich Helcl","Andrei Manea","Gianluca Vico"],"pdf_url":"https://arxiv.org/pdf/2507.22752v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22746v1","updated":"2025-07-30T15:03:36Z","published":"2025-07-30T15:03:36Z","title":"Next Tokens Denoising for Speech Synthesis","summary":"  While diffusion and autoregressive (AR) models have significantly advanced\ngenerative modeling, they each present distinct limitations. AR models, which\nrely on causal attention, cannot exploit future context and suffer from slow\ngeneration speeds. Conversely, diffusion models struggle with key-value (KV)\ncaching. To overcome these challenges, we introduce Dragon-FM, a novel\ntext-to-speech (TTS) design that unifies AR and flow-matching. This model\nprocesses 48 kHz audio codec tokens in chunks at a compact 12.5 tokens per\nsecond rate. This design enables AR modeling across chunks, ensuring global\ncoherence, while parallel flow-matching within chunks facilitates fast\niterative denoising. Consequently, the proposed model can utilize KV-cache\nacross chunks and incorporate future context within each chunk. Furthermore, it\nbridges continuous and discrete feature modeling, demonstrating that continuous\nAR flow-matching can predict discrete tokens with finite scalar quantizers.\nThis efficient codec and fast chunk-autoregressive architecture also makes the\nproposed model particularly effective for generating extended content.\nExperiment for demos of our work} on podcast datasets demonstrate its\ncapability to efficiently generate high-quality zero-shot podcasts.\n","authors":["Yanqing Liu","Ruiqing Xue","Chong Zhang","Yufei Liu","Gang Wang","Bohan Li","Yao Qian","Lei He","Shujie Liu","Sheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2507.22746v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22744v1","updated":"2025-07-30T15:00:00Z","published":"2025-07-30T15:00:00Z","title":"Reducing Hallucinations in Summarization via Reinforcement Learning with\n  Entity Hallucination Index","summary":"  Reducing hallucinations in abstractive summarization remains a critical\nchallenge for deploying language models (LMs) in real-world settings. In this\nwork, we introduce a rewarddriven fine-tuning framework that explicitly\noptimizes for Entity Hallucination Index (EHI), a metric designed to quantify\nthe presence, correctness, and grounding of named entities in generated\nsummaries. Given a corpus of meeting transcripts, we first generate baseline\nsummaries using a pre-trained LM and compute EHI scores via automatic entity\nextraction and matching. We then apply reinforcement learning to fine-tune the\nmodel parameters, using EHI as a reward signal to bias generation toward\nentity-faithful outputs. Our approach does not rely on human-written factuality\nannotations, enabling scalable fine-tuning. Experiments demonstrate consistent\nimprovements in EHI across datasets, with qualitative analysis revealing a\nsignificant reduction in entity-level hallucinations without degradation in\nfluency or informativeness. We release a reproducible Colab pipeline,\nfacilitating further research on hallucination-aware model fine-tuning using\nlightweight, hallucintion metrics like EHI.\n","authors":["Praveenkumar Katwe","Rakesh Chandra","Balabantaray Kali","Prasad Vittala"],"pdf_url":"https://arxiv.org/pdf/2507.22744v1.pdf","comment":"8"},{"id":"http://arxiv.org/abs/2502.13820v3","updated":"2025-07-30T14:58:42Z","published":"2025-02-19T15:32:11Z","title":"Scoring Verifiers: Evaluating Synthetic Verification for Code and\n  Reasoning","summary":"  Synthetic verification techniques such as generating test cases and reward\nmodelling are common ways to enhance the coding capabilities of large language\nmodels (LLM) beyond predefined tests. Additionally, code verification has\nrecently found great success as a critical component in improving reasoning\ncapability of LLMs via reinforcement learning. In this paper, we propose an\napproach which can transform existing coding benchmarks into scoring and\nranking datasets to evaluate the effectiveness of synthetic verifiers. We also\npropose multiple metrics to measure different aspects of the synthetic\nverifiers with the proposed benchmarks. By employing the proposed approach, we\nrelease four new benchmarks (HE-R, HE-R+, MBPP-R, and MBPP-R+), and analyzed\nsynthetic verification methods with standard, reasoning-based, and reward-based\nLLMs. Our experiments show that reasoning can significantly improve test case\ngeneration and that scaling the number of test cases enhances the verification\naccuracy.\n","authors":["Aleksander Ficek","Somshubra Majumdar","Vahid Noroozi","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2502.13820v3.pdf","comment":"COLM 2025"},{"id":"http://arxiv.org/abs/2507.22729v1","updated":"2025-07-30T14:49:30Z","published":"2025-07-30T14:49:30Z","title":"Resource-Efficient Adaptation of Large Language Models for Text\n  Embeddings via Prompt Engineering and Contrastive Fine-tuning","summary":"  Large Language Models (LLMs) have become a cornerstone in Natural Language\nProcessing (NLP), achieving impressive performance in text generation. Their\ntoken-level representations capture rich, human-aligned semantics. However,\npooling these vectors into a text embedding discards crucial information.\nNevertheless, many non-generative downstream tasks, such as clustering,\nclassification, or retrieval, still depend on accurate and controllable\nsentence- or document-level embeddings. We explore several adaptation\nstrategies for pre-trained, decoder-only LLMs: (i) various aggregation\ntechniques for token embeddings, (ii) task-specific prompt engineering, and\n(iii) text-level augmentation via contrastive fine-tuning. Combining these\ncomponents yields state-of-the-art performance on the English clustering track\nof the Massive Text Embedding Benchmark (MTEB). An analysis of the attention\nmap further shows that fine-tuning shifts focus from prompt tokens to\nsemantically relevant words, indicating more effective compression of meaning\ninto the final hidden state. Our experiments demonstrate that LLMs can be\neffectively adapted as text embedding models through a combination of prompt\nengineering and resource-efficient contrastive fine-tuning on synthetically\ngenerated positive pairs.\n","authors":["Benedikt Roth","Stephan Rappensperger","Tianming Qiu","Hamza Imamović","Julian Wörmann","Hao Shen"],"pdf_url":"https://arxiv.org/pdf/2507.22729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22720v1","updated":"2025-07-30T14:39:51Z","published":"2025-07-30T14:39:51Z","title":"Investigating Hallucination in Conversations for Low Resource Languages","summary":"  Large Language Models (LLMs) have demonstrated remarkable proficiency in\ngenerating text that closely resemble human writing. However, they often\ngenerate factually incorrect statements, a problem typically referred to as\n'hallucination'. Addressing hallucination is crucial for enhancing the\nreliability and effectiveness of LLMs. While much research has focused on\nhallucinations in English, our study extends this investigation to\nconversational data in three languages: Hindi, Farsi, and Mandarin. We offer a\ncomprehensive analysis of a dataset to examine both factual and linguistic\nerrors in these languages for GPT-3.5, GPT-4o, Llama-3.1, Gemma-2.0,\nDeepSeek-R1 and Qwen-3. We found that LLMs produce very few hallucinated\nresponses in Mandarin but generate a significantly higher number of\nhallucinations in Hindi and Farsi.\n","authors":["Amit Das","Md. Najib Hasan","Souvika Sarkar","Zheng Zhang","Fatemeh Jamshidi","Tathagata Bhattacharya","Nilanjana Raychawdhury","Dongji Feng","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2507.22720v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.13932v3","updated":"2025-07-30T14:37:56Z","published":"2025-04-14T19:31:21Z","title":"Enhancing Ultra-Low-Bit Quantization of Large Language Models Through\n  Saliency-Aware Partial Retraining","summary":"  The growing use of large language models has raised environmental and\neconomic concerns about their intensity of resource usage during inference.\nServing these models to each user requires substantial energy and water for\ncooling. Model compression techniques like quantization can shrink large\nlanguage models and make them more resource efficient at the cost of potential\nperformance degradation. Quantization methods compress model size through\nreplacing their high-precision parameters by quantized values of lower\nprecision. Among existing methods, the ApiQ method achieves superior accuracy\npreservation at minimal memory and time overhead. We investigate two ideas to\nextend performance in ultra-low-bit quantization beyond ApiQ's level. First, we\nlook into combining existing quantization-aware training techniques with ApiQ's\npartial training. We show that this does not outperform the baseline ApiQ\nmethod with limited training data and frozen weights. This leads to two key\ninsights: (1) The substantial representational capacity that is gained through\nfull retraining is unlikely to be feasible through partial training. (2) This\ngain may depend on using a large and diverse dataset in quantization-aware\ntraining. Second, through a novel approach informed by the two insights, we\npropose an ultra-low-bit quantization method that builds upon ApiQ and extends\nits performance without the need for full retraining. This publicly available\nmethod relies on a saliency-aware regularization term that prioritizes\npreserving the most impactful parameters during quantization. Our experiments\non LLaMA 7B and 13B benchmarks demonstrate that our method reduces the ApiQ's\naccuracy degradation by 10.85% and 7.54% respectively. A Python implementation\nof the proposed quantization method is publicly available on GitHub\nhttps://github.com/TokuyuSou/ULB-SAPR.\n","authors":["Deyu Cao","Samin Aref"],"pdf_url":"https://arxiv.org/pdf/2504.13932v3.pdf","comment":"This is a post-peer-review accepted manuscript from the proceedings\n  of the 22nd International Conference on Modeling Decisions for Artificial\n  Intelligence (MDAI'25). The publisher authenticated version and full citation\n  details are available on Springer's website (LNAI 15957).\n  https://doi.org/10.1007/978-3-032-00891-6_28"},{"id":"http://arxiv.org/abs/2507.22716v1","updated":"2025-07-30T14:29:44Z","published":"2025-07-30T14:29:44Z","title":"From Sufficiency to Reflection: Reinforcement-Guided Thinking Quality in\n  Retrieval-Augmented Reasoning for LLMs","summary":"  Reinforcement learning-based retrieval-augmented generation (RAG) methods\nenhance the reasoning abilities of large language models (LLMs). However, most\nrely only on final-answer rewards, overlooking intermediate reasoning quality.\nThis paper analyzes existing RAG reasoning models and identifies three main\nfailure patterns: (1) information insufficiency, meaning the model fails to\nretrieve adequate support; (2) faulty reasoning, where logical or content-level\nflaws appear despite sufficient information; and (3) answer-reasoning\ninconsistency, where a valid reasoning chain leads to a mismatched final\nanswer. We propose TIRESRAG-R1, a novel framework using a\nthink-retrieve-reflect process and a multi-dimensional reward system to improve\nreasoning and stability. TIRESRAG-R1 introduces: (1) a sufficiency reward to\nencourage thorough retrieval; (2) a reasoning quality reward to assess the\nrationality and accuracy of the reasoning chain; and (3) a reflection reward to\ndetect and revise errors. It also employs a difficulty-aware reweighting\nstrategy and training sample filtering to boost performance on complex tasks.\nExperiments on four multi-hop QA datasets show that TIRESRAG-R1 outperforms\nprior RAG methods and generalizes well to single-hop tasks. The code and data\nare available at: https://github.com/probe2/TIRESRAG-R1.\n","authors":["Jie He","Victor Gutierrez Basulto","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2507.22716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.11257v4","updated":"2025-07-30T13:57:49Z","published":"2025-04-15T14:56:21Z","title":"UI-E2I-Synth: Advancing GUI Grounding with Large-Scale Instruction\n  Synthesis","summary":"  Recent advancements in Large Vision-Language Models are accelerating the\ndevelopment of Graphical User Interface (GUI) agents that utilize human-like\nvision perception capabilities to enhance productivity on digital devices.\nCompared to approaches predicated on GUI metadata, which are platform-dependent\nand vulnerable to implementation variations, vision-based approaches offer\nbroader applicability. In this vision-based paradigm, the GUI instruction\ngrounding, which maps user instruction to the location of corresponding element\non the given screenshot, remains a critical challenge, particularly due to\nlimited public training dataset and resource-intensive manual instruction data\nannotation. In this paper, we delve into unexplored challenges in this task\nincluding element-to-screen ratio, unbalanced element type, and implicit\ninstruction. To address these challenges, we introduce a large-scale data\nsynthesis pipeline UI-E2I-Synth for generating varying complex instruction\ndatasets using GPT-4o instead of human annotators. Furthermore, we propose a\nnew GUI instruction grounding benchmark UI-I2E-Bench, which is designed to\naddress the limitations of existing benchmarks by incorporating diverse\nannotation aspects. Our model, trained on the synthesized data, achieves\nsuperior performance in GUI instruction grounding, demonstrating the\nadvancements of proposed data synthesis pipeline. The proposed benchmark,\naccompanied by extensive analyses, provides practical insights for future\nresearch in GUI grounding. We will release corresponding artifacts at\nhttps://microsoft.github.io/FIVE-UI-Evol/ .\n","authors":["Xinyi Liu","Xiaoyi Zhang","Ziyun Zhang","Yan Lu"],"pdf_url":"https://arxiv.org/pdf/2504.11257v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19947v2","updated":"2025-07-30T13:52:22Z","published":"2025-07-26T13:24:02Z","title":"Spatial Language Likelihood Grounding Network for Bayesian Fusion of\n  Human-Robot Observations","summary":"  Fusing information from human observations can help robots overcome sensing\nlimitations in collaborative tasks. However, an uncertainty-aware fusion\nframework requires a grounded likelihood representing the uncertainty of human\ninputs. This paper presents a Feature Pyramid Likelihood Grounding Network\n(FP-LGN) that grounds spatial language by learning relevant map image features\nand their relationships with spatial relation semantics. The model is trained\nas a probability estimator to capture aleatoric uncertainty in human language\nusing three-stage curriculum learning. Results showed that FP-LGN matched\nexpert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated\ngreater robustness with lower standard deviation. Collaborative sensing results\ndemonstrated that the grounded likelihood successfully enabled\nuncertainty-aware fusion of heterogeneous human language observations and robot\nsensor measurements, achieving significant improvements in human-robot\ncollaborative task performance.\n","authors":["Supawich Sitdhipol","Waritwong Sukprasongdee","Ekapol Chuangsuwanich","Rina Tse"],"pdf_url":"https://arxiv.org/pdf/2507.19947v2.pdf","comment":"Accepted to the 2025 IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC); Supplementary video: https://cu-asl.github.io/fp-lgn/"},{"id":"http://arxiv.org/abs/2507.22676v1","updated":"2025-07-30T13:37:06Z","published":"2025-07-30T13:37:06Z","title":"Listening to the Unspoken: Exploring 365 Aspects of Multimodal Interview\n  Performance Assessment","summary":"  Interview performance assessment is essential for determining candidates'\nsuitability for professional positions. To ensure holistic and fair\nevaluations, we propose a novel and comprehensive framework that explores\n``365'' aspects of interview performance by integrating \\textit{three}\nmodalities (video, audio, and text), \\textit{six} responses per candidate, and\n\\textit{five} key evaluation dimensions. The framework employs\nmodality-specific feature extractors to encode heterogeneous data streams and\nsubsequently fused via a Shared Compression Multilayer Perceptron. This module\ncompresses multimodal embeddings into a unified latent space, facilitating\nefficient feature interaction. To enhance prediction robustness, we incorporate\na two-level ensemble learning strategy: (1) independent regression heads\npredict scores for each response, and (2) predictions are aggregated across\nresponses using a mean-pooling mechanism to produce final scores for the five\ntarget dimensions. By listening to the unspoken, our approach captures both\nexplicit and implicit cues from multimodal data, enabling comprehensive and\nunbiased assessments. Achieving a multi-dimensional average MSE of 0.1824, our\nframework secured first place in the AVI Challenge 2025, demonstrating its\neffectiveness and robustness in advancing automated and multimodal interview\nperformance assessment. The full implementation is available at\nhttps://github.com/MSA-LMC/365Aspects.\n","authors":["Jia Li","Yang Wang","Wenhao Qian","Zhenzhen Hu","Richang Hong","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2507.22676v1.pdf","comment":"8 pages, 4 figures, ACM MM 2025.\n  github:https://github.com/MSA-LMC/365Aspects"},{"id":"http://arxiv.org/abs/2505.12474v2","updated":"2025-07-30T13:18:59Z","published":"2025-05-18T15:52:24Z","title":"What Are They Talking About? A Benchmark of Knowledge-Grounded\n  Discussion Summarization","summary":"  Traditional dialogue summarization primarily focuses on dialogue content,\nassuming it comprises adequate information for a clear summary. However, this\nassumption often fails for discussions grounded in shared background, where\nparticipants frequently omit context and use implicit references. This results\nin summaries that are confusing to readers unfamiliar with the background. To\naddress this, we introduce Knowledge-Grounded Discussion Summarization (KGDS),\na novel task that produces a supplementary background summary for context and a\nclear opinion summary with clarified references. To facilitate research, we\nconstruct the first KGDS benchmark, featuring news-discussion pairs and\nexpert-created multi-granularity gold annotations for evaluating sub-summaries.\nWe also propose a novel hierarchical evaluation framework with fine-grained and\ninterpretable metrics. Our extensive evaluation of 12 advanced large language\nmodels (LLMs) reveals that KGDS remains a significant challenge. The models\nfrequently miss key facts and retain irrelevant ones in background\nsummarization, and often fail to resolve implicit references in opinion summary\nintegration.\n","authors":["Weixiao Zhou","Junnan Zhu","Gengyao Li","Xianfu Cheng","Xinnian Liang","Feifei Zhai","Zhoujun Li"],"pdf_url":"https://arxiv.org/pdf/2505.12474v2.pdf","comment":"20 pages, 17 figures and 8 tables"},{"id":"http://arxiv.org/abs/2408.16440v2","updated":"2025-07-30T13:06:51Z","published":"2024-08-29T11:05:54Z","title":"Instruction-tuned Large Language Models for Machine Translation in the\n  Medical Domain","summary":"  Large Language Models (LLMs) have shown promising results on machine\ntranslation for high resource language pairs and domains. However, in\nspecialised domains (e.g. medical) LLMs have shown lower performance compared\nto standard neural machine translation models. The consistency in the machine\ntranslation of terminology is crucial for users, researchers, and translators\nin specialised domains. In this study, we compare the performance between\nbaseline LLMs and instruction-tuned LLMs in the medical domain. In addition, we\nintroduce terminology from specialised medical dictionaries into the\ninstruction formatted datasets for fine-tuning LLMs. The instruction-tuned LLMs\nsignificantly outperform the baseline models with automatic metrics.\n","authors":["Miguel Rios"],"pdf_url":"https://arxiv.org/pdf/2408.16440v2.pdf","comment":"Citation: Miguel Rios. 2025. Instruction-tuned Large Language Models\n  for Machine Translation in the Medical Domain. In Proceedings of Machine\n  Translation Summit XX Volume 1, pages 162-172"},{"id":"http://arxiv.org/abs/2503.03044v2","updated":"2025-07-30T12:53:56Z","published":"2025-03-04T22:50:17Z","title":"QE4PE: Word-level Quality Estimation for Human Post-Editing","summary":"  Word-level quality estimation (QE) methods aim to detect erroneous spans in\nmachine translations, which can direct and facilitate human post-editing. While\nthe accuracy of word-level QE systems has been assessed extensively, their\nusability and downstream influence on the speed, quality and editing choices of\nhuman post-editing remain understudied. In this study, we investigate the\nimpact of word-level QE on machine translation (MT) post-editing in a realistic\nsetting involving 42 professional post-editors across two translation\ndirections. We compare four error-span highlight modalities, including\nsupervised and uncertainty-based word-level QE methods, for identifying\npotential errors in the outputs of a state-of-the-art neural MT model.\nPost-editing effort and productivity are estimated from behavioral logs, while\nquality improvements are assessed by word- and segment-level human annotation.\nWe find that domain, language and editors' speed are critical factors in\ndetermining highlights' effectiveness, with modest differences between\nhuman-made and automated QE highlights underlining a gap between accuracy and\nusability in professional workflows.\n","authors":["Gabriele Sarti","Vilém Zouhar","Grzegorz Chrupała","Ana Guerberof-Arenas","Malvina Nissim","Arianna Bisazza"],"pdf_url":"https://arxiv.org/pdf/2503.03044v2.pdf","comment":"Accepted by TACL (pre-MIT Press publication version); Code:\n  https://github.com/gsarti/qe4pe. Dataset:\n  https://huggingface.co/datasets/gsarti/qe4pe"},{"id":"http://arxiv.org/abs/2507.22623v1","updated":"2025-07-30T12:42:35Z","published":"2025-07-30T12:42:35Z","title":"Multilingual Political Views of Large Language Models: Identification\n  and Steering","summary":"  Large language models (LLMs) are increasingly used in everyday tools and\napplications, raising concerns about their potential influence on political\nviews. While prior research has shown that LLMs often exhibit measurable\npolitical biases--frequently skewing toward liberal or progressive\npositions--key gaps remain. Most existing studies evaluate only a narrow set of\nmodels and languages, leaving open questions about the generalizability of\npolitical biases across architectures, scales, and multilingual settings.\nMoreover, few works examine whether these biases can be actively controlled.\n  In this work, we address these gaps through a large-scale study of political\norientation in modern open-source instruction-tuned LLMs. We evaluate seven\nmodels, including LLaMA-3.1, Qwen-3, and Aya-Expanse, across 14 languages using\nthe Political Compass Test with 11 semantically equivalent paraphrases per\nstatement to ensure robust measurement. Our results reveal that larger models\nconsistently shift toward libertarian-left positions, with significant\nvariations across languages and model families. To test the manipulability of\npolitical stances, we utilize a simple center-of-mass activation intervention\ntechnique and show that it reliably steers model responses toward alternative\nideological positions across multiple languages. Our code is publicly available\nat https://github.com/d-gurgurov/Political-Ideologies-LLMs.\n","authors":["Daniil Gurgurov","Katharina Trinley","Ivan Vykopal","Josef van Genabith","Simon Ostermann","Roberto Zamparelli"],"pdf_url":"https://arxiv.org/pdf/2507.22623v1.pdf","comment":"pre-print"},{"id":"http://arxiv.org/abs/2507.22608v1","updated":"2025-07-30T12:23:39Z","published":"2025-07-30T12:23:39Z","title":"Language Arithmetics: Towards Systematic Language Neuron Identification\n  and Manipulation","summary":"  Large language models (LLMs) exhibit strong multilingual abilities, yet the\nneural mechanisms behind language-specific processing remain unclear. We\nanalyze language-specific neurons in Llama-3.1-8B, Mistral-Nemo-12B, and\nAya-Expanse-8B & 32B across 21 typologically diverse languages, identifying\nneurons that control language behavior. Using the Language Activation\nProbability Entropy (LAPE) method, we show that these neurons cluster in deeper\nlayers, with non-Latin scripts showing greater specialization. Related\nlanguages share overlapping neurons, reflecting internal representations of\nlinguistic proximity.\n  Through language arithmetics, i.e. systematic activation addition and\nmultiplication, we steer models to deactivate unwanted languages and activate\ndesired ones, outperforming simpler replacement approaches. These interventions\neffectively guide behavior across five multilingual tasks: language forcing,\ntranslation, QA, comprehension, and NLI. Manipulation is more successful for\nhigh-resource languages, while typological similarity improves effectiveness.\nWe also demonstrate that cross-lingual neuron steering enhances downstream\nperformance and reveal internal \"fallback\" mechanisms for language selection\nwhen neurons are progressively deactivated. Our code is made publicly available\nat https://github.com/d-gurgurov/Language-Neurons-Manipulation.\n","authors":["Daniil Gurgurov","Katharina Trinley","Yusser Al Ghussin","Tanja Baeumel","Josef van Genabith","Simon Ostermann"],"pdf_url":"https://arxiv.org/pdf/2507.22608v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2507.22607v1","updated":"2025-07-30T12:23:21Z","published":"2025-07-30T12:23:21Z","title":"VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced\n  Multimodal Reasoning","summary":"  Reinforcement learning has proven its effectiveness in enhancing the\nreasoning capabilities of large language models. Recent research efforts have\nprogressively extended this paradigm to multimodal reasoning tasks. Due to the\ninherent complexity and diversity of multimodal tasks, especially in semantic\ncontent and problem formulations, existing models often exhibit unstable\nperformance across various domains and difficulty levels. To address these\nlimitations, we propose VL-Cogito, an advanced multimodal reasoning model\ntrained via a novel multi-stage Progressive Curriculum Reinforcement Learning\n(PCuRL) framework. PCuRL systematically guides the model through tasks of\ngradually increasing difficulty, substantially improving its reasoning\nabilities across diverse multimodal contexts. The framework introduces two key\ninnovations: (1) an online difficulty soft weighting mechanism, dynamically\nadjusting training difficulty across successive RL training stages; and (2) a\ndynamic length reward mechanism, which encourages the model to adaptively\nregulate its reasoning path length according to task complexity, thus balancing\nreasoning efficiency with correctness. Experimental evaluations demonstrate\nthat VL-Cogito consistently matches or surpasses existing reasoning-oriented\nmodels across mainstream multimodal benchmarks spanning mathematics, science,\nlogic, and general understanding, validating the effectiveness of our approach.\n","authors":["Ruifeng Yuan","Chenghao Xiao","Sicong Leng","Jianyu Wang","Long Li","Weiwen Xu","Hou Pong Chan","Deli Zhao","Tingyang Xu","Zhongyu Wei","Hao Zhang","Yu Rong"],"pdf_url":"https://arxiv.org/pdf/2507.22607v1.pdf","comment":"21 pages, 5 figures, 6 tables. Work in progress"},{"id":"http://arxiv.org/abs/2507.22025v2","updated":"2025-07-30T12:17:53Z","published":"2025-07-29T17:22:07Z","title":"UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and\n  Precise Inference-Time Grounding","summary":"  The emergence of Multimodal Large Language Models (MLLMs) has driven\nsignificant advances in Graphical User Interface (GUI) agent capabilities.\nNevertheless, existing GUI agent training and inference techniques still suffer\nfrom a dilemma for reasoning designs, ineffective reward, and visual noise. To\naddress these issues, we introduce UI-AGILE, a comprehensive framework\nenhancing GUI agents at both the training and inference stages. For training,\nwe propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:\n1) a Continuous Reward function to incentivize high-precision grounding; 2) a\n\"Simple Thinking\" reward to balance planning with speed and grounding accuracy;\nand 3) a Cropping-based Resampling strategy to mitigate the sparse reward\nproblem and improve learning on complex tasks. For inference, we present\nDecomposed Grounding with Selection, a novel method that dramatically improves\ngrounding accuracy on high-resolution displays by breaking the image into\nsmaller, manageable parts. Experiments show that UI-AGILE achieves the\nstate-of-the-art performance on two benchmarks ScreenSpot-Pro and\nScreenSpot-v2. For instance, using both our proposed training and inference\nenhancement methods brings 23% grounding accuracy improvement over the best\nbaseline on ScreenSpot-Pro.\n","authors":["Shuquan Lian","Yuhang Wu","Jia Ma","Zihan Song","Bingqi Chen","Xiawu Zheng","Hui Li"],"pdf_url":"https://arxiv.org/pdf/2507.22025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22603v1","updated":"2025-07-30T12:16:39Z","published":"2025-07-30T12:16:39Z","title":"BALSAM: A Platform for Benchmarking Arabic Large Language Models","summary":"  The impressive advancement of Large Language Models (LLMs) in English has not\nbeen matched across all languages. In particular, LLM performance in Arabic\nlags behind, due to data scarcity, linguistic diversity of Arabic and its\ndialects, morphological complexity, etc. Progress is further hindered by the\nquality of Arabic benchmarks, which typically rely on static, publicly\navailable data, lack comprehensive task coverage, or do not provide dedicated\nplatforms with blind test sets. This makes it challenging to measure actual\nprogress and to mitigate data contamination. Here, we aim to bridge these gaps.\nIn particular, we introduce BALSAM, a comprehensive, community-driven benchmark\naimed at advancing Arabic LLM development and evaluation. It includes 78 NLP\ntasks from 14 broad categories, with 52K examples divided into 37K test and 15K\ndevelopment, and a centralized, transparent platform for blind evaluation. We\nenvision BALSAM as a unifying platform that sets standards and promotes\ncollaborative research to advance Arabic LLM capabilities.\n","authors":["Rawan Al-Matham","Kareem Darwish","Raghad Al-Rasheed","Waad Alshammari","Muneera Alhoshan","Amal Almazrua","Asma Al Wazrah","Mais Alheraki","Firoj Alam","Preslav Nakov","Norah Alzahrani","Eman alBilali","Nizar Habash","Abdelrahman El-Sheikh","Muhammad Elmallah","Haonan Li","Hamdy Mubarak","Mohamed Anwar","Zaid Alyafeai","Ahmed Abdelali","Nora Altwairesh","Maram Hasanain","Abdulmohsen Al Thubaity","Shady Shehata","Bashar Alhafni","Injy Hamed","Go Inoue","Khalid Elmadani","Ossama Obeid","Fatima Haouari","Tamer Elsayed","Emad Alghamdi","Khalid Almubarak","Saied Alshahrani","Ola Aljarrah","Safa Alajlan","Areej Alshaqarawi","Maryam Alshihri","Sultana Alghurabi","Atikah Alzeghayer","Afrah Altamimi","Abdullah Alfaifi","Abdulrahman AlOsaimy"],"pdf_url":"https://arxiv.org/pdf/2507.22603v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.15586v4","updated":"2025-07-30T11:51:25Z","published":"2025-07-21T13:03:55Z","title":"Learning to Extract Rational Evidence via Reinforcement Learning for\n  Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) effectively improves the accuracy of\nLarge Language Models (LLMs). However, retrieval noises significantly impact\nthe quality of LLMs' generation, necessitating the development of denoising\nmechanisms. Previous methods extract evidence straightforwardly without\nexplicit thinking, which risks filtering out key clues and struggles with\ngeneralization. To this end, we propose EviOmni, which learns to extract\nrational evidence by (1) explicitly reasoning to identify potential cues within\nretrieval contents first, and then (2) consciously extracting to avoid omitting\nany key cues helpful for answering questions. Specifically, we frame evidence\nreasoning and evidence extraction into one unified response for end-to-end\ntraining; apply knowledge token masks for disentanglement to derive\nreasoning-based and extraction-based answers; and devise three types of\nverifiable reward functions, including answer, length, and format, to update\nthe model via the policy optimization algorithm. Extensive experiments on three\nbenchmark datasets show the effectiveness of EviOmni, providing compact and\nhigh-quality evidence, improving the accuracy of downstream tasks, and\npromoting effective application in online RAG systems.\n","authors":["Xinping Zhao","Shouzheng Huang","Yan Zhong","Xinshuo Hu","Meishan Zhang","Baotian Hu","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.15586v4.pdf","comment":"16 pages, 7 Figures, 10 Tables"},{"id":"http://arxiv.org/abs/2404.07214v3","updated":"2025-07-30T11:37:10Z","published":"2024-02-20T18:57:34Z","title":"Exploring the Frontier of Vision-Language Models: A Survey of Current\n  Methodologies and Future Directions","summary":"  The advent of Large Language Models (LLMs) has significantly reshaped the\ntrajectory of the AI revolution. Nevertheless, these LLMs exhibit a notable\nlimitation, as they are primarily adept at processing textual information. To\naddress this constraint, researchers have endeavored to integrate visual\ncapabilities with LLMs, resulting in the emergence of Vision-Language Models\n(VLMs). These advanced models are instrumental in tackling more intricate tasks\nsuch as image captioning and visual question answering. In our comprehensive\nsurvey paper, we delve into the key advancements within the realm of VLMs. Our\nclassification organizes VLMs into three distinct categories: models dedicated\nto vision-language understanding, models that process multimodal inputs to\ngenerate unimodal (textual) outputs and models that both accept and produce\nmultimodal inputs and outputs.This classification is based on their respective\ncapabilities and functionalities in processing and generating various\nmodalities of data.We meticulously dissect each model, offering an extensive\nanalysis of its foundational architecture, training data sources, as well as\nits strengths and limitations wherever possible, providing readers with a\ncomprehensive understanding of its essential components. We also analyzed the\nperformance of VLMs in various benchmark datasets. By doing so, we aim to offer\na nuanced understanding of the diverse landscape of VLMs. Additionally, we\nunderscore potential avenues for future research in this dynamic domain,\nanticipating further breakthroughs and advancements.\n","authors":["Akash Ghosh","Arkadeep Acharya","Sriparna Saha","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2404.07214v3.pdf","comment":"One of the first survey on Visual Language Models"},{"id":"http://arxiv.org/abs/2507.22581v1","updated":"2025-07-30T11:23:30Z","published":"2025-07-30T11:23:30Z","title":"Unveiling the Influence of Amplifying Language-Specific Neurons","summary":"  Language-specific neurons in LLMs that strongly correlate with individual\nlanguages have been shown to influence model behavior by deactivating them.\nHowever, their role in amplification remains underexplored. This work\ninvestigates the effect of amplifying language-specific neurons through\ninterventions across 18 languages, including low-resource ones, using three\nmodels primarily trained in different languages. We compare amplification\nfactors by their effectiveness in steering to the target language using a\nproposed Language Steering Shift (LSS) evaluation score, then evaluate it on\ndownstream tasks: commonsense reasoning (XCOPA, XWinograd), knowledge\n(Include), and translation (FLORES). The optimal amplification factors\neffectively steer output toward nearly all tested languages. Intervention using\nthis factor on downstream tasks improves self-language performance in some\ncases but generally degrades cross-language results. These findings highlight\nthe effect of language-specific neurons in multilingual behavior, where\namplification can be beneficial especially for low-resource languages, but\nprovides limited advantage for cross-lingual transfer.\n","authors":["Inaya Rahmanisa","Lyzander Marciano Andrylie","Krisna Mahardika Ihsani","Alfan Farizki Wicaksono","Haryo Akbarianto Wibowo","Alham Fikri Aji"],"pdf_url":"https://arxiv.org/pdf/2507.22581v1.pdf","comment":"Our code and dataset are made available at\n  https://github.com/tauimbz/lang-task-neuron"},{"id":"http://arxiv.org/abs/2412.08528v2","updated":"2025-07-30T11:13:27Z","published":"2024-12-11T16:38:34Z","title":"Efficient Continual Learning for Small Language Models with a Discrete\n  Key-Value Bottleneck","summary":"  Continual learning remains a challenge across various natural language\nprocessing (NLP) tasks, as models updated with new training data often risk\ncatastrophic forgetting of previously acquired knowledge. We introduce a\ndiscrete key-value bottleneck (DKVB) for encoder-only language models, enabling\nefficient continual learning through localized updates. Inspired by a discrete\nkey-value bottleneck in vision, we consider new and NLP-specific challenges. We\ncompare different bottleneck architectures for NLP and introduce a new,\ntask-independent initialization technique for the discrete keys. We evaluate\nour DKVB for NLP in four continual learning scenarios and show that it\nalleviates catastrophic forgetting. Our experiments demonstrate that the\nproposed approach achieves competitive performance compared to popular\ncontinual learning methods while incurring lower computational costs.\nFurthermore, we show that DKVB remains effective even in challenging\nsingle-head continual learning scenarios where no task ID is provided.\n","authors":["Andor Diera","Lukas Galke","Fabian Karl","Ansgar Scherp"],"pdf_url":"https://arxiv.org/pdf/2412.08528v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22565v1","updated":"2025-07-30T10:46:53Z","published":"2025-07-30T10:46:53Z","title":"Efficient Differentially Private Fine-Tuning of LLMs via Reinforcement\n  Learning","summary":"  The tension between data privacy and model utility has become the defining\nbottleneck for the practical deployment of large language models (LLMs) trained\non sensitive corpora including healthcare. Differentially private stochastic\ngradient descent (DP-SGD) guarantees formal privacy, yet it does so at a\npronounced cost: gradients are forcibly clipped and perturbed with noise,\ndegrading sample efficiency and final accuracy. Numerous variants have been\nproposed to soften this trade-off, but they all share a handicap: their control\nknobs are hard-coded, global, and oblivious to the evolving optimization\nlandscape. Consequently, practitioners are forced either to over-spend privacy\nbudget in pursuit of utility, or to accept mediocre models in order to stay\nwithin privacy constraints. We present RLDP, the first framework to cast DP\noptimization itself as a closed-loop control problem amenable to modern deep\nreinforcement learning (RL). RLDP continuously senses rich statistics of the\nlearning dynamics and acts by selecting fine-grained per parameter\ngradient-clipping thresholds as well as the magnitude of injected Gaussian\nnoise. A soft actor-critic (SAC) hyper-policy is trained online during language\nmodel fine-tuning; it learns, from scratch, how to allocate the privacy budget\nwhere it matters and when it matters. Across more than 1,600 ablation\nexperiments on GPT2-small, Llama-1B, Llama-3B, and Mistral-7B, RLDP delivers\nperplexity reductions of 1.3-30.5% (mean 5.4%) and an average 5.6% downstream\nutility gain. RLDP reaches each baseline's final utility after only 13-43% of\nthe gradient-update budget (mean speed-up 71%), all while honoring the same\n($\\epsilon$, $\\delta$)-DP contract and exhibiting equal or lower susceptibility\nto membership-inference and canary-extraction attacks.\n","authors":["Afshin Khadangi","Amir Sartipi","Igor Tchappi","Ramin Bahmani","Gilbert Fridgen"],"pdf_url":"https://arxiv.org/pdf/2507.22565v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22564v1","updated":"2025-07-30T10:40:53Z","published":"2025-07-30T10:40:53Z","title":"Exploiting Synergistic Cognitive Biases to Bypass Safety in LLMs","summary":"  Large Language Models (LLMs) demonstrate impressive capabilities across a\nwide range of tasks, yet their safety mechanisms remain susceptible to\nadversarial attacks that exploit cognitive biases -- systematic deviations from\nrational judgment. Unlike prior jailbreaking approaches focused on prompt\nengineering or algorithmic manipulation, this work highlights the overlooked\npower of multi-bias interactions in undermining LLM safeguards. We propose\nCognitiveAttack, a novel red-teaming framework that systematically leverages\nboth individual and combined cognitive biases. By integrating supervised\nfine-tuning and reinforcement learning, CognitiveAttack generates prompts that\nembed optimized bias combinations, effectively bypassing safety protocols while\nmaintaining high attack success rates. Experimental results reveal significant\nvulnerabilities across 30 diverse LLMs, particularly in open-source models.\nCognitiveAttack achieves a substantially higher attack success rate compared to\nthe SOTA black-box method PAP (60.1% vs. 31.6%), exposing critical limitations\nin current defense mechanisms. These findings highlight multi-bias interactions\nas a powerful yet underexplored attack vector. This work introduces a novel\ninterdisciplinary perspective by bridging cognitive science and LLM safety,\npaving the way for more robust and human-aligned AI systems.\n","authors":["Xikang Yang","Biyu Zhou","Xuehai Tang","Jizhong Han","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2507.22564v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16936v2","updated":"2025-07-30T10:40:50Z","published":"2024-12-22T09:14:35Z","title":"Rationale-guided Prompting for Knowledge-based Visual Question Answering","summary":"  Recently, Large Language Models (LLMs) have been used for knowledge-based\nVisual Question Answering (VQA). Despite the encouraging results of previous\nstudies, prior methods prompt LLMs to predict answers directly, neglecting\nintermediate thought processes. We argue that prior methods do not sufficiently\nactivate the capacities of LLMs. We propose a framework called PLRH that\nPrompts LLMs with Rationale Heuristics for knowledge-based VQA. The PLRH\nprompts LLMs with Chain of Thought (CoT) to generate rationale heuristics,\ni.e., intermediate thought processes, and then leverages the rationale\nheuristics to inspire LLMs to predict answers. Experiments show that our\napproach outperforms the existing baselines by more than 2.2 and 2.1 on OK-VQA\nand A-OKVQA, respectively.\n","authors":["Zhongjian Hu","Peng Yang","Bing Li","Fengyuan Liu"],"pdf_url":"https://arxiv.org/pdf/2412.16936v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19010v2","updated":"2025-07-30T10:40:17Z","published":"2025-05-25T07:26:00Z","title":"Co-AttenDWG: Co-Attentive Dimension-Wise Gating and Expert Fusion for\n  Multi-Modal Offensive Content Detection","summary":"  Multi-modal learning has emerged as a crucial research direction, as\nintegrating textual and visual information can substantially enhance\nperformance in tasks such as classification, retrieval, and scene\nunderstanding. Despite advances with large pre-trained models, existing\napproaches often suffer from insufficient cross-modal interactions and rigid\nfusion strategies, failing to fully harness the complementary strengths of\ndifferent modalities. To address these limitations, we propose Co-AttenDWG,\nco-attention with dimension-wise gating, and expert fusion. Our approach first\nprojects textual and visual features into a shared embedding space, where a\ndedicated co-attention mechanism enables simultaneous, fine-grained\ninteractions between modalities. This is further strengthened by a\ndimension-wise gating network, which adaptively modulates feature contributions\nat the channel level to emphasize salient information. In parallel, dual-path\nencoders independently refine modality-specific representations, while an\nadditional cross-attention layer aligns the modalities further. The resulting\nfeatures are aggregated via an expert fusion module that integrates learned\ngating and self-attention, yielding a robust unified representation.\nExperimental results on the MIMIC and SemEval Memotion 1.0 datasets show that\nCo-AttenDWG achieves state-of-the-art performance and superior cross-modal\nalignment, highlighting its effectiveness for diverse multi-modal applications.\n","authors":["Md. Mithun Hossain","Md. Shakil Hossain","Sudipto Chaki","M. F. Mridha"],"pdf_url":"https://arxiv.org/pdf/2505.19010v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22545v1","updated":"2025-07-30T10:17:07Z","published":"2025-07-30T10:17:07Z","title":"ControlMed: Adding Reasoning Control to Medical Language Model","summary":"  Reasoning Large Language Models (LLMs) with enhanced accuracy and\nexplainability are increasingly being adopted in the medical domain, as the\nlife-critical nature of clinical decision-making demands reliable support.\nDespite these advancements, existing reasoning LLMs often generate\nunnecessarily lengthy reasoning processes, leading to significant computational\noverhead and response latency. These limitations hinder their practical\ndeployment in real-world clinical environments. To address these challenges, we\nintroduce \\textbf{ControlMed}, a medical language model that enables users to\nactively control the length of the reasoning process at inference time through\nfine-grained control markers. ControlMed is trained through a three-stage\npipeline: 1) pre-training on a large-scale synthetic medical instruction\ndataset covering both \\textit{direct} and \\textit{reasoning responses}; 2)\nsupervised fine-tuning with multi-length reasoning data and explicit\nlength-control markers; and 3) reinforcement learning with model-based reward\nsignals to enhance factual accuracy and response quality. Experimental results\non a variety of English and Korean medical benchmarks demonstrate that our\nmodel achieves similar or better performance compared to state-of-the-art\nmodels. Furthermore, users can flexibly balance reasoning accuracy and\ncomputational efficiency by controlling the reasoning length as needed. These\nfindings demonstrate that ControlMed is a practical and adaptable solution for\nclinical question answering and medical information analysis.\n","authors":["Sung-Min Lee","Siyoon Lee","Juyeon Kim","Kyungmin Roh"],"pdf_url":"https://arxiv.org/pdf/2507.22545v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2507.22543v1","updated":"2025-07-30T10:16:23Z","published":"2025-07-30T10:16:23Z","title":"Pre-trained Models Perform the Best When Token Distributions Follow\n  Zipf's Law","summary":"  Tokenization is a fundamental step in natural language processing (NLP) and\nother sequence modeling domains, where the choice of vocabulary size\nsignificantly impacts model performance. Despite its importance, selecting an\noptimal vocabulary size remains underexplored, typically relying on heuristics\nor dataset-specific choices. In this work, we propose a principled method for\ndetermining the vocabulary size by analyzing token frequency distributions\nthrough Zipf's law. We show that downstream task performance correlates with\nhow closely token distributions follow power-law behavior, and that aligning\nwith Zipfian scaling improves both model efficiency and effectiveness.\nExtensive experiments across NLP, genomics, and chemistry demonstrate that\nmodels consistently achieve peak performance when the token distribution\nclosely adheres to Zipf's law, establishing Zipfian alignment as a robust and\ngeneralizable criterion for vocabulary size selection.\n","authors":["Yanjin He","Qingkai Zeng","Meng Jiang"],"pdf_url":"https://arxiv.org/pdf/2507.22543v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2507.22880v1","updated":"2025-07-30T17:55:09Z","published":"2025-07-30T17:55:09Z","title":"AUV-Fusion: Cross-Modal Adversarial Fusion of User Interactions and\n  Visual Perturbations Against VARS","summary":"  Modern Visual-Aware Recommender Systems (VARS) exploit the integration of\nuser interaction data and visual features to deliver personalized\nrecommendations with high precision. However, their robustness against\nadversarial attacks remains largely underexplored, posing significant risks to\nsystem reliability and security. Existing attack strategies suffer from notable\nlimitations: shilling attacks are costly and detectable, and visual-only\nperturbations often fail to align with user preferences. To address these\nchallenges, we propose AUV-Fusion, a cross-modal adversarial attack framework\nthat adopts high-order user preference modeling and cross-modal adversary\ngeneration. Specifically, we obtain robust user embeddings through multi-hop\nuser-item interactions and transform them via an MLP into semantically aligned\nperturbations. These perturbations are injected onto the latent space of a\npre-trained VAE within the diffusion model. By synergistically integrating\ngenuine user interaction data with visually plausible perturbations, AUV-Fusion\neliminates the need for injecting fake user profiles and effectively mitigates\nthe challenge of insufficient user preference extraction inherent in\ntraditional visual-only attacks. Comprehensive evaluations on diverse VARS\narchitectures and real-world datasets demonstrate that AUV-Fusion significantly\nenhances the exposure of target (cold-start) items compared to conventional\nbaseline methods. Moreover, AUV-Fusion maintains exceptional stealth under\nrigorous scrutiny.\n","authors":["Hai Ling","Tianchi Wang","Xiaohao Liu","Zhulin Tao","Lifang Yang","Xianglin Huang"],"pdf_url":"https://arxiv.org/pdf/2507.22880v1.pdf","comment":"14 pages,6 figures"},{"id":"http://arxiv.org/abs/2507.22879v1","updated":"2025-07-30T17:55:06Z","published":"2025-07-30T17:55:06Z","title":"RecGPT Technical Report","summary":"  Recommender systems are among the most impactful applications of artificial\nintelligence, serving as critical infrastructure connecting users, merchants,\nand platforms. However, most current industrial systems remain heavily reliant\non historical co-occurrence patterns and log-fitting objectives, i.e.,\noptimizing for past user interactions without explicitly modeling user intent.\nThis log-fitting approach often leads to overfitting to narrow historical\npreferences, failing to capture users' evolving and latent interests. As a\nresult, it reinforces filter bubbles and long-tail phenomena, ultimately\nharming user experience and threatening the sustainability of the whole\nrecommendation ecosystem.\n  To address these challenges, we rethink the overall design paradigm of\nrecommender systems and propose RecGPT, a next-generation framework that places\nuser intent at the center of the recommendation pipeline. By integrating large\nlanguage models (LLMs) into key stages of user interest mining, item retrieval,\nand explanation generation, RecGPT transforms log-fitting recommendation into\nan intent-centric process. To effectively align general-purpose LLMs to the\nabove domain-specific recommendation tasks at scale, RecGPT incorporates a\nmulti-stage training paradigm, which integrates reasoning-enhanced\npre-alignment and self-training evolution, guided by a Human-LLM cooperative\njudge system. Currently, RecGPT has been fully deployed on the Taobao App.\nOnline experiments demonstrate that RecGPT achieves consistent performance\ngains across stakeholders: users benefit from increased content diversity and\nsatisfaction, merchants and the platform gain greater exposure and conversions.\nThese comprehensive improvement results across all stakeholders validates that\nLLM-driven, intent-centric design can foster a more sustainable and mutually\nbeneficial recommendation ecosystem.\n","authors":["Chao Yi","Dian Chen","Gaoyang Guo","Jiakai Tang","Jian Wu","Jing Yu","Sunhao Dai","Wen Chen","Wenjun Yang","Yuning Jiang","Zhujin Gao","Bo Zheng","Chi Li","Dimin Wang","Dixuan Wang","Fan Li","Fan Zhang","Haibin Chen","Haozhuang Liu","Jialin Zhu","Jiamang Wang","Jiawei Wu","Jin Cui","Ju Huang","Kai Zhang","Kan Liu","Lang Tian","Liang Rao","Longbin Li","Lulu Zhao","Mao Zhang","Na He","Peiyang Wang","Qiqi Huang","Tao Luo","Wenbo Su","Xiaoxiao He","Xin Tong","Xu Chen","Xunke Xi","Yang Li","Yaxuan Wu","Yeqiu Yang","Yi Hu","Yinnan Song","Yuchen Li","Yujie Luo","Yujin Yuan","Yuliang Yan","Zhengyang Wang","Zhibo Xiao","Zhixin Ma","Zile Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.22879v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22878v1","updated":"2025-07-30T17:54:38Z","published":"2025-07-30T17:54:38Z","title":"GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for\n  Multiresolution Power Outage Analysis","summary":"  Detecting, analyzing, and predicting power outages is crucial for grid risk\nassessment and disaster mitigation. Numerous outages occur each year,\nexacerbated by extreme weather events such as hurricanes. Existing outage data\nare typically reported at the county level, limiting their spatial resolution\nand making it difficult to capture localized patterns. However, it offers\nexcellent temporal granularity. In contrast, nighttime light satellite image\ndata provides significantly higher spatial resolution and enables a more\ncomprehensive spatial depiction of outages, enhancing the accuracy of assessing\nthe geographic extent and severity of power loss after disaster events.\nHowever, these satellite data are only available on a daily basis. Integrating\nspatiotemporal visual and time-series data sources into a unified knowledge\nrepresentation can substantially improve power outage detection, analysis, and\npredictive reasoning. In this paper, we propose GeoOutageKG, a multimodal\nknowledge graph that integrates diverse data sources, including nighttime light\nsatellite image data, high-resolution spatiotemporal power outage maps, and\ncounty-level timeseries outage reports in the U.S. We describe our method for\nconstructing GeoOutageKG by aligning source data with a developed ontology,\nGeoOutageOnto. Currently, GeoOutageKG includes over 10.6 million individual\noutage records spanning from 2014 to 2024, 300,000 NTL images spanning from\n2012 to 2024, and 15,000 outage maps. GeoOutageKG is a novel, modular and\nreusable semantic resource that enables robust multimodal data integration. We\ndemonstrate its use through multiresolution analysis of geospatiotemporal power\noutages.\n","authors":["Ethan Frakes","Yinghui Wu","Roger H. French","Mengjie Li"],"pdf_url":"https://arxiv.org/pdf/2507.22878v1.pdf","comment":"Accepted to the 24th International Semantic Web Conference Resource\n  Track (ISWC 2025)"},{"id":"http://arxiv.org/abs/2507.01053v2","updated":"2025-07-30T13:27:00Z","published":"2025-06-27T16:24:17Z","title":"Conversational LLMs Simplify Secure Clinical Data Access, Understanding,\n  and Analysis","summary":"  As ever-larger clinical datasets become available, they have the potential to\nunlock unprecedented opportunities for medical research. Foremost among them is\nMedical Information Mart for Intensive Care (MIMIC-IV), the world's largest\nopen-source EHR database. However, the inherent complexity of these datasets,\nparticularly the need for sophisticated querying skills and the need to\nunderstand the underlying clinical settings, often presents a significant\nbarrier to their effective use. M3 lowers the technical barrier to\nunderstanding and querying MIMIC-IV data. With a single command it retrieves\nMIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the\nhosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers\nconverse with the database in plain English. Ask a clinical question in natural\nlanguage; M3 uses a language model to translate it into SQL, executes the query\nagainst the MIMIC-IV dataset, and returns structured results alongside the\nunderlying query for verifiability and reproducibility. Demonstrations show\nthat minutes of dialogue with M3 yield the kind of nuanced cohort analyses that\nonce demanded hours of handcrafted SQL and relied on understanding the\ncomplexities of clinical workflows. By simplifying access, M3 invites the\nbroader research community to mine clinical critical-care data and accelerates\nthe translation of raw records into actionable insight.\n","authors":["Rafi Al Attrach","Pedro Moreira","Rajna Fani","Renato Umeton","Leo Anthony Celi"],"pdf_url":"https://arxiv.org/pdf/2507.01053v2.pdf","comment":"10 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.22520v1","updated":"2025-07-30T09:46:56Z","published":"2025-07-30T09:46:56Z","title":"Sustainability Evaluation Metrics for Recommender Systems","summary":"  Sustainability-oriented evaluation metrics can help to assess the quality of\nrecommender systems beyond wide-spread metrics such as accuracy, precision,\nrecall, and satisfaction. Following the United Nations`s sustainable\ndevelopment goals (SDGs), such metrics can help to analyse the impact of\nrecommender systems on environmental, social, and economic aspects. We discuss\ndifferent basic sustainability evaluation metrics for recommender systems and\nanalyze their applications.\n","authors":["Alexander Felfernig","Damian Garber","Viet-Man Le","Sebastian Lubos","Thi Ngoc Trang Tran"],"pdf_url":"https://arxiv.org/pdf/2507.22520v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.16695v6","updated":"2025-07-30T05:26:45Z","published":"2023-05-26T07:31:30Z","title":"The Search for Stability: Learning Dynamics of Strategic Publishers with\n  Initial Documents","summary":"  We study a game-theoretic information retrieval model in which strategic\npublishers aim to maximize their chances of being ranked first by the search\nengine while maintaining the integrity of their original documents. We show\nthat the commonly used Probability Ranking Principle (PRP) ranking scheme\nresults in an unstable environment where games often fail to reach pure Nash\nequilibrium. We propose two families of ranking functions that do not adhere to\nthe PRP principle. We provide both theoretical and empirical evidence that\nthese methods lead to a stable search ecosystem, by providing positive results\non the learning dynamics convergence. We also define the publishers' and users'\nwelfare, demonstrate a possible publisher-user trade-off, and provide means for\na search system designer to control it. Finally, we show how instability harms\nlong-term users' welfare.\n","authors":["Omer Madmon","Idan Pipano","Itamar Reinman","Moshe Tennenholtz"],"pdf_url":"https://arxiv.org/pdf/2305.16695v6.pdf","comment":"Published in the Journal of Artificial Intelligence Research 83\n  (2025)"},{"id":"http://arxiv.org/abs/2507.22337v1","updated":"2025-07-30T02:44:20Z","published":"2025-07-30T02:44:20Z","title":"A Comprehensive Taxonomy of Negation for NLP and Neural Retrievers","summary":"  Understanding and solving complex reasoning tasks is vital for addressing the\ninformation needs of a user. Although dense neural models learn contextualised\nembeddings, they still underperform on queries containing negation. To\nunderstand this phenomenon, we study negation in both traditional neural\ninformation retrieval and LLM-based models. We (1) introduce a taxonomy of\nnegation that derives from philosophical, linguistic, and logical definitions;\n(2) generate two benchmark datasets that can be used to evaluate the\nperformance of neural information retrieval models and to fine-tune models for\na more robust performance on negation; and (3) propose a logic-based\nclassification mechanism that can be used to analyze the performance of\nretrieval models on existing datasets. Our taxonomy produces a balanced data\ndistribution over negation types, providing a better training setup that leads\nto faster convergence on the NevIR dataset. Moreover, we propose a\nclassification schema that reveals the coverage of negation types in existing\ndatasets, offering insights into the factors that might affect the\ngeneralization of fine-tuned models on negation.\n","authors":["Roxana Petcu","Samarth Bhargav","Maarten de Rijke","Evangelos Kanoulas"],"pdf_url":"https://arxiv.org/pdf/2507.22337v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2507.22877v1","updated":"2025-07-30T17:53:42Z","published":"2025-07-30T17:53:42Z","title":"Consistency of Feature Attribution in Deep Learning Architectures for\n  Multi-Omics","summary":"  Machine and deep learning have grown in popularity and use in biological\nresearch over the last decade but still present challenges in interpretability\nof the fitted model. The development and use of metrics to determine features\ndriving predictions and increase model interpretability continues to be an open\narea of research. We investigate the use of Shapley Additive Explanations\n(SHAP) on a multi-view deep learning model applied to multi-omics data for the\npurposes of identifying biomolecules of interest. Rankings of features via\nthese attribution methods are compared across various architectures to evaluate\nconsistency of the method. We perform multiple computational experiments to\nassess the robustness of SHAP and investigate modeling approaches and\ndiagnostics to increase and measure the reliability of the identification of\nimportant features. Accuracy of a random-forest model fit on subsets of\nfeatures selected as being most influential as well as clustering quality using\nonly these features are used as a measure of effectiveness of the attribution\nmethod. Our findings indicate that the rankings of features resulting from SHAP\nare sensitive to the choice of architecture as well as different random\ninitializations of weights, suggesting caution when using attribution methods\non multi-view deep learning models applied to multi-omics data. We present an\nalternative, simple method to assess the robustness of identification of\nimportant biomolecules.\n","authors":["Daniel Claborne","Javier Flores","Samantha Erwin","Luke Durell","Rachel Richardson","Ruby Fore","Lisa Bramer"],"pdf_url":"https://arxiv.org/pdf/2507.22877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22873v1","updated":"2025-07-30T17:47:25Z","published":"2025-07-30T17:47:25Z","title":"LCS: An AI-based Low-Complexity Scaler for Power-Efficient\n  Super-Resolution of Game Content","summary":"  The increasing complexity of content rendering in modern games has led to a\nproblematic growth in the workload of the GPU. In this paper, we propose an\nAI-based low-complexity scaler (LCS) inspired by state-of-the-art efficient\nsuper-resolution (ESR) models which could offload the workload on the GPU to a\nlow-power device such as a neural processing unit (NPU). The LCS is trained on\nGameIR image pairs natively rendered at low and high resolution. We utilize\nadversarial training to encourage reconstruction of perceptually important\ndetails, and apply reparameterization and quantization techniques to reduce\nmodel complexity and size. In our comparative analysis we evaluate the LCS\nalongside the publicly available AMD hardware-based Edge Adaptive Scaling\nFunction (EASF) and AMD FidelityFX Super Resolution 1 (FSR1) on five different\nmetrics, and find that the LCS achieves better perceptual quality,\ndemonstrating the potential of ESR models for upscaling on resource-constrained\ndevices.\n","authors":["Simon Pochinda","Momen K. Tageldeen","Mark Thompson","Tony Rinaldi","Troy Giorshev","Keith Lee","Jie Zhou","Frederick Walls"],"pdf_url":"https://arxiv.org/pdf/2507.22873v1.pdf","comment":"8 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.02610v2","updated":"2025-07-30T17:45:50Z","published":"2024-07-02T18:55:58Z","title":"Towards Federated Learning with On-device Training and Communication in\n  8-bit Floating Point","summary":"  Recent work has shown that 8-bit floating point (FP8) can be used for\nefficiently training neural networks with reduced computational cost compared\nto training in FP32/FP16. In this work, we investigate the use of FP8 training\nin a federated learning context. This approach brings not only the usual\nbenefits of FP8 which are desirable for on-device training at the edge, but\nalso reduces client-server communication costs due to significant weight\ncompression. We present a novel method for combining FP8 client training while\nmaintaining a global FP32 server model and provide convergence analysis.\nExperiments with various machine learning models and datasets show that our\nmethod consistently yields communication reductions of at least 2.9x across a\nvariety of tasks and models compared to an FP32 baseline to achieve the same\ntrained model accuracy.\n","authors":["Bokun Wang","Axel Berg","Durmus Alp Emre Acar","Chuteng Zhou"],"pdf_url":"https://arxiv.org/pdf/2407.02610v2.pdf","comment":"extended version"},{"id":"http://arxiv.org/abs/2501.13883v2","updated":"2025-07-30T17:37:43Z","published":"2025-01-23T17:56:40Z","title":"Utilizing Evolution Strategies to Train Transformers in Reinforcement\n  Learning","summary":"  We explore the capability of evolution strategies to train an agent with a\npolicy based on a transformer architecture in a reinforcement learning setting.\nWe performed experiments using OpenAI's highly parallelizable evolution\nstrategy to train Decision Transformer in the MuJoCo Humanoid locomotion\nenvironment and in the environment of Atari games, testing the ability of this\nblack-box optimization technique to train even such relatively large and\ncomplicated models (compared to those previously tested in the literature). The\nexamined evolution strategy proved to be, in general, capable of achieving\nstrong results and managed to produce high-performing agents, showcasing\nevolution's ability to tackle the training of even such complex models.\n","authors":["Matyáš Lorenc","Roman Neruda"],"pdf_url":"https://arxiv.org/pdf/2501.13883v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22859v1","updated":"2025-07-30T17:34:45Z","published":"2025-07-30T17:34:45Z","title":"Mesh based segmentation for automated margin line generation on incisors\n  receiving crown treatment","summary":"  Dental crowns are essential dental treatments for restoring damaged or\nmissing teeth of patients. Recent design approaches of dental crowns are\ncarried out using commercial dental design software. Once a scan of a\npreparation is uploaded to the software, a dental technician needs to manually\ndefine a precise margin line on the preparation surface, which constitutes a\nnon-repeatable and inconsistent procedure. This work proposes a new framework\nto determine margin lines automatically and accurately using deep learning. A\ndataset of incisor teeth was provided by a collaborating dental laboratory to\ntrain a deep learning segmentation model. A mesh-based neural network was\nmodified by changing its input channels and used to segment the prepared tooth\ninto two regions such that the margin line is contained within the boundary\nfaces separating the two regions. Next, k-fold cross-validation was used to\ntrain 5 models, and a voting classifier technique was used to combine their\nresults to enhance the segmentation. After that, boundary smoothing and\noptimization using the graph cut method were applied to refine the segmentation\nresults. Then, boundary faces separating the two regions were selected to\nrepresent the margin line faces. A spline was approximated to best fit the\ncenters of the boundary faces to predict the margin line. Our results show that\nan ensemble model combined with maximum probability predicted the highest\nnumber of successful test cases (7 out of 13) based on a maximum distance\nthreshold of 200 m (representing human error) between the predicted and ground\ntruth point clouds. It was also demonstrated that the better the quality of the\npreparation, the smaller the divergence between the predicted and ground truth\nmargin lines (Spearman's rank correlation coefficient of -0.683). We provide\nthe train and test datasets for the community.\n","authors":["Ammar Alsheghri","Ying Zhang","Farnoosh Ghadiri","Julia Keren","Farida Cheriet","Francois Guibault"],"pdf_url":"https://arxiv.org/pdf/2507.22859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.04395v2","updated":"2025-07-30T17:33:22Z","published":"2025-04-06T07:35:15Z","title":"Human-Level Competitive Pokémon via Scalable Offline Reinforcement\n  Learning with Transformers","summary":"  Competitive Pok\\'emon Singles (CPS) is a popular strategy game where players\nlearn to exploit their opponent based on imperfect information in battles that\ncan last more than one hundred stochastic turns. AI research in CPS has been\nled by heuristic tree search and online self-play, but the game may also create\na platform to study adaptive policies trained offline on large datasets. We\ndevelop a pipeline to reconstruct the first-person perspective of an agent from\nlogs saved from the third-person perspective of a spectator, thereby unlocking\na dataset of real human battles spanning more than a decade that grows larger\nevery day. This dataset enables a black-box approach where we train large\nsequence models to adapt to their opponent based solely on their input\ntrajectory while selecting moves without explicit search of any kind. We study\na progression from imitation learning to offline RL and offline fine-tuning on\nself-play data in the hardcore competitive setting of Pok\\'emon's four oldest\n(and most partially observed) game generations. The resulting agents outperform\na recent LLM Agent approach and a strong heuristic search engine. While playing\nanonymously in online battles against humans, our best agents climb to rankings\ninside the top 10% of active players. All agent checkpoints, training details,\ndatasets, and baselines are available at https://metamon.tech.\n","authors":["Jake Grigsby","Yuqi Xie","Justin Sasek","Steven Zheng","Yuke Zhu"],"pdf_url":"https://arxiv.org/pdf/2504.04395v2.pdf","comment":"Reinforcement Learning Conference 2025"},{"id":"http://arxiv.org/abs/2507.22857v1","updated":"2025-07-30T17:31:57Z","published":"2025-07-30T17:31:57Z","title":"Synchronization of mean-field models on the circle","summary":"  This paper considers a mean-field model of $n$ interacting particles whose\nstate space is the unit circle, a generalization of the classical Kuramoto\nmodel. Global synchronization is said to occur if after starting from almost\nany initial state, all particles coalesce to a common point on the circle. We\npropose a general synchronization criterion in terms of $L_1$-norm of the third\nderivative of the particle interaction function. As an application we resolve a\nconjecture for the so-called self-attention dynamics (stylized model of\ntransformers), by showing synchronization for all $\\beta \\ge -0.16$, which\nsignificantly extends the previous bound of $0\\le \\beta \\le 1$ from\nCriscitiello, Rebjock, McRae, and Boumal (2024). We also show that global\nsynchronization does not occur when $\\beta < -2/3$.\n","authors":["Yury Polyanskiy","Philippe Rigollet","Andrew Yao"],"pdf_url":"https://arxiv.org/pdf/2507.22857v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22855v1","updated":"2025-07-30T17:24:27Z","published":"2025-07-30T17:24:27Z","title":"Federated Learning on Riemannian Manifolds: A Gradient-Free\n  Projection-Based Approach","summary":"  Federated learning (FL) has emerged as a powerful paradigm for collaborative\nmodel training across distributed clients while preserving data privacy.\nHowever, existing FL algorithms predominantly focus on unconstrained\noptimization problems with exact gradient information, limiting its\napplicability in scenarios where only noisy function evaluations are accessible\nor where model parameters are constrained. To address these challenges, we\npropose a novel zeroth-order projection-based algorithm on Riemannian manifolds\nfor FL. By leveraging the projection operator, we introduce a computationally\nefficient zeroth-order Riemannian gradient estimator. Unlike existing\nestimators, ours requires only a simple Euclidean random perturbation,\neliminating the need to sample random vectors in the tangent space, thus\nreducing computational cost. Theoretically, we first prove the approximation\nproperties of the estimator and then establish the sublinear convergence of the\nproposed algorithm, matching the rate of its first-order counterpart.\nNumerically, we first assess the efficiency of our estimator using kernel\nprincipal component analysis. Furthermore, we apply the proposed algorithm to\ntwo real-world scenarios: zeroth-order attacks on deep neural networks and\nlow-rank neural network training to validate the theoretical findings.\n","authors":["Hongye Wang","Zhaoye Pan","Chang He","Jiaxiang Li","Bo Jiang"],"pdf_url":"https://arxiv.org/pdf/2507.22855v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22854v1","updated":"2025-07-30T17:24:23Z","published":"2025-07-30T17:24:23Z","title":"A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for\n  Reinforcement Learning under a Generative Model","summary":"  We propose novel classical and quantum online algorithms for learning\nfinite-horizon and infinite-horizon average-reward Markov Decision Processes\n(MDPs). Our algorithms are based on a hybrid exploration-generative\nreinforcement learning (RL) model wherein the agent can, from time to time,\nfreely interact with the environment in a generative sampling fashion, i.e., by\nhaving access to a \"simulator\". By employing known classical and new quantum\nalgorithms for approximating optimal policies under a generative model within\nour learning algorithms, we show that it is possible to avoid several paradigms\nfrom RL like \"optimism in the face of uncertainty\" and \"posterior sampling\" and\ninstead compute and use optimal policies directly, which yields better regret\nbounds compared to previous works. For finite-horizon MDPs, our quantum\nalgorithms obtain regret bounds which only depend logarithmically on the number\nof time steps $T$, thus breaking the $O(\\sqrt{T})$ classical barrier. This\nmatches the time dependence of the prior quantum works of Ganguly et al.\n(arXiv'23) and Zhong et al. (ICML'24), but with improved dependence on other\nparameters like state space size $S$ and action space size $A$. For\ninfinite-horizon MDPs, our classical and quantum bounds still maintain the\n$O(\\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we\npropose a novel measure of regret for infinite-horizon MDPs with respect to\nwhich our quantum algorithms have $\\operatorname{poly}\\log{T}$ regret,\nexponentially better compared to classical algorithms. Finally, we generalise\nall of our results to compact state spaces.\n","authors":["Andris Ambainis","Joao F. Doriguello","Debbie Lim"],"pdf_url":"https://arxiv.org/pdf/2507.22854v1.pdf","comment":"57 pages"},{"id":"http://arxiv.org/abs/2502.12920v3","updated":"2025-07-30T17:23:56Z","published":"2025-02-18T15:01:02Z","title":"Lightweight Online Adaption for Time Series Foundation Model Forecasts","summary":"  Foundation models (FMs) have emerged as a promising approach for time series\nforecasting. While effective, FMs typically remain fixed during deployment due\nto the high computational costs of learning them online. Consequently, deployed\nFMs fail to adapt their forecasts to current data characteristics, despite the\navailability of online feedback from newly arriving data. This raises the\nquestion of whether FM performance can be enhanced by the efficient usage of\nthis feedback. We propose ELF to answer this question. ELF is a lightweight\nmechanism for the online adaption of FM forecasts in response to online\nfeedback. ELF consists of two parts: a) the ELF-Forecaster which is used to\nlearn the current data distribution; and b) the ELF-Weighter which is used to\ncombine the forecasts of the FM and the ELF-Forecaster. We evaluate the\nperformance of ELF in conjunction with several recent FMs across a suite of\nstandard time series datasets. In all of our experiments we find that using ELF\nimproves performance. This work demonstrates how efficient usage of online\nfeedback can be used to improve FM forecasts.\n","authors":["Thomas L. Lee","William Toner","Rajkarn Singh","Artjom Joosen","Martin Asenov"],"pdf_url":"https://arxiv.org/pdf/2502.12920v3.pdf","comment":"9 pages, Published at ICML 2025"},{"id":"http://arxiv.org/abs/2507.20930v2","updated":"2025-07-30T17:19:41Z","published":"2025-07-28T15:41:53Z","title":"FRED: Financial Retrieval-Enhanced Detection and Editing of\n  Hallucinations in Language Models","summary":"  Hallucinations in large language models pose a critical challenge for\napplications requiring factual reliability, particularly in high-stakes domains\nsuch as finance. This work presents an effective approach for detecting and\nediting factually incorrect content in model-generated responses based on the\nprovided context. Given a user-defined domain-specific error taxonomy, we\nconstruct a synthetic dataset by inserting tagged errors into financial\nquestion-answering corpora and then fine-tune four language models, Phi-4,\nPhi-4-mini, Qwen3-4B, and Qwen3-14B, to detect and edit these factual\ninaccuracies. Our best-performing model, fine-tuned Phi-4, achieves an 8%\nimprovement in binary F1 score and a 30% gain in overall detection performance\ncompared to OpenAI-o3. Notably, our fine-tuned Phi-4-mini model, despite having\nonly 4 billion parameters, maintains competitive performance with just a 2%\ndrop in binary detection and a 0.1% decline in overall detection compared to\nOpenAI-o3. Our work provides a practical solution for detecting and editing\nfactual inconsistencies in financial text generation while introducing a\ngeneralizable framework that can enhance the trustworthiness and alignment of\nlarge language models across diverse applications beyond finance. Our code and\ndata are available at https://github.com/pegasi-ai/shield.\n","authors":["Likun Tan","Kuan-Wei Huang","Kevin Wu"],"pdf_url":"https://arxiv.org/pdf/2507.20930v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06680v2","updated":"2025-07-30T17:16:46Z","published":"2025-01-12T01:31:07Z","title":"Application of Vision-Language Model to Pedestrians Behavior and Scene\n  Understanding in Autonomous Driving","summary":"  Vision-language models (VLMs) have become a promising approach to enhancing\nperception and decision-making in autonomous driving. The gap remains in\napplying VLMs to understand complex scenarios interacting with pedestrians and\nefficient vehicle deployment. In this paper, we propose a knowledge\ndistillation method that transfers knowledge from large-scale vision-language\nfoundation models to efficient vision networks, and we apply it to pedestrian\nbehavior prediction and scene understanding tasks, achieving promising results\nin generating more diverse and comprehensive semantic attributes. We also\nutilize multiple pre-trained models and ensemble techniques to boost the\nmodel's performance. We further examined the effectiveness of the model after\nknowledge distillation; the results show significant metric improvements in\nopen-vocabulary perception and trajectory prediction tasks, which can\npotentially enhance the end-to-end performance of autonomous driving.\n","authors":["Haoxiang Gao","Li Zhang","Yu Zhao","Zhou Yang","Jinghan Cao"],"pdf_url":"https://arxiv.org/pdf/2501.06680v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22849v1","updated":"2025-07-30T17:15:50Z","published":"2025-07-30T17:15:50Z","title":"Decentralized Differentially Private Power Method","summary":"  We propose a novel Decentralized Differentially Private Power Method\n(D-DP-PM) for performing Principal Component Analysis (PCA) in networked\nmulti-agent settings. Unlike conventional decentralized PCA approaches where\neach agent accesses the full n-dimensional sample space, we address the\nchallenging scenario where each agent observes only a subset of dimensions\nthrough row-wise data partitioning. Our method ensures\n$(\\epsilon,\\delta)$-Differential Privacy (DP) while enabling collaborative\nestimation of global eigenvectors across the network without requiring a\ncentral aggregator. We achieve this by having agents share only local\nembeddings of the current eigenvector iterate, leveraging both the inherent\nprivacy from random initialization and carefully calibrated Gaussian noise\nadditions. We prove that our algorithm satisfies the prescribed\n$(\\epsilon,\\delta)$-DP guarantee and establish convergence rates that\nexplicitly characterize the impact of the network topology. Our theoretical\nanalysis, based on linear dynamics and high-dimensional probability theory,\nprovides tight bounds on both privacy and utility. Experiments on real-world\ndatasets demonstrate that D-DP-PM achieves superior privacy-utility tradeoffs\ncompared to naive local DP approaches, with particularly strong performance in\nmoderate privacy regimes ($\\epsilon\\in[2, 5]$). The method converges rapidly,\nallowing practitioners to trade iterations for enhanced privacy while\nmaintaining competitive utility.\n","authors":["Andrew Campbell","Anna Scaglione","Sean Peisert"],"pdf_url":"https://arxiv.org/pdf/2507.22849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19194v2","updated":"2025-07-30T17:06:45Z","published":"2025-05-25T15:41:11Z","title":"Curvature Dynamic Black-box Attack: revisiting adversarial robustness\n  via dynamic curvature estimation","summary":"  Adversarial attack reveals the vulnerability of deep learning models. For\nabout a decade, countless attack and defense methods have been proposed,\nleading to robustified classifiers and better understanding of models. Among\nthese methods, curvature-based approaches have attracted attention because it\nis assumed that high curvature may give rise to rough decision boundary.\nHowever, the most commonly used \\textit{curvature} is the curvature of loss\nfunction, scores or other parameters from within the model as opposed to\ndecision boundary curvature, since the former can be relatively easily formed\nusing second order derivative. In this paper, we propose a new query-efficient\nmethod, dynamic curvature estimation(DCE), to estimate the decision boundary\ncurvature in a black-box setting. Our approach is based on CGBA, a black-box\nadversarial attack. By performing DCE on a wide range of classifiers, we\ndiscovered, statistically, a connection between decision boundary curvature and\nadversarial robustness. We also propose a new attack method, curvature dynamic\nblack-box attack(CDBA) with improved performance using the dynamically\nestimated curvature.\n","authors":["Peiran Sun"],"pdf_url":"https://arxiv.org/pdf/2505.19194v2.pdf","comment":"This article contains several flaws"},{"id":"http://arxiv.org/abs/2507.22844v1","updated":"2025-07-30T17:00:48Z","published":"2025-07-30T17:00:48Z","title":"RLVMR: Reinforcement Learning with Verifiable Meta-Reasoning Rewards for\n  Robust Long-Horizon Agents","summary":"  The development of autonomous agents for complex, long-horizon tasks is a\ncentral goal in AI. However, dominant training paradigms face a critical\nlimitation: reinforcement learning (RL) methods that optimize solely for final\ntask success often reinforce flawed or inefficient reasoning paths, a problem\nwe term inefficient exploration. This leads to agents that are brittle and fail\nto generalize, as they learn to find solutions without learning how to reason\ncoherently. To address this, we introduce RLVMR, a novel framework that\nintegrates dense, process-level supervision into end-to-end RL by rewarding\nverifiable, meta-reasoning behaviors. RLVMR equips an agent to explicitly tag\nits cognitive steps, such as planning, exploration, and reflection, and\nprovides programmatic, rule-based rewards for actions that contribute to\neffective problem-solving. These process-centric rewards are combined with the\nfinal outcome signal and optimized using a critic-free policy gradient method.\nOn the challenging ALFWorld and ScienceWorld benchmarks, RLVMR achieves new\nstate-of-the-art results, with our 7B model reaching an 83.6% success rate on\nthe most difficult unseen task split. Our analysis confirms these gains stem\nfrom improved reasoning quality, including significant reductions in redundant\nactions and enhanced error recovery, leading to more robust, efficient, and\ninterpretable agents.\n","authors":["Zijing Zhang","Ziyang Chen","Mingxiao Li","Zhaopeng Tu","Xiaolong Li"],"pdf_url":"https://arxiv.org/pdf/2507.22844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22842v1","updated":"2025-07-30T17:00:05Z","published":"2025-07-30T17:00:05Z","title":"Subgrid BoostCNN: Efficient Boosting of Convolutional Networks via\n  Gradient-Guided Feature Selection","summary":"  Convolutional Neural Networks (CNNs) have achieved remarkable success across\na wide range of machine learning tasks by leveraging hierarchical feature\nlearning through deep architectures. However, the large number of layers and\nmillions of parameters often make CNNs computationally expensive to train,\nrequiring extensive time and manual tuning to discover optimal architectures.\nIn this paper, we introduce a novel framework for boosting CNN performance that\nintegrates dynamic feature selection with the principles of BoostCNN. Our\napproach incorporates two key strategies: subgrid selection and importance\nsampling, to guide training toward informative regions of the feature space. We\nfurther develop a family of algorithms that embed boosting weights directly\ninto the network training process using a least squares loss formulation. This\nintegration not only alleviates the burden of manual architecture design but\nalso enhances accuracy and efficiency. Experimental results across several\nfine-grained classification benchmarks demonstrate that our boosted CNN\nvariants consistently outperform conventional CNNs in both predictive\nperformance and training speed.\n","authors":["Biyi Fang","Jean Utke","Truong Vo","Diego Klabjan"],"pdf_url":"https://arxiv.org/pdf/2507.22842v1.pdf","comment":"10 pages, 5 figures. Experimental results reported on CIFAR-10, SVHN,\n  and ImageNetSub datasets. arXiv admin note: substantial text overlap with\n  arXiv:2203.00761"},{"id":"http://arxiv.org/abs/2507.22840v1","updated":"2025-07-30T16:56:42Z","published":"2025-07-30T16:56:42Z","title":"PAF-Net: Phase-Aligned Frequency Decoupling Network for Multi-Process\n  Manufacturing Quality Prediction","summary":"  Accurate quality prediction in multi-process manufacturing is critical for\nindustrial efficiency but hindered by three core challenges: time-lagged\nprocess interactions, overlapping operations with mixed periodicity, and\ninter-process dependencies in shared frequency bands. To address these, we\npropose PAF-Net, a frequency decoupled time series prediction framework with\nthree key innovations: (1) A phase-correlation alignment method guided by\nfrequency domain energy to synchronize time-lagged quality series, resolving\ntemporal misalignment. (2) A frequency independent patch attention mechanism\npaired with Discrete Cosine Transform (DCT) decomposition to capture\nheterogeneous operational features within individual series. (3) A frequency\ndecoupled cross attention module that suppresses noise from irrelevant\nfrequencies, focusing exclusively on meaningful dependencies within shared\nbands. Experiments on 4 real-world datasets demonstrate PAF-Net's superiority.\nIt outperforms 10 well-acknowledged baselines by 7.06% lower MSE and 3.88%\nlower MAE. Our code is available at\nhttps://github.com/StevenLuan904/PAF-Net-Official.\n","authors":["Yang Luo","Haoyang Luan","Haoyun Pan","Yongquan Jia","Xiaofeng Gao","Guihai Chen"],"pdf_url":"https://arxiv.org/pdf/2507.22840v1.pdf","comment":"7 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.22832v1","updated":"2025-07-30T16:47:42Z","published":"2025-07-30T16:47:42Z","title":"Tapping into the Black Box: Uncovering Aligned Representations in\n  Pretrained Neural Networks","summary":"  In this paper we argue that ReLU networks learn an implicit linear model we\ncan actually tap into. We describe that alleged model formally and show that we\ncan approximately pull its decision boundary back to the input space with\ncertain simple modification to the backward pass. The resulting gradients\n(called excitation pullbacks) reveal high-resolution input- and target-specific\nfeatures of remarkable perceptual alignment on a number of popular\nImageNet-pretrained deep architectures. This strongly suggests that neural\nnetworks do, in fact, rely on learned interpretable patterns that can be\nrecovered after training. Thus, our findings may have profound implications for\nknowledge discovery and the development of dependable artificial systems.\n","authors":["Maciej Satkiewicz"],"pdf_url":"https://arxiv.org/pdf/2507.22832v1.pdf","comment":"15 pages, 4 figures, preprint"},{"id":"http://arxiv.org/abs/2407.18044v2","updated":"2025-07-30T16:28:54Z","published":"2024-07-25T13:47:01Z","title":"The Geometry of Queries: Query-Based Innovations in Retrieval-Augmented\n  Generation for Healthcare QA","summary":"  Deploying Large Language Models (LLMs) for healthcare question answering\nrequires robust methods to ensure accuracy and reliability. This work\nintroduces Query-Based Retrieval Augmented Generation (QB-RAG), a framework for\nenhancing Retrieval-Augmented Generation (RAG) systems in healthcare\nquestion-answering by pre-aligning user queries with a database of curated,\nanswerable questions derived from healthcare content. A key component of QB-RAG\nis an LLM-based filtering mechanism that ensures that only relevant and\nanswerable questions are included in the database, enabling reliable reference\nquery generation at scale. We provide theoretical motivation for QB-RAG,\nconduct a comparative analysis of existing retrieval enhancement techniques,\nand introduce a generalizable, comprehensive evaluation framework that assesses\nboth the retrieval effectiveness and the quality of the generated response\nbased on faithfulness, relevance, and adherence to the guideline. Our empirical\nevaluation on a healthcare data set demonstrates the superior performance of\nQB-RAG compared to existing retrieval methods, highlighting its practical value\nin building trustworthy digital health applications for health\nquestion-answering.\n","authors":["Eric Yang","Jonathan Amar","Jong Ha Lee","Bhawesh Kumar","Yugang Jia"],"pdf_url":"https://arxiv.org/pdf/2407.18044v2.pdf","comment":"27 pages"},{"id":"http://arxiv.org/abs/2505.00291v2","updated":"2025-07-30T16:27:11Z","published":"2025-05-01T04:27:35Z","title":"Repetition Makes Perfect: Recurrent Graph Neural Networks Match Message\n  Passing Limit","summary":"  We precisely characterize the expressivity of computable Recurrent Graph\nNeural Networks (recurrent GNNs). We prove that recurrent GNNs with\nfinite-precision parameters, sum aggregation, and ReLU activation, can compute\nany graph algorithm that respects the natural message-passing invariance\ninduced by the Color Refinement (or Weisfeiler-Leman) algorithm. While it is\nwell known that the expressive power of GNNs is limited by this invariance\n[Morris et al., AAAI 2019; Xu et al., ICLR 2019], we establish that recurrent\nGNNs can actually match this limit. This is in contrast to non-recurrent GNNs,\nwhich have the power of Weisfeiler-Leman only in a very weak, \"non-uniform\",\nsense where each graph size requires a different GNN to compute with. Our\nconstruction introduces only a polynomial overhead in both time and space.\n  Furthermore, we show that by incorporating random initialization, for\nconnected graphs recurrent GNNs can express all graph algorithms. In\nparticular, any polynomial-time graph algorithm can be emulated on connected\ngraphs in polynomial time by a recurrent GNN with random initialization.\n","authors":["Eran Rosenbluth","Martin Grohe"],"pdf_url":"https://arxiv.org/pdf/2505.00291v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.13362v2","updated":"2025-07-30T16:08:55Z","published":"2025-06-16T11:09:27Z","title":"Mitigating loss of variance in ensemble data assimilation: machine\n  learning-based and distance-free localization","summary":"  We propose two new methods based/inspired by machine learning for tabular\ndata and distance-free localization to enhance the covariance estimations in an\nensemble data assimilation. The main goal is to enhance the data assimilation\nresults by mitigating loss of variance due to sampling errors. We also analyze\nthe suitability of several machine learning models and the balance between\naccuracy and computational cost of the covariance estimations. We introduce two\ndistance-free localization techniques leveraging machine learning methods\nspecifically tailored for tabular data. The methods are integrated into the\nEnsemble Smoother with Multiple Data Assimilation (ES-MDA) framework. The\nresults show that the proposed localizations improve covariance accuracy and\nenhance data assimilation and uncertainty quantification results. We observe\nreduced variance loss for the input variables using the proposed methods.\nFurthermore, we compare several machine learning models, assessing their\nsuitability for the problem in terms of computational cost, and quality of the\ncovariance estimation and data match. The influence of ensemble size is also\ninvestigated, providing insights into balancing accuracy and computational\nefficiency. Our findings demonstrate that certain machine learning models are\nmore suitable for this problem. This study introduces two novel methods that\nmitigate variance loss for model parameters in ensemble-based data\nassimilation, offering practical solutions that are easy to implement and do\nnot require any additional numerical simulation or hyperparameter tuning.\n","authors":["Vinicius L. S. Silva","Gabriel S. Seabra","Alexandre A. Emerick"],"pdf_url":"https://arxiv.org/pdf/2506.13362v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02744v2","updated":"2025-07-30T16:07:24Z","published":"2024-10-03T17:55:17Z","title":"Neutral Residues: Revisiting Adapters for Model Extension","summary":"  We address the problem of extending a pretrained large language model to a\nnew domain that was not seen during training. Standard techniques, such as\nfinetuning or low-rank adaptation (LoRA) are successful at domain adaptation,\nbut do not formally add capacity to the model. This often leads to a trade-off,\nbetween performing well on the new domain vs. degrading performance on the\noriginal domain. Here, we revisit and improve adapters to extend LLMs from\nthree angles: data, architecture and training procedure, which are\nadvantageously considered jointly. The resulting method, called neutral\nresidues, modifies adapters in a way that leads each new residual block to\noutput near-zeros on the original domain. This solution leads to strong results\nwhen adapting a state-of-the-art model originally trained on English to a new\nlanguage. Neutral residues significantly outperform competing approaches such\nas finetuning, LoRA or vanilla adapters in terms of the trade-off between\nlearning the new language and not forgetting English.\n","authors":["Franck Signe Talla","Edouard Grave","Hervé Jégou"],"pdf_url":"https://arxiv.org/pdf/2410.02744v2.pdf","comment":"Accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2507.22798v1","updated":"2025-07-30T16:01:18Z","published":"2025-07-30T16:01:18Z","title":"Quantifying surprise in clinical care: Detecting highly informative\n  events in electronic health records with foundation models","summary":"  We present a foundation model-derived method to identify highly informative\ntokens and events in electronic health records. Our approach considers incoming\ndata in the entire context of a patient's hospitalization and so can flag\nanomalous events that rule-based approaches would consider within a normal\nrange. We demonstrate that the events our model flags are significant for\npredicting downstream patient outcomes and that a fraction of events identified\nas carrying little information can safely be dropped. Additionally, we show how\ninformativeness can help interpret the predictions of prognostic models trained\non foundation model-derived representations.\n","authors":["Michael C. Burkhart","Bashar Ramadan","Luke Solo","William F. Parker","Brett K. Beaulieu-Jones"],"pdf_url":"https://arxiv.org/pdf/2507.22798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.07052v4","updated":"2025-07-30T16:00:53Z","published":"2023-11-13T03:36:18Z","title":"Towards the Law of Capacity Gap in Distilling Language Models","summary":"  Language model (LM) distillation aims at distilling the knowledge in a large\nteacher LM to a small student one. As a critical issue facing LM distillation,\na superior student often arises from a teacher of a relatively small scale\ninstead of a larger one, especially in the presence of substantial capacity gap\nbetween the teacher and student. This issue, often referred to as the\n\\textit{curse of capacity gap}, suggests that there is likely an optimal\nteacher yielding the best-performing student along the scaling course of the\nteacher. Consequently, distillation trials on teachers of a wide range of\nscales are called for to determine the optimal teacher, which becomes\ncomputationally intensive in the context of large LMs (LLMs). This paper\naddresses this critical bottleneck by providing the \\textit{law of capacity\ngap} inducted from a preliminary study on distilling a broad range of\nsmall-scale (<3B) LMs, where the optimal teacher consistently scales linearly\nwith the student scale across different model and data scales. By extending the\nlaw to LLM distillation on a larger scale (7B), we succeed in obtaining\nversatile LLMs that outperform a wide array of competitors.\n","authors":["Chen Zhang","Qiuchi Li","Dawei Song","Zheyu Ye","Yan Gao","Yan Hu"],"pdf_url":"https://arxiv.org/pdf/2311.07052v4.pdf","comment":"32 pages, 10 figures, 15 tables, accepted to ACL 2025. Code and\n  checkpoints are available at https://github.com/GeneZC/MiniMA"},{"id":"http://arxiv.org/abs/2507.22789v1","updated":"2025-07-30T15:55:08Z","published":"2025-07-30T15:55:08Z","title":"G-Core: A Simple, Scalable and Balanced RLHF Trainer","summary":"  Reinforcement Learning from Human Feedback (RLHF) has become an increasingly\npopular paradigm for training large language models (LLMs) and diffusion\nmodels. While existing RLHF training systems have enabled significant progress,\nthey often face challenges in scaling to multi-modal and diffusion workflows\nand adapting to dynamic workloads. In particular, current approaches may\nencounter limitations in controller scalability, flexible resource placement,\nand efficient orchestration when handling complex RLHF pipelines, especially in\nscenarios involving dynamic sampling or generative reward modeling. In this\npaper, we present \\textbf{G-Core}, a simple, scalable, and balanced RLHF\ntraining framework designed to address these challenges. G-Core introduces a\nparallel controller programming model, enabling flexible and efficient\norchestration of complex RLHF workflows without the bottlenecks of a single\ncentralized controller. Furthermore, we propose a dynamic placement schema that\nadaptively partitions resources and schedules workloads, significantly reducing\nhardware idle time and improving utilization, even under highly variable\ntraining conditions. G-Core has successfully trained models that support WeChat\nproduct features serving a large-scale user base, demonstrating its\neffectiveness and robustness in real-world scenarios. Our results show that\nG-Core advances the state of the art in RLHF training, providing a solid\nfoundation for future research and deployment of large-scale, human-aligned\nmodels.\n","authors":["Junyu Wu","Weiming Chang","Xiaotao Liu","Guanyou He","Haoqiang Hong","Boqi Liu","Hongtao Tian","Tao Yang","Yunsheng Shi","Feng Lin","Ting Yao"],"pdf_url":"https://arxiv.org/pdf/2507.22789v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22787v1","updated":"2025-07-30T15:51:54Z","published":"2025-07-30T15:51:54Z","title":"Amorphous Solid Model of Vectorial Hopfield Neural Networks","summary":"  We present a vectorial extension of the Hopfield associative memory model\ninspired by the theory of amorphous solids, where binary neural states are\nreplaced by unit vectors $\\mathbf{s}_i \\in \\mathbb{R}^3$ on the sphere $S^2$.\nThe generalized Hebbian learning rule creates a block-structured weight matrix\nthrough outer products of stored pattern vectors, analogous to the Hessian\nmatrix structure in amorphous solids. We demonstrate that this model exhibits\nquantifiable structural properties characteristic of disordered materials:\nenergy landscapes with deep minima for stored patterns versus random\nconfigurations (energy gaps $\\sim 7$ units), strongly anisotropic correlations\nencoded in the weight matrix (anisotropy ratios $\\sim 10^2$), and\norder-disorder transitions controlled by the pattern density $\\gamma = P/(N\n\\cdot d)$. The enhanced memory capacity ($\\gamma_c \\approx 0.55$ for a\nfully-connected network) compared to binary networks ($\\gamma_c \\approx 0.138$)\nand the emergence of orientational correlations establish connections between\nassociative memory mechanisms and amorphous solid physics, particularly in\nsystems with continuous orientational degrees of freedom. We also unveil the\nscaling with the coordination number $Z$ of the memory capacity: $\\gamma_c \\sim\n(Z-6)$ from the isostatic point $Z_c =6$ of the 3D elastic network, which\nclosely mirrors the scaling of the shear modulus $G \\sim (Z-6)$ in 3D\ncentral-force spring networks.\n","authors":["F. Gallavotti","A. Zaccone"],"pdf_url":"https://arxiv.org/pdf/2507.22787v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22786v1","updated":"2025-07-30T15:51:20Z","published":"2025-07-30T15:51:20Z","title":"DO-EM: Density Operator Expectation Maximization","summary":"  Density operators, quantum generalizations of probability distributions, are\ngaining prominence in machine learning due to their foundational role in\nquantum computing. Generative modeling based on density operator models\n(\\textbf{DOMs}) is an emerging field, but existing training algorithms -- such\nas those for the Quantum Boltzmann Machine -- do not scale to real-world data,\nsuch as the MNIST dataset. The Expectation-Maximization algorithm has played a\nfundamental role in enabling scalable training of probabilistic latent variable\nmodels on real-world datasets. \\textit{In this paper, we develop an\nExpectation-Maximization framework to learn latent variable models defined\nthrough \\textbf{DOMs} on classical hardware, with resources comparable to those\nused for probabilistic models, while scaling to real-world data.} However,\ndesigning such an algorithm is nontrivial due to the absence of a well-defined\nquantum analogue to conditional probability, which complicates the Expectation\nstep. To overcome this, we reformulate the Expectation step as a quantum\ninformation projection (QIP) problem and show that the Petz Recovery Map\nprovides a solution under sufficient conditions. Using this formulation, we\nintroduce the Density Operator Expectation Maximization (DO-EM) algorithm -- an\niterative Minorant-Maximization procedure that optimizes a quantum evidence\nlower bound. We show that the \\textbf{DO-EM} algorithm ensures non-decreasing\nlog-likelihood across iterations for a broad class of models. Finally, we\npresent Quantum Interleaved Deep Boltzmann Machines (\\textbf{QiDBMs}), a\n\\textbf{DOM} that can be trained with the same resources as a DBM. When trained\nwith \\textbf{DO-EM} under Contrastive Divergence, a \\textbf{QiDBM} outperforms\nlarger classical DBMs in image generation on the MNIST dataset, achieving a\n40--60\\% reduction in the Fr\\'echet Inception Distance.\n","authors":["Adit Vishnu","Abhay Shastry","Dhruva Kashyap","Chiranjib Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2507.22786v1.pdf","comment":"Main text: 9 pages 1 Figure. Total: 23 pages 3 Figures"},{"id":"http://arxiv.org/abs/2507.22782v1","updated":"2025-07-30T15:48:38Z","published":"2025-07-30T15:48:38Z","title":"Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic\n  Policies","summary":"  This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement\nlearning algorithm designed to enhance multi-agent collaboration in cooperative\nenvironments. TAAC employs a Centralized Training/Centralized Execution scheme\nincorporating multi-headed attention mechanisms in both the actor and critic.\nThis design facilitates dynamic, inter-agent communication, allowing agents to\nexplicitly query teammates, thereby efficiently managing the exponential growth\nof joint-action spaces while ensuring a high degree of collaboration. We\nfurther introduce a penalized loss function which promotes diverse yet\ncomplementary roles among agents. We evaluate TAAC in a simulated soccer\nenvironment against benchmark algorithms representing other multi-agent\nparadigms, including Proximal Policy Optimization and Multi-Agent\nActor-Attention-Critic. We find that TAAC exhibits superior performance and\nenhanced collaborative behaviors across a variety of metrics (win rates, goal\ndifferentials, Elo ratings, inter-agent connectivity, balanced spatial\ndistributions, and frequent tactical interactions such as ball possession\nswaps).\n","authors":["Hugo Garrido-Lestache","Jeremy Kedziora"],"pdf_url":"https://arxiv.org/pdf/2507.22782v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2411.16229v2","updated":"2025-07-30T15:42:47Z","published":"2024-11-25T09:42:42Z","title":"Effective Non-Random Extreme Learning Machine","summary":"  The Extreme Learning Machine (ELM) is a growing statistical technique widely\napplied to regression problems. In essence, ELMs are single-layer neural\nnetworks where the hidden layer weights are randomly sampled from a specific\ndistribution, while the output layer weights are learned from the data. Two of\nthe key challenges with this approach are the architecture design, specifically\ndetermining the optimal number of neurons in the hidden layer, and the method's\nsensitivity to the random initialization of hidden layer weights.\n  This paper introduces a new and enhanced learning algorithm for regression\ntasks, the Effective Non-Random ELM (ENR-ELM), which simplifies the\narchitecture design and eliminates the need for random hidden layer weight\nselection. The proposed method incorporates concepts from signal processing,\nsuch as basis functions and projections, into the ELM framework. We introduce\ntwo versions of the ENR-ELM: the approximated ENR-ELM and the incremental\nENR-ELM. Experimental results on both synthetic and real datasets demonstrate\nthat our method overcomes the problems of traditional ELM while maintaining\ncomparable predictive performance.\n","authors":["Daniela De Canditiis","Fabiano Veglianti"],"pdf_url":"https://arxiv.org/pdf/2411.16229v2.pdf","comment":"To appear in Neural Computing and Applications (online 29 July 2025)"},{"id":"http://arxiv.org/abs/2507.22776v1","updated":"2025-07-30T15:37:58Z","published":"2025-07-30T15:37:58Z","title":"Label-free estimation of clinically relevant performance metrics under\n  distribution shifts","summary":"  Performance monitoring is essential for safe clinical deployment of image\nclassification models. However, because ground-truth labels are typically\nunavailable in the target dataset, direct assessment of real-world model\nperformance is infeasible. State-of-the-art performance estimation methods\naddress this by leveraging confidence scores to estimate the target accuracy.\nDespite being a promising direction, the established methods mainly estimate\nthe model's accuracy and are rarely evaluated in a clinical domain, where\nstrong class imbalances and dataset shifts are common. Our contributions are\ntwofold: First, we introduce generalisations of existing performance prediction\nmethods that directly estimate the full confusion matrix. Then, we benchmark\ntheir performance on chest x-ray data in real-world distribution shifts as well\nas simulated covariate and prevalence shifts. The proposed confusion matrix\nestimation methods reliably predicted clinically relevant counting metrics on\nmedical images under distribution shifts. However, our simulated shift\nscenarios exposed important failure modes of current performance estimation\ntechniques, calling for a better understanding of real-world deployment\ncontexts when implementing these performance monitoring techniques for\npostmarket surveillance of medical AI models.\n","authors":["Tim Flühmann","Alceu Bissoto","Trung-Dung Hoang","Lisa M. Koch"],"pdf_url":"https://arxiv.org/pdf/2507.22776v1.pdf","comment":"Accepted oral at UNSURE 2025 @ MICCAI"},{"id":"http://arxiv.org/abs/2507.22772v1","updated":"2025-07-30T15:35:51Z","published":"2025-07-30T15:35:51Z","title":"Empirical Evaluation of Concept Drift in ML-Based Android Malware\n  Detection","summary":"  Despite outstanding results, machine learning-based Android malware detection\nmodels struggle with concept drift, where rapidly evolving malware\ncharacteristics degrade model effectiveness. This study examines the impact of\nconcept drift on Android malware detection, evaluating two datasets and nine\nmachine learning and deep learning algorithms, as well as Large Language Models\n(LLMs). Various feature types--static, dynamic, hybrid, semantic, and\nimage-based--were considered. The results showed that concept drift is\nwidespread and significantly affects model performance. Factors influencing the\ndrift include feature types, data environments, and detection methods.\nBalancing algorithms helped with class imbalance but did not fully address\nconcept drift, which primarily stems from the dynamic nature of the malware\nlandscape. No strong link was found between the type of algorithm used and\nconcept drift, the impact was relatively minor compared to other variables\nsince hyperparameters were not fine-tuned, and the default algorithm\nconfigurations were used. While LLMs using few-shot learning demonstrated\npromising detection performance, they did not fully mitigate concept drift,\nhighlighting the need for further investigation.\n","authors":["Ahmed Sabbah","Radi Jarrar","Samer Zein","David Mohaisen"],"pdf_url":"https://arxiv.org/pdf/2507.22772v1.pdf","comment":"18 pages, 12 tables, 14 figures, paper under review"},{"id":"http://arxiv.org/abs/2506.11378v2","updated":"2025-07-30T15:34:07Z","published":"2025-06-13T01:01:07Z","title":"The Effect of Stochasticity in Score-Based Diffusion Sampling: a KL\n  Divergence Analysis","summary":"  Sampling in score-based diffusion models can be performed by solving either a\nreverse-time stochastic differential equation (SDE) parameterized by an\narbitrary time-dependent stochasticity parameter or a probability flow ODE,\ncorresponding to the stochasticity parameter set to zero. In this work, we\nstudy the effect of this stochasticity on the generation process through bounds\non the Kullback-Leibler (KL) divergence, complementing the analysis with\nnumerical and analytical examples. Our main results apply to linear forward\nSDEs with additive noise and Lipschitz-continuous score functions, and quantify\nhow errors from the prior distribution and score approximation propagate under\ndifferent choices of the stochasticity parameter. The theoretical bounds are\nderived using log-Sobolev inequalities for the marginals of the forward\nprocess, which enable a more effective control of the KL divergence decay along\nsampling. For exact score functions, we find that stochasticity acts as an\nerror-correcting mechanism, decreasing KL divergence along the sampling\ntrajectory. For an approximate score function, there is a trade-off between\nerror correction and score error amplification, so that stochasticity can\neither improve or worsen the performance, depending on the structure of the\nscore error. Numerical experiments on simple datasets and a fully analytical\nexample are included to illustrate and enlighten the theoretical results.\n","authors":["Bernardo P. Schaeffer","Ricardo M. S. Rosa","Glauco Valle"],"pdf_url":"https://arxiv.org/pdf/2506.11378v2.pdf","comment":"27 pages, 16 figures"},{"id":"http://arxiv.org/abs/2507.22767v1","updated":"2025-07-30T15:32:18Z","published":"2025-07-30T15:32:18Z","title":"Teaching the Teacher: Improving Neural Network Distillability for\n  Symbolic Regression via Jacobian Regularization","summary":"  Distilling large neural networks into simple, human-readable symbolic\nformulas is a promising path toward trustworthy and interpretable AI. However,\nthis process is often brittle, as the complex functions learned by standard\nnetworks are poor targets for symbolic discovery, resulting in low-fidelity\nstudent models. In this work, we propose a novel training paradigm to address\nthis challenge. Instead of passively distilling a pre-trained network, we\nintroduce a \\textbf{Jacobian-based regularizer} that actively encourages the\n``teacher'' network to learn functions that are not only accurate but also\ninherently smoother and more amenable to distillation. We demonstrate through\nextensive experiments on a suite of real-world regression benchmarks that our\nmethod is highly effective. By optimizing the regularization strength for each\nproblem, we improve the $R^2$ score of the final distilled symbolic model by an\naverage of \\textbf{120\\% (relative)} compared to the standard distillation\npipeline, all while maintaining the teacher's predictive accuracy. Our work\npresents a practical and principled method for significantly improving the\nfidelity of interpretable models extracted from complex neural networks.\n","authors":["Soumyadeep Dhar","Kei Sen Fong","Mehul Motani"],"pdf_url":"https://arxiv.org/pdf/2507.22767v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22766v1","updated":"2025-07-30T15:31:39Z","published":"2025-07-30T15:31:39Z","title":"Bayesian Optimization of Process Parameters of a Sensor-Based Sorting\n  System using Gaussian Processes as Surrogate Models","summary":"  Sensor-based sorting systems enable the physical separation of a material\nstream into two fractions. The sorting decision is based on the image data\nevaluation of the sensors used and is carried out using actuators. Various\nprocess parameters must be set depending on the properties of the material\nstream, the dimensioning of the system, and the required sorting accuracy.\nHowever, continuous verification and re-adjustment are necessary due to\nchanging requirements and material stream compositions. In this paper, we\nintroduce an approach for optimizing, recurrently monitoring and adjusting the\nprocess parameters of a sensor-based sorting system. Based on Bayesian\nOptimization, Gaussian process regression models are used as surrogate models\nto achieve specific requirements for system behavior with the uncertainties\ncontained therein. This method minimizes the number of necessary experiments\nwhile simultaneously considering two possible optimization targets based on the\nrequirements for both material output streams. In addition, uncertainties are\nconsidered during determining sorting accuracies in the model calculation. We\nevaluated the method with three example process parameters.\n","authors":["Felix Kronenwett","Georg Maier","Thomas Laengle"],"pdf_url":"https://arxiv.org/pdf/2507.22766v1.pdf","comment":"Accepted at the 30th IEEE International Conference on Emerging\n  Technologies and Factory Automation (ETFA)"},{"id":"http://arxiv.org/abs/2507.22760v1","updated":"2025-07-30T15:21:22Z","published":"2025-07-30T15:21:22Z","title":"Of Good Demons and Bad Angels: Guaranteeing Safe Control under Finite\n  Precision","summary":"  As neural networks (NNs) become increasingly prevalent in safety-critical\nneural network-controlled cyber-physical systems (NNCSs), formally guaranteeing\ntheir safety becomes crucial. For these systems, safety must be ensured\nthroughout their entire operation, necessitating infinite-time horizon\nverification. To verify the infinite-time horizon safety of NNCSs, recent\napproaches leverage Differential Dynamic Logic (dL). However, these dL-based\nguarantees rely on idealized, real-valued NN semantics and fail to account for\nroundoff errors introduced by finite-precision implementations. This paper\nbridges the gap between theoretical guarantees and real-world implementations\nby incorporating robustness under finite-precision perturbations -- in sensing,\nactuation, and computation -- into the safety verification. We model the\nproblem as a hybrid game between a good Demon, responsible for control actions,\nand a bad Angel, introducing perturbations. This formulation enables formal\nproofs of robustness w.r.t. a given (bounded) perturbation. Leveraging this\nbound, we employ state-of-the-art mixed-precision fixed-point tuners to\nsynthesize sound and efficient implementations, thus providing a complete\nend-to-end solution. We evaluate our approach on case studies from the\nautomotive and aeronautics domains, producing efficient NN implementations with\nrigorous infinite-time horizon safety guarantees.\n","authors":["Samuel Teuber","Debasmita Lohar","Bernhard Beckert"],"pdf_url":"https://arxiv.org/pdf/2507.22760v1.pdf","comment":"15 pages, 3 figures, 1 table; Accepted at FMCAD 2025"},{"id":"http://arxiv.org/abs/2507.22758v1","updated":"2025-07-30T15:19:38Z","published":"2025-07-30T15:19:38Z","title":"MASCA: LLM based-Multi Agents System for Credit Assessment","summary":"  Recent advancements in financial problem-solving have leveraged LLMs and\nagent-based systems, with a primary focus on trading and financial modeling.\nHowever, credit assessment remains an underexplored challenge, traditionally\ndependent on rule-based methods and statistical models. In this paper, we\nintroduce MASCA, an LLM-driven multi-agent system designed to enhance credit\nevaluation by mirroring real-world decision-making processes. The framework\nemploys a layered architecture where specialized LLM-based agents\ncollaboratively tackle sub-tasks. Additionally, we integrate contrastive\nlearning for risk and reward assessment to optimize decision-making. We further\npresent a signaling game theory perspective on hierarchical multi-agent\nsystems, offering theoretical insights into their structure and interactions.\nOur paper also includes a detailed bias analysis in credit assessment,\naddressing fairness concerns. Experimental results demonstrate that MASCA\noutperforms baseline approaches, highlighting the effectiveness of hierarchical\nLLM-based multi-agent systems in financial applications, particularly in credit\nscoring.\n","authors":["Gautam Jajoo","Pranjal A Chitale","Saksham Agarwal"],"pdf_url":"https://arxiv.org/pdf/2507.22758v1.pdf","comment":"Accepted at ACL REALM Workshop. Work in Progress"},{"id":"http://arxiv.org/abs/2411.02038v2","updated":"2025-07-30T15:05:10Z","published":"2024-11-04T12:40:18Z","title":"Addressing Representation Collapse in Vector Quantized Models with One\n  Linear Layer","summary":"  Vector Quantization (VQ) is essential for discretizing continuous\nrepresentations in unsupervised learning but suffers from representation\ncollapse, causing low codebook utilization and limiting scalability. Existing\nsolutions often rely on complex optimizations or reduce latent dimensionality,\nwhich compromises model capacity and fails to fully solve the problem. We\nidentify the root cause as disjoint codebook optimization, where only a few\ncode vectors are updated via gradient descent. To fix this, we propose\n\\textbf{Sim}ple\\textbf{VQ}, which reparameterizes code vectors through a\nlearnable linear transformation layer over a latent basis, optimizing the\n\\textit{entire linear space} rather than nearest \\textit{individual code\nvectors}. Although the multiplication of two linear matrices is equivalent to\napplying a single linear layer, this simple approach effectively prevents\ncollapse. Extensive experiments on image and audio tasks demonstrate that SimVQ\nimproves codebook usage, is easy to implement, and generalizes well across\nmodalities and architectures.\n","authors":["Yongxin Zhu","Bocheng Li","Yifei Xin","Zhihua Xia","Linli Xu"],"pdf_url":"https://arxiv.org/pdf/2411.02038v2.pdf","comment":"Accepted at ICCV2025"},{"id":"http://arxiv.org/abs/2502.13820v3","updated":"2025-07-30T14:58:42Z","published":"2025-02-19T15:32:11Z","title":"Scoring Verifiers: Evaluating Synthetic Verification for Code and\n  Reasoning","summary":"  Synthetic verification techniques such as generating test cases and reward\nmodelling are common ways to enhance the coding capabilities of large language\nmodels (LLM) beyond predefined tests. Additionally, code verification has\nrecently found great success as a critical component in improving reasoning\ncapability of LLMs via reinforcement learning. In this paper, we propose an\napproach which can transform existing coding benchmarks into scoring and\nranking datasets to evaluate the effectiveness of synthetic verifiers. We also\npropose multiple metrics to measure different aspects of the synthetic\nverifiers with the proposed benchmarks. By employing the proposed approach, we\nrelease four new benchmarks (HE-R, HE-R+, MBPP-R, and MBPP-R+), and analyzed\nsynthetic verification methods with standard, reasoning-based, and reward-based\nLLMs. Our experiments show that reasoning can significantly improve test case\ngeneration and that scaling the number of test cases enhances the verification\naccuracy.\n","authors":["Aleksander Ficek","Somshubra Majumdar","Vahid Noroozi","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2502.13820v3.pdf","comment":"COLM 2025"},{"id":"http://arxiv.org/abs/2506.16965v2","updated":"2025-07-30T14:53:10Z","published":"2025-06-20T12:52:44Z","title":"RocketStack: Level-aware deep recursive ensemble learning framework with\n  adaptive feature fusion and model pruning dynamics","summary":"  Ensemble learning remains a cornerstone of machine learning, with stacking\nused to integrate predictions from multiple base learners through a meta-model.\nHowever, deep stacking remains rare, as most designs prioritize horizontal\ndiversity over recursive depth due to model complexity, feature redundancy, and\ncomputational burden. To address these challenges, RocketStack, a level-aware\nrecursive ensemble framework, is introduced and explored up to ten stacking\nlevels, extending beyond prior architectures. The framework incrementally\nprunes weaker learners at each level, enabling deeper stacking without\nexcessive complexity. To mitigate early performance saturation, mild Gaussian\nnoise is added to out-of-fold (OOF) scores before pruning, and compared against\nstrict OOF pruning. Further both per-level and periodic feature compressions\nare explored using attention-based selection, Simple, Fast, Efficient (SFE)\nfilter, and autoencoders. Across 33 datasets (23 binary, 10 multi-class),\nlinear-trend tests confirmed rising accuracy with depth in most variants, and\nthe top performing meta-model at each level increasingly outperformed the\nstrongest standalone ensemble. In the binary subset, periodic SFE with mild\nOOF-score randomization reached 97.08% at level 10, 5.14% above the\nstrict-pruning configuration and cut runtime by 10.5% relative to no\ncompression. In the multi-class subset, periodic attention selection reached\n98.60% at level 10, exceeding the strongest baseline by 6.11%, while reducing\nruntime by 56.1% and feature dimensionality by 74% compared to no compression.\nThese findings highlight mild randomization as an effective regularizer and\nperiodic compression as a stabilizer. Echoing the design of multistage rockets\nin aerospace (prune, compress, propel) RocketStack achieves deep recursive\nensembling with tractable complexity.\n","authors":["Çağatay Demirel"],"pdf_url":"https://arxiv.org/pdf/2506.16965v2.pdf","comment":"30 pages, 1 graphical abstract, 7 figures, 9 tables, 2 supplementary\n  figures"},{"id":"http://arxiv.org/abs/2504.10487v2","updated":"2025-07-30T14:39:53Z","published":"2025-04-14T17:59:59Z","title":"FLOSS: Free Lunch in Open-vocabulary Semantic Segmentation","summary":"  In this paper, we challenge the conventional practice in Open-Vocabulary\nSemantic Segmentation (OVSS) of using averaged class-wise text embeddings,\nwhich are typically obtained by encoding each class name with multiple\ntemplates (e.g., a photo of <class>, a sketch of a <class>). We investigate the\nimpact of templates for OVSS, and find that for each class, there exist\nsingle-template classifiers--which we refer to as class-experts--that\nsignificantly outperform the conventional averaged classifier. First, to\nidentify these class-experts, we introduce a novel approach that estimates them\nwithout any labeled data or training. By leveraging the class-wise prediction\nentropy of single-template classifiers, we select those yielding the lowest\nentropy as the most reliable class-experts. Second, we combine the outputs of\nclass-experts in a new fusion process. Our plug-and-play method, coined FLOSS,\nis orthogonal and complementary to existing OVSS methods, offering an\nimprovement without the need for additional labels or training. Extensive\nexperiments show that FLOSS consistently enhances state-of-the-art OVSS models,\ngeneralizes well across datasets with different distribution shifts, and\ndelivers substantial improvements in low-data scenarios where only a few\nunlabeled images are available. Our code is available at\nhttps://github.com/yasserben/FLOSS .\n","authors":["Yasser Benigmim","Mohammad Fahes","Tuan-Hung Vu","Andrei Bursuc","Raoul de Charette"],"pdf_url":"https://arxiv.org/pdf/2504.10487v2.pdf","comment":"ICCV 2025; Project Page: https://yasserben.github.io/FLOSS/"},{"id":"http://arxiv.org/abs/2504.13932v3","updated":"2025-07-30T14:37:56Z","published":"2025-04-14T19:31:21Z","title":"Enhancing Ultra-Low-Bit Quantization of Large Language Models Through\n  Saliency-Aware Partial Retraining","summary":"  The growing use of large language models has raised environmental and\neconomic concerns about their intensity of resource usage during inference.\nServing these models to each user requires substantial energy and water for\ncooling. Model compression techniques like quantization can shrink large\nlanguage models and make them more resource efficient at the cost of potential\nperformance degradation. Quantization methods compress model size through\nreplacing their high-precision parameters by quantized values of lower\nprecision. Among existing methods, the ApiQ method achieves superior accuracy\npreservation at minimal memory and time overhead. We investigate two ideas to\nextend performance in ultra-low-bit quantization beyond ApiQ's level. First, we\nlook into combining existing quantization-aware training techniques with ApiQ's\npartial training. We show that this does not outperform the baseline ApiQ\nmethod with limited training data and frozen weights. This leads to two key\ninsights: (1) The substantial representational capacity that is gained through\nfull retraining is unlikely to be feasible through partial training. (2) This\ngain may depend on using a large and diverse dataset in quantization-aware\ntraining. Second, through a novel approach informed by the two insights, we\npropose an ultra-low-bit quantization method that builds upon ApiQ and extends\nits performance without the need for full retraining. This publicly available\nmethod relies on a saliency-aware regularization term that prioritizes\npreserving the most impactful parameters during quantization. Our experiments\non LLaMA 7B and 13B benchmarks demonstrate that our method reduces the ApiQ's\naccuracy degradation by 10.85% and 7.54% respectively. A Python implementation\nof the proposed quantization method is publicly available on GitHub\nhttps://github.com/TokuyuSou/ULB-SAPR.\n","authors":["Deyu Cao","Samin Aref"],"pdf_url":"https://arxiv.org/pdf/2504.13932v3.pdf","comment":"This is a post-peer-review accepted manuscript from the proceedings\n  of the 22nd International Conference on Modeling Decisions for Artificial\n  Intelligence (MDAI'25). The publisher authenticated version and full citation\n  details are available on Springer's website (LNAI 15957).\n  https://doi.org/10.1007/978-3-032-00891-6_28"},{"id":"http://arxiv.org/abs/2507.22710v1","updated":"2025-07-30T14:21:32Z","published":"2025-07-30T14:21:32Z","title":"Enhanced Prediction of CAR T-Cell Cytotoxicity with Quantum-Kernel\n  Methods","summary":"  Chimeric antigen receptor (CAR) T-cells are T-cells engineered to recognize\nand kill specific tumor cells. Through their extracellular domains, CAR T-cells\nbind tumor cell antigens which triggers CAR T activation and proliferation.\nThese processes are regulated by co-stimulatory domains present in the\nintracellular region of the CAR T-cell. Through integrating novel signaling\ncomponents into the co-stimulatory domains, it is possible to modify CAR T-cell\nphenotype. Identifying and experimentally testing new CAR constructs based on\nlibraries of co-stimulatory domains is nontrivial given the vast combinatorial\nspace defined by such libraries. This leads to a highly data constrained,\npoorly explored combinatorial problem, where the experiments undersample all\npossible combinations. We propose a quantum approach using a Projected Quantum\nKernel (PQK) to address this challenge. PQK operates by embedding classical\ndata into a high dimensional Hilbert space and employs a kernel method to\nmeasure sample similarity. Using 61 qubits on a gate-based quantum computer, we\ndemonstrate the largest PQK application to date and an enhancement in the\nclassification performance over purely classical machine learning methods for\nCAR T cytotoxicity prediction. Importantly, we show improved learning for\nspecific signaling domains and domain positions, particularly where there was\nlower information highlighting the potential for quantum computing in\ndata-constrained problems.\n","authors":["Filippo Utro","Meltem Tolunay","Kahn Rhrissorrakrai","Tanvi P. Gujarati","Jie Shi","Sara Capponi","Mirko Amico","Nate Earnest-Noble","Laxmi Parida"],"pdf_url":"https://arxiv.org/pdf/2507.22710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11409v4","updated":"2025-07-30T14:09:44Z","published":"2025-01-20T11:16:44Z","title":"Unsupervised Learning in Echo State Networks for Input Reconstruction","summary":"  Echo state networks (ESNs) are a class of recurrent neural networks in which\nonly the readout layer is trainable, while the recurrent and input layers are\nfixed. This architectural constraint enables computationally efficient\nprocessing of time-series data. Traditionally, the readout layer in ESNs is\ntrained using supervised learning with target outputs. In this study, we focus\non input reconstruction (IR), where the readout layer is trained to reconstruct\nthe input time series fed into the ESN. We show that IR can be achieved through\nunsupervised learning (UL), without access to supervised targets, provided that\nthe ESN parameters are known a priori and satisfy invertibility conditions.\nThis formulation allows applications relying on IR, such as dynamical system\nreplication and noise filtering, to be reformulated within the UL framework via\nstraightforward integration with existing algorithms. Our results suggest that\nprior knowledge of ESN parameters can reduce reliance on supervision, thereby\nestablishing a new principle: not only by fixing part of the network parameters\nbut also by exploiting their specific values. Furthermore, our UL-based\nalgorithms for input reconstruction and related tasks are suitable for\nautonomous processing, offering insights into how analogous computational\nmechanisms might operate in the brain in principle. These findings contribute\nto a deeper understanding of the mathematical foundations of ESNs and their\nrelevance to models in computational neuroscience.\n","authors":["Taiki Yamada","Yuichi Katori","Kantaro Fujiwara"],"pdf_url":"https://arxiv.org/pdf/2501.11409v4.pdf","comment":"35 pages, 11 figures. This paper has been accepted for publication in\n  Neural Computation (MIT Press)"},{"id":"http://arxiv.org/abs/2410.07501v2","updated":"2025-07-30T14:06:57Z","published":"2024-10-10T00:33:25Z","title":"Inferring biological processes with intrinsic noise from cross-sectional\n  data","summary":"  Inferring dynamical models from data continues to be a significant challenge\nin computational biology, especially given the stochastic nature of many\nbiological processes. We explore a common scenario in omics, where\nstatistically independent cross-sectional samples are available at a few time\npoints, and the goal is to infer the underlying diffusion process that\ngenerated the data. Existing inference approaches often simplify or ignore\nnoise intrinsic to the system, compromising accuracy for the sake of\noptimization ease. We circumvent this compromise by inferring the phase-space\nprobability flow that shares the same time-dependent marginal distributions as\nthe underlying stochastic process. Our approach, probability flow inference\n(PFI), disentangles force from intrinsic stochasticity while retaining the\nalgorithmic ease of ODE inference. Analytically, we prove that for\nOrnstein-Uhlenbeck processes the regularized PFI formalism yields a unique\nsolution in the limit of well-sampled distributions. In practical applications,\nwe show that PFI enables accurate parameter and force estimation in\nhigh-dimensional stochastic reaction networks, and that it allows inference of\ncell differentiation dynamics with molecular noise, outperforming\nstate-of-the-art approaches.\n","authors":["Suryanarayana Maddu","Victor Chardès","Michael. J. Shelley"],"pdf_url":"https://arxiv.org/pdf/2410.07501v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.23215v2","updated":"2025-07-30T13:58:12Z","published":"2025-03-29T20:38:04Z","title":"Unsupervised Learning: Comparative Analysis of Clustering Techniques on\n  High-Dimensional Data","summary":"  This paper presents a comprehensive comparative analysis of prominent\nclustering algorithms K-means, DBSCAN, and Spectral Clustering on\nhigh-dimensional datasets. We introduce a novel evaluation framework that\nassesses clustering performance across multiple dimensionality reduction\ntechniques (PCA, t-SNE, and UMAP) using diverse quantitative metrics.\nExperiments conducted on MNIST, Fashion-MNIST, and UCI HAR datasets reveal that\npreprocessing with UMAP consistently improves clustering quality across all\nalgorithms, with Spectral Clustering demonstrating superior performance on\ncomplex manifold structures. Our findings show that algorithm selection should\nbe guided by data characteristics, with Kmeans excelling in computational\nefficiency, DBSCAN in handling irregular clusters, and Spectral Clustering in\ncapturing complex relationships. This research contributes a systematic\napproach for evaluating and selecting clustering techniques for high\ndimensional data applications.\n","authors":["Vishnu Vardhan Baligodugula","Fathi Amsaad"],"pdf_url":"https://arxiv.org/pdf/2503.23215v2.pdf","comment":"The paper is being withdrawn due to significant errors in the\n  analysis that affect the validity of the conclusions. A revised version may\n  be submitted in the future once the issues are resolved"},{"id":"http://arxiv.org/abs/2505.14136v2","updated":"2025-07-30T13:53:32Z","published":"2025-05-20T09:39:54Z","title":"Local Mixtures of Experts: Essentially Free Test-Time Training via Model\n  Merging","summary":"  Mixture of expert (MoE) models are a promising approach to increasing model\ncapacity without increasing inference cost, and are core components of many\nstate-of-the-art language models. However, current MoE models typically use\nonly few experts due to prohibitive training and inference cost. We propose\nTest-Time Model Merging (TTMM) which scales the MoE paradigm to an order of\nmagnitude more experts and uses model merging to avoid almost any test-time\noverhead. We show that TTMM is an approximation of test-time training (TTT),\nwhich fine-tunes an expert model for each prediction task, i.e., prompt. TTT\nhas recently been shown to significantly improve language models, but is\ncomputationally expensive. We find that performance of TTMM improves with more\nexperts and approaches the performance of TTT. Moreover, we find that with a 1B\nparameter base model, TTMM is more than 100x faster than TTT at test-time by\namortizing the cost of TTT at train-time. Thus, TTMM offers a promising\ncost-effective approach to scale test-time training.\n","authors":["Ryo Bertolissi","Jonas Hübotter","Ido Hakimi","Andreas Krause"],"pdf_url":"https://arxiv.org/pdf/2505.14136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19947v2","updated":"2025-07-30T13:52:22Z","published":"2025-07-26T13:24:02Z","title":"Spatial Language Likelihood Grounding Network for Bayesian Fusion of\n  Human-Robot Observations","summary":"  Fusing information from human observations can help robots overcome sensing\nlimitations in collaborative tasks. However, an uncertainty-aware fusion\nframework requires a grounded likelihood representing the uncertainty of human\ninputs. This paper presents a Feature Pyramid Likelihood Grounding Network\n(FP-LGN) that grounds spatial language by learning relevant map image features\nand their relationships with spatial relation semantics. The model is trained\nas a probability estimator to capture aleatoric uncertainty in human language\nusing three-stage curriculum learning. Results showed that FP-LGN matched\nexpert-designed rules in mean Negative Log-Likelihood (NLL) and demonstrated\ngreater robustness with lower standard deviation. Collaborative sensing results\ndemonstrated that the grounded likelihood successfully enabled\nuncertainty-aware fusion of heterogeneous human language observations and robot\nsensor measurements, achieving significant improvements in human-robot\ncollaborative task performance.\n","authors":["Supawich Sitdhipol","Waritwong Sukprasongdee","Ekapol Chuangsuwanich","Rina Tse"],"pdf_url":"https://arxiv.org/pdf/2507.19947v2.pdf","comment":"Accepted to the 2025 IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC); Supplementary video: https://cu-asl.github.io/fp-lgn/"},{"id":"http://arxiv.org/abs/2507.22665v1","updated":"2025-07-30T13:22:28Z","published":"2025-07-30T13:22:28Z","title":"Cluster-Based Random Forest Visualization and Interpretation","summary":"  Random forests are a machine learning method used to automatically classify\ndatasets and consist of a multitude of decision trees. While these random\nforests often have higher performance and generalize better than a single\ndecision tree, they are also harder to interpret. This paper presents a\nvisualization method and system to increase interpretability of random forests.\nWe cluster similar trees which enables users to interpret how the model\nperforms in general without needing to analyze each individual decision tree in\ndetail, or interpret an oversimplified summary of the full forest. To\nmeaningfully cluster the decision trees, we introduce a new distance metric\nthat takes into account both the decision rules as well as the predictions of a\npair of decision trees. We also propose two new visualization methods that\nvisualize both clustered and individual decision trees: (1) The Feature Plot,\nwhich visualizes the topological position of features in the decision trees,\nand (2) the Rule Plot, which visualizes the decision rules of the decision\ntrees. We demonstrate the efficacy of our approach through a case study on the\n\"Glass\" dataset, which is a relatively complex standard machine learning\ndataset, as well as a small user study.\n","authors":["Max Sondag","Christofer Meinecke","Dennis Collaris","Tatiana von Landesberger","Stef van den Elzen"],"pdf_url":"https://arxiv.org/pdf/2507.22665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.04858v3","updated":"2025-07-30T13:13:40Z","published":"2025-04-07T09:14:47Z","title":"Don't Lag, RAG: Training-Free Adversarial Detection Using RAG","summary":"  Adversarial patch attacks pose a major threat to vision systems by embedding\nlocalized perturbations that mislead deep models. Traditional defense methods\noften require retraining or fine-tuning, making them impractical for real-world\ndeployment. We propose a training-free Visual Retrieval-Augmented Generation\n(VRAG) framework that integrates Vision-Language Models (VLMs) for adversarial\npatch detection. By retrieving visually similar patches and images that\nresemble stored attacks in a continuously expanding database, VRAG performs\ngenerative reasoning to identify diverse attack types, all without additional\ntraining or fine-tuning. We extensively evaluate open-source large-scale VLMs,\nincluding Qwen-VL-Plus, Qwen2.5-VL-72B, and UI-TARS-72B-DPO, alongside\nGemini-2.0, a closed-source model. Notably, the open-source UI-TARS-72B-DPO\nmodel achieves up to 95 percent classification accuracy, setting a new\nstate-of-the-art for open-source adversarial patch detection. Gemini-2.0\nattains the highest overall accuracy, 98 percent, but remains closed-source.\nExperimental results demonstrate VRAG's effectiveness in identifying a variety\nof adversarial patches with minimal human annotation, paving the way for\nrobust, practical defenses against evolving adversarial patch attacks.\n","authors":["Roie Kazoom","Raz Lapid","Moshe Sipper","Ofer Hadar"],"pdf_url":"https://arxiv.org/pdf/2504.04858v3.pdf","comment":"Accepted at VecDB @ ICML 2025"},{"id":"http://arxiv.org/abs/2507.22647v1","updated":"2025-07-30T13:03:24Z","published":"2025-07-30T13:03:24Z","title":"Transductive Model Selection under Prior Probability Shift","summary":"  Transductive learning is a supervised machine learning task in which, unlike\nin traditional inductive learning, the unlabelled data that require labelling\nare a finite set and are available at training time. Similarly to inductive\nlearning contexts, transductive learning contexts may be affected by dataset\nshift, i.e., may be such that the IID assumption does not hold. We here propose\na method, tailored to transductive classification contexts, for performing\nmodel selection (i.e., hyperparameter optimisation) when the data exhibit prior\nprobability shift, an important type of dataset shift typical of anti-causal\nlearning problems. In our proposed method the hyperparameters can be optimised\ndirectly on the unlabelled data to which the trained classifier must be\napplied; this is unlike traditional model selection methods, that are based on\nperforming cross-validation on the labelled training data. We provide\nexperimental results that show the benefits brought about by our method.\n","authors":["Lorenzo Volpi","Alejandro Moreo","Fabrizio Sebastiani"],"pdf_url":"https://arxiv.org/pdf/2507.22647v1.pdf","comment":null}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2507.22877v1","updated":"2025-07-30T17:53:42Z","published":"2025-07-30T17:53:42Z","title":"Consistency of Feature Attribution in Deep Learning Architectures for\n  Multi-Omics","summary":"  Machine and deep learning have grown in popularity and use in biological\nresearch over the last decade but still present challenges in interpretability\nof the fitted model. The development and use of metrics to determine features\ndriving predictions and increase model interpretability continues to be an open\narea of research. We investigate the use of Shapley Additive Explanations\n(SHAP) on a multi-view deep learning model applied to multi-omics data for the\npurposes of identifying biomolecules of interest. Rankings of features via\nthese attribution methods are compared across various architectures to evaluate\nconsistency of the method. We perform multiple computational experiments to\nassess the robustness of SHAP and investigate modeling approaches and\ndiagnostics to increase and measure the reliability of the identification of\nimportant features. Accuracy of a random-forest model fit on subsets of\nfeatures selected as being most influential as well as clustering quality using\nonly these features are used as a measure of effectiveness of the attribution\nmethod. Our findings indicate that the rankings of features resulting from SHAP\nare sensitive to the choice of architecture as well as different random\ninitializations of weights, suggesting caution when using attribution methods\non multi-view deep learning models applied to multi-omics data. We present an\nalternative, simple method to assess the robustness of identification of\nimportant biomolecules.\n","authors":["Daniel Claborne","Javier Flores","Samantha Erwin","Luke Durell","Rachel Richardson","Ruby Fore","Lisa Bramer"],"pdf_url":"https://arxiv.org/pdf/2507.22877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22854v1","updated":"2025-07-30T17:24:23Z","published":"2025-07-30T17:24:23Z","title":"A Bit of Freedom Goes a Long Way: Classical and Quantum Algorithms for\n  Reinforcement Learning under a Generative Model","summary":"  We propose novel classical and quantum online algorithms for learning\nfinite-horizon and infinite-horizon average-reward Markov Decision Processes\n(MDPs). Our algorithms are based on a hybrid exploration-generative\nreinforcement learning (RL) model wherein the agent can, from time to time,\nfreely interact with the environment in a generative sampling fashion, i.e., by\nhaving access to a \"simulator\". By employing known classical and new quantum\nalgorithms for approximating optimal policies under a generative model within\nour learning algorithms, we show that it is possible to avoid several paradigms\nfrom RL like \"optimism in the face of uncertainty\" and \"posterior sampling\" and\ninstead compute and use optimal policies directly, which yields better regret\nbounds compared to previous works. For finite-horizon MDPs, our quantum\nalgorithms obtain regret bounds which only depend logarithmically on the number\nof time steps $T$, thus breaking the $O(\\sqrt{T})$ classical barrier. This\nmatches the time dependence of the prior quantum works of Ganguly et al.\n(arXiv'23) and Zhong et al. (ICML'24), but with improved dependence on other\nparameters like state space size $S$ and action space size $A$. For\ninfinite-horizon MDPs, our classical and quantum bounds still maintain the\n$O(\\sqrt{T})$ dependence but with better $S$ and $A$ factors. Nonetheless, we\npropose a novel measure of regret for infinite-horizon MDPs with respect to\nwhich our quantum algorithms have $\\operatorname{poly}\\log{T}$ regret,\nexponentially better compared to classical algorithms. Finally, we generalise\nall of our results to compact state spaces.\n","authors":["Andris Ambainis","Joao F. Doriguello","Debbie Lim"],"pdf_url":"https://arxiv.org/pdf/2507.22854v1.pdf","comment":"57 pages"},{"id":"http://arxiv.org/abs/2502.12920v3","updated":"2025-07-30T17:23:56Z","published":"2025-02-18T15:01:02Z","title":"Lightweight Online Adaption for Time Series Foundation Model Forecasts","summary":"  Foundation models (FMs) have emerged as a promising approach for time series\nforecasting. While effective, FMs typically remain fixed during deployment due\nto the high computational costs of learning them online. Consequently, deployed\nFMs fail to adapt their forecasts to current data characteristics, despite the\navailability of online feedback from newly arriving data. This raises the\nquestion of whether FM performance can be enhanced by the efficient usage of\nthis feedback. We propose ELF to answer this question. ELF is a lightweight\nmechanism for the online adaption of FM forecasts in response to online\nfeedback. ELF consists of two parts: a) the ELF-Forecaster which is used to\nlearn the current data distribution; and b) the ELF-Weighter which is used to\ncombine the forecasts of the FM and the ELF-Forecaster. We evaluate the\nperformance of ELF in conjunction with several recent FMs across a suite of\nstandard time series datasets. In all of our experiments we find that using ELF\nimproves performance. This work demonstrates how efficient usage of online\nfeedback can be used to improve FM forecasts.\n","authors":["Thomas L. Lee","William Toner","Rajkarn Singh","Artjom Joosen","Martin Asenov"],"pdf_url":"https://arxiv.org/pdf/2502.12920v3.pdf","comment":"9 pages, Published at ICML 2025"},{"id":"http://arxiv.org/abs/2507.22842v1","updated":"2025-07-30T17:00:05Z","published":"2025-07-30T17:00:05Z","title":"Subgrid BoostCNN: Efficient Boosting of Convolutional Networks via\n  Gradient-Guided Feature Selection","summary":"  Convolutional Neural Networks (CNNs) have achieved remarkable success across\na wide range of machine learning tasks by leveraging hierarchical feature\nlearning through deep architectures. However, the large number of layers and\nmillions of parameters often make CNNs computationally expensive to train,\nrequiring extensive time and manual tuning to discover optimal architectures.\nIn this paper, we introduce a novel framework for boosting CNN performance that\nintegrates dynamic feature selection with the principles of BoostCNN. Our\napproach incorporates two key strategies: subgrid selection and importance\nsampling, to guide training toward informative regions of the feature space. We\nfurther develop a family of algorithms that embed boosting weights directly\ninto the network training process using a least squares loss formulation. This\nintegration not only alleviates the burden of manual architecture design but\nalso enhances accuracy and efficiency. Experimental results across several\nfine-grained classification benchmarks demonstrate that our boosted CNN\nvariants consistently outperform conventional CNNs in both predictive\nperformance and training speed.\n","authors":["Biyi Fang","Jean Utke","Truong Vo","Diego Klabjan"],"pdf_url":"https://arxiv.org/pdf/2507.22842v1.pdf","comment":"10 pages, 5 figures. Experimental results reported on CIFAR-10, SVHN,\n  and ImageNetSub datasets. arXiv admin note: substantial text overlap with\n  arXiv:2203.00761"},{"id":"http://arxiv.org/abs/2411.16229v2","updated":"2025-07-30T15:42:47Z","published":"2024-11-25T09:42:42Z","title":"Effective Non-Random Extreme Learning Machine","summary":"  The Extreme Learning Machine (ELM) is a growing statistical technique widely\napplied to regression problems. In essence, ELMs are single-layer neural\nnetworks where the hidden layer weights are randomly sampled from a specific\ndistribution, while the output layer weights are learned from the data. Two of\nthe key challenges with this approach are the architecture design, specifically\ndetermining the optimal number of neurons in the hidden layer, and the method's\nsensitivity to the random initialization of hidden layer weights.\n  This paper introduces a new and enhanced learning algorithm for regression\ntasks, the Effective Non-Random ELM (ENR-ELM), which simplifies the\narchitecture design and eliminates the need for random hidden layer weight\nselection. The proposed method incorporates concepts from signal processing,\nsuch as basis functions and projections, into the ELM framework. We introduce\ntwo versions of the ENR-ELM: the approximated ENR-ELM and the incremental\nENR-ELM. Experimental results on both synthetic and real datasets demonstrate\nthat our method overcomes the problems of traditional ELM while maintaining\ncomparable predictive performance.\n","authors":["Daniela De Canditiis","Fabiano Veglianti"],"pdf_url":"https://arxiv.org/pdf/2411.16229v2.pdf","comment":"To appear in Neural Computing and Applications (online 29 July 2025)"},{"id":"http://arxiv.org/abs/2506.16965v2","updated":"2025-07-30T14:53:10Z","published":"2025-06-20T12:52:44Z","title":"RocketStack: Level-aware deep recursive ensemble learning framework with\n  adaptive feature fusion and model pruning dynamics","summary":"  Ensemble learning remains a cornerstone of machine learning, with stacking\nused to integrate predictions from multiple base learners through a meta-model.\nHowever, deep stacking remains rare, as most designs prioritize horizontal\ndiversity over recursive depth due to model complexity, feature redundancy, and\ncomputational burden. To address these challenges, RocketStack, a level-aware\nrecursive ensemble framework, is introduced and explored up to ten stacking\nlevels, extending beyond prior architectures. The framework incrementally\nprunes weaker learners at each level, enabling deeper stacking without\nexcessive complexity. To mitigate early performance saturation, mild Gaussian\nnoise is added to out-of-fold (OOF) scores before pruning, and compared against\nstrict OOF pruning. Further both per-level and periodic feature compressions\nare explored using attention-based selection, Simple, Fast, Efficient (SFE)\nfilter, and autoencoders. Across 33 datasets (23 binary, 10 multi-class),\nlinear-trend tests confirmed rising accuracy with depth in most variants, and\nthe top performing meta-model at each level increasingly outperformed the\nstrongest standalone ensemble. In the binary subset, periodic SFE with mild\nOOF-score randomization reached 97.08% at level 10, 5.14% above the\nstrict-pruning configuration and cut runtime by 10.5% relative to no\ncompression. In the multi-class subset, periodic attention selection reached\n98.60% at level 10, exceeding the strongest baseline by 6.11%, while reducing\nruntime by 56.1% and feature dimensionality by 74% compared to no compression.\nThese findings highlight mild randomization as an effective regularizer and\nperiodic compression as a stabilizer. Echoing the design of multistage rockets\nin aerospace (prune, compress, propel) RocketStack achieves deep recursive\nensembling with tractable complexity.\n","authors":["Çağatay Demirel"],"pdf_url":"https://arxiv.org/pdf/2506.16965v2.pdf","comment":"30 pages, 1 graphical abstract, 7 figures, 9 tables, 2 supplementary\n  figures"},{"id":"http://arxiv.org/abs/2503.23215v2","updated":"2025-07-30T13:58:12Z","published":"2025-03-29T20:38:04Z","title":"Unsupervised Learning: Comparative Analysis of Clustering Techniques on\n  High-Dimensional Data","summary":"  This paper presents a comprehensive comparative analysis of prominent\nclustering algorithms K-means, DBSCAN, and Spectral Clustering on\nhigh-dimensional datasets. We introduce a novel evaluation framework that\nassesses clustering performance across multiple dimensionality reduction\ntechniques (PCA, t-SNE, and UMAP) using diverse quantitative metrics.\nExperiments conducted on MNIST, Fashion-MNIST, and UCI HAR datasets reveal that\npreprocessing with UMAP consistently improves clustering quality across all\nalgorithms, with Spectral Clustering demonstrating superior performance on\ncomplex manifold structures. Our findings show that algorithm selection should\nbe guided by data characteristics, with Kmeans excelling in computational\nefficiency, DBSCAN in handling irregular clusters, and Spectral Clustering in\ncapturing complex relationships. This research contributes a systematic\napproach for evaluating and selecting clustering techniques for high\ndimensional data applications.\n","authors":["Vishnu Vardhan Baligodugula","Fathi Amsaad"],"pdf_url":"https://arxiv.org/pdf/2503.23215v2.pdf","comment":"The paper is being withdrawn due to significant errors in the\n  analysis that affect the validity of the conclusions. A revised version may\n  be submitted in the future once the issues are resolved"},{"id":"http://arxiv.org/abs/2507.22640v1","updated":"2025-07-30T12:58:02Z","published":"2025-07-30T12:58:02Z","title":"Safe Deployment of Offline Reinforcement Learning via Input Convex\n  Action Correction","summary":"  Offline reinforcement learning (offline RL) offers a promising framework for\ndeveloping control strategies in chemical process systems using historical\ndata, without the risks or costs of online experimentation. This work\ninvestigates the application of offline RL to the safe and efficient control of\nan exothermic polymerisation continuous stirred-tank reactor. We introduce a\nGymnasium-compatible simulation environment that captures the reactor's\nnonlinear dynamics, including reaction kinetics, energy balances, and\noperational constraints. The environment supports three industrially relevant\nscenarios: startup, grade change down, and grade change up. It also includes\nreproducible offline datasets generated from proportional-integral controllers\nwith randomised tunings, providing a benchmark for evaluating offline RL\nalgorithms in realistic process control tasks.\n  We assess behaviour cloning and implicit Q-learning as baseline algorithms,\nhighlighting the challenges offline agents face, including steady-state offsets\nand degraded performance near setpoints. To address these issues, we propose a\nnovel deployment-time safety layer that performs gradient-based action\ncorrection using input convex neural networks (PICNNs) as learned cost models.\nThe PICNN enables real-time, differentiable correction of policy actions by\ndescending a convex, state-conditioned cost surface, without requiring\nretraining or environment interaction.\n  Experimental results show that offline RL, particularly when combined with\nconvex action correction, can outperform traditional control approaches and\nmaintain stability across all scenarios. These findings demonstrate the\nfeasibility of integrating offline RL with interpretable and safety-aware\ncorrections for high-stakes chemical process control, and lay the groundwork\nfor more reliable data-driven automation in industrial systems.\n","authors":["Alex Durkin","Jasper Stolte","Matthew Jones","Raghuraman Pitchumani","Bei Li","Christian Michler","Mehmet Mercangöz"],"pdf_url":"https://arxiv.org/pdf/2507.22640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22632v1","updated":"2025-07-30T12:53:08Z","published":"2025-07-30T12:53:08Z","title":"A Unified Analysis of Generalization and Sample Complexity for\n  Semi-Supervised Domain Adaptation","summary":"  Domain adaptation seeks to leverage the abundant label information in a\nsource domain to improve classification performance in a target domain with\nlimited labels. While the field has seen extensive methodological development,\nits theoretical foundations remain relatively underexplored. Most existing\ntheoretical analyses focus on simplified settings where the source and target\ndomains share the same input space and relate target-domain performance to\nmeasures of domain discrepancy. Although insightful, these analyses may not\nfully capture the behavior of modern approaches that align domains into a\nshared space via feature transformations. In this paper, we present a\ncomprehensive theoretical study of domain adaptation algorithms based on domain\nalignment. We consider the joint learning of domain-aligning feature\ntransformations and a shared classifier in a semi-supervised setting. We first\nderive generalization bounds in a broad setting, in terms of covering numbers\nof the relevant function classes. We then extend our analysis to characterize\nthe sample complexity of domain-adaptive neural networks employing maximum mean\ndiscrepancy (MMD) or adversarial objectives. Our results rely on a rigorous\nanalysis of the covering numbers of these architectures. We show that, for both\nMMD-based and adversarial models, the sample complexity admits an upper bound\nthat scales quadratically with network depth and width. Furthermore, our\nanalysis suggests that in semi-supervised settings, robustness to limited\nlabeled target data can be achieved by scaling the target loss proportionally\nto the square root of the number of labeled target samples. Experimental\nevaluation in both shallow and deep settings lends support to our theoretical\nfindings.\n","authors":["Elif Vural","Huseyin Karaca"],"pdf_url":"https://arxiv.org/pdf/2507.22632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22629v1","updated":"2025-07-30T12:49:53Z","published":"2025-07-30T12:49:53Z","title":"Quantum-assisted Gaussian process regression using random Fourier\n  features","summary":"  Probabilistic machine learning models are distinguished by their ability to\nintegrate prior knowledge of noise statistics, smoothness parameters, and\ntraining data uncertainty. A common approach involves modeling data with\nGaussian processes; however, their computational complexity quickly becomes\nintractable as the training dataset grows. To address this limitation, we\nintroduce a quantum-assisted algorithm for sparse Gaussian process regression\nbased on the random Fourier feature kernel approximation. We start by encoding\nthe data matrix into a quantum state using a multi-controlled unitary\noperation, which encodes the classical representation of the random Fourier\nfeatures matrix used for kernel approximation. We then employ a quantum\nprincipal component analysis along with a quantum phase estimation technique to\nextract the spectral decomposition of the kernel matrix. We apply a conditional\nrotation operator to the ancillary qubit based on the eigenvalue. We then use\nHadamard and swap tests to compute the mean and variance of the posterior\nGaussian distribution. We achieve a polynomial-order computational speedup\nrelative to the classical method.\n","authors":["Cristian A. Galvis-Florez","Ahmad Farooq","Simo Särkkä"],"pdf_url":"https://arxiv.org/pdf/2507.22629v1.pdf","comment":"Accepted at 2025 IEEE International Conference on Quantum Software\n  (QSW)"},{"id":"http://arxiv.org/abs/2507.22004v2","updated":"2025-07-30T11:55:45Z","published":"2025-07-29T16:53:44Z","title":"Horseshoe Forests for High-Dimensional Causal Survival Analysis","summary":"  We develop a Bayesian tree ensemble model to estimate heterogeneous treatment\neffects in censored survival data with high-dimensional covariates. Instead of\nimposing sparsity through the tree structure, we place a horseshoe prior\ndirectly on the step heights to achieve adaptive global-local shrinkage. This\nstrategy allows flexible regularisation and reduces noise. We develop a\nreversible jump Gibbs sampler to accommodate the non-conjugate horseshoe prior\nwithin the tree ensemble framework. We show through extensive simulations that\nthe method accurately estimates treatment effects in high-dimensional covariate\nspaces, at various sparsity levels, and under non-linear treatment effect\nfunctions. We further illustrate the practical utility of the proposed approach\nby a re-analysis of pancreatic ductal adenocarcinoma (PDAC) survival data from\nThe Cancer Genome Atlas.\n","authors":["Tijn Jacobs","Wessel N. van Wieringen","Stéphanie L. van der Pas"],"pdf_url":"https://arxiv.org/pdf/2507.22004v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22493v1","updated":"2025-07-30T09:00:39Z","published":"2025-07-30T09:00:39Z","title":"LVM-GP: Uncertainty-Aware PDE Solver via coupling latent variable model\n  and Gaussian process","summary":"  We propose a novel probabilistic framework, termed LVM-GP, for uncertainty\nquantification in solving forward and inverse partial differential equations\n(PDEs) with noisy data. The core idea is to construct a stochastic mapping from\nthe input to a high-dimensional latent representation, enabling\nuncertainty-aware prediction of the solution. Specifically, the architecture\nconsists of a confidence-aware encoder and a probabilistic decoder. The encoder\nimplements a high-dimensional latent variable model based on a Gaussian process\n(LVM-GP), where the latent representation is constructed by interpolating\nbetween a learnable deterministic feature and a Gaussian process prior, with\nthe interpolation strength adaptively controlled by a confidence function\nlearned from data. The decoder defines a conditional Gaussian distribution over\nthe solution field, where the mean is predicted by a neural operator applied to\nthe latent representation, allowing the model to learn flexible\nfunction-to-function mapping. Moreover, physical laws are enforced as soft\nconstraints in the loss function to ensure consistency with the underlying PDE\nstructure. Compared to existing approaches such as Bayesian physics-informed\nneural networks (B-PINNs) and deep ensembles, the proposed framework can\nefficiently capture functional dependencies via merging a latent Gaussian\nprocess and neural operator, resulting in competitive predictive accuracy and\nrobust uncertainty quantification. Numerical experiments demonstrate the\neffectiveness and reliability of the method.\n","authors":["Xiaodong Feng","Ling Guo","Xiaoliang Wan","Hao Wu","Tao Zhou","Wenwen Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.22493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.02002v2","updated":"2025-07-30T08:25:58Z","published":"2025-02-04T04:30:03Z","title":"The Ball-Proximal (=\"Broximal\") Point Method: a New Algorithm,\n  Convergence Theory, and Applications","summary":"  Non-smooth and non-convex global optimization poses significant challenges\nacross various applications, where standard gradient-based methods often\nstruggle. We propose the Ball-Proximal Point Method, Broximal Point Method, or\nBall Point Method (BPM) for short - a novel algorithmic framework inspired by\nthe classical Proximal Point Method (PPM) (Rockafellar, 1976), which, as we\nshow, sheds new light on several foundational optimization paradigms and\nphenomena, including non-convex and non-smooth optimization, acceleration,\nsmoothing, adaptive stepsize selection, and trust-region methods. At the core\nof BPM lies the ball-proximal (\"broximal\") operator, which arises from the\nclassical proximal operator by replacing the quadratic distance penalty by a\nball constraint. Surprisingly, and in sharp contrast with the sublinear rate of\nPPM in the nonsmooth convex regime, we prove that BPM converges linearly and in\na finite number of steps in the same regime. Furthermore, by introducing the\nconcept of ball-convexity, we prove that BPM retains the same global\nconvergence guarantees under weaker assumptions, making it a powerful tool for\na broader class of potentially non-convex optimization problems. Just like PPM\nplays the role of a conceptual method inspiring the development of practically\nefficient algorithms and algorithmic elements, e.g., gradient descent, adaptive\nstep sizes, acceleration (Ahn & Sra, 2020), and \"W\" in AdamW (Zhuang et al.,\n2022), we believe that BPM should be understood in the same manner: as a\nblueprint and inspiration for further development.\n","authors":["Kaja Gruntkowska","Hanmin Li","Aadi Rane","Peter Richtárik"],"pdf_url":"https://arxiv.org/pdf/2502.02002v2.pdf","comment":"47 pages, 3 figures"},{"id":"http://arxiv.org/abs/2507.22396v1","updated":"2025-07-30T05:30:46Z","published":"2025-07-30T05:30:46Z","title":"CLuP practically achieves $\\sim 1.77$ positive and $\\sim 0.33$ negative\n  Hopfield model ground state free energy","summary":"  We study algorithmic aspects of finding $n$-dimensional \\emph{positive} and\n\\emph{negative} Hopfield ($\\pm$Hop) model ground state free energies. This\ncorresponds to classical maximization of random positive/negative semi-definite\nquadratic forms over binary $\\left \\{\\pm \\frac{1}{\\sqrt{n}} \\right \\}^n$\nvectors. The key algorithmic question is whether these problems can be\ncomputationally efficiently approximated within a factor $\\approx 1$. Following\nthe introduction and success of \\emph{Controlled Loosening-up} (CLuP-SK)\nalgorithms in finding near ground state energies of closely related\nSherrington-Kirkpatrick (SK) models [82], we here propose a CLuP$\\pm$Hop\ncounterparts for $\\pm$Hop models. Fully lifted random duality theory (fl RDT)\n[78] is utilized to characterize CLuP$\\pm$Hop \\emph{typical} dynamics. An\nexcellent agreement between practical performance and theoretical predictions\nis observed. In particular, for $n$ as small as few thousands CLuP$\\pm$Hop\nachieve $\\sim 1.77$ and $\\sim 0.33$ as the ground state free energies of the\npositive and negative Hopfield models. At the same time we obtain on the 6th\nlevel of lifting (6-spl RDT) corresponding theoretical thermodynamic\n($n\\rightarrow\\infty$) limits $\\approx 1.7784$ and $\\approx 0.3281$. This\npositions determining Hopfield models near ground state energies as\n\\emph{typically} easy problems. Moreover, the very same 6th lifting level\nevaluations allow to uncover a fundamental intrinsic difference between two\nmodels: $+$Hop's near optimal configurations are \\emph{typically close} to each\nother whereas the $-$Hop's are \\emph{typically far away}.\n","authors":["Mihailo Stojnic"],"pdf_url":"https://arxiv.org/pdf/2507.22396v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.11448v3","updated":"2025-07-30T04:49:23Z","published":"2025-01-20T12:35:58Z","title":"An accuracy-runtime trade-off comparison of scalable Gaussian process\n  approximations for spatial data","summary":"  Gaussian processes (GPs) are flexible, probabilistic, non-parametric models\nwidely employed in various fields such as spatial statistics and machine\nlearning. A drawback of Gaussian processes is their computational cost having\n$\\mathcal{O}(N^3)$ time and $\\mathcal{O}(N^2)$ memory complexity which makes\nthem prohibitive for large data sets. Numerous approximation techniques have\nbeen proposed to address this limitation. In this work, we systematically\ncompare the accuracy of different Gaussian process approximations concerning\nlikelihood evaluation, parameter estimation, and prediction taking into account\nthe computational time required to perform these tasks. In other words, we\nanalyze the trade-off between accuracy and runtime on multiple simulated and\nlarge-scale real-world data sets. We find that Vecchia approximations\nconsistently emerge as the most accurate in almost all experiments.\n","authors":["Filippo Rambelli","Fabio Sigrist"],"pdf_url":"https://arxiv.org/pdf/2501.11448v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.12630v2","updated":"2025-07-30T02:11:56Z","published":"2024-02-20T01:22:04Z","title":"FAST: An Optimization Framework for Fast Additive Segmentation in\n  Transparent ML","summary":"  We present FAST, an optimization framework for fast additive segmentation.\nFAST segments piecewise constant shape functions for each feature in a dataset\nto produce transparent additive models. The framework leverages a novel\noptimization procedure to fit these models $\\sim$2 orders of magnitude faster\nthan existing state-of-the-art methods, such as explainable boosting machines\n\\citep{nori2019interpretml}. We also develop new feature selection algorithms\nin the FAST framework to fit parsimonious models that perform well. Through\nexperiments and case studies, we show that FAST improves the computational\nefficiency and interpretability of additive models.\n","authors":["Brian Liu","Rahul Mazumder"],"pdf_url":"https://arxiv.org/pdf/2402.12630v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.03616v4","updated":"2025-07-30T01:09:18Z","published":"2024-06-05T20:23:52Z","title":"BEACON: A Bayesian Optimization Strategy for Novelty Search in Expensive\n  Black-Box Systems","summary":"  Novelty search (NS) refers to a class of exploration algorithms that seek to\nuncover diverse system behaviors through simulations or experiments. Such\ndiversity is central to many AI-driven discovery and design tasks, including\nmaterial and drug development, neural architecture search, and reinforcement\nlearning. However, existing NS methods typically rely on evolutionary\nstrategies and other meta-heuristics that require dense sampling of the input\nspace, making them impractical for expensive black-box systems. In this work,\nwe introduce BEACON, a sample-efficient, Bayesian optimization-inspired\napproach to NS that is tailored for settings where the input-to-behavior\nrelationship is opaque and costly to evaluate. BEACON models this mapping using\nmulti-output Gaussian processes (MOGPs) and selects new inputs by maximizing a\nnovelty metric computed from posterior samples of the MOGP, effectively\nbalancing the exploration-exploitation trade-off. By leveraging recent advances\nin posterior sampling and high-dimensional GP modeling, our method remains\nscalable to large input spaces and datasets. We evaluate BEACON across ten\nsynthetic benchmarks and eight real-world tasks, including the design of\ndiverse materials for clean energy applications. Our results show that BEACON\nsignificantly outperforms existing NS baselines, consistently discovering a\nbroader set of behaviors under tight evaluation budgets.\n","authors":["Wei-Ting Tang","Ankush Chakrabarty","Joel A. Paulson"],"pdf_url":"https://arxiv.org/pdf/2406.03616v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21197v2","updated":"2025-07-30T23:42:06Z","published":"2025-07-28T04:37:03Z","title":"AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation\n  for EHR-Based Clinical Prediction","summary":"  Machine learning interpretation (MLI) has primarily been leveraged to build\nclinician trust and uncover actionable insights in EHRs. However, the intrinsic\ncomplexity and heterogeneity of EHR data limit its effectiveness in guiding\nsubgroup-specific modeling. We propose AdaptHetero, a novel MLI-driven\nframework that transforms interpretability insights into actionable guidance\nfor tailoring model training and evaluation across subpopulations within\nindividual hospital systems. Evaluated on three large-scale EHR datasets:\nGOSSIS-1-eICU, WiDS, and MIMIC-IV, AdaptHetero consistently identifies\nheterogeneous model behaviors in predicting ICU mortality, in-hospital death,\nand hidden hypoxemia. By integrating SHAP-based interpretation and unsupervised\nclustering, the framework enhances the identification of clinically meaningful\nsubgroup-specific characteristics, leading to improved predictive performance\nand optimized clinical deployment.\n","authors":["Ling Liao","Eva Aagaard"],"pdf_url":"https://arxiv.org/pdf/2507.21197v2.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2506.14781v2","updated":"2025-07-30T19:09:52Z","published":"2025-05-24T20:41:45Z","title":"Two-dimensional Parallel Tempering for Constrained Optimization","summary":"  Sampling Boltzmann probability distributions plays a key role in machine\nlearning and optimization, motivating the design of hardware accelerators such\nas Ising machines. While the Ising model can in principle encode arbitrary\noptimization problems, practical implementations are often hindered by soft\nconstraints that either slow down mixing when too strong, or fail to enforce\nfeasibility when too weak. We introduce a two-dimensional extension of the\npowerful parallel tempering algorithm (PT) that addresses this challenge by\nadding a second dimension of replicas interpolating the penalty strengths. This\nscheme ensures constraint satisfaction in the final replicas, analogous to\nlow-energy states at low temperature. The resulting two-dimensional parallel\ntempering algorithm (2D-PT) improves mixing in heavily constrained replicas and\neliminates the need to explicitly tune the penalty strength. In a\nrepresentative example of graph sparsification with copy constraints, 2D-PT\nachieves near-ideal mixing, with Kullback-Leibler divergence decaying as\nO(1/t). When applied to sparsified Wishart instances, 2D-PT yields orders of\nmagnitude speedup over conventional PT with the same number of replicas. The\nmethod applies broadly to constrained Ising problems and can be deployed on\nexisting Ising machines.\n","authors":["Corentin Delacour","M Mahmudul Hasan Sajeeb","Joao P. Hespanha","Kerem Y. Camsari"],"pdf_url":"https://arxiv.org/pdf/2506.14781v2.pdf","comment":"Added references in Introduction"},{"id":"http://arxiv.org/abs/2407.01621v2","updated":"2025-07-30T18:26:45Z","published":"2024-06-29T03:17:53Z","title":"Deciphering interventional dynamical causality from non-intervention\n  complex systems","summary":"  Detecting and quantifying causality is a focal topic in the fields of\nscience, engineering, and interdisciplinary studies. However, causal studies on\nnon-intervention systems attract much attention but remain extremely\nchallenging. Delay-embedding technique provides a promising approach. In this\nstudy, we propose a framework named Interventional Dynamical Causality (IntDC)\nin contrast to the traditional Constructive Dynamical Causality (ConDC). ConDC,\nincluding Granger causality, transfer entropy and convergence of cross-mapping,\nmeasures the causality by constructing a dynamical model without considering\ninterventions. A computational criterion, Interventional Embedding Entropy\n(IEE), is proposed to measure causal strengths in an interventional manner. IEE\nis an intervened causal information flow but in the delay-embedding space.\nFurther, the IEE theoretically and numerically enables the deciphering of IntDC\nsolely from observational (non-interventional) time-series data, without\nrequiring any knowledge of dynamical models or real interventions in the\nconsidered system. In particular, IEE can be applied to rank causal effects\naccording to their importance and construct causal networks from data. We\nconducted numerical experiments to demonstrate that IEE can find causal edges\naccurately, eliminate effects of confounding, and quantify causal strength\nrobustly over traditional indices. We also applied IEE to real-world tasks. IEE\nperformed as an accurate and robust tool for causal analyses solely from the\nobservational data. The IntDC framework and IEE algorithm provide an efficient\napproach to the study of causality from time series in diverse non-intervention\ncomplex systems.\n","authors":["Jifan Shi","Yang Li","Juan Zhao","Siyang Leng","Rui Bao","Kazuyuki Aihara","Luonan Chen","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2407.01621v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23017v1","updated":"2025-07-30T18:25:42Z","published":"2025-07-30T18:25:42Z","title":"A Smoothing Newton Method for Rank-one Matrix Recovery","summary":"  We consider the phase retrieval problem, which involves recovering a rank-one\npositive semidefinite matrix from rank-one measurements. A recently proposed\nalgorithm based on Bures-Wasserstein gradient descent (BWGD) exhibits\nsuperlinear convergence, but it is unstable, and existing theory can only prove\nlocal linear convergence for higher rank matrix recovery. We resolve this gap\nby revealing that BWGD implements Newton's method with a nonsmooth and\nnonconvex objective. We develop a smoothing framework that regularizes the\nobjective, enabling a stable method with rigorous superlinear convergence\nguarantees. Experiments on synthetic data demonstrate this superior stability\nwhile maintaining fast convergence.\n","authors":["Tyler Maunu","Gabriel Abreu"],"pdf_url":"https://arxiv.org/pdf/2507.23017v1.pdf","comment":"12 pages, 4 figures"},{"id":"http://arxiv.org/abs/2507.22786v1","updated":"2025-07-30T15:51:20Z","published":"2025-07-30T15:51:20Z","title":"DO-EM: Density Operator Expectation Maximization","summary":"  Density operators, quantum generalizations of probability distributions, are\ngaining prominence in machine learning due to their foundational role in\nquantum computing. Generative modeling based on density operator models\n(\\textbf{DOMs}) is an emerging field, but existing training algorithms -- such\nas those for the Quantum Boltzmann Machine -- do not scale to real-world data,\nsuch as the MNIST dataset. The Expectation-Maximization algorithm has played a\nfundamental role in enabling scalable training of probabilistic latent variable\nmodels on real-world datasets. \\textit{In this paper, we develop an\nExpectation-Maximization framework to learn latent variable models defined\nthrough \\textbf{DOMs} on classical hardware, with resources comparable to those\nused for probabilistic models, while scaling to real-world data.} However,\ndesigning such an algorithm is nontrivial due to the absence of a well-defined\nquantum analogue to conditional probability, which complicates the Expectation\nstep. To overcome this, we reformulate the Expectation step as a quantum\ninformation projection (QIP) problem and show that the Petz Recovery Map\nprovides a solution under sufficient conditions. Using this formulation, we\nintroduce the Density Operator Expectation Maximization (DO-EM) algorithm -- an\niterative Minorant-Maximization procedure that optimizes a quantum evidence\nlower bound. We show that the \\textbf{DO-EM} algorithm ensures non-decreasing\nlog-likelihood across iterations for a broad class of models. Finally, we\npresent Quantum Interleaved Deep Boltzmann Machines (\\textbf{QiDBMs}), a\n\\textbf{DOM} that can be trained with the same resources as a DBM. When trained\nwith \\textbf{DO-EM} under Contrastive Divergence, a \\textbf{QiDBM} outperforms\nlarger classical DBMs in image generation on the MNIST dataset, achieving a\n40--60\\% reduction in the Fr\\'echet Inception Distance.\n","authors":["Adit Vishnu","Abhay Shastry","Dhruva Kashyap","Chiranjib Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2507.22786v1.pdf","comment":"Main text: 9 pages 1 Figure. Total: 23 pages 3 Figures"}],"Computation":[{"id":"http://arxiv.org/abs/2507.22629v1","updated":"2025-07-30T12:49:53Z","published":"2025-07-30T12:49:53Z","title":"Quantum-assisted Gaussian process regression using random Fourier\n  features","summary":"  Probabilistic machine learning models are distinguished by their ability to\nintegrate prior knowledge of noise statistics, smoothness parameters, and\ntraining data uncertainty. A common approach involves modeling data with\nGaussian processes; however, their computational complexity quickly becomes\nintractable as the training dataset grows. To address this limitation, we\nintroduce a quantum-assisted algorithm for sparse Gaussian process regression\nbased on the random Fourier feature kernel approximation. We start by encoding\nthe data matrix into a quantum state using a multi-controlled unitary\noperation, which encodes the classical representation of the random Fourier\nfeatures matrix used for kernel approximation. We then employ a quantum\nprincipal component analysis along with a quantum phase estimation technique to\nextract the spectral decomposition of the kernel matrix. We apply a conditional\nrotation operator to the ancillary qubit based on the eigenvalue. We then use\nHadamard and swap tests to compute the mean and variance of the posterior\nGaussian distribution. We achieve a polynomial-order computational speedup\nrelative to the classical method.\n","authors":["Cristian A. Galvis-Florez","Ahmad Farooq","Simo Särkkä"],"pdf_url":"https://arxiv.org/pdf/2507.22629v1.pdf","comment":"Accepted at 2025 IEEE International Conference on Quantum Software\n  (QSW)"},{"id":"http://arxiv.org/abs/2501.11448v3","updated":"2025-07-30T04:49:23Z","published":"2025-01-20T12:35:58Z","title":"An accuracy-runtime trade-off comparison of scalable Gaussian process\n  approximations for spatial data","summary":"  Gaussian processes (GPs) are flexible, probabilistic, non-parametric models\nwidely employed in various fields such as spatial statistics and machine\nlearning. A drawback of Gaussian processes is their computational cost having\n$\\mathcal{O}(N^3)$ time and $\\mathcal{O}(N^2)$ memory complexity which makes\nthem prohibitive for large data sets. Numerous approximation techniques have\nbeen proposed to address this limitation. In this work, we systematically\ncompare the accuracy of different Gaussian process approximations concerning\nlikelihood evaluation, parameter estimation, and prediction taking into account\nthe computational time required to perform these tasks. In other words, we\nanalyze the trade-off between accuracy and runtime on multiple simulated and\nlarge-scale real-world data sets. We find that Vecchia approximations\nconsistently emerge as the most accurate in almost all experiments.\n","authors":["Filippo Rambelli","Fabio Sigrist"],"pdf_url":"https://arxiv.org/pdf/2501.11448v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23106v1","updated":"2025-07-30T21:13:26Z","published":"2025-07-30T21:13:26Z","title":"Efficient inference of dynamic gene regulatory networks using discrete\n  penalty","summary":"  Gene regulatory networks (GRNs) orchestrate cellular decision making and\nsurvival strategies. Inferring the structure of these networks from\nhigh-dimensional transcriptomics data is a central challenge in systems\nbiology. Traditional approaches to GRN inference, such as the graphical lasso\nand its joint extensions, rely on $\\ell_1$ penalty to induce sparsity but can\nbias network recovery and require extensive hyperparameter tuning. Here, we\npresent a scalable framework for the joint inference of dynamic GRNs using a\ndiscrete $\\ell_0$ penalty, enabling direct and unbiased control over network\nsparsity. Leveraging recent algorithmic advances, we efficiently solve the\nresulting mixed-integer optimization problem for populations structured as\narbitrary tree hypergraphs, accommodating both continuous and categorical\ndistinctions among biological samples. After validating our method on synthetic\nbenchmarks, we apply it to single-cell and spatial transcriptomics data from\nglioblastoma (GBM) patient tumors. Our approach reconstructs gene networks\nacross tumor clusters, maps network rewiring along hypoxia gradients, and\nreveals niche-specific differences between primary and recurrent tumors. By\nproviding a robust and interpretable tool for GRN inference in complex tissues,\nour work facilitates high-resolution dissection of tumor heterogeneity and\nadaptation, with broad applicability to emerging large-scale transcriptomic\ndatasets.\n","authors":["Visweswaran Ravikumar","Aaresh Bhathena","Wajd N Al-Holou","Salar Fattahi","Arvind Rao"],"pdf_url":"https://arxiv.org/pdf/2507.23106v1.pdf","comment":null}]},"2025-07-31T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2507.23776v1","updated":"2025-07-31T17:58:25Z","published":"2025-07-31T17:58:25Z","title":"Cascaded Information Disclosure for Generalized Evaluation of Problem\n  Solving Capabilities","summary":"  While question-answering~(QA) benchmark performance is an automatic and\nscalable method to compare LLMs, it is an indirect method of evaluating their\nunderlying problem-solving capabilities. Therefore, we propose a holistic and\ngeneralizable framework based on \\emph{cascaded question disclosure} that\nprovides a more accurate estimate of the models' problem-solving capabilities\nwhile maintaining the scalability and automation. This approach collects model\nresponses in a stagewise manner with each stage revealing partial information\nabout the question designed to elicit generalized reasoning in LLMs. We find\nthat our approach not only provides a better comparison between LLMs, but also\ninduces better intermediate traces in models compared to the standard QA\nparadigm. We empirically verify this behavior on diverse reasoning and\nknowledge-heavy QA datasets by comparing LLMs of varying sizes and families.\nOur approach narrows the performance gap observed in the standard QA evaluation\nsettings, indicating that the prevalent indirect QA paradigm of evaluation\noverestimates the differences in performance between models. We further\nvalidate our findings by extensive ablation studies.\n","authors":["Yunxiang Yan","Tomohiro Sawada","Kartik Goyal"],"pdf_url":"https://arxiv.org/pdf/2507.23776v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2507.23773v1","updated":"2025-07-31T17:57:20Z","published":"2025-07-31T17:57:20Z","title":"SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning\n  Architecture with LLM-Based World Model","summary":"  AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.\n","authors":["Mingkai Deng","Jinyu Hou","Yilin Shen","Hongxia Jin","Graham Neubig","Zhiting Hu","Eric Xing"],"pdf_url":"https://arxiv.org/pdf/2507.23773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.06448v3","updated":"2025-07-31T17:54:47Z","published":"2025-07-08T23:22:34Z","title":"Perception-Aware Policy Optimization for Multimodal Reasoning","summary":"  Reinforcement Learning with Verifiable Rewards (RLVR) has proven to be a\nhighly effective strategy for endowing Large Language Models (LLMs) with robust\nmulti-step reasoning abilities. However, its design and optimizations remain\ntailored to purely textual domains, resulting in suboptimal performance when\napplied to multimodal reasoning tasks. In particular, we observe that a major\nsource of error in current multimodal reasoning lies in the perception of\nvisual inputs. To address this bottleneck, we propose PAPO, a novel policy\ngradient algorithm that encourages the model to learn to perceive while\nlearning to reason. Specifically, we introduce the Implicit Perception Loss in\nthe form of a KL divergence term, which can be seamlessly plugged into\nmainstream RLVR algorithms such as GRPO and DAPO. Notably, PAPO does not rely\non additional data curation, reward models, or stronger teacher models. To\nfurther enhance the training stability of PAPO, we introduce the Double Entropy\nLoss, which effectively regularizes the new KL objective without compromising\nperformance. Despite its simplicity, PAPO yields significant overall\nimprovements of 4.4%-17.5% on diverse multimodal benchmarks. The improvements\nare more pronounced, approaching 8.0%-19.1%, on tasks with high vision\ndependency. We also observe a substantial reduction of 30.5% in perception\nerrors, indicating improved perceptual capabilities with PAPO. Overall, our\nwork introduces a deeper integration of perception-aware supervision into core\nlearning objectives and lays the groundwork for a new RL framework that\nencourages visually grounded reasoning. Code and data will be made publicly\navailable for research purposes. Project page:\nhttps://mikewangwzhl.github.io/PAPO.\n","authors":["Zhenhailong Wang","Xuehang Guo","Sofia Stoica","Haiyang Xu","Hongru Wang","Hyeonjeong Ha","Xiusi Chen","Yangyi Chen","Ming Yan","Fei Huang","Heng Ji"],"pdf_url":"https://arxiv.org/pdf/2507.06448v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23751v1","updated":"2025-07-31T17:38:50Z","published":"2025-07-31T17:38:50Z","title":"CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning\n  and non-reasoning tasks","summary":"  We propose CoT-Self-Instruct, a synthetic data generation method that\ninstructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the\ngiven seed tasks, and then to generate a new synthetic prompt of similar\nquality and complexity for use in LLM training, followed by filtering for\nhigh-quality data with automatic metrics. In verifiable reasoning, our\nsynthetic data significantly outperforms existing training datasets, such as\ns1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For\nnon-verifiable instruction-following tasks, our method surpasses the\nperformance of human or standard self-instruct prompts on both AlpacaEval 2.0\nand Arena-Hard.\n","authors":["Ping Yu","Jack Lanchantin","Tianlu Wang","Weizhe Yuan","Olga Golovneva","Ilia Kulikov","Sainbayar Sukhbaatar","Jason Weston","Jing Xu"],"pdf_url":"https://arxiv.org/pdf/2507.23751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23740v1","updated":"2025-07-31T17:24:04Z","published":"2025-07-31T17:24:04Z","title":"Rule2Text: Natural Language Explanation of Logical Rules in Knowledge\n  Graphs","summary":"  Knowledge graphs (KGs) often contain sufficient information to support the\ninference of new facts. Identifying logical rules not only improves the\ncompleteness of a knowledge graph but also enables the detection of potential\nerrors, reveals subtle data patterns, and enhances the overall capacity for\nreasoning and interpretation. However, the complexity of such rules, combined\nwith the unique labeling conventions of each KG, can make them difficult for\nhumans to understand. In this paper, we explore the potential of large language\nmodels to generate natural language explanations for logical rules.\nSpecifically, we extract logical rules using the AMIE 3.5.1 rule discovery\nalgorithm from the benchmark dataset FB15k-237 and two large-scale datasets,\nFB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including\nzero- and few-shot prompting, including variable entity types, and\nchain-of-thought reasoning. We conduct a comprehensive human evaluation of the\ngenerated explanations based on correctness, clarity, and hallucination, and\nalso assess the use of large language models as automatic judges. Our results\ndemonstrate promising performance in terms of explanation correctness and\nclarity, although several challenges remain for future research. All scripts\nand data used in this study are publicly available at\nhttps://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.\n","authors":["Nasim Shirvani-Mahdavi","Devin Wingfield","Amin Ghasemi","Chengkai Li"],"pdf_url":"https://arxiv.org/pdf/2507.23740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13481v3","updated":"2025-07-31T17:19:39Z","published":"2024-01-24T14:29:39Z","title":"How AI Ideas Affect the Creativity, Diversity, and Evolution of Human\n  Ideas: Evidence From a Large, Dynamic Experiment","summary":"  Exposure to large language model output is rapidly increasing. How will\nseeing AI-generated ideas affect human ideas? We conducted an experiment (800+\nparticipants, 40+ countries) where participants viewed creative ideas that were\nfrom ChatGPT or prior experimental participants and then brainstormed their own\nidea. We varied the number of AI-generated examples (none, low, or high\nexposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic\nexperiment design -- ideas from prior participants in an experimental condition\nare used as stimuli for future participants in the same experimental condition\n-- speaks to the interdependent process of cultural creation: creative ideas\nare built upon prior ideas. Hence, we capture the compounding effects of having\nLLMs 'in the culture loop'. We find that high AI exposure (but not low AI\nexposure) did not affect the creativity of individual ideas but did increase\nthe average amount and rate of change of collective idea diversity. AI made\nideas different, not better. There were no main effects of disclosure. We also\nfound that self-reported creative people were less influenced by knowing an\nidea was from AI and that participants may knowingly adopt AI ideas when the\ntask is difficult. Our findings suggest that introducing AI ideas may increase\ncollective diversity but not individual creativity.\n","authors":["Joshua Ashkinaze","Julia Mendelsohn","Li Qiwei","Ceren Budak","Eric Gilbert"],"pdf_url":"https://arxiv.org/pdf/2401.13481v3.pdf","comment":"Accepted at ACM Collective Intelligence 2025. Originally posted 2024"},{"id":"http://arxiv.org/abs/2507.23726v1","updated":"2025-07-31T17:00:30Z","published":"2025-07-31T17:00:30Z","title":"Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving","summary":"  LLMs have demonstrated strong mathematical reasoning abilities by leveraging\nreinforcement learning with long chain-of-thought, yet they continue to\nstruggle with theorem proving due to the lack of clear supervision signals when\nsolely using natural language. Dedicated domain-specific languages like Lean\nprovide clear supervision via formal verification of proofs, enabling effective\ntraining through reinforcement learning. In this work, we propose\n\\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover\ncan iteratively refine its proof based on Lean feedback, proved lemmas, and\nself-summarization. To solve IMO-level contest problems, we design three\ntest-time inference strategies that enable both deep and broad reasoning.\nSeed-Prover proves $78.1\\%$ of formalized past IMO problems, saturates MiniF2F,\nand achieves over 50\\% on PutnamBench, outperforming the previous\nstate-of-the-art by a large margin. To address the lack of geometry support in\nLean, we introduce a geometry reasoning engine \\textbf{Seed-Geometry}, which\noutperforms previous formal geometry engines. We use these two systems to\nparticipate in IMO 2025 and fully prove 5 out of 6 problems. This work\nrepresents a significant advancement in automated mathematical reasoning,\ndemonstrating the effectiveness of formal verification with long\nchain-of-thought reasoning.\n","authors":["Luoxin Chen","Jinming Gu","Liankai Huang","Wenhao Huang","Zhicheng Jiang","Allan Jie","Xiaoran Jin","Xing Jin","Chenggang Li","Kaijing Ma","Cheng Ren","Jiawei Shen","Wenlei Shi","Tong Sun","He Sun","Jiahui Wang","Siran Wang","Zhihong Wang","Chenrui Wei","Shufa Wei","Yonghui Wu","Yuchen Wu","Yihang Xia","Huajian Xin","Fan Yang","Huaiyuan Ying","Hongyi Yuan","Zheng Yuan","Tianyang Zhan","Chi Zhang","Yue Zhang","Ge Zhang","Tianyun Zhao","Jianqiu Zhao","Yichi Zhou","Thomas Hanwen Zhu"],"pdf_url":"https://arxiv.org/pdf/2507.23726v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22879v2","updated":"2025-07-31T16:54:43Z","published":"2025-07-30T17:55:06Z","title":"RecGPT Technical Report","summary":"  Recommender systems are among the most impactful applications of artificial\nintelligence, serving as critical infrastructure connecting users, merchants,\nand platforms. However, most current industrial systems remain heavily reliant\non historical co-occurrence patterns and log-fitting objectives, i.e.,\noptimizing for past user interactions without explicitly modeling user intent.\nThis log-fitting approach often leads to overfitting to narrow historical\npreferences, failing to capture users' evolving and latent interests. As a\nresult, it reinforces filter bubbles and long-tail phenomena, ultimately\nharming user experience and threatening the sustainability of the whole\nrecommendation ecosystem.\n  To address these challenges, we rethink the overall design paradigm of\nrecommender systems and propose RecGPT, a next-generation framework that places\nuser intent at the center of the recommendation pipeline. By integrating large\nlanguage models (LLMs) into key stages of user interest mining, item retrieval,\nand explanation generation, RecGPT transforms log-fitting recommendation into\nan intent-centric process. To effectively align general-purpose LLMs to the\nabove domain-specific recommendation tasks at scale, RecGPT incorporates a\nmulti-stage training paradigm, which integrates reasoning-enhanced\npre-alignment and self-training evolution, guided by a Human-LLM cooperative\njudge system. Currently, RecGPT has been fully deployed on the Taobao App.\nOnline experiments demonstrate that RecGPT achieves consistent performance\ngains across stakeholders: users benefit from increased content diversity and\nsatisfaction, merchants and the platform gain greater exposure and conversions.\nThese comprehensive improvement results across all stakeholders validates that\nLLM-driven, intent-centric design can foster a more sustainable and mutually\nbeneficial recommendation ecosystem.\n","authors":["Chao Yi","Dian Chen","Gaoyang Guo","Jiakai Tang","Jian Wu","Jing Yu","Mao Zhang","Sunhao Dai","Wen Chen","Wenjun Yang","Yuning Jiang","Zhujin Gao","Bo Zheng","Chi Li","Dimin Wang","Dixuan Wang","Fan Li","Fan Zhang","Haibin Chen","Haozhuang Liu","Jialin Zhu","Jiamang Wang","Jiawei Wu","Jin Cui","Ju Huang","Kai Zhang","Kan Liu","Lang Tian","Liang Rao","Longbin Li","Lulu Zhao","Na He","Peiyang Wang","Qiqi Huang","Tao Luo","Wenbo Su","Xiaoxiao He","Xin Tong","Xu Chen","Xunke Xi","Yang Li","Yaxuan Wu","Yeqiu Yang","Yi Hu","Yinnan Song","Yuchen Li","Yujie Luo","Yujin Yuan","Yuliang Yan","Zhengyang Wang","Zhibo Xiao","Zhixin Ma","Zile Zhou","Ziqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.22879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.08184v3","updated":"2025-07-31T16:45:51Z","published":"2025-06-09T19:49:11Z","title":"Unable to Forget: Proactive Interference Reveals Working Memory Limits\n  in LLMs Beyond Context Length","summary":"  Information retrieval in Large Language Models (LLMs) is increasingly\nrecognized as intertwined with generation capabilities rather than mere lookup.\nWhile longer contexts are often assumed to improve retrieval, the effects of\nintra-context interference remain understudied. To address this, we adapt the\nproactive interference (PI) paradigm from cognitive science, where earlier\ninformation disrupts recall of newer updates. In humans, susceptibility to such\ninterference is inversely linked to working memory capacity. We introduce\nPI-LLM, an evaluation that sequentially streams semantically related key-value\nupdates and queries only the final values. Although these final values are\nclearly positioned just before the query, LLM retrieval accuracy declines\nlog-linearly toward zero as interference accumulates; errors arise from\nretrieving previously overwritten values. Attempts to mitigate interference via\nprompt engineering (e.g., instructing models to ignore earlier input) yield\nlimited success. These findings reveal a fundamental constraint on LLMs'\nability to disentangle interference and flexibly manipulate information,\nsuggesting a working memory bottleneck beyond mere context access. This calls\nfor approaches that strengthen models' ability to suppress irrelevant content\nduring retrieval.\n","authors":["Chupei Wang","Jiaqiu Vince Sun"],"pdf_url":"https://arxiv.org/pdf/2506.08184v3.pdf","comment":"Accepted at ICML 2025 Workshop on Long Context Foundation Models\n  (ICFM). Code: https://github.com/zhuangziGiantfish/Unable-to-Forget"},{"id":"http://arxiv.org/abs/2507.23701v1","updated":"2025-07-31T16:22:55Z","published":"2025-07-31T16:22:55Z","title":"TextQuests: How Good are LLMs at Text-Based Video Games?","summary":"  Evaluating AI agents within complex, interactive environments that mirror\nreal-world challenges is critical for understanding their practical\ncapabilities. While existing agent benchmarks effectively assess skills like\ntool use or performance on structured tasks, they often do not fully capture an\nagent's ability to operate autonomously in exploratory environments that demand\nsustained, self-directed reasoning over a long and growing context. To spur the\ndevelopment of agents capable of more robust intrinsic reasoning over long\nhorizons, we introduce TextQuests, a benchmark based on the Infocom suite of\ninteractive fiction games. These text-based adventures, which can take human\nplayers over 30 hours and require hundreds of precise actions to solve, serve\nas an effective proxy for evaluating AI agents on focused, stateful tasks. The\nbenchmark is specifically designed to assess an LLM agent's capacity for\nself-contained problem-solving by precluding the use of external tools, thereby\nfocusing on intrinsic long-context reasoning capabilities in an exploratory\nenvironment characterized by the need for trial-and-error learning and\nsustained problem-solving within a single interactive session. We release\nTextQuests at https://textquests.ai.\n","authors":["Long Phan","Mantas Mazeika","Andy Zou","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2507.23701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23674v1","updated":"2025-07-31T15:50:57Z","published":"2025-07-31T15:50:57Z","title":"TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached\n  Responses","summary":"  Large Language Models (LLMs) process millions of queries daily, making\nefficient response caching a compelling optimization for reducing cost and\nlatency. However, preserving relevance to user queries using this approach\nproves difficult due to the personalized nature of chatbot interactions and the\nlimited accuracy of semantic similarity search. To address this, we present\nTweakLLM, a novel routing architecture that employs a lightweight LLM to\ndynamically adapt cached responses to incoming prompts. Through comprehensive\nevaluation, including user studies with side-by-side comparisons, satisfaction\nvoting, as well as multi-agent LLM debates, we demonstrate that TweakLLM\nmaintains response quality comparable to frontier models while significantly\nimproving cache effectiveness. Our results across real-world datasets highlight\nTweakLLM as a scalable, resource-efficient caching solution for high-volume LLM\ndeployments without compromising user experience.\n","authors":["Muhammad Taha Cheema","Abeer Aamir","Khawaja Gul Muhammad","Naveed Anwar Bhatti","Ihsan Ayyub Qazi","Zafar Ayyub Qazi"],"pdf_url":"https://arxiv.org/pdf/2507.23674v1.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2507.23661v1","updated":"2025-07-31T15:39:46Z","published":"2025-07-31T15:39:46Z","title":"Arabic Hate Speech Identification and Masking in Social Media using Deep\n  Learning Models and Pre-trained Models Fine-tuning","summary":"  Hate speech identification in social media has become an increasingly\nimportant issue in recent years. In this research, we address two problems: 1)\nto detect hate speech in Arabic text, 2) to clean a given text from hate\nspeech. The meaning of cleaning here is replacing each bad word with stars\nbased on the number of letters for each word. Regarding the first problem, we\nconduct several experiments using deep learning models and transformers to\ndetermine the best model in terms of the F1 score. Regarding second problem, we\nconsider it as a machine translation task, where the input is a sentence\ncontaining dirty text and the output is the same sentence with masking the\ndirty text. The presented methods achieve the best model in hate speech\ndetection with a 92\\% Macro F1 score and 95\\% accuracy. Regarding the text\ncleaning experiment, the best result in the hate speech masking model reached\n0.3 in BLEU score with 1-gram, which is a good result compared with the state\nof the art machine translation systems.\n","authors":["Salam Thabet Doghmash","Motaz Saad"],"pdf_url":"https://arxiv.org/pdf/2507.23661v1.pdf","comment":"23 pages, 5 figures"},{"id":"http://arxiv.org/abs/2507.08606v3","updated":"2025-07-31T15:39:10Z","published":"2025-07-11T14:00:56Z","title":"DocPolarBERT: A Pre-trained Model for Document Understanding with\n  Relative Polar Coordinate Encoding of Layout Structures","summary":"  We introduce DocPolarBERT, a layout-aware BERT model for document\nunderstanding that eliminates the need for absolute 2D positional embeddings.\nWe extend self-attention to take into account text block positions in relative\npolar coordinate system rather than the Cartesian one. Despite being\npre-trained on a dataset more than six times smaller than the widely used\nIIT-CDIP corpus, DocPolarBERT achieves state-of-the-art results. These results\ndemonstrate that a carefully designed attention mechanism can compensate for\nreduced pre-training data, offering an efficient and effective alternative for\ndocument understanding.\n","authors":["Benno Uthayasooriyar","Antoine Ly","Franck Vermet","Caio Corro"],"pdf_url":"https://arxiv.org/pdf/2507.08606v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21903v2","updated":"2025-07-31T15:33:32Z","published":"2025-07-29T15:14:39Z","title":"Who's important? -- SUnSET: Synergistic Understanding of Stakeholder,\n  Events and Time for Timeline Generation","summary":"  As news reporting becomes increasingly global and decentralized online,\ntracking related events across multiple sources presents significant\nchallenges. Existing news summarization methods typically utilizes Large\nLanguage Models and Graphical methods on article-based summaries. However, this\nis not effective since it only considers the textual content of similarly dated\narticles to understand the gist of the event. To counteract the lack of\nanalysis on the parties involved, it is essential to come up with a novel\nframework to gauge the importance of stakeholders and the connection of related\nevents through the relevant entities involved. Therefore, we present SUnSET:\nSynergistic Understanding of Stakeholder, Events and Time for the task of\nTimeline Summarization (TLS). We leverage powerful Large Language Models (LLMs)\nto build SET triplets and introduced the use of stakeholder-based ranking to\nconstruct a $Relevancy$ metric, which can be extended into general situations.\nOur experimental results outperform all prior baselines and emerged as the new\nState-of-the-Art, highlighting the impact of stakeholder information within\nnews article.\n","authors":["Tiviatis Sim","Kaiwen Yang","Shen Xin","Kenji Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2507.21903v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.18102v2","updated":"2025-07-31T15:25:09Z","published":"2025-05-23T16:57:34Z","title":"How Can I Publish My LLM Benchmark Without Giving the True Answers Away?","summary":"  Publishing a large language model (LLM) benchmark on the Internet risks\ncontaminating future LLMs: the benchmark may be unintentionally (or\nintentionally) used to train or select a model. A common mitigation is to keep\nthe benchmark private and let participants submit their models or predictions\nto the organizers. However, this strategy will require trust in a single\norganization and still permits test-set overfitting through repeated queries.\nTo overcome this issue, we propose a way to publish benchmarks without\ncompletely disclosing the ground-truth answers to the questions, while still\nmaintaining the ability to openly evaluate LLMs. Our main idea is to inject\nrandomness to the answers by preparing several logically correct answers, and\nonly include one of them as the solution in the benchmark. This reduces the\nbest possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is\nthis helpful to keep us from disclosing the ground truth, but this approach\nalso offers a test for detecting data contamination. In principle, even fully\ncapable models should not surpass the Bayes accuracy. If a model surpasses this\nceiling despite this expectation, this is a strong signal of data\ncontamination. We present experimental evidence that our method can detect data\ncontamination accurately on a wide range of benchmarks, models, and training\nmethodologies.\n","authors":["Takashi Ishida","Thanawat Lodkaew","Ikko Yamane"],"pdf_url":"https://arxiv.org/pdf/2505.18102v2.pdf","comment":"Extended version of the paper presented as an Oral at the ICML 2025\n  Workshop on the Impact of Memorization on Trustworthy Foundation Models"},{"id":"http://arxiv.org/abs/2504.04640v2","updated":"2025-07-31T15:18:47Z","published":"2025-04-06T23:17:07Z","title":"Splits! A Flexible Dataset and Evaluation Framework for Sociocultural\n  Linguistic Investigation","summary":"  Variation in language use, shaped by speakers' sociocultural background and\nspecific context of use, offers a rich lens into cultural perspectives, values,\nand opinions. However, the computational study of these Sociocultural\nLinguistic Phenomena (SLP) has often been limited to bespoke analyses of\nspecific groups or topics, hindering the pace of scientific discovery. To\naddress this, we introduce Splits!, a 9.7 million-post dataset from Reddit\ndesigned for systematic and flexible research. The dataset contains posts from\nover 53,000 users across 6 demographic groups, organized into 89 discussion\ntopics to enable comparative analysis. We validate Splits! via\nself-identification and by successfully replicating several known SLPs from\nexisting literature. We complement this dataset with a framework that leverages\nefficient retrieval methods to rapidly validate potential SLPs (PSLPs) by\nautomatically evaluating whether a given hypothesis is supported by our data.\nCrucially, to distinguish between novel and obvious insights, the framework\nincorporates a human-validated measure of a hypothesis's ``unexpectedness.'' We\ndemonstrate that the two-stage process reduces the number of statistically\nsignificant findings requiring manual inspection by a factor of 1.5-1.8x,\nstreamlining the discovery of promising phenomena for further investigation.\n","authors":["Eylon Caplan","Tania Chakraborty","Dan Goldwasser"],"pdf_url":"https://arxiv.org/pdf/2504.04640v2.pdf","comment":"Preprint, under review"},{"id":"http://arxiv.org/abs/2507.11832v2","updated":"2025-07-31T14:57:22Z","published":"2025-07-16T01:39:32Z","title":"ILID: Native Script Language Identification for Indian Languages","summary":"  The language identification task is a crucial fundamental step in NLP. Often\nit serves as a pre-processing step for widely used NLP applications such as\nmultilingual machine translation, information retrieval, question and\nanswering, and text summarization. The core challenge of language\nidentification lies in distinguishing languages in noisy, short, and code-mixed\nenvironments. This becomes even harder in case of diverse Indian languages that\nexhibit lexical and phonetic similarities, but have distinct differences. Many\nIndian languages share the same script, making the task even more challenging.\nTaking all these challenges into account, we develop and release a dataset of\n250K sentences consisting of 23 languages including English and all 22 official\nIndian languages labeled with their language identifiers, where data in most\nlanguages are newly created. We also develop and release baseline models using\nstate-of-the-art approaches in machine learning and fine-tuning pre-trained\ntransformer models. Our models outperforms the state-of-the-art pre-trained\ntransformer models for the language identification task. The dataset and the\ncodes are available at https://yashingle-ai.github.io/ILID/ and in Huggingface\nopen source libraries.\n","authors":["Yash Ingle","Pruthwik Mishra"],"pdf_url":"https://arxiv.org/pdf/2507.11832v2.pdf","comment":"10 pages, 1 figure, 6 tables, Paper accepted in RANLP 2025"},{"id":"http://arxiv.org/abs/2507.23607v1","updated":"2025-07-31T14:47:16Z","published":"2025-07-31T14:47:16Z","title":"Deep Learning-based Prediction of Clinical Trial Enrollment with\n  Uncertainty Estimates","summary":"  Clinical trials are a systematic endeavor to assess the safety and efficacy\nof new drugs or treatments. Conducting such trials typically demands\nsignificant financial investment and meticulous planning, highlighting the need\nfor accurate predictions of trial outcomes. Accurately predicting patient\nenrollment, a key factor in trial success, is one of the primary challenges\nduring the planning phase. In this work, we propose a novel deep learning-based\nmethod to address this critical challenge. Our method, implemented as a neural\nnetwork model, leverages pre-trained language models (PLMs) to capture the\ncomplexities and nuances of clinical documents, transforming them into\nexpressive representations. These representations are then combined with\nencoded tabular features via an attention mechanism. To account for\nuncertainties in enrollment prediction, we enhance the model with a\nprobabilistic layer based on the Gamma distribution, which enables range\nestimation. We apply the proposed model to predict clinical trial duration,\nassuming site-level enrollment follows a Poisson-Gamma process. We carry out\nextensive experiments on real-world clinical trial data, and show that the\nproposed method can effectively predict the number of patients enrolled at a\nnumber of sites for a given clinical trial, outperforming established baseline\nmodels.\n","authors":["Tien Huu Do","Antoine Masquelier","Nae Eoun Lee","Jonathan Crowther"],"pdf_url":"https://arxiv.org/pdf/2507.23607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.15299v3","updated":"2025-07-31T14:38:33Z","published":"2025-03-19T15:21:48Z","title":"Inside-Out: Hidden Factual Knowledge in LLMs","summary":"  This work presents a framework for assessing whether large language models\n(LLMs) encode more factual knowledge in their parameters than what they express\nin their outputs. While a few studies hint at this possibility, none has\nclearly defined or demonstrated this phenomenon. We first propose a formal\ndefinition of knowledge, quantifying it for a given question as the fraction of\ncorrect-incorrect answer pairs where the correct one is ranked higher. This\ngives rise to external and internal knowledge, depending on the information\nused to score individual answer candidates: either the model's observable\ntoken-level probabilities or its intermediate computations. Hidden knowledge\narises when internal knowledge exceeds external knowledge. We then present a\ncase study, applying this framework to three popular open-weights LLMs in a\nclosed-book QA setup. Our results indicate that: (1) LLMs consistently encode\nmore factual knowledge internally than what they express externally, with an\naverage relative gap of 40%. (2) Surprisingly, some knowledge is so deeply\nhidden that a model can internally know an answer perfectly, yet fail to\ngenerate it even once, despite large-scale repeated sampling of 1,000 answers.\nThis reveals fundamental limitations in the generation capabilities of LLMs,\nwhich (3) put a practical constraint on scaling test-time compute via repeated\nanswer sampling in closed-book QA: significant performance improvements remain\ninaccessible because some answers are practically never sampled, yet if they\nwere, we would be guaranteed to rank them first.\n","authors":["Zorik Gekhman","Eyal Ben David","Hadas Orgad","Eran Ofek","Yonatan Belinkov","Idan Szpektor","Jonathan Herzig","Roi Reichart"],"pdf_url":"https://arxiv.org/pdf/2503.15299v3.pdf","comment":"Accepted to COLM 2025"},{"id":"http://arxiv.org/abs/2507.23588v1","updated":"2025-07-31T14:24:59Z","published":"2025-07-31T14:24:59Z","title":"DiffLoRA: Differential Low-Rank Adapters for Large Language Models","summary":"  Differential Transformer has recently been proposed to improve performance in\nTransformer models by canceling out noise through a denoiser attention\nmechanism. In this work, we introduce DiffLoRA, a parameter-efficient\nadaptation of the differential attention mechanism, with low-rank adapters on\nboth positive and negative attention terms. This approach retains the\nefficiency of LoRA while aiming to benefit from the performance gains of\ndifferential attention. We evaluate DiffLoRA across a broad range of NLP tasks,\nincluding general benchmarks, many-shot in-context learning, RAG, and\nlong-context tests. We observe that, although DiffLoRA falls short of other\nparameter-efficient fine-tuning methods in most evaluation tasks, it shows\ninteresting results in certain domains (+11 pts on LoRA for HumanEval). We\nanalyze the attention patterns post-finetuning to identify the reasons for this\nbehavior.\n","authors":["Alexandre Misrahi","Nadezhda Chirkova","Maxime Louis","Vassilina Nikoulina"],"pdf_url":"https://arxiv.org/pdf/2507.23588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23577v1","updated":"2025-07-31T14:08:04Z","published":"2025-07-31T14:08:04Z","title":"T-Detect: Tail-Aware Statistical Normalization for Robust Detection of\n  Adversarial Machine-Generated Text","summary":"  The proliferation of sophisticated text generation models necessitates the\ndevelopment of robust detection methods capable of identifying\nmachine-generated content, particularly text designed to evade detection\nthrough adversarial perturbations. Existing zero-shot detectors often rely on\nstatistical measures that implicitly assume Gaussian distributions, a premise\nthat falters when confronted with the heavy-tailed statistical artifacts\ncharacteristic of adversarial or non-native English texts. This paper\nintroduces T-Detect, a novel detection method that fundamentally redesigns the\nstatistical core of curvature-based detectors. Our primary innovation is the\nreplacement of standard Gaussian normalization with a heavy-tailed discrepancy\nscore derived from the Student's t-distribution. This approach is theoretically\ngrounded in the empirical observation that adversarial texts exhibit\nsignificant leptokurtosis, rendering traditional statistical assumptions\ninadequate. T-Detect computes a detection score by normalizing the\nlog-likelihood of a passage against the expected moments of a t-distribution,\nproviding superior resilience to statistical outliers. We validate our approach\non the challenging RAID benchmark for adversarial text and the comprehensive\nHART dataset. Experiments show that T-Detect provides a consistent performance\nuplift over strong baselines, improving AUROC by up to 3.9\\% in targeted\ndomains. When integrated into a two-dimensional detection framework (CT), our\nmethod achieves state-of-the-art performance, with an AUROC of 0.926 on the\nBooks domain of RAID. Our contributions are a new, theoretically-justified\nstatistical foundation for text detection, an ablation-validated method that\ndemonstrates superior robustness, and a comprehensive analysis of its\nperformance under adversarial conditions. Ours code are released at\nhttps://github.com/ResearAI/t-detect.\n","authors":["Alva West","Luodan Zhang","Liuliu Zhang","Minjun Zhu","Yixuan Weng","Yue Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.23577v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02744v3","updated":"2025-07-31T14:02:13Z","published":"2024-10-03T17:55:17Z","title":"Neutral Residues: Revisiting Adapters for Model Extension","summary":"  We address the problem of extending a pretrained large language model to a\nnew domain that was not seen during training. Standard techniques, such as\nfinetuning or low-rank adaptation (LoRA) are successful at domain adaptation,\nbut do not formally add capacity to the model. This often leads to a trade-off,\nbetween performing well on the new domain vs. degrading performance on the\noriginal domain. Here, we revisit and improve adapters to extend LLMs from\nthree angles: data, architecture and training procedure, which are\nadvantageously considered jointly. The resulting method, called neutral\nresidues, modifies adapters in a way that leads each new residual block to\noutput near-zeros on the original domain. This solution leads to strong results\nwhen adapting a state-of-the-art model originally trained on English to a new\nlanguage. Neutral residues significantly outperform competing approaches such\nas finetuning, LoRA or vanilla adapters in terms of the trade-off between\nlearning the new language and not forgetting English.\n","authors":["Franck Signe Talla","Edouard Grave","Hervé Jégou"],"pdf_url":"https://arxiv.org/pdf/2410.02744v3.pdf","comment":"Accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2411.18337v4","updated":"2025-07-31T13:39:18Z","published":"2024-11-27T13:35:32Z","title":"Can LLMs assist with Ambiguity? A Quantitative Evaluation of various\n  Large Language Models on Word Sense Disambiguation","summary":"  Ambiguous words are often found in modern digital communications. Lexical\nambiguity challenges traditional Word Sense Disambiguation (WSD) methods, due\nto limited data. Consequently, the efficiency of translation, information\nretrieval, and question-answering systems is hindered by these limitations.\nThis study investigates the use of Large Language Models (LLMs) to improve WSD\nusing a novel approach combining a systematic prompt augmentation mechanism\nwith a knowledge base (KB) consisting of different sense interpretations. The\nproposed method incorporates a human-in-loop approach for prompt augmentation\nwhere prompt is supported by Part-of-Speech (POS) tagging, synonyms of\nambiguous words, aspect-based sense filtering and few-shot prompting to guide\nthe LLM. By utilizing a few-shot Chain of Thought (COT) prompting-based\napproach, this work demonstrates a substantial improvement in performance. The\nevaluation was conducted using FEWS test data and sense tags. This research\nadvances accurate word interpretation in social media and digital\ncommunication.\n","authors":["T. G. D. K. Sumanathilaka","Nicholas Micallef","Julian Hough"],"pdf_url":"https://arxiv.org/pdf/2411.18337v4.pdf","comment":"12 pages,6 tables, 1 figure, Proceedings of the 1st International\n  Conference on NLP & AI for Cyber Security"},{"id":"http://arxiv.org/abs/2507.23541v1","updated":"2025-07-31T13:31:01Z","published":"2025-07-31T13:31:01Z","title":"Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via\n  Progressive Reinforcement Learning","summary":"  In medical scenarios, effectively retrieving external knowledge and\nleveraging it for rigorous logical reasoning is of significant importance.\nDespite their potential, existing work has predominantly focused on enhancing\neither retrieval or reasoning capabilities of the models in isolation, with\nlittle attention given to their joint optimization, which leads to limited\ncoordination between the two processes. Additionally, current methods rely\nheavily on supervised fine-tuning (SFT), which can cause models to memorize\nexisting problem-solving pathways, thereby restricting their generalization\nability when confronted with novel problem contexts. Furthermore, while some\nstudies have explored to improve retrieval-augmented reasoning in general\ndomains via reinforcement learning, their reward function designs do not\nadequately capture the specific demands of the medical domain. To address these\nchallenges, we introduce **Med-R$^3$**, a **Med**ical **R**etrieval-augmented\n**R**easoning framework driven by progressive **R**einforcement learning. In\nthis framework, we first develop the model's ability to perform logical\nreasoning over medical problems. Subsequently, on the basis of this foundation,\nwe adaptively optimize the retrieval capability to better align with the\ncharacteristics of knowledge corpus and external information utilization\nthroughout the reasoning process. Finally, we conduct joint optimization of the\nmodel's retrieval and reasoning coordination. Extensive experiments indicate\nthat **Med-R$^3$** could achieve state-of-the-art performances, with\nLLaMA3.1-8B-Instruct + Med-R$^3$ surpassing closed-sourced GPT-4o-mini by\n3.93\\% at a comparable parameter scale, while Qwen2.5-14B augmented with\nMed-R$^3$ shows a more substantial gain of 13.53\\%.\n","authors":["Keer Lu","Zheng Liang","Youquan Li","Jiejun Tan","Da Pan","Shusen Zhang","Guosheng Dong","Huang Leng"],"pdf_url":"https://arxiv.org/pdf/2507.23541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19060v2","updated":"2025-07-31T13:22:45Z","published":"2025-07-25T08:23:00Z","title":"PurpCode: Reasoning for Safer Code Generation","summary":"  We introduce PurpCode, the first post-training recipe for training safe code\nreasoning models towards generating secure code and defending against malicious\ncyberactivities. PurpCode trains a reasoning model in two stages: (i) Rule\nLearning, which explicitly teaches the model to reference cybersafety rules to\ngenerate vulnerability-free code and to avoid facilitating malicious\ncyberactivities; and (ii) Reinforcement Learning, which optimizes model safety\nand preserves model utility through diverse, multi-objective reward mechanisms.\nTo empower the training pipelines with comprehensive cybersafety data, we\nconduct internal red-teaming to synthesize comprehensive and high-coverage\nprompts based on real-world tasks for inducing unsafe cyberactivities in the\nmodel. Based on PurpCode, we develop a reasoning-based coding model, namely\nPurpCode-32B, which demonstrates state-of-the-art cybersafety, outperforming\nvarious frontier models. Meanwhile, our alignment method decreases the model\noverrefusal rates in both general and cybersafety-specific scenarios, while\npreserving model utility in both code generation and common security knowledge.\n","authors":["Jiawei Liu","Nirav Diwan","Zhe Wang","Haoyu Zhai","Xiaona Zhou","Kiet A. Nguyen","Tianjiao Yu","Muntasir Wahed","Yinlin Deng","Hadjer Benkraouda","Yuxiang Wei","Lingming Zhang","Ismini Lourentzou","Gang Wang"],"pdf_url":"https://arxiv.org/pdf/2507.19060v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23511v1","updated":"2025-07-31T12:47:43Z","published":"2025-07-31T12:47:43Z","title":"MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio\n  Understanding Tasks","summary":"  While large audio-language models have advanced open-ended audio\nunderstanding, they still fall short of nuanced human-level comprehension. This\ngap persists largely because current benchmarks, limited by data annotations\nand evaluation metrics, fail to reliably distinguish between generic and highly\ndetailed model outputs. To this end, this work introduces MECAT, a Multi-Expert\nConstructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via\na pipeline that integrates analysis from specialized expert models with\nChain-of-Thought large language model reasoning, MECAT provides\nmulti-perspective, fine-grained captions and open-set question-answering pairs.\nThe benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced\nAudio Text Evaluation). This metric penalizes generic terms and rewards\ndetailed descriptions by combining single-sample semantic similarity with\ncross-sample discriminability. A comprehensive evaluation of state-of-the-art\naudio models is also presented, providing new insights into their current\ncapabilities and limitations. The data and code are available at\nhttps://github.com/xiaomi-research/mecat\n","authors":["Yadong Niu","Tianzi Wang","Heinrich Dinkel","Xingwei Sun","Jiahao Zhou","Gang Li","Jizhong Liu","Xunying Liu","Junbo Zhang","Jian Luan"],"pdf_url":"https://arxiv.org/pdf/2507.23511v1.pdf","comment":"9 main pages, 5 figures, 3 tables, and 14 appendix pages"},{"id":"http://arxiv.org/abs/2503.15621v2","updated":"2025-07-31T12:41:25Z","published":"2025-03-19T18:10:12Z","title":"LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for\n  Enhanced Visual Instruction Tuning","summary":"  Recent progress in Multimodal Large Language Models (MLLMs) has highlighted\nthe critical roles of both the visual backbone and the underlying language\nmodel. While prior work has primarily focused on scaling these components to\nbillions of parameters, the trade-offs between model size, architecture, and\nperformance remain underexplored. Additionally, inconsistencies in training\ndata and evaluation protocols have hindered direct comparisons, making it\ndifficult to derive optimal design choices. In this paper, we introduce\nLLaVA-MORE, a new family of MLLMs that integrates recent language models with\ndiverse visual backbones. To ensure fair comparisons, we employ a unified\ntraining protocol applied consistently across all architectures. Our analysis\nsystematically explores both small- and medium-scale LLMs -- including Phi-4,\nLLaMA-3.1, and Gemma-2 -- to evaluate multimodal reasoning, generation, and\ninstruction following, while examining the relationship between model size and\nperformance. Beyond evaluating the LLM impact on final results, we conduct a\ncomprehensive study of various visual encoders, ranging from CLIP-based\narchitectures to alternatives such as DINOv2, SigLIP, and SigLIP2. Additional\nexperiments investigate the effects of increased image resolution and\nvariations in pre-training datasets. Overall, our results provide insights into\nthe design of more effective MLLMs, offering a reproducible evaluation\nframework that facilitates direct comparisons and can guide future model\ndevelopment. Our source code and trained models are publicly available at:\nhttps://github.com/aimagelab/LLaVA-MORE.\n","authors":["Federico Cocchi","Nicholas Moratelli","Davide Caffagni","Sara Sarto","Lorenzo Baraldi","Marcella Cornia","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2503.15621v2.pdf","comment":"ICCV 2025 Workshop on What is Next in Multimodal Foundation Models"},{"id":"http://arxiv.org/abs/2507.23486v1","updated":"2025-07-31T12:10:00Z","published":"2025-07-31T12:10:00Z","title":"A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and\n  Effectiveness in Clinical Domains","summary":"  Large language models (LLMs) hold promise in clinical decision support but\nface major challenges in safety evaluation and effectiveness validation. We\ndeveloped the Clinical Safety-Effectiveness Dual-Track Benchmark (CSEDB), a\nmultidimensional framework built on clinical expert consensus, encompassing 30\ncriteria covering critical areas like critical illness recognition, guideline\nadherence, and medication safety, with weighted consequence measures.\nThirty-two specialist physicians developed and reviewed 2,069 open-ended Q&A\nitems aligned with these criteria, spanning 26 clinical departments to simulate\nreal-world scenarios. Benchmark testing of six LLMs revealed moderate overall\nperformance (average total score 57.2%, safety 54.7%, effectiveness 62.3%),\nwith a significant 13.3% performance drop in high-risk scenarios (p < 0.0001).\nDomain-specific medical LLMs showed consistent performance advantages over\ngeneral-purpose models, with relatively higher top scores in safety (0.912) and\neffectiveness (0.861). The findings of this study not only provide a\nstandardized metric for evaluating the clinical application of medical LLMs,\nfacilitating comparative analyses, risk exposure identification, and\nimprovement directions across different scenarios, but also hold the potential\nto promote safer and more effective deployment of large language models in\nhealthcare environments.\n","authors":["Shirui Wang","Zhihui Tang","Huaxia Yang","Qiuhong Gong","Tiantian Gu","Hongyang Ma","Yongxin Wang","Wubin Sun","Zeliang Lian","Kehang Mao","Yinan Jiang","Zhicheng Huang","Lingyun Ma","Wenjie Shen","Yajie Ji","Yunhui Tan","Chunbo Wang","Yunlu Gao","Qianling Ye","Rui Lin","Mingyu Chen","Lijuan Niu","Zhihao Wang","Peng Yu","Mengran Lang","Yue Liu","Huimin Zhang","Haitao Shen","Long Chen","Qiguang Zhao","Si-Xuan Liu","Lina Zhou","Hua Gao","Dongqiang Ye","Lingmin Meng","Youtao Yu","Naixin Liang","Jianxiong Wu"],"pdf_url":"https://arxiv.org/pdf/2507.23486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23465v1","updated":"2025-07-31T11:41:04Z","published":"2025-07-31T11:41:04Z","title":"Role-Aware Language Models for Secure and Contextualized Access Control\n  in Organizations","summary":"  As large language models (LLMs) are increasingly deployed in enterprise\nsettings, controlling model behavior based on user roles becomes an essential\nrequirement. Existing safety methods typically assume uniform access and focus\non preventing harmful or toxic outputs, without addressing role-specific access\nconstraints. In this work, we investigate whether LLMs can be fine-tuned to\ngenerate responses that reflect the access privileges associated with different\norganizational roles. We explore three modeling strategies: a BERT-based\nclassifier, an LLM-based classifier, and role-conditioned generation. To\nevaluate these approaches, we construct two complementary datasets. The first\nis adapted from existing instruction-tuning corpora through clustering and role\nlabeling, while the second is synthetically generated to reflect realistic,\nrole-sensitive enterprise scenarios. We assess model performance across varying\norganizational structures and analyze robustness to prompt injection, role\nmismatch, and jailbreak attempts.\n","authors":["Saeed Almheiri","Yerulan Kongrat","Adrian Santosh","Ruslan Tasmukhanov","Josemaria Vera","Muhammad Dehan Al Kautsar","Fajri Koto"],"pdf_url":"https://arxiv.org/pdf/2507.23465v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23453v1","updated":"2025-07-31T11:29:42Z","published":"2025-07-31T11:29:42Z","title":"Counterfactual Evaluation for Blind Attack Detection in LLM-based\n  Evaluation Systems","summary":"  This paper investigates defenses for LLM-based evaluation systems against\nprompt injection. We formalize a class of threats called blind attacks, where a\ncandidate answer is crafted independently of the true answer to deceive the\nevaluator. To counter such attacks, we propose a framework that augments\nStandard Evaluation (SE) with Counterfactual Evaluation (CFE), which\nre-evaluates the submission against a deliberately false ground-truth answer.\nAn attack is detected if the system validates an answer under both standard and\ncounterfactual conditions. Experiments show that while standard evaluation is\nhighly vulnerable, our SE+CFE framework significantly improves security by\nboosting attack detection with minimal performance trade-offs.\n","authors":["Lijia Liu","Takumi Kondo","Kyohei Atarashi","Koh Takeuchi","Jiyi Li","Shigeru Saito","Hisashi Kashima"],"pdf_url":"https://arxiv.org/pdf/2507.23453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.14928v3","updated":"2025-07-31T11:11:30Z","published":"2025-04-21T07:48:20Z","title":"EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent\n  Dialogue Framework","summary":"  Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.\n","authors":["Yao Shi","Rongkeng Liang","Yong Xu"],"pdf_url":"https://arxiv.org/pdf/2504.14928v3.pdf","comment":"Paper URL: https://aclanthology.org/2025.acl-long.1576 ;Presentation\n  Video: https://www.youtube.com/watch?v=j63ooKE50I0"},{"id":"http://arxiv.org/abs/2505.18497v2","updated":"2025-07-31T11:02:54Z","published":"2025-05-24T04:24:59Z","title":"The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic\n  Competence in Large Language Models","summary":"  Current large language models (LLMs) have demonstrated emerging capabilities\nin social intelligence tasks, including implicature resolution and\ntheory-of-mind reasoning, both of which require substantial pragmatic\nunderstanding. However, how LLMs acquire this pragmatic competence throughout\nthe training process remains poorly understood. In this work, we introduce\nALTPRAG, a dataset grounded in the pragmatic concept of alternatives, to\nevaluate whether LLMs at different training stages can accurately infer nuanced\nspeaker intentions. Each instance pairs two equally plausible yet pragmatically\ndivergent continuations and requires the model to (i) infer the speaker's\nintended meaning and (ii) explain when and why a speaker would choose one\nutterance over its alternative, thus directly probing pragmatic competence\nthrough contrastive reasoning. We systematically evaluate 22 LLMs across 3 key\ntraining stages: after pre-training, supervised fine-tuning (SFT), and\npreference optimization, to examine the development of pragmatic competence.\nOur results show that even base models exhibit notable sensitivity to pragmatic\ncues, which improves consistently with increases in model and data scale.\nAdditionally, SFT and RLHF contribute further gains, particularly in\ncognitive-pragmatic scenarios. These findings highlight pragmatic competence as\nan emergent and compositional property of LLM training and offer new insights\nfor aligning models with human communicative norms.\n","authors":["Kefan Yu","Qingcheng Zeng","Weihao Xuan","Wanxin Li","Jingyi Wu","Rob Voigt"],"pdf_url":"https://arxiv.org/pdf/2505.18497v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23407v1","updated":"2025-07-31T10:27:48Z","published":"2025-07-31T10:27:48Z","title":"Beyond Passive Critical Thinking: Fostering Proactive Questioning to\n  Enhance Human-AI Collaboration","summary":"  Critical thinking is essential for building robust AI systems, preventing\nthem from blindly accepting flawed data or biased reasoning. However, prior\nwork has primarily focused on passive critical thinking, where models simply\nreject problematic queries without taking constructive steps to address user\nrequests. In this work, we introduce proactive critical thinking, a paradigm\nwhere models actively seek missing or clarifying information from users to\nresolve their queries better. To evaluate this capability, we present GSM-MC\nand GSM-MCE, two novel benchmarks based on GSM8K for assessing mathematical\nreasoning under incomplete or misleading conditions. GSM-MC contains 1,368 math\nproblems with a key variable deliberately removed, requiring models to identify\nand request the missing information. GSM-MCE further increases the difficulty\nby introducing irrelevant details to test robustness against distractions.\nExperiments on Qwen3 and Llama series models show that, while these models\nexcel in traditional reasoning tasks due to extensive post-training and\ninference-time scaling, they struggle with proactive critical thinking,\nespecially smaller ones. However, we demonstrate that reinforcement learning\n(RL) can significantly improve this ability. Using our enhanced RL algorithm,\nwe achieve substantial gains, boosting the Qwen3-1.7B's accuracy from 0.15% to\n73.98% on GSM-MC. We hope this work advances models that collaborate more\neffectively with users in problem-solving through proactive critical thinking.\n","authors":["Ante Wang","Yujie Lin","Jingyao Liu","Suhang Wu","Hao Liu","Xinyan Xiao","Jinsong Su"],"pdf_url":"https://arxiv.org/pdf/2507.23407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.16725v2","updated":"2025-07-31T10:20:56Z","published":"2025-07-22T16:08:12Z","title":"RAVine: Reality-Aligned Evaluation for Agentic Search","summary":"  Agentic search, as a more autonomous and adaptive paradigm of retrieval\naugmentation, is driving the evolution of intelligent search systems. However,\nexisting evaluation frameworks fail to align well with the goals of agentic\nsearch. First, the complex queries commonly used in current benchmarks often\ndeviate from realistic user search scenarios. Second, prior approaches tend to\nintroduce noise when extracting ground truth for end-to-end evaluations,\nleading to distorted assessments at a fine-grained level. Third, most current\nframeworks focus solely on the quality of final answers, neglecting the\nevaluation of the iterative process inherent to agentic search. To address\nthese limitations, we propose RAVine -- a Reality-Aligned eValuation framework\nfor agentic LLMs with search. RAVine targets multi-point queries and long-form\nanswers that better reflect user intents, and introduces an attributable ground\ntruth construction strategy to enhance the accuracy of fine-grained evaluation.\nMoreover, RAVine examines model's interaction with search tools throughout the\niterative process, and accounts for factors of efficiency. We benchmark a\nseries of models using RAVine and derive several insights, which we hope will\ncontribute to advancing the development of agentic search systems. The code and\ndatasets are available at https://github.com/SwordFaith/RAVine.\n","authors":["Yilong Xu","Xiang Long","Zhi Zheng","Jinhua Gao"],"pdf_url":"https://arxiv.org/pdf/2507.16725v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23404v1","updated":"2025-07-31T10:18:28Z","published":"2025-07-31T10:18:28Z","title":"Enhanced Arabic Text Retrieval with Attentive Relevance Scoring","summary":"  Arabic poses a particular challenge for natural language processing (NLP) and\ninformation retrieval (IR) due to its complex morphology, optional diacritics\nand the coexistence of Modern Standard Arabic (MSA) and various dialects.\nDespite the growing global significance of Arabic, it is still underrepresented\nin NLP research and benchmark resources. In this paper, we present an enhanced\nDense Passage Retrieval (DPR) framework developed specifically for Arabic. At\nthe core of our approach is a novel Attentive Relevance Scoring (ARS) that\nreplaces standard interaction mechanisms with an adaptive scoring function that\nmore effectively models the semantic relevance between questions and passages.\nOur method integrates pre-trained Arabic language models and architectural\nrefinements to improve retrieval performance and significantly increase ranking\naccuracy when answering Arabic questions. The code is made publicly available\nat \\href{https://github.com/Bekhouche/APR}{GitHub}.\n","authors":["Salah Eddine Bekhouche","Azeddine Benlamoudi","Yazid Bounab","Fadi Dornaika","Abdenour Hadid"],"pdf_url":"https://arxiv.org/pdf/2507.23404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23400v1","updated":"2025-07-31T10:14:03Z","published":"2025-07-31T10:14:03Z","title":"MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based\n  on Multi-Relational Graphs and Structural Entropy Minimization","summary":"  The core challenge faced by multi-document summarization is the complexity of\nrelationships among documents and the presence of information redundancy. Graph\nclustering is an effective paradigm for addressing this issue, as it models the\ncomplex relationships among documents using graph structures and reduces\ninformation redundancy through clustering, achieving significant research\nprogress. However, existing methods often only consider single-relational\ngraphs and require a predefined number of clusters, which hinders their ability\nto fully represent rich relational information and adaptively partition\nsentence groups to reduce redundancy. To overcome these limitations, we propose\nMRGSEM-Sum, an unsupervised multi-document summarization framework based on\nmulti-relational graphs and structural entropy minimization. Specifically, we\nconstruct a multi-relational graph that integrates semantic and discourse\nrelations between sentences, comprehensively modeling the intricate and dynamic\nconnections among sentences across documents. We then apply a two-dimensional\nstructural entropy minimization algorithm for clustering, automatically\ndetermining the optimal number of clusters and effectively organizing sentences\ninto coherent groups. Finally, we introduce a position-aware compression\nmechanism to distill each cluster, generating concise and informative\nsummaries. Extensive experiments on four benchmark datasets (Multi-News,\nDUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently\noutperforms previous unsupervised methods and, in several cases, achieves\nperformance comparable to supervised models and large language models. Human\nevaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high\nconsistency and coverage, approaching human-level quality.\n","authors":["Yongbing Zhang","Fang Nan","Shengxiang Gao","Yuxin Huang","Kaiwen Tan","Zhengtao Yu"],"pdf_url":"https://arxiv.org/pdf/2507.23400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23399v1","updated":"2025-07-31T10:13:48Z","published":"2025-07-31T10:13:48Z","title":"Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM\n  Deployment for Translators","summary":"  The rapid proliferation of Large Language Models presents both opportunities\nand challenges for the translation field. While commercial, cloud-based AI\nchatbots have garnered significant attention in translation studies, concerns\nregarding data privacy, security, and equitable access necessitate exploration\nof alternative deployment models. This paper investigates the feasibility and\nperformance of locally deployable, free language models as a viable alternative\nto proprietary, cloud-based AI solutions. This study evaluates three\nopen-source models installed on CPU-based platforms and compared against\ncommercially available online chat-bots. The evaluation focuses on functional\nperformance rather than a comparative analysis of human-machine translation\nquality, an area already subject to extensive research. The platforms assessed\nwere chosen for their accessibility and ease of use across various operating\nsystems. While local deployment introduces its own challenges, the benefits of\nenhanced data control, improved privacy, and reduced dependency on cloud\nservices are compelling. The findings of this study contribute to a growing\nbody of knowledge concerning the democratization of AI technology and inform\nfuture research and development efforts aimed at making LLMs more accessible\nand practical for a wider range of users, specifically focusing on the needs of\nindividual translators and small businesses.\n","authors":["Peter Sandrini"],"pdf_url":"https://arxiv.org/pdf/2507.23399v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23386v1","updated":"2025-07-31T10:01:11Z","published":"2025-07-31T10:01:11Z","title":"Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models","summary":"  Decoder-only large language models (LLMs) are increasingly used to build\nembedding models that effectively encode the semantic information of natural\nlanguage texts into dense vector representations for various embedding tasks.\nHowever, many existing methods primarily focus on removing the causal attention\nmask in LLMs to enable bidirectional attention, potentially undermining the\nmodel's ability to extract semantic information acquired during pretraining.\nAdditionally, leading unidirectional approaches often rely on extra input text\nto overcome the inherent limitations of causal attention, inevitably increasing\ncomputational costs. In this work, we propose Causal2Vec, a general-purpose\nembedding model tailored to enhance the performance of decoder-only LLMs\nwithout altering their original architectures or introducing significant\ncomputational overhead. Specifically, we first employ a lightweight BERT-style\nmodel to pre-encode the input text into a single Contextual token, which is\nthen prepended to the LLM's input sequence, allowing each token to capture\ncontextualized information even without attending to future tokens.\nFurthermore, to mitigate the recency bias introduced by last-token pooling and\nhelp LLMs better leverage the semantic information encoded in the Contextual\ntoken, we concatenate the last hidden states of Contextual and EOS tokens as\nthe final text embedding. In practice, Causal2Vec achieves state-of-the-art\nperformance on the Massive Text Embeddings Benchmark (MTEB) among models\ntrained solely on publicly available retrieval datasets, while reducing the\nrequired sequence length by up to 85% and inference time by up to 82% compared\nto best-performing methods.\n","authors":["Ailiang Lin","Zhuoyun Li","Kotaro Funakoshi"],"pdf_url":"https://arxiv.org/pdf/2507.23386v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23382v1","updated":"2025-07-31T09:59:17Z","published":"2025-07-31T09:59:17Z","title":"MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints\n  in Multimodal Large Language Models","summary":"  Multimodal planning capabilities refer to the ability to predict, reason, and\ndesign steps for task execution with multimodal context, which is essential for\ncomplex reasoning and decision-making across multiple steps. However, current\nbenchmarks face two key challenges: (1) they cannot directly assess multimodal\nreal-world planning capabilities, and (2) they lack constraints or implicit\nconstraints across modalities. To address these issues, we introduce Multimodal\nPlanning with Complex Constraints (MPCC), the first benchmark to systematically\nevaluate MLLMs' ability to handle multimodal constraints in planning. To\naddress the first challenge, MPCC focuses on three real-world tasks: Flight\nPlanning, Calendar Planning, and Meeting Planning. To solve the second\nchallenge, we introduce complex constraints (e.g. budget, temporal, and\nspatial) in these tasks, with graded difficulty levels (EASY, MEDIUM, HARD) to\nseparate constraint complexity from search space expansion. Experiments on 13\nadvanced MLLMs reveal significant challenges: closed-source models achieve only\n21.3% feasible plans, while open-source models average below 11%. Additionally,\nwe observe that MLLMs are highly sensitive to constraint complexity and that\ntraditional multimodal prompting strategies fail in multi-constraint scenarios.\nOur work formalizes multimodal constraints in planning, provides a rigorous\nevaluation framework, and highlights the need for advancements in\nconstraint-aware reasoning for real-world MLLM applications.\n","authors":["Yiyan Ji","Haoran Chen","Qiguang Chen","Chengyue Wu","Libo Qin","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2507.23382v1.pdf","comment":"Accepted to ACM Multimedia 2025"},{"id":"http://arxiv.org/abs/2506.07106v2","updated":"2025-07-31T09:33:35Z","published":"2025-06-08T12:28:38Z","title":"Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive,\n  and Inductive Reasoning in Language Models","summary":"  Large language models (LLMs) have shown strong performance across natural\nlanguage reasoning tasks, yet their reasoning processes remain brittle and\ndifficult to interpret. Prompting techniques like Chain-of-Thought (CoT)\nenhance reliability by eliciting intermediate reasoning steps or aggregating\nmultiple outputs. However, they lack mechanisms for enforcing logical structure\nand assessing internal coherence. We introduce Theorem-of-Thought (ToTh), a\nnovel framework that models reasoning as collaboration among three parallel\nagents, each simulating a distinct mode of inference: abductive, deductive, and\ninductive. Each agent produces a reasoning trace, which is structured into a\nformal reasoning graph. To evaluate consistency, we apply Bayesian belief\npropagation guided by natural language inference (NLI), assigning confidence\nscores to each step. The most coherent graph is selected to derive the final\nanswer. Experiments on symbolic (WebOfLies) and numerical (MultiArith)\nreasoning benchmarks show that ToTh consistently outperforms CoT,\nSelf-Consistency, and CoT-Decoding across multiple LLMs, while producing\ninterpretable and logically grounded reasoning chains. Our findings suggest a\npromising direction for building more robust and cognitively inspired LLM\nreasoning. The implementation is available at\nhttps://github.com/KurbanIntelligenceLab/theorem-of-thought.\n","authors":["Samir Abdaljalil","Hasan Kurban","Khalid Qaraqe","Erchin Serpedin"],"pdf_url":"https://arxiv.org/pdf/2506.07106v2.pdf","comment":"ACL 2025 KnowFM"},{"id":"http://arxiv.org/abs/2506.21875v2","updated":"2025-07-31T09:23:52Z","published":"2025-06-27T03:18:45Z","title":"WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation","summary":"  Recent multi-modal Large Language Models (LLMs) such as GPT-4o have\ndemonstrated strong capabilities of direct speech interaction. However, the\nlack of specialized and comprehensive benchmarks for end-to-end speech LLM\nevaluation hinders optimizing the user experience of Audio LLMs in real-world\napplications. Existing evaluation methods often adapt text-based benchmarks,\noverlooking speech's unique characteristics and challenges, including prosody,\nhomophones, stuttering, and differing user expectations. Here, we present a\nnovel approach to thoroughly evaluate LLMs in practical speech conversations.\nWe systematically curate real-world chat data relevant to spoken scenarios,\nintroduce diversity in speaker attributes and acoustic conditions, and augment\nthe dataset with speech-specific phenomena. We further design a query-aware\nevaluation method to use customized evaluation checklists and prompts to\nenhance the accuracy of automatic evaluation. We conduct comprehensive testing\nand detailed analysis of various mainstream speech models, revealing\nsignificant differences in model performance across different speech scenarios.\nThe use of query-aware evaluation further enables a finer-grained assessment\nunder various speech-specific scenarios. Our benchmark can provide valuable\ninsights for speech model development and evaluation.\n","authors":["Jian Zhang","Linhao Zhang","Bokai Lei","Chuhan Wu","Wei Jia","Xiao Zhou"],"pdf_url":"https://arxiv.org/pdf/2506.21875v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23364v1","updated":"2025-07-31T09:20:04Z","published":"2025-07-31T09:20:04Z","title":"Holistic Evaluations of Topic Models","summary":"  Topic models are gaining increasing commercial and academic interest for\ntheir ability to summarize large volumes of unstructured text. As unsupervised\nmachine learning methods, they enable researchers to explore data and help\ngeneral users understand key themes in large text collections. However, they\nrisk becoming a 'black box', where users input data and accept the output as an\naccurate summary without scrutiny. This article evaluates topic models from a\ndatabase perspective, drawing insights from 1140 BERTopic model runs. The goal\nis to identify trade-offs in optimizing model parameters and to reflect on what\nthese findings mean for the interpretation and responsible use of topic models\n","authors":["Thomas Compton"],"pdf_url":"https://arxiv.org/pdf/2507.23364v1.pdf","comment":"10 pages, 6 tables"},{"id":"http://arxiv.org/abs/2504.11952v3","updated":"2025-07-31T09:14:25Z","published":"2025-04-16T10:29:30Z","title":"Robust and Fine-Grained Detection of AI Generated Texts","summary":"  An ideal detection system for machine generated content is supposed to work\nwell on any generator as many more advanced LLMs come into existence day by\nday. Existing systems often struggle with accurately identifying AI-generated\ncontent over shorter texts. Further, not all texts might be entirely authored\nby a human or LLM, hence we focused more over partial cases i.e human-LLM\nco-authored texts. Our paper introduces a set of models built for the task of\ntoken classification which are trained on an extensive collection of\nhuman-machine co-authored texts, which performed well over texts of unseen\ndomains, unseen generators, texts by non-native speakers and those with\nadversarial inputs. We also introduce a new dataset of over 2.4M such texts\nmostly co-authored by several popular proprietary LLMs over 23 languages. We\nalso present findings of our models' performance over each texts of each domain\nand generator. Additional findings include comparison of performance against\neach adversarial method, length of input texts and characteristics of generated\ntexts compared to the original human authored texts.\n","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Kanwal Mehreen","Drishti Sharma","Siddhant Gupta","Jebish Purbey","Ashay Srivastava","Subhasya TippaReddy","Arvind Reddy Bobbili","Suraj Telugara Chandrashekhar","Modabbir Adeeb","Srinadh Vura","Suman Debnath","Hamza Farooq"],"pdf_url":"https://arxiv.org/pdf/2504.11952v3.pdf","comment":"18 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.23361v1","updated":"2025-07-31T09:13:42Z","published":"2025-07-31T09:13:42Z","title":"SWE-Exp: Experience-Driven Software Issue Resolution","summary":"  Recent advances in large language model (LLM) agents have shown remarkable\nprogress in software issue resolution, leveraging advanced techniques such as\nmulti-agent collaboration and Monte Carlo Tree Search (MCTS). However, current\nagents act as memoryless explorers - treating each problem separately without\nretaining or reusing knowledge from previous repair experiences. This leads to\nredundant exploration of failed trajectories and missed chances to adapt\nsuccessful issue resolution methods to similar problems. To address this\nproblem, we introduce SWE-Exp, an experience - enhanced approach that distills\nconcise and actionable experience from prior agent trajectories, enabling\ncontinuous learning across issues. Our method introduces a multi-faceted\nexperience bank that captures both successful and failed repair attempts.\nSpecifically, it extracts reusable issue resolution knowledge at different\nlevels - from high-level problem comprehension to specific code changes.\nExperiments show that SWE-Exp achieves state-of-the-art resolution rate (41.6%\nPass@1) on SWE-bench-Verified under open-source agent frameworks. Our approach\nestablishes a new paradigm in which automated software engineering agents\nsystematically accumulate and leverage repair expertise, fundamentally shifting\nfrom trial-and-error exploration to strategic, experience-driven issue\nresolution.\n","authors":["Silin Chen","Shaoxin Lin","Xiaodong Gu","Yuling Shi","Heng Lian","Longfei Yun","Dong Chen","Weiguo Sun","Lin Cao","Qianxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2507.23361v1.pdf","comment":"Our code and data are available at\n  https://github.com/YerbaPage/SWE-Exp"},{"id":"http://arxiv.org/abs/2507.22607v2","updated":"2025-07-31T09:09:45Z","published":"2025-07-30T12:23:21Z","title":"VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced\n  Multimodal Reasoning","summary":"  Reinforcement learning has proven its effectiveness in enhancing the\nreasoning capabilities of large language models. Recent research efforts have\nprogressively extended this paradigm to multimodal reasoning tasks. Due to the\ninherent complexity and diversity of multimodal tasks, especially in semantic\ncontent and problem formulations, existing models often exhibit unstable\nperformance across various domains and difficulty levels. To address these\nlimitations, we propose VL-Cogito, an advanced multimodal reasoning model\ntrained via a novel multi-stage Progressive Curriculum Reinforcement Learning\n(PCuRL) framework. PCuRL systematically guides the model through tasks of\ngradually increasing difficulty, substantially improving its reasoning\nabilities across diverse multimodal contexts. The framework introduces two key\ninnovations: (1) an online difficulty soft weighting mechanism, dynamically\nadjusting training difficulty across successive RL training stages; and (2) a\ndynamic length reward mechanism, which encourages the model to adaptively\nregulate its reasoning path length according to task complexity, thus balancing\nreasoning efficiency with correctness. Experimental evaluations demonstrate\nthat VL-Cogito consistently matches or surpasses existing reasoning-oriented\nmodels across mainstream multimodal benchmarks spanning mathematics, science,\nlogic, and general understanding, validating the effectiveness of our approach.\n","authors":["Ruifeng Yuan","Chenghao Xiao","Sicong Leng","Jianyu Wang","Long Li","Weiwen Xu","Hou Pong Chan","Deli Zhao","Tingyang Xu","Zhongyu Wei","Hao Zhang","Yu Rong"],"pdf_url":"https://arxiv.org/pdf/2507.22607v2.pdf","comment":"21 pages, 5 figures, 6 tables. Work in progress"},{"id":"http://arxiv.org/abs/2507.23358v1","updated":"2025-07-31T09:08:59Z","published":"2025-07-31T09:08:59Z","title":"Text-to-SQL Task-oriented Dialogue Ontology Construction","summary":"  Large language models (LLMs) are widely used as general-purpose knowledge\nsources, but they rely on parametric knowledge, limiting explainability and\ntrustworthiness. In task-oriented dialogue (TOD) systems, this separation is\nexplicit, using an external database structured by an explicit ontology to\nensure explainability and controllability. However, building such ontologies\nrequires manual labels or supervised training. We introduce TeQoDO: a\nText-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM\nautonomously builds a TOD ontology from scratch without supervision using its\ninherent SQL programming capabilities combined with dialogue theory provided in\nthe prompt. We show that TeQoDO outperforms transfer learning approaches, and\nits constructed ontology is competitive on a downstream dialogue state tracking\ntask. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also\nscales to allow construction of much larger ontologies, which we investigate on\na Wikipedia and ArXiv dataset. We view this as a step towards broader\napplication of ontologies to increase LLM explainability.\n","authors":["Renato Vukovic","Carel van Niekerk","Michael Heck","Benjamin Ruppik","Hsien-Chin Lin","Shutong Feng","Nurul Lubis","Milica Gasic"],"pdf_url":"https://arxiv.org/pdf/2507.23358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07695v2","updated":"2025-07-31T08:57:40Z","published":"2025-07-10T12:19:03Z","title":"KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM\n  question-answering capabilities","summary":"  Fine-tuning is an immensely resource-intensive process when retraining Large\nLanguage Models (LLMs) to incorporate a larger body of knowledge. Although many\nfine-tuning techniques have been developed to reduce the time and computational\ncost involved, the challenge persists as LLMs continue to grow in size and\ncomplexity. To address this, a new approach to knowledge expansion in LLMs is\nneeded. Retrieval-Augmented Generation (RAG) offers one such alternative by\nstoring external knowledge in a database and retrieving relevant chunks to\nsupport question answering. However, naive implementations of RAG face\nsignificant limitations in scalability and answer accuracy. This paper\nintroduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome\nthese limitations. Inspired by the divide-and-conquer paradigm, K2RAG\nintegrates dense and sparse vector search, knowledge graphs, and text\nsummarization to improve retrieval quality and system efficiency. The framework\nalso includes a preprocessing step that summarizes the training data,\nsignificantly reducing the training time. K2RAG was evaluated using the\nMultiHopRAG dataset, where the proposed pipeline was trained on the document\ncorpus and tested on a separate evaluation set. Results demonstrated notable\nimprovements over common naive RAG implementations. K2RAG achieved the highest\nmean answer similarity score of 0.57, and reached the highest third quartile\n(Q3) similarity of 0.82, indicating better alignment with ground-truth answers.\nIn addition to improved accuracy, the framework proved highly efficient. The\nsummarization step reduced the average training time of individual components\nby 93%, and execution speed was up to 40% faster than traditional knowledge\ngraph-based RAG systems. K2RAG also demonstrated superior scalability,\nrequiring three times less VRAM than several naive RAG implementations tested\nin this study.\n","authors":["Hruday Markondapatnaikuni","Basem Suleiman","Abdelkarim Erradi","Shijing Chen"],"pdf_url":"https://arxiv.org/pdf/2507.07695v2.pdf","comment":"21 pages, 14 figures"},{"id":"http://arxiv.org/abs/2507.23348v1","updated":"2025-07-31T08:54:46Z","published":"2025-07-31T08:54:46Z","title":"SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution","summary":"  Issue resolution has made remarkable progress thanks to the advanced\nreasoning capabilities of large language models (LLMs). Recently, agent-based\nframeworks such as SWE-agent have further advanced this progress by enabling\nautonomous, tool-using agents to tackle complex software engineering tasks.\nWhile existing agent-based issue resolution approaches are primarily based on\nagents' independent explorations, they often get stuck in local solutions and\nfail to identify issue patterns that span across different parts of the\ncodebase. To address this limitation, we propose SWE-Debate, a competitive\nmulti-agent debate framework that encourages diverse reasoning paths and\nachieves more consolidated issue localization. SWE-Debate first creates\nmultiple fault propagation traces as localization proposals by traversing a\ncode dependency graph. Then, it organizes a three-round debate among\nspecialized agents, each embodying distinct reasoning perspectives along the\nfault propagation trace. This structured competition enables agents to\ncollaboratively converge on a consolidated fix plan. Finally, this consolidated\nfix plan is integrated into an MCTS-based code modification agent for patch\ngeneration. Experiments on the SWE-bench benchmark show that SWE-Debate\nachieves new state-of-the-art results in open-source agent frameworks and\noutperforms baselines by a large margin.\n","authors":["Han Li","Yuling Shi","Shaoxin Lin","Xiaodong Gu","Heng Lian","Xin Wang","Yantao Jia","Tao Huang","Qianxiang Wang"],"pdf_url":"https://arxiv.org/pdf/2507.23348v1.pdf","comment":"Our code and data are available at\n  https://github.com/YerbaPage/SWE-Debate"},{"id":"http://arxiv.org/abs/2504.09753v3","updated":"2025-07-31T08:49:18Z","published":"2025-04-13T23:10:13Z","title":"Improving Multilingual Capabilities with Cultural and Local Knowledge in\n  Large Language Models While Enhancing Native Performance","summary":"  Large Language Models (LLMs) have shown remarkable capabilities, but their\ndevelopment has primarily focused on English and other high-resource languages,\nleaving many languages underserved. We present our latest Hindi-English\nbi-lingual LLM \\textbf{Mantra-14B} with ~3\\% average improvement in benchmark\nscores over both languages, outperforming models twice its size. Using a\ncurated dataset composed of English and Hindi instruction data of 485K samples,\nwe instruction tuned models such as Qwen-2.5-14B-Instruct and Phi-4 to improve\nperformance over both English and Hindi. Our experiments encompassing seven\ndifferent LLMs of varying parameter sizes and over 140 training attempts with\nvarying English-Hindi training data ratios demonstrated that it is possible to\nsignificantly improve multilingual performance without compromising native\nperformance. Further, our approach avoids resource-intensive techniques like\nvocabulary expansion or architectural modifications, thus keeping the model\nsize small. Our results indicate that modest fine-tuning with culturally and\nlocally informed data can bridge performance gaps without incurring significant\ncomputational overhead. We release our training code, datasets, and models\nunder mit and apache licenses to aid further research towards under-represented\nand low-resource languages.\n","authors":["Ram Mohan Rao Kadiyala","Siddartha Pullakhandam","Siddhant Gupta","Drishti Sharma","Jebish Purbey","Kanwal Mehreen","Muhammad Arham","Suman Debnath","Hamza Farooq"],"pdf_url":"https://arxiv.org/pdf/2504.09753v3.pdf","comment":"24 pages, 18 figures"},{"id":"http://arxiv.org/abs/2507.23336v1","updated":"2025-07-31T08:32:37Z","published":"2025-07-31T08:32:37Z","title":"DSBC : Data Science task Benchmarking with Context engineering","summary":"  Recent advances in large language models (LLMs) have significantly impacted\ndata science workflows, giving rise to specialized data science agents designed\nto automate analytical tasks. Despite rapid adoption, systematic benchmarks\nevaluating the efficacy and limitations of these agents remain scarce. In this\npaper, we introduce a comprehensive benchmark specifically crafted to reflect\nreal-world user interactions with data science agents by observing usage of our\ncommercial applications. We evaluate three LLMs: Claude-4.0-Sonnet,\nGemini-2.5-Flash, and OpenAI-o4-Mini across three approaches: zero-shot with\ncontext engineering, multi-step with context engineering, and with SmolAgent.\nOur benchmark assesses performance across a diverse set of eight data science\ntask categories, additionally exploring the sensitivity of models to common\nprompting issues, such as data leakage and slightly ambiguous instructions. We\nfurther investigate the influence of temperature parameters on overall and\ntask-specific outcomes for each model and approach. Our findings reveal\ndistinct performance disparities among the evaluated models and methodologies,\nhighlighting critical factors that affect practical deployment. The benchmark\ndataset and evaluation framework introduced herein aim to provide a foundation\nfor future research of more robust and effective data science agents.\n","authors":["Ram Mohan Rao Kadiyala","Siddhant Gupta","Jebish Purbey","Giulio Martini","Suman Debnath","Hamza Farooq"],"pdf_url":"https://arxiv.org/pdf/2507.23336v1.pdf","comment":"32 pages"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2507.22879v2","updated":"2025-07-31T16:54:43Z","published":"2025-07-30T17:55:06Z","title":"RecGPT Technical Report","summary":"  Recommender systems are among the most impactful applications of artificial\nintelligence, serving as critical infrastructure connecting users, merchants,\nand platforms. However, most current industrial systems remain heavily reliant\non historical co-occurrence patterns and log-fitting objectives, i.e.,\noptimizing for past user interactions without explicitly modeling user intent.\nThis log-fitting approach often leads to overfitting to narrow historical\npreferences, failing to capture users' evolving and latent interests. As a\nresult, it reinforces filter bubbles and long-tail phenomena, ultimately\nharming user experience and threatening the sustainability of the whole\nrecommendation ecosystem.\n  To address these challenges, we rethink the overall design paradigm of\nrecommender systems and propose RecGPT, a next-generation framework that places\nuser intent at the center of the recommendation pipeline. By integrating large\nlanguage models (LLMs) into key stages of user interest mining, item retrieval,\nand explanation generation, RecGPT transforms log-fitting recommendation into\nan intent-centric process. To effectively align general-purpose LLMs to the\nabove domain-specific recommendation tasks at scale, RecGPT incorporates a\nmulti-stage training paradigm, which integrates reasoning-enhanced\npre-alignment and self-training evolution, guided by a Human-LLM cooperative\njudge system. Currently, RecGPT has been fully deployed on the Taobao App.\nOnline experiments demonstrate that RecGPT achieves consistent performance\ngains across stakeholders: users benefit from increased content diversity and\nsatisfaction, merchants and the platform gain greater exposure and conversions.\nThese comprehensive improvement results across all stakeholders validates that\nLLM-driven, intent-centric design can foster a more sustainable and mutually\nbeneficial recommendation ecosystem.\n","authors":["Chao Yi","Dian Chen","Gaoyang Guo","Jiakai Tang","Jian Wu","Jing Yu","Mao Zhang","Sunhao Dai","Wen Chen","Wenjun Yang","Yuning Jiang","Zhujin Gao","Bo Zheng","Chi Li","Dimin Wang","Dixuan Wang","Fan Li","Fan Zhang","Haibin Chen","Haozhuang Liu","Jialin Zhu","Jiamang Wang","Jiawei Wu","Jin Cui","Ju Huang","Kai Zhang","Kan Liu","Lang Tian","Liang Rao","Longbin Li","Lulu Zhao","Na He","Peiyang Wang","Qiqi Huang","Tao Luo","Wenbo Su","Xiaoxiao He","Xin Tong","Xu Chen","Xunke Xi","Yang Li","Yaxuan Wu","Yeqiu Yang","Yi Hu","Yinnan Song","Yuchen Li","Yujie Luo","Yujin Yuan","Yuliang Yan","Zhengyang Wang","Zhibo Xiao","Zhixin Ma","Zile Zhou","Ziqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.22879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.12311v3","updated":"2025-07-31T16:17:52Z","published":"2025-07-16T15:06:29Z","title":"An Ecosystem for Ontology Interoperability","summary":"  Ontology interoperability is one of the complicated issues that restricts the\nuse of ontologies in knowledge graphs (KGs). Different ontologies with\nconflicting and overlapping concepts make it difficult to design, develop, and\ndeploy an interoperable ontology for downstream tasks. We propose an ecosystem\nfor ontology interoperability. The ecosystem employs three state-of-the-art\nsemantic techniques in different phases of the ontology engineering life cycle:\nontology design patterns (ODPs) in the design phase, ontology matching and\nversioning (OM\\&OV) in the develop phase, and ontology-compliant knowledge\ngraphs (OCKGs) in the deploy phase, to achieve better ontology interoperability\nand data integration in real-world applications. A case study of sensor\nobservation in the building domain validates the usefulness of the proposed\necosystem.\n","authors":["Zhangcheng Qiang"],"pdf_url":"https://arxiv.org/pdf/2507.12311v3.pdf","comment":"5 pages, 8 figures"},{"id":"http://arxiv.org/abs/2507.23669v1","updated":"2025-07-31T15:48:12Z","published":"2025-07-31T15:48:12Z","title":"Automating AI Failure Tracking: Semantic Association of Reports in AI\n  Incident Database","summary":"  Artificial Intelligence (AI) systems are transforming critical sectors such\nas healthcare, finance, and transportation, enhancing operational efficiency\nand decision-making processes. However, their deployment in high-stakes domains\nhas exposed vulnerabilities that can result in significant societal harm. To\nsystematically study and mitigate these risk, initiatives like the AI Incident\nDatabase (AIID) have emerged, cataloging over 3,000 real-world AI failure\nreports. Currently, associating a new report with the appropriate AI Incident\nrelies on manual expert intervention, limiting scalability and delaying the\nidentification of emerging failure patterns.\n  To address this limitation, we propose a retrieval-based framework that\nautomates the association of new reports with existing AI Incidents through\nsemantic similarity modeling. We formalize the task as a ranking problem, where\neach report-comprising a title and a full textual description-is compared to\npreviously documented AI Incidents based on embedding cosine similarity.\nBenchmarking traditional lexical methods, cross-encoder architectures, and\ntransformer-based sentence embedding models, we find that the latter\nconsistently achieve superior performance. Our analysis further shows that\ncombining titles and descriptions yields substantial improvements in ranking\naccuracy compared to using titles alone. Moreover, retrieval performance\nremains stable across variations in description length, highlighting the\nrobustness of the framework. Finally, we find that retrieval performance\nconsistently improves as the training set expands. Our approach provides a\nscalable and efficient solution for supporting the maintenance of the AIID.\n","authors":["Diego Russo","Gian Marco Orlando","Valerio La Gatta","Vincenzo Moscato"],"pdf_url":"https://arxiv.org/pdf/2507.23669v1.pdf","comment":"Accepted at the 28th European Conference on Artificial Intelligence\n  (ECAI 2025)"},{"id":"http://arxiv.org/abs/2507.23664v1","updated":"2025-07-31T15:43:51Z","published":"2025-07-31T15:43:51Z","title":"Personalized Education with Ranking Alignment Recommendation","summary":"  Personalized question recommendation aims to guide individual students\nthrough questions to enhance their mastery of learning targets. Most previous\nmethods model this task as a Markov Decision Process and use reinforcement\nlearning to solve, but they struggle with efficient exploration, failing to\nidentify the best questions for each student during training. To address this,\nwe propose Ranking Alignment Recommendation (RAR), which incorporates\ncollaborative ideas into the exploration mechanism, enabling more efficient\nexploration within limited training episodes. Experiments show that RAR\neffectively improves recommendation performance, and our framework can be\napplied to any RL-based question recommender. Our code is available in\nhttps://github.com/wuming29/RAR.git.\n","authors":["Haipeng Liu","Yuxuan Liu","Ting Long"],"pdf_url":"https://arxiv.org/pdf/2507.23664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21903v2","updated":"2025-07-31T15:33:32Z","published":"2025-07-29T15:14:39Z","title":"Who's important? -- SUnSET: Synergistic Understanding of Stakeholder,\n  Events and Time for Timeline Generation","summary":"  As news reporting becomes increasingly global and decentralized online,\ntracking related events across multiple sources presents significant\nchallenges. Existing news summarization methods typically utilizes Large\nLanguage Models and Graphical methods on article-based summaries. However, this\nis not effective since it only considers the textual content of similarly dated\narticles to understand the gist of the event. To counteract the lack of\nanalysis on the parties involved, it is essential to come up with a novel\nframework to gauge the importance of stakeholders and the connection of related\nevents through the relevant entities involved. Therefore, we present SUnSET:\nSynergistic Understanding of Stakeholder, Events and Time for the task of\nTimeline Summarization (TLS). We leverage powerful Large Language Models (LLMs)\nto build SET triplets and introduced the use of stakeholder-based ranking to\nconstruct a $Relevancy$ metric, which can be extended into general situations.\nOur experimental results outperform all prior baselines and emerged as the new\nState-of-the-Art, highlighting the impact of stakeholder information within\nnews article.\n","authors":["Tiviatis Sim","Kaiwen Yang","Shen Xin","Kenji Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2507.21903v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06254v2","updated":"2025-07-31T11:48:39Z","published":"2024-11-09T19:03:56Z","title":"KeyB2: Selecting Key Blocks is Also Important for Long Document Ranking\n  with Large Language Models","summary":"  The emergence of large language models (LLMs) such as Llama has significantly\nadvanced neural information retrieval (IR). However, applying LLMs to long\ndocument reranking remains computationally expensive and may be ineffective.\nMoreover, the internal behavior of LLMs during document relevance judgment is\nstill underexplored. In this paper, we begin with an in-depth analysis of\ndecoder-only LLM attention patterns and find that several attention heads\nconsistently align with relevance signals, yet this alignment deteriorates as\nirrelevant content increases. Motivated by this observation, we revisit and\nextend the block selection paradigm, introducing KeyB2, a scalable reranking\nframework that combines block pre-selection with powerful decoder-only LLMs.\nKeyB2 generalizes the selection stage to support BM25, cross-encoder, and\nbi-encoder, and adapts LLM to compute fine-grained relevance scores. We further\nintroduce a new bi-encoder strategy that performs strongly and efficiently.\nExtensive experiments on TREC DL 2019/2023 document task, Robust04, and MLDR-zh\ndemonstrate that KeyB2 outperforms baselines including RankLLaMA,\nRankLLaMA-MaxP/AvgP, and KeyB, achieving new state-of-the-art (SOTA) results on\nTREC DL 2019 document reranking task. In addition, KeyB2 reduces reranking\nlatency compared with RankLLaMA by over 83% and memory usage by over 74%,\npositioning it as a practical and effective solution for long document ranking\nwith LLMs.\n","authors":["Minghan Li","Eric Gaussier","Juntao Li","Guodong Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.06254v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23459v1","updated":"2025-07-31T11:37:11Z","published":"2025-07-31T11:37:11Z","title":"KLAN: Kuaishou Landing-page Adaptive Navigator","summary":"  Modern online platforms configure multiple pages to accommodate diverse user\nneeds. This multi-page architecture inherently establishes a two-stage\ninteraction paradigm between the user and the platform: (1) Stage I: page\nnavigation, navigating users to a specific page and (2) Stage II: in-page\ninteraction, where users engage with customized content within the specific\npage. While the majority of research has been focusing on the sequential\nrecommendation task that improves users' feedback in Stage II, there has been\nlittle investigation on how to achieve better page navigation in Stage I. To\nfill this gap, we formally define the task of Personalized Landing Page\nModeling (PLPM) into the field of recommender systems: Given a user upon app\nentry, the goal of PLPM is to proactively select the most suitable landing page\nfrom a set of candidates (e.g., functional tabs, content channels, or\naggregation pages) to optimize the short-term PDR metric and the long-term user\nengagement and satisfaction metrics, while adhering to industrial constraints.\nAdditionally, we propose KLAN (Kuaishou Landing-page Adaptive Navigator), a\nhierarchical solution framework designed to provide personalized landing pages\nunder the formulation of PLPM. KLAN comprises three key components: (1)\nKLAN-ISP captures inter-day static page preference; (2) KLAN-IIT captures\nintra-day dynamic interest transitions and (3) KLAN-AM adaptively integrates\nboth components for optimal navigation decisions. Extensive online experiments\nconducted on the Kuaishou platform demonstrate the effectiveness of KLAN,\nobtaining +0.205% and +0.192% improvements on in Daily Active Users (DAU) and\nuser Lifetime (LT). Our KLAN is ultimately deployed on the online platform at\nfull traffic, serving hundreds of millions of users. To promote further\nresearch in this important area, we will release our dataset and code upon\npaper acceptance.\n","authors":["Fan Li","Chang Meng","Jiaqi Fu","Shuchang Liu","Jiashuo Zhang","Tianke Zhang","Xueliang Wang","Xiaoqiang Feng"],"pdf_url":"https://arxiv.org/pdf/2507.23459v1.pdf","comment":"We propose PLPM, a new task for selecting optimal landing pages upon\n  user entry. Our solution, KLAN, models static and dynamic user interests and\n  is successfully deployed on Kuaishou, improving DAU and user lifetime"},{"id":"http://arxiv.org/abs/2507.23410v1","updated":"2025-07-31T10:33:47Z","published":"2025-07-31T10:33:47Z","title":"Towards LLM-Enhanced Product Line Scoping","summary":"  The idea of product line scoping is to identify the set of features and\nconfigurations that a product line should include, i.e., offer for\nconfiguration purposes. In this context, a major scoping task is to find a\nbalance between commercial relevance and technical feasibility. Traditional\nproduct line scoping approaches rely on formal feature models and require a\nmanual analysis which can be quite time-consuming. In this paper, we sketch how\nLarge Language Models (LLMs) can be applied to support product line scoping\ntasks with a natural language interaction based scoping process. Using a\nworking example from the smarthome domain, we sketch how LLMs can be applied to\nevaluate different feature model alternatives. We discuss open research\nchallenges regarding the integration of LLMs with product line scoping.\n","authors":["Alexander Felfernig","Damian Garber","Viet-Man Le","Sebastian Lubos","Thi Ngoc Trang Tran"],"pdf_url":"https://arxiv.org/pdf/2507.23410v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.16725v2","updated":"2025-07-31T10:20:56Z","published":"2025-07-22T16:08:12Z","title":"RAVine: Reality-Aligned Evaluation for Agentic Search","summary":"  Agentic search, as a more autonomous and adaptive paradigm of retrieval\naugmentation, is driving the evolution of intelligent search systems. However,\nexisting evaluation frameworks fail to align well with the goals of agentic\nsearch. First, the complex queries commonly used in current benchmarks often\ndeviate from realistic user search scenarios. Second, prior approaches tend to\nintroduce noise when extracting ground truth for end-to-end evaluations,\nleading to distorted assessments at a fine-grained level. Third, most current\nframeworks focus solely on the quality of final answers, neglecting the\nevaluation of the iterative process inherent to agentic search. To address\nthese limitations, we propose RAVine -- a Reality-Aligned eValuation framework\nfor agentic LLMs with search. RAVine targets multi-point queries and long-form\nanswers that better reflect user intents, and introduces an attributable ground\ntruth construction strategy to enhance the accuracy of fine-grained evaluation.\nMoreover, RAVine examines model's interaction with search tools throughout the\niterative process, and accounts for factors of efficiency. We benchmark a\nseries of models using RAVine and derive several insights, which we hope will\ncontribute to advancing the development of agentic search systems. The code and\ndatasets are available at https://github.com/SwordFaith/RAVine.\n","authors":["Yilong Xu","Xiang Long","Zhi Zheng","Jinhua Gao"],"pdf_url":"https://arxiv.org/pdf/2507.16725v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23400v1","updated":"2025-07-31T10:14:03Z","published":"2025-07-31T10:14:03Z","title":"MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based\n  on Multi-Relational Graphs and Structural Entropy Minimization","summary":"  The core challenge faced by multi-document summarization is the complexity of\nrelationships among documents and the presence of information redundancy. Graph\nclustering is an effective paradigm for addressing this issue, as it models the\ncomplex relationships among documents using graph structures and reduces\ninformation redundancy through clustering, achieving significant research\nprogress. However, existing methods often only consider single-relational\ngraphs and require a predefined number of clusters, which hinders their ability\nto fully represent rich relational information and adaptively partition\nsentence groups to reduce redundancy. To overcome these limitations, we propose\nMRGSEM-Sum, an unsupervised multi-document summarization framework based on\nmulti-relational graphs and structural entropy minimization. Specifically, we\nconstruct a multi-relational graph that integrates semantic and discourse\nrelations between sentences, comprehensively modeling the intricate and dynamic\nconnections among sentences across documents. We then apply a two-dimensional\nstructural entropy minimization algorithm for clustering, automatically\ndetermining the optimal number of clusters and effectively organizing sentences\ninto coherent groups. Finally, we introduce a position-aware compression\nmechanism to distill each cluster, generating concise and informative\nsummaries. Extensive experiments on four benchmark datasets (Multi-News,\nDUC-2004, PubMed, and WikiSum) demonstrate that our approach consistently\noutperforms previous unsupervised methods and, in several cases, achieves\nperformance comparable to supervised models and large language models. Human\nevaluation demonstrates that the summaries generated by MRGSEM-Sum exhibit high\nconsistency and coverage, approaching human-level quality.\n","authors":["Yongbing Zhang","Fang Nan","Shengxiang Gao","Yuxin Huang","Kaiwen Tan","Zhengtao Yu"],"pdf_url":"https://arxiv.org/pdf/2507.23400v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23364v1","updated":"2025-07-31T09:20:04Z","published":"2025-07-31T09:20:04Z","title":"Holistic Evaluations of Topic Models","summary":"  Topic models are gaining increasing commercial and academic interest for\ntheir ability to summarize large volumes of unstructured text. As unsupervised\nmachine learning methods, they enable researchers to explore data and help\ngeneral users understand key themes in large text collections. However, they\nrisk becoming a 'black box', where users input data and accept the output as an\naccurate summary without scrutiny. This article evaluates topic models from a\ndatabase perspective, drawing insights from 1140 BERTopic model runs. The goal\nis to identify trade-offs in optimizing model parameters and to reflect on what\nthese findings mean for the interpretation and responsible use of topic models\n","authors":["Thomas Compton"],"pdf_url":"https://arxiv.org/pdf/2507.23364v1.pdf","comment":"10 pages, 6 tables"},{"id":"http://arxiv.org/abs/2507.23358v1","updated":"2025-07-31T09:08:59Z","published":"2025-07-31T09:08:59Z","title":"Text-to-SQL Task-oriented Dialogue Ontology Construction","summary":"  Large language models (LLMs) are widely used as general-purpose knowledge\nsources, but they rely on parametric knowledge, limiting explainability and\ntrustworthiness. In task-oriented dialogue (TOD) systems, this separation is\nexplicit, using an external database structured by an explicit ontology to\nensure explainability and controllability. However, building such ontologies\nrequires manual labels or supervised training. We introduce TeQoDO: a\nText-to-SQL task-oriented Dialogue Ontology construction method. Here, an LLM\nautonomously builds a TOD ontology from scratch without supervision using its\ninherent SQL programming capabilities combined with dialogue theory provided in\nthe prompt. We show that TeQoDO outperforms transfer learning approaches, and\nits constructed ontology is competitive on a downstream dialogue state tracking\ntask. Ablation studies demonstrate the key role of dialogue theory. TeQoDO also\nscales to allow construction of much larger ontologies, which we investigate on\na Wikipedia and ArXiv dataset. We view this as a step towards broader\napplication of ontologies to increase LLM explainability.\n","authors":["Renato Vukovic","Carel van Niekerk","Michael Heck","Benjamin Ruppik","Hsien-Chin Lin","Shutong Feng","Nurul Lubis","Milica Gasic"],"pdf_url":"https://arxiv.org/pdf/2507.23358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23334v1","updated":"2025-07-31T08:31:05Z","published":"2025-07-31T08:31:05Z","title":"MUST-RAG: MUSical Text Question Answering with Retrieval Augmented\n  Generation","summary":"  Recent advancements in Large language models (LLMs) have demonstrated\nremarkable capabilities across diverse domains. While they exhibit strong\nzero-shot performance on various tasks, LLMs' effectiveness in music-related\napplications remains limited due to the relatively small proportion of\nmusic-specific knowledge in their training data. To address this limitation, we\npropose MusT-RAG, a comprehensive framework based on Retrieval Augmented\nGeneration (RAG) to adapt general-purpose LLMs for text-only music question\nanswering (MQA) tasks. RAG is a technique that provides external knowledge to\nLLMs by retrieving relevant context information when generating answers to\nquestions. To optimize RAG for the music domain, we (1) propose MusWikiDB, a\nmusic-specialized vector database for the retrieval stage, and (2) utilizes\ncontext information during both inference and fine-tuning processes to\neffectively transform general-purpose LLMs into music-specific models. Our\nexperiment demonstrates that MusT-RAG significantly outperforms traditional\nfine-tuning approaches in enhancing LLMs' music domain adaptation capabilities,\nshowing consistent improvements across both in-domain and out-of-domain MQA\nbenchmarks. Additionally, our MusWikiDB proves substantially more effective\nthan general Wikipedia corpora, delivering superior performance and\ncomputational efficiency.\n","authors":["Daeyong Kwon","SeungHeon Doh","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2507.23334v1.pdf","comment":"8 pages, 2 figures"},{"id":"http://arxiv.org/abs/2507.18518v2","updated":"2025-07-31T06:47:49Z","published":"2025-07-24T15:41:34Z","title":"Transform Before You Query: A Privacy-Preserving Approach for Vector\n  Retrieval with Embedding Space Alignment","summary":"  Vector Database (VDB) can efficiently index and search high-dimensional\nvector embeddings from unstructured data, crucially enabling fast semantic\nsimilarity search essential for modern AI applications like generative AI and\nrecommendation systems. Since current VDB service providers predominantly use\nproprietary black-box models, users are forced to expose raw query text to them\nvia API in exchange for the vector retrieval services. Consequently, if query\ntext involves confidential records from finance or healthcare domains, this\nmechanism inevitably leads to critical leakage of user's sensitive information.\nTo address this issue, we introduce STEER (\\textbf{S}ecure \\textbf{T}ransformed\n\\textbf{E}mbedding v\\textbf{E}ctor\\textbf{ R}etrieval), a private vector\nretrieval framework that leverages the alignment relationship between the\nsemantic spaces of different embedding models to derive approximate embeddings\nfor the query text. STEER performs the retrieval using the approximate\nembeddings within the original VDB and requires no modifications to the server\nside. Our theoretical and experimental analyses demonstrate that STEER\neffectively safeguards query text privacy while maintaining the retrieval\naccuracy. Even though approximate embeddings are approximations of the\nembeddings from proprietary models, they still prevent the providers from\nrecovering the query text through Embedding Inversion Attacks (EIAs). Extensive\nexperimental results show that Recall@100 of STEER can basically achieve a\ndecrease of less than 5\\%. Furthermore, even when searching within a text\ncorpus of millions of entries, STEER achieves a Recall@20 accuracy 20\\% higher\nthan current baselines.\n","authors":["Ruiqi He","Zekun Fei","Jiaqi Li","Xinyuan Zhu","Biao Yi","Siyi Lv","Weijie Liu","Zheli Liu"],"pdf_url":"https://arxiv.org/pdf/2507.18518v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23267v1","updated":"2025-07-31T05:56:21Z","published":"2025-07-31T05:56:21Z","title":"Your Spending Needs Attention: Modeling Financial Habits with\n  Transformers","summary":"  Predictive models play a crucial role in the financial industry, enabling\nrisk prediction, fraud detection, and personalized recommendations, where\nslight changes in core model performance can result in billions of dollars in\nrevenue or losses. While financial institutions have access to enormous amounts\nof user data (e.g., bank transactions, in-app events, and customer support\nlogs), leveraging this data effectively remains challenging due to its\ncomplexity and scale. Thus, in many financial institutions, most production\nmodels follow traditional machine learning (ML) approaches by converting\nunstructured data into manually engineered tabular features. Conversely, other\ndomains (e.g., natural language processing) have effectively utilized\nself-supervised learning (SSL) to learn rich representations from raw data,\nremoving the need for manual feature extraction. In this paper, we investigate\nusing transformer-based representation learning models for transaction data,\nhypothesizing that these models, trained on massive data, can provide a novel\nand powerful approach to understanding customer behavior. We propose a new\nmethod enabling the use of SSL with transaction data by adapting\ntransformer-based models to handle both textual and structured attributes. Our\napproach, denoted nuFormer, includes an end-to-end fine-tuning method that\nintegrates user embeddings with existing tabular features. Our experiments\ndemonstrate improvements for large-scale recommendation problems at Nubank.\nNotably, these gains are achieved solely through enhanced representation\nlearning rather than incorporating new data sources.\n","authors":["D. T. Braithwaite","Misael Cavalcanti","R. Austin McEver","Hiroto Udagawa","Daniel Silva","Rohan Ramanath","Felipe Meneses","Arissa Yoshida","Evan Wingert","Matheus Ramos","Brian Zanfelice","Aman Gupta"],"pdf_url":"https://arxiv.org/pdf/2507.23267v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.01124v2","updated":"2025-07-31T05:19:47Z","published":"2024-02-02T03:52:21Z","title":"TransFR: Transferable Federated Recommendation with Adapter Tuning on\n  Pre-trained Language Models","summary":"  Federated recommendations (FRs), facilitating multiple local clients to\ncollectively learn a global model without disclosing user private data, have\nemerged as a prevalent on-device service. In conventional FRs, a dominant\nparadigm is to utilize discrete identities to represent clients and items,\nwhich are then mapped to domain-specific embeddings to participate in model\ntraining. Despite considerable performance, we reveal three inherent\nlimitations that can not be ignored in federated settings, i.e.,\nnon-transferability across domains, ineffectiveness in cold-start settings, and\npotential privacy violations during federated training. To this end, we propose\na transferable federated recommendation model, TransFR, which delicately\nincorporates the general capabilities empowered by pre-trained models and the\npersonalized abilities by fine-tuning local private data. Specifically, it\nfirst learns domain-agnostic representations of items by exploiting pre-trained\nmodels with public textual corpora. To tailor for FR tasks, we further\nintroduce efficient federated adapter-tuning and test-time adaptation\nmechanisms, which facilitate personalized local adapters for each client by\nfitting their private data distributions. We theoretically prove the advantages\nof incorporating adapter tuning in FRs regarding both effectiveness and\nprivacy. Through extensive experiments, we show that our TransFR model\nsurpasses several state-of-the-art FRs on transferability.\n","authors":["Honglei Zhang","Zhiwei Li","Haoxuan Li","Xin Zhou","Jie Zhang","Yidong Li"],"pdf_url":"https://arxiv.org/pdf/2402.01124v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23209v1","updated":"2025-07-31T03:05:05Z","published":"2025-07-31T03:05:05Z","title":"Not Just What, But When: Integrating Irregular Intervals to LLM for\n  Sequential Recommendation","summary":"  Time intervals between purchasing items are a crucial factor in sequential\nrecommendation tasks, whereas existing approaches focus on item sequences and\noften overlook by assuming the intervals between items are static. However,\ndynamic intervals serve as a dimension that describes user profiling on not\nonly the history within a user but also different users with the same item\nhistory. In this work, we propose IntervalLLM, a novel framework that\nintegrates interval information into LLM and incorporates the novel\ninterval-infused attention to jointly consider information of items and\nintervals. Furthermore, unlike prior studies that address the cold-start\nscenario only from the perspectives of users and items, we introduce a new\nviewpoint: the interval perspective to serve as an additional metric for\nevaluating recommendation methods on the warm and cold scenarios. Extensive\nexperiments on 3 benchmarks with both traditional- and LLM-based baselines\ndemonstrate that our IntervalLLM achieves not only 4.4% improvements in average\nbut also the best-performing warm and cold scenarios across all users, items,\nand the proposed interval perspectives. In addition, we observe that the cold\nscenario from the interval perspective experiences the most significant\nperformance drop among all recommendation methods. This finding underscores the\nnecessity of further research on interval-based cold challenges and our\nintegration of interval information in the realm of sequential recommendation\ntasks. Our code is available here:\nhttps://github.com/sony/ds-research-code/tree/master/recsys25-IntervalLLM.\n","authors":["Wei-Wei Du","Takuma Udagawa","Kei Tateno"],"pdf_url":"https://arxiv.org/pdf/2507.23209v1.pdf","comment":"Accepted by RecSys 2025 short paper track"},{"id":"http://arxiv.org/abs/2507.23208v1","updated":"2025-07-31T03:04:34Z","published":"2025-07-31T03:04:34Z","title":"Are Recommenders Self-Aware? Label-Free Recommendation Performance\n  Estimation via Model Uncertainty","summary":"  Can a recommendation model be self-aware? This paper investigates the\nrecommender's self-awareness by quantifying its uncertainty, which provides a\nlabel-free estimation of its performance. Such self-assessment can enable more\ninformed understanding and decision-making before the recommender engages with\nany users. To this end, we propose an intuitive and effective method,\nprobability-based List Distribution uncertainty (LiDu). LiDu measures\nuncertainty by determining the probability that a recommender will generate a\ncertain ranking list based on the prediction distributions of individual items.\nWe validate LiDu's ability to represent model self-awareness in two settings:\n(1) with a matrix factorization model on a synthetic dataset, and (2) with\npopular recommendation algorithms on real-world datasets. Experimental results\nshow that LiDu is more correlated with recommendation performance than a series\nof label-free performance estimators. Additionally, LiDu provides valuable\ninsights into the dynamic inner states of models throughout training and\ninference. This work establishes an empirical connection between recommendation\nuncertainty and performance, framing it as a step towards more transparent and\nself-evaluating recommender systems.\n","authors":["Jiayu Li","Ziyi Ye","Guohao Jian","Zhiqiang Guo","Weizhi Ma","Qingyao Ai","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.23208v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2507.23784v1","updated":"2025-07-31T17:59:40Z","published":"2025-07-31T17:59:40Z","title":"SUB: Benchmarking CBM Generalization via Synthetic Attribute\n  Substitutions","summary":"  Concept Bottleneck Models (CBMs) and other concept-based interpretable models\nshow great promise for making AI applications more transparent, which is\nessential in fields like medicine. Despite their success, we demonstrate that\nCBMs struggle to reliably identify the correct concepts under distribution\nshifts. To assess the robustness of CBMs to concept variations, we introduce\nSUB: a fine-grained image and concept benchmark containing 38,400 synthetic\nimages based on the CUB dataset. To create SUB, we select a CUB subset of 33\nbird classes and 45 concepts to generate images which substitute a specific\nconcept, such as wing color or belly pattern. We introduce a novel Tied\nDiffusion Guidance (TDG) method to precisely control generated images, where\nnoise sharing for two parallel denoising processes ensures that both the\ncorrect bird class and the correct attribute are generated. This novel\nbenchmark enables rigorous evaluation of CBMs and similar interpretable models,\ncontributing to the development of more robust methods. Our code is available\nat https://github.com/ExplainableML/sub and the dataset at\nhttp://huggingface.co/datasets/Jessica-bader/SUB.\n","authors":["Jessica Bader","Leander Girrbach","Stephan Alaniz","Zeynep Akata"],"pdf_url":"https://arxiv.org/pdf/2507.23784v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2507.23777v1","updated":"2025-07-31T17:58:30Z","published":"2025-07-31T17:58:30Z","title":"XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation\n  Acceleration via Multi-Head Speculative Decoding","summary":"  Current auto-regressive models can generate high-quality, topologically\nprecise meshes; however, they necessitate thousands-or even tens of\nthousands-of next-token predictions during inference, resulting in substantial\nlatency. We introduce XSpecMesh, a quality-preserving acceleration method for\nauto-regressive mesh generation models. XSpecMesh employs a lightweight,\nmulti-head speculative decoding scheme to predict multiple tokens in parallel\nwithin a single forward pass, thereby accelerating inference. We further\npropose a verification and resampling strategy: the backbone model verifies\neach predicted token and resamples any tokens that do not meet the quality\ncriteria. In addition, we propose a distillation strategy that trains the\nlightweight decoding heads by distilling from the backbone model, encouraging\ntheir prediction distributions to align and improving the success rate of\nspeculative predictions. Extensive experiments demonstrate that our method\nachieves a 1.7x speedup without sacrificing generation quality. Our code will\nbe released.\n","authors":["Dian Chen","Yansong Qu","Xinyang Li","Ming Li","Shengchuan Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.23777v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23773v1","updated":"2025-07-31T17:57:20Z","published":"2025-07-31T17:57:20Z","title":"SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning\n  Architecture with LLM-Based World Model","summary":"  AI agents built on large language models (LLMs) hold enormous promise, but\ncurrent practice focuses on a one-task-one-agent approach, which not only falls\nshort of scalability and generality, but also suffers from the fundamental\nlimitations of autoregressive LLMs. On the other hand, humans are general\nagents who reason by mentally simulating the outcomes of their actions and\nplans. Moving towards a more general and powerful AI agent, we introduce\nSimuRA, a goal-oriented architecture for generalized agentic reasoning. Based\non a principled formulation of optimal agent in any environment, \\modelname\novercomes the limitations of autoregressive reasoning by introducing a world\nmodel for planning via simulation. The generalized world model is implemented\nusing LLM, which can flexibly plan in a wide range of environments using the\nconcept-rich latent space of natural language. Experiments on difficult web\nbrowsing tasks show that \\modelname improves the success of flight search from\n0\\% to 32.2\\%. World-model-based planning, in particular, shows consistent\nadvantage of up to 124\\% over autoregressive planning, demonstrating the\nadvantage of world model simulation as a reasoning paradigm. We are excited\nabout the possibility for training a single, general agent model based on LLMs\nthat can act superintelligently in all environments. To start, we make SimuRA,\na web-browsing agent built on \\modelname with pretrained LLMs, available as a\nresearch demo for public testing.\n","authors":["Mingkai Deng","Jinyu Hou","Yilin Shen","Hongxia Jin","Graham Neubig","Zhiting Hu","Eric Xing"],"pdf_url":"https://arxiv.org/pdf/2507.23773v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21035v2","updated":"2025-07-31T17:57:18Z","published":"2025-07-28T17:55:08Z","title":"GenoMAS: A Multi-Agent Framework for Scientific Discovery via\n  Code-Driven Gene Expression Analysis","summary":"  Gene expression analysis holds the key to many biomedical discoveries, yet\nextracting insights from raw transcriptomic data remains formidable due to the\ncomplexity of multiple large, semi-structured files and the need for extensive\ndomain expertise. Current automation approaches are often limited by either\ninflexible workflows that break down in edge cases or by fully autonomous\nagents that lack the necessary precision for rigorous scientific inquiry.\nGenoMAS charts a different course by presenting a team of LLM-based scientists\nthat integrates the reliability of structured workflows with the adaptability\nof autonomous agents. GenoMAS orchestrates six specialized LLM agents through\ntyped message-passing protocols, each contributing complementary strengths to a\nshared analytic canvas. At the heart of GenoMAS lies a guided-planning\nframework: programming agents unfold high-level task guidelines into Action\nUnits and, at each juncture, elect to advance, revise, bypass, or backtrack,\nthereby maintaining logical coherence while bending gracefully to the\nidiosyncrasies of genomic data.\n  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation\nof 89.13% for data preprocessing and an F$_1$ of 60.48% for gene\nidentification, surpassing the best prior art by 10.61% and 16.85%\nrespectively. Beyond metrics, GenoMAS surfaces biologically plausible\ngene-phenotype associations corroborated by the literature, all while adjusting\nfor latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.\n","authors":["Haoyang Liu","Yijiang Li","Haohan Wang"],"pdf_url":"https://arxiv.org/pdf/2507.21035v2.pdf","comment":"51 pages (13 pages for the main text, 9 pages for references, and 29\n  pages for the appendix)"},{"id":"http://arxiv.org/abs/2507.23771v1","updated":"2025-07-31T17:56:28Z","published":"2025-07-31T17:56:28Z","title":"Consensus-Driven Active Model Selection","summary":"  The widespread availability of off-the-shelf machine learning models poses a\nchallenge: which model, of the many available candidates, should be chosen for\na given data analysis task? This question of model selection is traditionally\nanswered by collecting and annotating a validation dataset -- a costly and\ntime-intensive process. We propose a method for active model selection, using\npredictions from candidate models to prioritize the labeling of test data\npoints that efficiently differentiate the best candidate. Our method, CODA,\nperforms consensus-driven active model selection by modeling relationships\nbetween classifiers, categories, and data points within a probabilistic\nframework. The framework uses the consensus and disagreement between models in\nthe candidate pool to guide the label acquisition process, and Bayesian\ninference to update beliefs about which model is best as more information is\ncollected. We validate our approach by curating a collection of 26 benchmark\ntasks capturing a range of model selection scenarios. CODA outperforms existing\nmethods for active model selection significantly, reducing the annotation\neffort required to discover the best model by upwards of 70% compared to the\nprevious state-of-the-art. Code and data are available at\nhttps://github.com/justinkay/coda.\n","authors":["Justin Kay","Grant Van Horn","Subhransu Maji","Daniel Sheldon","Sara Beery"],"pdf_url":"https://arxiv.org/pdf/2507.23771v1.pdf","comment":"ICCV 2025 Highlight. 16 pages, 8 figures"},{"id":"http://arxiv.org/abs/2507.23768v1","updated":"2025-07-31T17:55:16Z","published":"2025-07-31T17:55:16Z","title":"Formal Bayesian Transfer Learning via the Total Risk Prior","summary":"  In analyses with severe data-limitations, augmenting the target dataset with\ninformation from ancillary datasets in the application domain, called source\ndatasets, can lead to significantly improved statistical procedures. However,\nexisting methods for this transfer learning struggle to deal with situations\nwhere the source datasets are also limited and not guaranteed to be\nwell-aligned with the target dataset. A typical strategy is to use the\nempirical loss minimizer on the source data as a prior mean for the target\nparameters, which places the estimation of source parameters outside of the\nBayesian formalism. Our key conceptual contribution is to use a risk minimizer\nconditional on source parameters instead. This allows us to construct a single\njoint prior distribution for all parameters from the source datasets as well as\nthe target dataset. As a consequence, we benefit from full Bayesian uncertainty\nquantification and can perform model averaging via Gibbs sampling over\nindicator variables governing the inclusion of each source dataset. We show how\na particular instantiation of our prior leads to a Bayesian Lasso in a\ntransformed coordinate system and discuss computational techniques to scale our\napproach to moderately sized datasets. We also demonstrate that recently\nproposed minimax-frequentist transfer learning techniques may be viewed as an\napproximate Maximum a Posteriori approach to our model. Finally, we demonstrate\nsuperior predictive performance relative to the frequentist baseline on a\ngenetics application, especially when the source data are limited.\n","authors":["Nathan Wycoff","Ali Arab","Lisa O. Singh"],"pdf_url":"https://arxiv.org/pdf/2507.23768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23767v1","updated":"2025-07-31T17:55:07Z","published":"2025-07-31T17:55:07Z","title":"Scaled Beta Models and Feature Dilution for Dynamic Ticket Pricing","summary":"  A novel approach is presented for identifying distinct signatures of\nperforming acts in the secondary ticket resale market by analyzing dynamic\npricing distributions. Using a newly curated, time series dataset from the\nSeatGeek API, we model ticket pricing distributions as scaled Beta\ndistributions. This enables accurate parameter estimation from incomplete\nstatistical data using a hybrid of quantile matching and the method of moments.\nIncorporating the estimated $\\alpha$ and $\\beta$ parameters into Random Forest\nclassifiers significantly improves pairwise artist classification accuracy,\ndemonstrating the unique economic signatures in event pricing data.\nAdditionally, we provide theoretical and empirical evidence that incorporating\nzero-variance (constant-value) features into Random Forest models acts as an\nimplicit regularizer, enhancing feature variety and robustness. This\nregularization promotes deeper, more varied trees in the ensemble, improving\nthe bias-variance tradeoff and mitigating overfitting to dominant features.\nThese findings are validated on both the new ticket pricing dataset and the\nstandard UCI ML handwritten digits dataset.\n","authors":["Jonathan R. Landers"],"pdf_url":"https://arxiv.org/pdf/2507.23767v1.pdf","comment":"27 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2507.23756v1","updated":"2025-07-31T17:41:30Z","published":"2025-07-31T17:41:30Z","title":"Improving annotator selection in Active Learning using a mood and\n  fatigue-aware Recommender System","summary":"  This study centers on overcoming the challenge of selecting the best\nannotators for each query in Active Learning (AL), with the objective of\nminimizing misclassifications. AL recognizes the challenges related to cost and\ntime when acquiring labeled data, and decreases the number of labeled data\nneeded. Nevertheless, there is still the necessity to reduce annotation errors,\naiming to be as efficient as possible, to achieve the expected accuracy faster.\nMost strategies for query-annotator pairs do not consider internal factors that\naffect productivity, such as mood, attention, motivation, and fatigue levels.\nThis work addresses this gap in the existing literature, by not only\nconsidering how the internal factors influence annotators (mood and fatigue\nlevels) but also presenting a new query-annotator pair strategy, using a\nKnowledge-Based Recommendation System (RS). The RS ranks the available\nannotators, allowing to choose one or more to label the queried instance using\ntheir past accuracy values, and their mood and fatigue levels, as well as\ninformation about the instance queried. This work bases itself on existing\nliterature on mood and fatigue influence on human performance, simulating\nannotators in a realistic manner, and predicting their performance with the RS.\nThe results show that considering past accuracy values, as well as mood and\nfatigue levels reduces the number of annotation errors made by the annotators,\nand the uncertainty of the model through its training, when compared to not\nusing internal factors. Accuracy and F1-score values were also better in the\nproposed approach, despite not being as substantial as the aforementioned. The\nmethodologies and findings presented in this study begin to explore the open\nchallenge of human cognitive factors affecting AL.\n","authors":["Diana Mortagua"],"pdf_url":"https://arxiv.org/pdf/2507.23756v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22174v2","updated":"2025-07-31T17:34:18Z","published":"2025-07-27T08:00:43Z","title":"Spatial-Temporal Reinforcement Learning for Network Routing with\n  Non-Markovian Traffic","summary":"  Reinforcement Learning (RL) has been widely used for packet routing in\ncommunication networks, but traditional RL methods rely on the Markov\nassumption that the current state contains all necessary information for\ndecision-making. In reality, internet traffic is non-Markovian, and past states\ndo influence routing performance. Moreover, common deep RL approaches use\nfunction approximators, such as neural networks, that do not model the spatial\nstructure in network topologies. To address these shortcomings, we design a\nnetwork environment with non-Markovian traffic and introduce a spatial-temporal\nRL (STRL) framework for packet routing. Our approach outperforms traditional\nbaselines by more than 19% during training and 7% for inference despite a\nchange in network topology.\n","authors":["Molly Wang","Kin. K Leung"],"pdf_url":"https://arxiv.org/pdf/2507.22174v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23740v1","updated":"2025-07-31T17:24:04Z","published":"2025-07-31T17:24:04Z","title":"Rule2Text: Natural Language Explanation of Logical Rules in Knowledge\n  Graphs","summary":"  Knowledge graphs (KGs) often contain sufficient information to support the\ninference of new facts. Identifying logical rules not only improves the\ncompleteness of a knowledge graph but also enables the detection of potential\nerrors, reveals subtle data patterns, and enhances the overall capacity for\nreasoning and interpretation. However, the complexity of such rules, combined\nwith the unique labeling conventions of each KG, can make them difficult for\nhumans to understand. In this paper, we explore the potential of large language\nmodels to generate natural language explanations for logical rules.\nSpecifically, we extract logical rules using the AMIE 3.5.1 rule discovery\nalgorithm from the benchmark dataset FB15k-237 and two large-scale datasets,\nFB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including\nzero- and few-shot prompting, including variable entity types, and\nchain-of-thought reasoning. We conduct a comprehensive human evaluation of the\ngenerated explanations based on correctness, clarity, and hallucination, and\nalso assess the use of large language models as automatic judges. Our results\ndemonstrate promising performance in terms of explanation correctness and\nclarity, although several challenges remain for future research. All scripts\nand data used in this study are publicly available at\nhttps://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.\n","authors":["Nasim Shirvani-Mahdavi","Devin Wingfield","Amin Ghasemi","Chengkai Li"],"pdf_url":"https://arxiv.org/pdf/2507.23740v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23736v1","updated":"2025-07-31T17:19:38Z","published":"2025-07-31T17:19:38Z","title":"DICOM De-Identification via Hybrid AI and Rule-Based Framework for\n  Scalable, Uncertainty-Aware Redaction","summary":"  Access to medical imaging and associated text data has the potential to drive\nmajor advances in healthcare research and patient outcomes. However, the\npresence of Protected Health Information (PHI) and Personally Identifiable\nInformation (PII) in Digital Imaging and Communications in Medicine (DICOM)\nfiles presents a significant barrier to the ethical and secure sharing of\nimaging datasets. This paper presents a hybrid de-identification framework\ndeveloped by Impact Business Information Solutions (IBIS) that combines\nrule-based and AI-driven techniques, and rigorous uncertainty quantification\nfor comprehensive PHI/PII removal from both metadata and pixel data.\n  Our approach begins with a two-tiered rule-based system targeting explicit\nand inferred metadata elements, further augmented by a large language model\n(LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of\nsynthetic datasets simulating realistic clinical PHI/PII. For pixel data, we\nemploy an uncertainty-aware Faster R-CNN model to localize embedded text,\nextract candidate PHI via Optical Character Recognition (OCR), and apply the\nNER pipeline for final redaction. Crucially, uncertainty quantification\nprovides confidence measures for AI-based detections to enhance automation\nreliability and enable informed human-in-the-loop verification to manage\nresidual risks.\n  This uncertainty-aware deidentification framework achieves robust performance\nacross benchmark datasets and regulatory standards, including DICOM, HIPAA, and\nTCIA compliance metrics. By combining scalable automation, uncertainty\nquantification, and rigorous quality assurance, our solution addresses critical\nchallenges in medical data de-identification and supports the secure, ethical,\nand trustworthy release of imaging data for research.\n","authors":["Kyle Naddeo","Nikolas Koutsoubis","Rahul Krish","Ghulam Rasool","Nidhal Bouaynaya","Tony OSullivan","Raj Krish"],"pdf_url":"https://arxiv.org/pdf/2507.23736v1.pdf","comment":"15 pages, 6 figures,"},{"id":"http://arxiv.org/abs/2505.07797v2","updated":"2025-07-31T17:02:05Z","published":"2025-05-12T17:48:28Z","title":"A Theoretical Framework for Explaining Reinforcement Learning with\n  Shapley Values","summary":"  Reinforcement learning agents can achieve super-human performance in complex\ndecision-making tasks, but their behaviour is often difficult to understand and\nexplain. This lack of explanation limits deployment, especially in\nsafety-critical settings where understanding and trust are essential. We\nidentify three core explanatory targets that together provide a comprehensive\nview of reinforcement learning agents: behaviour, outcomes, and predictions. We\ndevelop a unified theoretical framework for explaining these three elements of\nreinforcement learning agents through the influence of individual features that\nthe agent observes in its environment. We derive feature influences by using\nShapley values, which collectively and uniquely satisfy a set of well-motivated\naxioms for fair and consistent credit assignment. The proposed approach,\nShapley Values for Explaining Reinforcement Learning (SVERL), provides a single\ntheoretical framework to comprehensively and meaningfully explain reinforcement\nlearning agents. It yields explanations with precise semantics that are not\nonly interpretable but also mathematically justified, enabling us to identify\nand correct conceptual issues in prior explanations. Through illustrative\nexamples, we show how SVERL produces useful, intuitive explanations of agent\nbehaviour, outcomes, and predictions, which are not apparent from observing\nagent behaviour alone.\n","authors":["Daniel Beechey","Thomas M. S. Smith","Özgür Şimşek"],"pdf_url":"https://arxiv.org/pdf/2505.07797v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.00830v2","updated":"2025-07-31T17:00:35Z","published":"2025-05-01T19:43:12Z","title":"Intersectional Divergence: Measuring Fairness in Regression","summary":"  Fairness in machine learning research is commonly framed in the context of\nclassification tasks, leaving critical gaps in regression. In this paper, we\npropose a novel approach to measure intersectional fairness in regression\ntasks, going beyond the focus on single protected attributes from existing work\nto consider combinations of all protected attributes. Furthermore, we contend\nthat it is insufficient to measure the average error of groups without regard\nfor imbalanced domain preferences. Accordingly, we propose Intersectional\nDivergence (ID) as the first fairness measure for regression tasks that 1)\ndescribes fair model behavior across multiple protected attributes and 2)\ndifferentiates the impact of predictions in target ranges most relevant to\nusers. We extend our proposal demonstrating how ID can be adapted into a loss\nfunction, IDLoss, that satisfies convergence guarantees and has piecewise\nsmooth properties that enable practical optimization. Through an extensive\nexperimental evaluation, we demonstrate how ID allows unique insights into\nmodel behavior and fairness, and how incorporating IDLoss into optimization can\nconsiderably improve single-attribute and intersectional model fairness while\nmaintaining a competitive balance in predictive performance.\n","authors":["Joe Germino","Nuno Moniz","Nitesh V. Chawla"],"pdf_url":"https://arxiv.org/pdf/2505.00830v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22782v2","updated":"2025-07-31T16:47:21Z","published":"2025-07-30T15:48:38Z","title":"Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic\n  Policies","summary":"  This paper introduces Team-Attention-Actor-Critic (TAAC), a reinforcement\nlearning algorithm designed to enhance multi-agent collaboration in cooperative\nenvironments. TAAC employs a Centralized Training/Centralized Execution scheme\nincorporating multi-headed attention mechanisms in both the actor and critic.\nThis design facilitates dynamic, inter-agent communication, allowing agents to\nexplicitly query teammates, thereby efficiently managing the exponential growth\nof joint-action spaces while ensuring a high degree of collaboration. We\nfurther introduce a penalized loss function which promotes diverse yet\ncomplementary roles among agents. We evaluate TAAC in a simulated soccer\nenvironment against benchmark algorithms representing other multi-agent\nparadigms, including Proximal Policy Optimization and Multi-Agent\nActor-Attention-Critic. We find that TAAC exhibits superior performance and\nenhanced collaborative behaviors across a variety of metrics (win rates, goal\ndifferentials, Elo ratings, inter-agent connectivity, balanced spatial\ndistributions, and frequent tactical interactions such as ball possession\nswaps).\n","authors":["Hugo Garrido-Lestache","Jeremy Kedziora"],"pdf_url":"https://arxiv.org/pdf/2507.22782v2.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2408.03351v2","updated":"2025-07-31T16:45:54Z","published":"2024-08-05T22:16:27Z","title":"Quantum Transfer Learning for MNIST Classification Using a Hybrid\n  Quantum-Classical Approach","summary":"  We implement a hybrid quantum-classical model for image classification that\ncompresses MNIST digit images into a low-dimensional feature space and then\nmaps these features onto a 5-qubit quantum state. First, an autoencoder\ncompresses each $28\\times28$ image (784 pixels) into a 64-dimensional latent\nvector, preserving salient features of the digit with minimal reconstruction\nerror. We further reduce the latent representation to 5 principal components\nusing Principal Component Analysis (PCA), to match the 5 available qubits.\nThese 5 features are encoded as rotation angles in a quantum circuit with 5\nqubits. The quantum feature map applies single-qubit rotations ($R_y$ gates)\nproportional to the feature values, followed by a Hadamard gate and a cascade\nof entangling CNOT gates to produce a non-product entangled state. Measuring\nthe 5-qubit state yields a 32-dimensional probability distribution over basis\noutcomes, which serves as a quantum-enhanced feature vector for classification.\nA classical neural network with a softmax output is then trained on these\n32-dimensional quantum feature vectors to predict the digit class. We evaluate\nthe hybrid model on the MNIST dataset and compare it to a purely classical\nbaseline that uses the 64-dimensional autoencoder latent features for\nclassification. The results show that the hybrid model can successfully\nclassify digits, demonstrating the feasibility of integrating quantum computing\nin the classification pipeline, although its accuracy (about 75\\% on test data)\ncurrently falls below the classical baseline (about 98\\% on the same compressed\ndata).\n","authors":["Soumyadip Sarkar"],"pdf_url":"https://arxiv.org/pdf/2408.03351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23712v1","updated":"2025-07-31T16:41:06Z","published":"2025-07-31T16:41:06Z","title":"Anomalous Samples for Few-Shot Anomaly Detection","summary":"  Several anomaly detection and classification methods rely on large amounts of\nnon-anomalous or \"normal\" samples under the assump- tion that anomalous data is\ntypically harder to acquire. This hypothesis becomes questionable in Few-Shot\nsettings, where as little as one anno- tated sample can make a significant\ndifference. In this paper, we tackle the question of utilizing anomalous\nsamples in training a model for bi- nary anomaly classification. We propose a\nmethodology that incorporates anomalous samples in a multi-score anomaly\ndetection score leveraging recent Zero-Shot and memory-based techniques. We\ncompare the utility of anomalous samples to that of regular samples and study\nthe benefits and limitations of each. In addition, we propose an\naugmentation-based validation technique to optimize the aggregation of the\ndifferent anomaly scores and demonstrate its effectiveness on popular\nindustrial anomaly detection datasets.\n","authors":["Aymane Abdali","Bartosz Boguslawski","Lucas Drumetz","Vincent Gripon"],"pdf_url":"https://arxiv.org/pdf/2507.23712v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19095v2","updated":"2025-07-31T16:36:45Z","published":"2025-07-25T09:25:55Z","title":"GCL-GCN: Graphormer and Contrastive Learning Enhanced Attributed Graph\n  Clustering Network","summary":"  Attributed graph clustering holds significant importance in modern data\nanalysis. However, due to the complexity of graph data and the heterogeneity of\nnode attributes, leveraging graph information for clustering remains\nchallenging. To address this, we propose a novel deep graph clustering model,\nGCL-GCN, specifically designed to address the limitations of existing models in\ncapturing local dependencies and complex structures when dealing with sparse\nand heterogeneous graph data. GCL-GCN introduces an innovative Graphormer\nmodule that combines centrality encoding and spatial relationships, effectively\ncapturing both global and local information between nodes, thereby enhancing\nthe quality of node representations. Additionally, we propose a novel\ncontrastive learning module that significantly enhances the discriminative\npower of feature representations. In the pre-training phase, this module\nincreases feature distinction through contrastive learning on the original\nfeature matrix, ensuring more identifiable initial representations for\nsubsequent graph convolution and clustering tasks. Extensive experimental\nresults on six datasets demonstrate that GCL-GCN outperforms 14 advanced\nmethods in terms of clustering quality and robustness. Specifically, on the\nCora dataset, it improves ACC, NMI, and ARI by 4.94%, 13.01%, and 10.97%,\nrespectively, compared to the primary comparison method MBN.\n","authors":["Binxiong Li","Xu Xiang","Xue Li","Quanzhou Lou","Binyu Zhao","Yujie Liu","Huijie Tang","Benhan Yang"],"pdf_url":"https://arxiv.org/pdf/2507.19095v2.pdf","comment":"The source code for this study is available at\n  https://github.com/YF-W/GCL-GCN"},{"id":"http://arxiv.org/abs/2206.03234v3","updated":"2025-07-31T16:34:37Z","published":"2022-06-07T12:26:28Z","title":"Disparate Conditional Prediction in Multiclass Classifiers","summary":"  We propose methods for auditing multiclass classifiers for fairness under\nmulticlass equalized odds,by estimating the deviation from equalized odds when\nthe classifier is not completely fair. We generalize to multiclass classifiers\nthe measure of Disparate Conditional Prediction (DCP), originally suggested by\nSabato & Yom-Tov (2020) for binary classifiers. DCP is defined as the fraction\nof the population for which the classifier predicts with conditional prediction\nprobabilities that differ from the closest common baseline. We provide new\nlocal-optimization methods for estimating the multiclass DCPunder two different\nregimes,one in which the conditional confusion matrices for each protected\nsub-population are known, and one in which these cannot be estimated, for\ninstance, because the classifier is inaccessible or because good-quality\nindividual-level data is not available. These methods can be used to detect\nclassifiers that likely treat a significant fraction of the population\nunfairly. Experiments demonstrate the accuracy of the methods. Code is provided\nat https://github.com/sivansabato/ DCPmulticlass.\n","authors":["Sivan Sabato","Eran Treister","Elad Yom-Tov"],"pdf_url":"https://arxiv.org/pdf/2206.03234v3.pdf","comment":"Published at ICML 2025"},{"id":"http://arxiv.org/abs/2504.10403v3","updated":"2025-07-31T15:59:35Z","published":"2025-04-14T16:52:34Z","title":"Satellite Federated Fine-Tuning for Foundation Models in Space Computing\n  Power Networks","summary":"  Advancements in artificial intelligence (AI) and low-earth orbit (LEO)\nsatellites have promoted the application of large remote sensing foundation\nmodels for various downstream tasks. However, direct downloading of these\nmodels for fine-tuning on the ground is impeded by privacy concerns and limited\nbandwidth. Satellite federated learning (FL) offers a solution by enabling\nmodel fine-tuning directly on-board satellites and aggregating model updates\nwithout data downloading. Nevertheless, for large foundation models, the\ncomputational capacity of satellites is insufficient to support effective\non-board fine-tuning in traditional satellite FL frameworks. To address these\nchallenges, we propose a satellite-ground collaborative federated fine-tuning\nframework. The key of the framework lies in how to reasonably decompose and\nallocate model components to alleviate insufficient on-board computation\ncapabilities. During fine-tuning, satellites exchange intermediate results with\nground stations or other satellites for forward propagation and back\npropagation, which brings communication challenges due to the special\ncommunication topology of space transmission networks, such as intermittent\nsatellite-ground communication, short duration of satellite-ground\ncommunication windows, and unstable inter-orbit inter-satellite links (ISLs).\nTo reduce transmission delays, we further introduce tailored communication\nstrategies that integrate both communication and computing resources.\nSpecifically, we propose a parallel intra-orbit communication strategy, a\ntopology-aware satellite-ground communication strategy, and a\nlatency-minimalization inter-orbit communication strategy to reduce space\ncommunication costs. Simulation results demonstrate significant reductions in\ntraining time with improvements of approximately 33%.\n","authors":["Yan Zhu","Jingyang Zhu","Ting Wang","Yuanming Shi","Chunxiao Jiang","Khaled Ben Letaief"],"pdf_url":"https://arxiv.org/pdf/2504.10403v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23682v1","updated":"2025-07-31T15:57:46Z","published":"2025-07-31T15:57:46Z","title":"villa-X: Enhancing Latent Action Modeling in Vision-Language-Action\n  Models","summary":"  Visual-Language-Action (VLA) models have emerged as a popular paradigm for\nlearning robot manipulation policies that can follow language instructions and\ngeneralize to novel scenarios. Recent work has begun to explore the\nincorporation of latent actions, an abstract representation of visual change\nbetween two frames, into VLA pre-training. In this paper, we introduce villa-X,\na novel Visual-Language-Latent-Action (ViLLA) framework that advances latent\naction modeling for learning generalizable robot manipulation policies. Our\napproach improves both how latent actions are learned and how they are\nincorporated into VLA pre-training. Together, these contributions enable\nvilla-X to achieve superior performance across simulated environments including\nSIMPLER and LIBERO, as well as on two real-world robot setups including gripper\nand dexterous hand manipulation. We believe the ViLLA paradigm holds\nsignificant promise, and that our villa-X provides a strong foundation for\nfuture research.\n","authors":["Xiaoyu Chen","Hangxing Wei","Pushi Zhang","Chuheng Zhang","Kaixin Wang","Yanjiang Guo","Rushuai Yang","Yucen Wang","Xinquan Xiao","Li Zhao","Jianyu Chen","Jiang Bian"],"pdf_url":"https://arxiv.org/pdf/2507.23682v1.pdf","comment":"Project page: https://aka.ms/villa-x"},{"id":"http://arxiv.org/abs/2507.23676v1","updated":"2025-07-31T15:51:41Z","published":"2025-07-31T15:51:41Z","title":"DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for\n  Microbiome Data","summary":"  Microbiome data analysis is essential for understanding host health and\ndisease, yet its inherent sparsity and noise pose major challenges for accurate\nimputation, hindering downstream tasks such as biomarker discovery. Existing\nimputation methods, including recent diffusion-based models, often fail to\ncapture the complex interdependencies between microbial taxa and overlook\ncontextual metadata that can inform imputation. We introduce DepMicroDiff, a\nnovel framework that combines diffusion-based generative modeling with a\nDependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise\ndependencies and autoregressive relationships. DepMicroDiff is further enhanced\nby VAE-based pretraining across diverse cancer datasets and conditioning on\npatient metadata encoded via a large language model (LLM). Experiments on TCGA\nmicrobiome datasets show that DepMicroDiff substantially outperforms\nstate-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),\ncosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer\ntypes, demonstrating its robustness and generalizability for microbiome\nimputation.\n","authors":["Rabeya Tus Sadia","Qiang Cheng"],"pdf_url":"https://arxiv.org/pdf/2507.23676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06946v3","updated":"2025-07-31T15:51:12Z","published":"2024-12-09T19:45:30Z","title":"A Deep Learning Powered Numerical Relativity Surrogate for Binary Black\n  Hole Waveforms","summary":"  Gravitational-wave approximants are essential for gravitational-wave\nastronomy, allowing the coverage binary black hole parameter space for\ninference or match filtering without costly numerical relativity (NR)\nsimulations, but generally trading some accuracy for computational efficiency.\nTo reduce this trade-off, NR surrogate models can be constructed using\ninterpolation within NR waveform space. We present a 2-stage training approach\nfor neural network-based NR surrogate models. Initially trained on\napproximant-generated waveforms and then fine-tuned with NR data, these\ndual-stage artificial neural surrogate (\\texttt{DANSur}) models offer rapid and\ncompetitively accurate waveform generation, generating millions in under 20ms\non a GPU while keeping mean mismatches with NR around $10^{-4}$. Implemented in\nthe \\textsc{bilby} framework, we show they can be used for parameter estimation\ntasks.\n","authors":["Osvaldo Gramaxo Freitas","Anastasios Theodoropoulos","Nino Villanueva","Tiago Fernandes","Solange Nunes","José A. Font","Antonio Onofre","Alejandro Torres-Forné","José D. Martin-Guerrero"],"pdf_url":"https://arxiv.org/pdf/2412.06946v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23675v1","updated":"2025-07-31T15:51:10Z","published":"2025-07-31T15:51:10Z","title":"One-Step Flow Policy Mirror Descent","summary":"  Diffusion policies have achieved great success in online reinforcement\nlearning (RL) due to their strong expressive capacity. However, the inference\nof diffusion policy models relies on a slow iterative sampling process, which\nlimits their responsiveness. To overcome this limitation, we propose Flow\nPolicy Mirror Descent (FPMD), an online RL algorithm that enables 1-step\nsampling during policy inference. Our approach exploits a theoretical\nconnection between the distribution variance and the discretization error of\nsingle-step sampling in straight interpolation flow matching models, and\nrequires no extra distillation or consistency training. We present two\nalgorithm variants based on flow policy and MeanFlow policy parametrizations,\nrespectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate\nthat our algorithms show strong performance comparable to diffusion policy\nbaselines while requiring hundreds of times fewer function evaluations during\ninference.\n","authors":["Tianyi Chen","Haitong Ma","Na Li","Kai Wang","Bo Dai"],"pdf_url":"https://arxiv.org/pdf/2507.23675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23674v1","updated":"2025-07-31T15:50:57Z","published":"2025-07-31T15:50:57Z","title":"TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached\n  Responses","summary":"  Large Language Models (LLMs) process millions of queries daily, making\nefficient response caching a compelling optimization for reducing cost and\nlatency. However, preserving relevance to user queries using this approach\nproves difficult due to the personalized nature of chatbot interactions and the\nlimited accuracy of semantic similarity search. To address this, we present\nTweakLLM, a novel routing architecture that employs a lightweight LLM to\ndynamically adapt cached responses to incoming prompts. Through comprehensive\nevaluation, including user studies with side-by-side comparisons, satisfaction\nvoting, as well as multi-agent LLM debates, we demonstrate that TweakLLM\nmaintains response quality comparable to frontier models while significantly\nimproving cache effectiveness. Our results across real-world datasets highlight\nTweakLLM as a scalable, resource-efficient caching solution for high-volume LLM\ndeployments without compromising user experience.\n","authors":["Muhammad Taha Cheema","Abeer Aamir","Khawaja Gul Muhammad","Naveed Anwar Bhatti","Ihsan Ayyub Qazi","Zafar Ayyub Qazi"],"pdf_url":"https://arxiv.org/pdf/2507.23674v1.pdf","comment":"13 pages, 9 figures"},{"id":"http://arxiv.org/abs/2507.23673v1","updated":"2025-07-31T15:49:57Z","published":"2025-07-31T15:49:57Z","title":"SAMSA: Segment Anything Model Enhanced with Spectral Angles for\n  Hyperspectral Interactive Medical Image Segmentation","summary":"  Hyperspectral imaging (HSI) provides rich spectral information for medical\nimaging, yet encounters significant challenges due to data limitations and\nhardware variations. We introduce SAMSA, a novel interactive segmentation\nframework that combines an RGB foundation model with spectral analysis. SAMSA\nefficiently utilizes user clicks to guide both RGB segmentation and spectral\nsimilarity computations. The method addresses key limitations in HSI\nsegmentation through a unique spectral feature fusion strategy that operates\nindependently of spectral band count and resolution. Performance evaluation on\npublicly available datasets has shown 81.0% 1-click and 93.4% 5-click DICE on a\nneurosurgical and 81.1% 1-click and 89.2% 5-click DICE on an intraoperative\nporcine hyperspectral dataset. Experimental results demonstrate SAMSA's\neffectiveness in few-shot and zero-shot learning scenarios and using minimal\ntraining examples. Our approach enables seamless integration of datasets with\ndifferent spectral characteristics, providing a flexible framework for\nhyperspectral medical image analysis.\n","authors":["Alfie Roddan","Tobias Czempiel","Chi Xu","Daniel S. Elson","Stamatia Giannarou"],"pdf_url":"https://arxiv.org/pdf/2507.23673v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23665v1","updated":"2025-07-31T15:45:38Z","published":"2025-07-31T15:45:38Z","title":"SHAP-Guided Regularization in Machine Learning Models","summary":"  Feature attribution methods such as SHapley Additive exPlanations (SHAP) have\nbecome instrumental in understanding machine learning models, but their role in\nguiding model optimization remains underexplored. In this paper, we propose a\nSHAP-guided regularization framework that incorporates feature importance\nconstraints into model training to enhance both predictive performance and\ninterpretability. Our approach applies entropy-based penalties to encourage\nsparse, concentrated feature attributions while promoting stability across\nsamples. The framework is applicable to both regression and classification\ntasks. Our first exploration started with investigating a tree-based model\nregularization using TreeSHAP. Through extensive experiments on benchmark\nregression and classification datasets, we demonstrate that our method improves\ngeneralization performance while ensuring robust and interpretable feature\nattributions. The proposed technique offers a novel, explainability-driven\nregularization approach, making machine learning models both more accurate and\nmore reliable.\n","authors":["Amal Saadallah"],"pdf_url":"https://arxiv.org/pdf/2507.23665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.15738v4","updated":"2025-07-31T15:42:11Z","published":"2024-07-22T15:41:23Z","title":"Parallel Split Learning with Global Sampling","summary":"  Distributed deep learning in resource-constrained environments faces\nscalability and generalization challenges due to large effective batch sizes\nand non-identically distributed client data. We introduce a server-driven\nsampling strategy that maintains a fixed global batch size by dynamically\nadjusting client-side batch sizes. This decouples the effective batch size from\nthe number of participating devices and ensures that global batches better\nreflect the overall data distribution. Using standard concentration bounds, we\nestablish tighter deviation guarantees compared to existing approaches.\nEmpirical results on a benchmark dataset confirm that the proposed method\nimproves model accuracy, training efficiency, and convergence stability,\noffering a scalable solution for learning at the network edge.\n","authors":["Mohammad Kohankhaki","Ahmad Ayad","Mahdi Barhoush","Anke Schmeink"],"pdf_url":"https://arxiv.org/pdf/2407.15738v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.18102v2","updated":"2025-07-31T15:25:09Z","published":"2025-05-23T16:57:34Z","title":"How Can I Publish My LLM Benchmark Without Giving the True Answers Away?","summary":"  Publishing a large language model (LLM) benchmark on the Internet risks\ncontaminating future LLMs: the benchmark may be unintentionally (or\nintentionally) used to train or select a model. A common mitigation is to keep\nthe benchmark private and let participants submit their models or predictions\nto the organizers. However, this strategy will require trust in a single\norganization and still permits test-set overfitting through repeated queries.\nTo overcome this issue, we propose a way to publish benchmarks without\ncompletely disclosing the ground-truth answers to the questions, while still\nmaintaining the ability to openly evaluate LLMs. Our main idea is to inject\nrandomness to the answers by preparing several logically correct answers, and\nonly include one of them as the solution in the benchmark. This reduces the\nbest possible accuracy, i.e., Bayes accuracy, of the benchmark. Not only is\nthis helpful to keep us from disclosing the ground truth, but this approach\nalso offers a test for detecting data contamination. In principle, even fully\ncapable models should not surpass the Bayes accuracy. If a model surpasses this\nceiling despite this expectation, this is a strong signal of data\ncontamination. We present experimental evidence that our method can detect data\ncontamination accurately on a wide range of benchmarks, models, and training\nmethodologies.\n","authors":["Takashi Ishida","Thanawat Lodkaew","Ikko Yamane"],"pdf_url":"https://arxiv.org/pdf/2505.18102v2.pdf","comment":"Extended version of the paper presented as an Oral at the ICML 2025\n  Workshop on the Impact of Memorization on Trustworthy Foundation Models"},{"id":"http://arxiv.org/abs/2502.17264v2","updated":"2025-07-31T15:15:50Z","published":"2025-02-24T15:46:18Z","title":"Kandinsky Conformal Prediction: Beyond Class- and Covariate-Conditional\n  Coverage","summary":"  Conformal prediction is a powerful distribution-free framework for\nconstructing prediction sets with coverage guarantees. Classical methods, such\nas split conformal prediction, provide marginal coverage, ensuring that the\nprediction set contains the label of a random test point with a target\nprobability. However, these guarantees may not hold uniformly across different\nsubpopulations, leading to disparities in coverage. Prior work has explored\ncoverage guarantees conditioned on events related to the covariates and label\nof the test point. We present Kandinsky conformal prediction, a framework that\nsignificantly expands the scope of conditional coverage guarantees. In contrast\nto Mondrian conformal prediction, which restricts its coverage guarantees to\ndisjoint groups -- reminiscent of the rigid, structured grids of Piet\nMondrian's art -- our framework flexibly handles overlapping and fractional\ngroup memberships defined jointly on covariates and labels, reflecting the\nlayered, intersecting forms in Wassily Kandinsky's compositions. Our algorithm\nunifies and extends existing methods, encompassing covariate-based group\nconditional, class conditional, and Mondrian conformal prediction as special\ncases, while achieving a minimax-optimal high-probability conditional coverage\nbound. Finally, we demonstrate the practicality of our approach through\nempirical evaluation on real-world datasets.\n","authors":["Konstantina Bairaktari","Jiayun Wu","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2502.17264v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23638v1","updated":"2025-07-31T15:14:36Z","published":"2025-07-31T15:14:36Z","title":"OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature\n  Gradient Analysis and Reinforcement Learning-Based Trust Weighting","summary":"  Federated Learning (FL) enables collaborative model training across\ndistributed medical institutions while preserving patient privacy, but remains\nvulnerable to Byzantine attacks and statistical heterogeneity. We present\nOptiGradTrust, a comprehensive defense framework that evaluates gradient\nupdates through a novel six-dimensional fingerprint including VAE\nreconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency\nratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module\nfor adaptive trust scoring. To address convergence challenges under data\nheterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch\nNormalization with proximal regularization for optimal accuracy-convergence\ntrade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI\ndatasets under various Byzantine attack scenarios demonstrates significant\nimprovements over state-of-the-art defenses, achieving up to +1.6 percentage\npoints over FLGuard under non-IID conditions while maintaining robust\nperformance against diverse attack patterns through our adaptive learning\napproach.\n","authors":["Mohammad Karami","Fatemeh Ghassemi","Hamed Kebriaei","Hamid Azadegan"],"pdf_url":"https://arxiv.org/pdf/2507.23638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23632v1","updated":"2025-07-31T15:10:03Z","published":"2025-07-31T15:10:03Z","title":"On the Expressiveness of Softmax Attention: A Recurrent Neural Network\n  Perspective","summary":"  Since its introduction, softmax attention has become the backbone of modern\ntransformer architectures due to its expressiveness and scalability across a\nwide range of tasks. However, the main drawback of softmax attention is the\nquadratic memory requirement and computational complexity with respect to the\nsequence length. By replacing the softmax nonlinearity, linear attention and\nsimilar methods have been introduced to avoid the quadratic bottleneck of\nsoftmax attention. Despite these linear forms of attention being derived from\nthe original softmax formulation, they typically lag in terms of downstream\naccuracy. While strong intuition of the softmax nonlinearity on the query and\nkey inner product suggests that it has desirable properties compared to other\nnonlinearities, the question of why this discrepancy exists still remains\nunanswered. This work demonstrates that linear attention is an approximation of\nsoftmax attention by deriving the recurrent form of softmax attention. Using\nthis form, each part of softmax attention can be described in the language of\nrecurrent neural networks (RNNs). Describing softmax attention as an RNN allows\nfor the ablation of the components of softmax attention to understand the\nimportance of each part and how they interact. In this way, our work helps\nexplain why softmax attention is more expressive than its counterparts.\n","authors":["Gabriel Mongaras","Eric C. Larson"],"pdf_url":"https://arxiv.org/pdf/2507.23632v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22303v2","updated":"2025-07-31T15:08:10Z","published":"2025-07-30T00:27:18Z","title":"CS-SHRED: Enhancing SHRED for Robust Recovery of Spatiotemporal Dynamics","summary":"  We present CS-SHRED, a novel deep learning architecture that integrates\nCompressed Sensing (CS) into a Shallow Recurrent Decoder (SHRED) to reconstruct\nspatiotemporal dynamics from incomplete, compressed, or corrupted data. Our\napproach introduces two key innovations. First, by incorporating CS techniques\ninto the SHRED architecture, our method leverages a batch-based forward\nframework with $\\ell_1$ regularization to robustly recover signals even in\nscenarios with sparse sensor placements, noisy measurements, and incomplete\nsensor acquisitions. Second, an adaptive loss function dynamically combines\nMean Squared Error (MSE) and Mean Absolute Error (MAE) terms with a piecewise\nSignal-to-Noise Ratio (SNR) regularization, which suppresses noise and outliers\nin low-SNR regions while preserving fine-scale features in high-SNR regions.\n  We validate CS-SHRED on challenging problems including viscoelastic fluid\nflows, maximum specific humidity fields, sea surface temperature distributions,\nand rotating turbulent flows. Compared to the traditional SHRED approach,\nCS-SHRED achieves significantly higher reconstruction fidelity -- as\ndemonstrated by improved SSIM and PSNR values, lower normalized errors, and\nenhanced LPIPS scores-thereby providing superior preservation of small-scale\nstructures and increased robustness against noise and outliers.\n  Our results underscore the advantages of the jointly trained CS and SHRED\ndesign architecture which includes an LSTM sequence model for characterizing\nthe temporal evolution with a shallow decoder network (SDN) for modeling the\nhigh-dimensional state space. The SNR-guided adaptive loss function for the\nspatiotemporal data recovery establishes CS-SHRED as a promising tool for a\nwide range of applications in environmental, climatic, and scientific data\nanalyses.\n","authors":["Romulo B. da Silva","Diego Passos","Cássio M. Oishi","J. Nathan Kutz"],"pdf_url":"https://arxiv.org/pdf/2507.22303v2.pdf","comment":"30 pages, 7 figures, 13 tables. Code:\n  https://github.com/romulobrito/cs-shred"},{"id":"http://arxiv.org/abs/2507.23620v1","updated":"2025-07-31T15:00:15Z","published":"2025-07-31T15:00:15Z","title":"DivControl: Knowledge Diversion for Controllable Image Generation","summary":"  Diffusion models have advanced from text-to-image (T2I) to image-to-image\n(I2I) generation by incorporating structured inputs such as depth maps,\nenabling fine-grained spatial control. However, existing methods either train\nseparate models for each condition or rely on unified architectures with\nentangled representations, resulting in poor generalization and high adaptation\ncosts for novel conditions. To this end, we propose DivControl, a decomposable\npretraining framework for unified controllable generation and efficient\nadaptation. DivControl factorizes ControlNet via SVD into basic\ncomponents-pairs of singular vectors-which are disentangled into\ncondition-agnostic learngenes and condition-specific tailors through knowledge\ndiversion during multi-condition training. Knowledge diversion is implemented\nvia a dynamic gate that performs soft routing over tailors based on the\nsemantics of condition instructions, enabling zero-shot generalization and\nparameter-efficient adaptation to novel conditions. To further improve\ncondition fidelity and training efficiency, we introduce a representation\nalignment loss that aligns condition embeddings with early diffusion features.\nExtensive experiments demonstrate that DivControl achieves state-of-the-art\ncontrollability with 36.4$\\times$ less training cost, while simultaneously\nimproving average performance on basic conditions. It also delivers strong\nzero-shot and few-shot performance on unseen conditions, demonstrating superior\nscalability, modularity, and transferability.\n","authors":["Yucheng Xie","Fu Feng","Ruixiao Shi","Jing Wang","Yong Rui","Xin Geng"],"pdf_url":"https://arxiv.org/pdf/2507.23620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23615v1","updated":"2025-07-31T14:53:35Z","published":"2025-07-31T14:53:35Z","title":"L-GTA: Latent Generative Modeling for Time Series Augmentation","summary":"  Data augmentation is gaining importance across various aspects of time series\nanalysis, from forecasting to classification and anomaly detection tasks. We\nintroduce the Latent Generative Transformer Augmentation (L-GTA) model, a\ngenerative approach using a transformer-based variational recurrent\nautoencoder. This model uses controlled transformations within the latent space\nof the model to generate new time series that preserve the intrinsic properties\nof the original dataset. L-GTA enables the application of diverse\ntransformations, ranging from simple jittering to magnitude warping, and\ncombining these basic transformations to generate more complex synthetic time\nseries datasets. Our evaluation of several real-world datasets demonstrates the\nability of L-GTA to produce more reliable, consistent, and controllable\naugmented data. This translates into significant improvements in predictive\naccuracy and similarity measures compared to direct transformation methods.\n","authors":["Luis Roque","Carlos Soares","Vitor Cerqueira","Luis Torgo"],"pdf_url":"https://arxiv.org/pdf/2507.23615v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12098v2","updated":"2025-07-31T14:50:20Z","published":"2024-12-16T18:59:53Z","title":"MaxInfoRL: Boosting exploration in reinforcement learning through\n  information gain maximization","summary":"  Reinforcement learning (RL) algorithms aim to balance exploiting the current\nbest strategy with exploring new options that could lead to higher rewards.\nMost common RL algorithms use undirected exploration, i.e., select random\nsequences of actions. Exploration can also be directed using intrinsic rewards,\nsuch as curiosity or model epistemic uncertainty. However, effectively\nbalancing task and intrinsic rewards is challenging and often task-dependent.\nIn this work, we introduce a framework, MaxInfoRL, for balancing intrinsic and\nextrinsic exploration. MaxInfoRL steers exploration towards informative\ntransitions, by maximizing intrinsic rewards such as the information gain about\nthe underlying task. When combined with Boltzmann exploration, this approach\nnaturally trades off maximization of the value function with that of the\nentropy over states, rewards, and actions. We show that our approach achieves\nsublinear regret in the simplified setting of multi-armed bandits. We then\napply this general formulation to a variety of off-policy model-free RL methods\nfor continuous state-action spaces, yielding novel algorithms that achieve\nsuperior performance across hard exploration problems and complex scenarios\nsuch as visual control tasks.\n","authors":["Bhavya Sukhija","Stelian Coros","Andreas Krause","Pieter Abbeel","Carmelo Sferrazza"],"pdf_url":"https://arxiv.org/pdf/2412.12098v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23609v1","updated":"2025-07-31T14:47:40Z","published":"2025-07-31T14:47:40Z","title":"Consistent Point Matching","summary":"  This study demonstrates that incorporating a consistency heuristic into the\npoint-matching algorithm \\cite{yerebakan2023hierarchical} improves robustness\nin matching anatomical locations across pairs of medical images. We validated\nour approach on diverse longitudinal internal and public datasets spanning CT\nand MRI modalities. Notably, it surpasses state-of-the-art results on the Deep\nLesion Tracking dataset. Additionally, we show that the method effectively\naddresses landmark localization. The algorithm operates efficiently on standard\nCPU hardware and allows configurable trade-offs between speed and robustness.\nThe method enables high-precision navigation between medical images without\nrequiring a machine learning model or training data.\n","authors":["Halid Ziya Yerebakan","Gerardo Hermosillo Valadez"],"pdf_url":"https://arxiv.org/pdf/2507.23609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23607v1","updated":"2025-07-31T14:47:16Z","published":"2025-07-31T14:47:16Z","title":"Deep Learning-based Prediction of Clinical Trial Enrollment with\n  Uncertainty Estimates","summary":"  Clinical trials are a systematic endeavor to assess the safety and efficacy\nof new drugs or treatments. Conducting such trials typically demands\nsignificant financial investment and meticulous planning, highlighting the need\nfor accurate predictions of trial outcomes. Accurately predicting patient\nenrollment, a key factor in trial success, is one of the primary challenges\nduring the planning phase. In this work, we propose a novel deep learning-based\nmethod to address this critical challenge. Our method, implemented as a neural\nnetwork model, leverages pre-trained language models (PLMs) to capture the\ncomplexities and nuances of clinical documents, transforming them into\nexpressive representations. These representations are then combined with\nencoded tabular features via an attention mechanism. To account for\nuncertainties in enrollment prediction, we enhance the model with a\nprobabilistic layer based on the Gamma distribution, which enables range\nestimation. We apply the proposed model to predict clinical trial duration,\nassuming site-level enrollment follows a Poisson-Gamma process. We carry out\nextensive experiments on real-world clinical trial data, and show that the\nproposed method can effectively predict the number of patients enrolled at a\nnumber of sites for a given clinical trial, outperforming established baseline\nmodels.\n","authors":["Tien Huu Do","Antoine Masquelier","Nae Eoun Lee","Jonathan Crowther"],"pdf_url":"https://arxiv.org/pdf/2507.23607v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23604v1","updated":"2025-07-31T14:42:12Z","published":"2025-07-31T14:42:12Z","title":"Hierarchical Message-Passing Policies for Multi-Agent Reinforcement\n  Learning","summary":"  Decentralized Multi-Agent Reinforcement Learning (MARL) methods allow for\nlearning scalable multi-agent policies, but suffer from partial observability\nand induced non-stationarity. These challenges can be addressed by introducing\nmechanisms that facilitate coordination and high-level planning. Specifically,\ncoordination and temporal abstraction can be achieved through communication\n(e.g., message passing) and Hierarchical Reinforcement Learning (HRL)\napproaches to decision-making. However, optimization issues limit the\napplicability of hierarchical policies to multi-agent systems. As such, the\ncombination of these approaches has not been fully explored. To fill this void,\nwe propose a novel and effective methodology for learning multi-agent\nhierarchies of message-passing policies. We adopt the feudal HRL framework and\nrely on a hierarchical graph structure for planning and coordination among\nagents. Agents at lower levels in the hierarchy receive goals from the upper\nlevels and exchange messages with neighboring agents at the same level. To\nlearn hierarchical multi-agent policies, we design a novel reward-assignment\nmethod based on training the lower-level policies to maximize the advantage\nfunction associated with the upper levels. Results on relevant benchmarks show\nthat our method performs favorably compared to the state of the art.\n","authors":["Tommaso Marzi","Cesare Alippi","Andrea Cini"],"pdf_url":"https://arxiv.org/pdf/2507.23604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23600v1","updated":"2025-07-31T14:40:33Z","published":"2025-07-31T14:40:33Z","title":"EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and\n  Multivariate Curve Resolution","summary":"  Signal unmixing analysis decomposes data into basic patterns and is widely\napplied in chemical and biological research. Multivariate curve resolution\n(MCR), a branch of signal unmixing, separates mixed chemical signals into base\npatterns (components) and their concentrations, playing a key role in\nunderstanding composition. Classical MCR is typically framed as matrix\nfactorization (MF) and requires a user-specified component count, usually\nunknown in real data. As dataset size or component count increases, the\nscalability and reliability of MF-based MCR face significant challenges. This\nstudy reformulates MCR as a generative process (gMCR), and introduces an\nenergy-based deep learning solver, EB-gMCR, that automatically discovers the\nsmallest component set able to reconstruct the data faithfully. EB-gMCR starts\nfrom a large candidate pool (e.g., 1024 spectra) and employs a differentiable\ngating network to retain only active components while estimating their\nconcentrations. On noisy synthetic datasets containing up to 256 latent\nsources, EB-gMCR maintained R^2 >= 0.98 and recovered the component count\nwithin 5% of the ground truth; at lower noise it achieved R^2 >= 0.99 with near\nexact component estimation. Additional chemical priors, such as non-negativity\nor nonlinear mixing, enter as simple plug-in functions, enabling adaptation to\nother instruments or domains without altering the core learning process. By\nuniting high-capacity generative modeling and hard component selection, EB-gMCR\noffers a practical route to large-scale signal unmixing analysis, including\nchemical library-driven scenarios. The source code is available at\nhttps://github.com/b05611038/ebgmcr_solver.\n","authors":["Yu-Tang Chang","Shih-Fang Chen"],"pdf_url":"https://arxiv.org/pdf/2507.23600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.01430v3","updated":"2025-07-31T14:26:12Z","published":"2023-04-04T00:26:13Z","title":"Divided Attention: Unsupervised Multi-Object Discovery with Contextually\n  Separated Slots","summary":"  We investigate the emergence of objects in visual perception in the absence\nof any semantic annotation. The resulting model has received no supervision,\ndoes not use any pre-trained features, and yet it can segment the domain of an\nimage into multiple independently moving regions. The resulting motion\nsegmentation method can handle an unknown and varying number of objects in\nreal-time. The core multi-modal conditional encoder-decoder architecture has\none modality (optical flow) feed the encoder to produce a collection of latent\ncodes (slots), and the other modality (color image) conditions the decoder to\ngenerate the first modality (flow) from the slots. The training criterion is\ndesigned to foster 'information separation' among the slots, while the\narchitecture explicitly allocates activations to individual slots, leading to a\nmethod we call Divided Attention (DivA). At test time, DivA handles a different\nnumber of objects and different image resolution than seen at training, and is\ninvariant to permutations of the slots. DivA achieves state-of-the-art\nperformance while tripling the runtime speed of comparable methods, up to 104\nFPS, and reduces the performance gap from supervised methods to 12% or less.\nObjects bootstrapped by DivA can then be used to prime static classifiers via\ncontrastive learning. On fewer than 5,000 video clips, training DINO on DivA's\nobject proposals narrows the performance gap to ImageNet-based training by up\nto 30.2% compared to training directly on the video frames.\n","authors":["Dong Lao","Zhengyang Hu","Francesco Locatello","Yanchao Yang","Stefano Soatto"],"pdf_url":"https://arxiv.org/pdf/2304.01430v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.06275v2","updated":"2025-07-31T14:24:03Z","published":"2025-05-06T16:16:42Z","title":"SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like\n  Optical Spectrograms","summary":"  Wave-like images-from attosecond streaking spectrograms to optical spectra,\naudio mel-spectrograms and periodic video frames-encode critical harmonic\nstructures that elude conventional feature extractors. We propose a unified,\nmatrix-equivalent framework that reinterprets convolution and attention as\nlinear transforms on flattened inputs, revealing filter weights as basis\nvectors spanning latent feature subspaces. To infuse spectral priors we apply\nelementwise $\\sin(\\cdot)$ mappings to each weight matrix. Embedding these\ntransforms into CNN, ViT and Capsule architectures yields Sin-Basis Networks\nwith heightened sensitivity to periodic motifs and built-in invariance to\nspatial shifts. Experiments on a diverse collection of wave-like image\ndatasets-including 80,000 synthetic attosecond streaking spectrograms,\nthousands of Raman, photoluminescence and FTIR spectra, mel-spectrograms from\nAudioSet and cycle-pattern frames from Kinetics-demonstrate substantial gains\nin reconstruction accuracy, translational robustness and zero-shot cross-domain\ntransfer. Theoretical analysis via matrix isomorphism and Mercer-kernel\ntruncation quantifies how sinusoidal reparametrization enriches expressivity\nwhile preserving stability in data-scarce regimes. Sin-Basis Networks thus\noffer a lightweight, physics-informed approach to deep learning across all\nwave-form imaging modalities.\n","authors":["Yuzhou Zhu","Zheng Zhang","Ruyi Zhang","Liang Zhou"],"pdf_url":"https://arxiv.org/pdf/2505.06275v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19219v2","updated":"2025-07-31T14:16:44Z","published":"2025-05-25T16:28:06Z","title":"Where Paths Collide: A Comprehensive Survey of Classic and\n  Learning-Based Multi-Agent Pathfinding","summary":"  Multi-Agent Path Finding (MAPF) is a fundamental problem in artificial\nintelligence and robotics, requiring the computation of collision-free paths\nfor multiple agents navigating from their start locations to designated goals.\nAs autonomous systems become increasingly prevalent in warehouses, urban\ntransportation, and other complex environments, MAPF has evolved from a\ntheoretical challenge to a critical enabler of real-world multi-robot\ncoordination. This comprehensive survey bridges the long-standing divide\nbetween classical algorithmic approaches and emerging learning-based methods in\nMAPF research. We present a unified framework that encompasses search-based\nmethods (including Conflict-Based Search, Priority-Based Search, and Large\nNeighborhood Search), compilation-based approaches (SAT, SMT, CSP, ASP, and MIP\nformulations), and data-driven techniques (reinforcement learning, supervised\nlearning, and hybrid strategies). Through systematic analysis of experimental\npractices across 200+ papers, we uncover significant disparities in evaluation\nmethodologies, with classical methods typically tested on larger-scale\ninstances (up to 200 by 200 grids with 1000+ agents) compared to learning-based\napproaches (predominantly 10-100 agents). We provide a comprehensive taxonomy\nof evaluation metrics, environment types, and baseline selections, highlighting\nthe need for standardized benchmarking protocols. Finally, we outline promising\nfuture directions including mixed-motive MAPF with game-theoretic\nconsiderations, language-grounded planning with large language models, and\nneural solver architectures that combine the rigor of classical methods with\nthe flexibility of deep learning. This survey serves as both a comprehensive\nreference for researchers and a practical guide for deploying MAPF solutions in\nincreasingly complex real-world applications.\n","authors":["Shiyue Wang","Haozheng Xu","Yuhan Zhang","Jingran Lin","Changhong Lu","Xiangfeng Wang","Wenhao Li"],"pdf_url":"https://arxiv.org/pdf/2505.19219v2.pdf","comment":"112 pages, 21 figures, 20 tables. The project website is:\n  https://wangsh1yue.github.io/Where-Paths-Collide"},{"id":"http://arxiv.org/abs/2507.23581v1","updated":"2025-07-31T14:11:16Z","published":"2025-07-31T14:11:16Z","title":"GraphRAG-R1: Graph Retrieval-Augmented Generation with\n  Process-Constrained Reinforcement Learning","summary":"  Graph Retrieval-Augmented Generation (GraphRAG) has shown great effectiveness\nin enhancing the reasoning abilities of LLMs by leveraging graph structures for\nknowledge representation and modeling complex real-world relationships.\nHowever, existing GraphRAG methods still face significant bottlenecks when\nhandling complex problems that require multi-hop reasoning, as their query and\nretrieval phases are largely based on pre-defined heuristics and do not fully\nutilize the reasoning potentials of LLMs. To address this problem, we propose\nGraphRAG-R1, an adaptive GraphRAG framework by training LLMs with\nprocess-constrained outcome-based reinforcement learning (RL) to enhance the\nmulti-hop reasoning ability. Our method can decompose complex problems,\nautonomously invoke retrieval tools to acquire necessary information, and\nperform effective reasoning. Specifically, we utilize a modified version of\nGroup Relative Policy Optimization (GRPO) that supports rollout-with-thinking\ncapability. Next, we design two process-constrained reward functions. To handle\nthe shallow retrieval problem, we design a Progressive Retrieval Attenuation\n(PRA) reward to encourage essential retrievals. Then, to handle the\nover-thinking problem, we design Cost-Aware F1 (CAF) reward to balance the\nmodel performance with computational costs. We further design a phase-dependent\ntraining strategy, containing three training stages corresponding to cold start\nand these two rewards. Lastly, our method adopts a hybrid graph-textual\nretrieval to improve the reasoning capacity. Extensive experimental results\ndemonstrate that GraphRAG-R1 boosts LLM capabilities in solving complex\nreasoning problems compared to state-of-the-art GraphRAG methods on both\nin-domain and out-of-domain datasets. Furthermore, our framework can be\nflexibly integrated with various existing retrieval methods, consistently\ndelivering performance improvements.\n","authors":["Chuanyue Yu","Kuo Zhao","Yuhan Li","Heng Chang","Mingjian Feng","Xiangzhe Jiang","Yufei Sun","Jia Li","Yuzhi Zhang","Jianxin Li","Ziwei Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.23581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02744v3","updated":"2025-07-31T14:02:13Z","published":"2024-10-03T17:55:17Z","title":"Neutral Residues: Revisiting Adapters for Model Extension","summary":"  We address the problem of extending a pretrained large language model to a\nnew domain that was not seen during training. Standard techniques, such as\nfinetuning or low-rank adaptation (LoRA) are successful at domain adaptation,\nbut do not formally add capacity to the model. This often leads to a trade-off,\nbetween performing well on the new domain vs. degrading performance on the\noriginal domain. Here, we revisit and improve adapters to extend LLMs from\nthree angles: data, architecture and training procedure, which are\nadvantageously considered jointly. The resulting method, called neutral\nresidues, modifies adapters in a way that leads each new residual block to\noutput near-zeros on the original domain. This solution leads to strong results\nwhen adapting a state-of-the-art model originally trained on English to a new\nlanguage. Neutral residues significantly outperform competing approaches such\nas finetuning, LoRA or vanilla adapters in terms of the trade-off between\nlearning the new language and not forgetting English.\n","authors":["Franck Signe Talla","Edouard Grave","Hervé Jégou"],"pdf_url":"https://arxiv.org/pdf/2410.02744v3.pdf","comment":"Accepted at ICML 2025"},{"id":"http://arxiv.org/abs/2507.23568v1","updated":"2025-07-31T13:57:38Z","published":"2025-07-31T13:57:38Z","title":"Optimised Feature Subset Selection via Simulated Annealing","summary":"  We introduce SA-FDR, a novel algorithm for $\\ell_0$-norm feature selection\nthat considers this task as a combinatorial optimisation problem and solves it\nby using simulated annealing to perform a global search over the space of\nfeature subsets. The optimisation is guided by the Fisher discriminant ratio,\nwhich we use as a computationally efficient proxy for model quality in\nclassification tasks. Our experiments, conducted on datasets with up to\nhundreds of thousands of samples and hundreds of features, demonstrate that\nSA-FDR consistently selects more compact feature subsets while achieving a high\npredictive accuracy. This ability to recover informative yet minimal sets of\nfeatures stems from its capacity to capture inter-feature dependencies often\nmissed by greedy optimisation approaches. As a result, SA-FDR provides a\nflexible and effective solution for designing interpretable models in\nhigh-dimensional settings, particularly when model sparsity, interpretability,\nand performance are crucial.\n","authors":["Fernando Martínez-García","Álvaro Rubio-García","Samuel Fernández-Lorenzo","Juan José García-Ripoll","Diego Porras"],"pdf_url":"https://arxiv.org/pdf/2507.23568v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2404.09363v2","updated":"2025-07-31T13:56:02Z","published":"2024-04-14T21:30:00Z","title":"Momentum-based gradient descent methods for Lie groups","summary":"  Polyak's Heavy Ball (PHB; Polyak, 1964), a.k.a. Classical Momentum, and\nNesterov's Accelerated Gradient (NAG; Nesterov, 1983) are well-established\nmomentum-descent methods for optimization. Although the latter generally\noutperforms the former, primarily, generalizations of PHB-like methods to\nnonlinear spaces have not been sufficiently explored in the literature. In this\npaper, we propose a generalization of NAG-like methods for Lie group\noptimization. This generalization is based on the variational one-to-one\ncorrespondence between classical and accelerated momentum methods (Campos et\nal., 2023). We provide numerical experiments for chosen retractions on the\ngroup of rotations based on the Frobenius norm and the Rosenbrock function to\ndemonstrate the effectiveness of our proposed methods, and that align with\nresults of the Euclidean case, that is, a faster convergence rate for NAG.\n","authors":["Cédric M. Campos","David Martín de Diego","José Torrente"],"pdf_url":"https://arxiv.org/pdf/2404.09363v2.pdf","comment":"22 pages, 2 algorithms, 6 figures"},{"id":"http://arxiv.org/abs/2312.14057v4","updated":"2025-07-31T13:54:58Z","published":"2023-12-21T17:34:18Z","title":"Weighted least-squares approximation with determinantal point processes\n  and generalized volume sampling","summary":"  We consider the problem of approximating a function from $L^2$ by an element\nof a given $m$-dimensional space $V_m$, associated with some feature map\n$\\boldsymbol{\\varphi}$, using evaluations of the function at random points\n$x_1, \\dots,x_n$. After recalling some results on optimal weighted\nleast-squares using independent and identically distributed points, we consider\nweighted least-squares using projection determinantal point processes (DPP) or\nvolume sampling. These distributions introduce dependence between the points\nthat promotes diversity in the selected features $\\boldsymbol{\\varphi}(x_i)$.\nWe first provide a generalized version of volume-rescaled sampling yielding\nquasi-optimality results in expectation with a number of samples $n =\nO(m\\log(m))$, that means that the expected $L^2$ error is bounded by a constant\ntimes the best approximation error in $L^2$. Also, further assuming that the\nfunction is in some normed vector space $H$ continuously embedded in $L^2$, we\nfurther prove that the approximation error in $L^2$ is almost surely bounded by\nthe best approximation error measured in the $H$-norm. This includes the cases\nof functions from $L^\\infty$ or reproducing kernel Hilbert spaces. Finally, we\npresent an alternative strategy consisting in using independent repetitions of\nprojection DPP (or volume sampling), yielding similar error bounds as with\ni.i.d. or volume sampling, but in practice with a much lower number of samples.\nNumerical experiments illustrate the performance of the different strategies.\n","authors":["Anthony Nouy","Bertrand Michel"],"pdf_url":"https://arxiv.org/pdf/2312.14057v4.pdf","comment":"Compared with the first version, conjectures (13) on DPP and (16) on\n  volume sampling have been modified, including a convexity requirement. Proofs\n  of propositions 5.4 and 5.13 have been modified accordingly. Remarks 5.5 and\n  5.6 have been added to discuss alternatives to conjecture (13) on DPP"},{"id":"http://arxiv.org/abs/2402.03158v2","updated":"2025-07-31T13:53:50Z","published":"2024-02-05T16:27:59Z","title":"Optimal and Near-Optimal Adaptive Vector Quantization","summary":"  Quantization is a fundamental optimization for many machine-learning use\ncases, including compressing gradients, model weights and activations, and\ndatasets. The most accurate form of quantization is \\emph{adaptive}, where the\nerror is minimized with respect to a given input, rather than optimizing for\nthe worst case. However, optimal adaptive quantization methods are considered\ninfeasible in terms of both their runtime and memory requirements.\n  We revisit the Adaptive Vector Quantization (AVQ) problem and present\nalgorithms that find optimal solutions with asymptotically improved time and\nspace complexity. We also present an even faster near-optimal algorithm for\nlarge inputs. Our experiments show our algorithms may open the door to using\nAVQ more extensively in a variety of machine learning applications.\n","authors":["Ran Ben-Basat","Yaniv Ben-Itzhak","Michael Mitzenmacher","Shay Vargaftik"],"pdf_url":"https://arxiv.org/pdf/2402.03158v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23562v1","updated":"2025-07-31T13:49:44Z","published":"2025-07-31T13:49:44Z","title":"Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2\n  Neuromorphic Platform","summary":"  Spiking Neural Networks (SNNs) promise orders-of-magnitude lower power\nconsumption and low-latency inference on neuromorphic hardware for a wide range\nof robotic tasks. In this work, we present an energy-efficient implementation\nof a reinforcement learning (RL) algorithm using quantized SNNs to solve two\nclassical control tasks. The network is trained using the Q-learning algorithm,\nthen fine-tuned and quantized to low-bit (8-bit) precision for embedded\ndeployment on the SpiNNaker2 neuromorphic chip. To evaluate the comparative\nadvantage of SpiNNaker2 over conventional computing platforms, we analyze\ninference latency, dynamic power consumption, and energy cost per inference for\nour SNN models, comparing performance against a GTX 1650 GPU baseline. Our\nresults demonstrate SpiNNaker2's strong potential for scalable, low-energy\nneuromorphic computing, achieving up to 32x reduction in energy consumption.\nInference latency remains on par with GPU-based execution, with improvements\nobserved in certain task settings, reinforcing SpiNNaker2's viability for\nreal-time neuromorphic control and making the neuromorphic approach a\ncompelling direction for efficient deep Q-learning.\n","authors":["Sirine Arfa","Bernhard Vogginger","Christian Mayr"],"pdf_url":"https://arxiv.org/pdf/2507.23562v1.pdf","comment":"8 pages, 5 figures, 3 tables"},{"id":"http://arxiv.org/abs/2412.04502v2","updated":"2025-07-31T13:39:20Z","published":"2024-12-02T15:37:37Z","title":"Physics-informed Gaussian Processes as Linear Model Predictive\n  Controller","summary":"  We introduce a novel algorithm for controlling linear time invariant systems\nin a tracking problem. The controller is based on a Gaussian Process (GP) whose\nrealizations satisfy a system of linear ordinary differential equations with\nconstant coefficients. Control inputs for tracking are determined by\nconditioning the prior GP on the setpoints, i.e. control as inference. The\nresulting Model Predictive Control scheme incorporates pointwise soft\nconstraints by introducing virtual setpoints to the posterior Gaussian process.\nWe show theoretically that our controller satisfies open-loop stability for the\noptimal control problem by leveraging general results from Bayesian inference\nand demonstrate this result in a numerical example.\n","authors":["Jörn Tebbe","Andreas Besginow","Markus Lange-Hegermann"],"pdf_url":"https://arxiv.org/pdf/2412.04502v2.pdf","comment":"Accepted at L4DC 2025"},{"id":"http://arxiv.org/abs/2507.23756v1","updated":"2025-07-31T17:41:30Z","published":"2025-07-31T17:41:30Z","title":"Improving annotator selection in Active Learning using a mood and\n  fatigue-aware Recommender System","summary":"  This study centers on overcoming the challenge of selecting the best\nannotators for each query in Active Learning (AL), with the objective of\nminimizing misclassifications. AL recognizes the challenges related to cost and\ntime when acquiring labeled data, and decreases the number of labeled data\nneeded. Nevertheless, there is still the necessity to reduce annotation errors,\naiming to be as efficient as possible, to achieve the expected accuracy faster.\nMost strategies for query-annotator pairs do not consider internal factors that\naffect productivity, such as mood, attention, motivation, and fatigue levels.\nThis work addresses this gap in the existing literature, by not only\nconsidering how the internal factors influence annotators (mood and fatigue\nlevels) but also presenting a new query-annotator pair strategy, using a\nKnowledge-Based Recommendation System (RS). The RS ranks the available\nannotators, allowing to choose one or more to label the queried instance using\ntheir past accuracy values, and their mood and fatigue levels, as well as\ninformation about the instance queried. This work bases itself on existing\nliterature on mood and fatigue influence on human performance, simulating\nannotators in a realistic manner, and predicting their performance with the RS.\nThe results show that considering past accuracy values, as well as mood and\nfatigue levels reduces the number of annotation errors made by the annotators,\nand the uncertainty of the model through its training, when compared to not\nusing internal factors. Accuracy and F1-score values were also better in the\nproposed approach, despite not being as substantial as the aforementioned. The\nmethodologies and findings presented in this study begin to explore the open\nchallenge of human cognitive factors affecting AL.\n","authors":["Diana Mortagua"],"pdf_url":"https://arxiv.org/pdf/2507.23756v1.pdf","comment":"Master's thesis"}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2507.23768v1","updated":"2025-07-31T17:55:16Z","published":"2025-07-31T17:55:16Z","title":"Formal Bayesian Transfer Learning via the Total Risk Prior","summary":"  In analyses with severe data-limitations, augmenting the target dataset with\ninformation from ancillary datasets in the application domain, called source\ndatasets, can lead to significantly improved statistical procedures. However,\nexisting methods for this transfer learning struggle to deal with situations\nwhere the source datasets are also limited and not guaranteed to be\nwell-aligned with the target dataset. A typical strategy is to use the\nempirical loss minimizer on the source data as a prior mean for the target\nparameters, which places the estimation of source parameters outside of the\nBayesian formalism. Our key conceptual contribution is to use a risk minimizer\nconditional on source parameters instead. This allows us to construct a single\njoint prior distribution for all parameters from the source datasets as well as\nthe target dataset. As a consequence, we benefit from full Bayesian uncertainty\nquantification and can perform model averaging via Gibbs sampling over\nindicator variables governing the inclusion of each source dataset. We show how\na particular instantiation of our prior leads to a Bayesian Lasso in a\ntransformed coordinate system and discuss computational techniques to scale our\napproach to moderately sized datasets. We also demonstrate that recently\nproposed minimax-frequentist transfer learning techniques may be viewed as an\napproximate Maximum a Posteriori approach to our model. Finally, we demonstrate\nsuperior predictive performance relative to the frequentist baseline on a\ngenetics application, especially when the source data are limited.\n","authors":["Nathan Wycoff","Ali Arab","Lisa O. Singh"],"pdf_url":"https://arxiv.org/pdf/2507.23768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23767v1","updated":"2025-07-31T17:55:07Z","published":"2025-07-31T17:55:07Z","title":"Scaled Beta Models and Feature Dilution for Dynamic Ticket Pricing","summary":"  A novel approach is presented for identifying distinct signatures of\nperforming acts in the secondary ticket resale market by analyzing dynamic\npricing distributions. Using a newly curated, time series dataset from the\nSeatGeek API, we model ticket pricing distributions as scaled Beta\ndistributions. This enables accurate parameter estimation from incomplete\nstatistical data using a hybrid of quantile matching and the method of moments.\nIncorporating the estimated $\\alpha$ and $\\beta$ parameters into Random Forest\nclassifiers significantly improves pairwise artist classification accuracy,\ndemonstrating the unique economic signatures in event pricing data.\nAdditionally, we provide theoretical and empirical evidence that incorporating\nzero-variance (constant-value) features into Random Forest models acts as an\nimplicit regularizer, enhancing feature variety and robustness. This\nregularization promotes deeper, more varied trees in the ensemble, improving\nthe bias-variance tradeoff and mitigating overfitting to dominant features.\nThese findings are validated on both the new ticket pricing dataset and the\nstandard UCI ML handwritten digits dataset.\n","authors":["Jonathan R. Landers"],"pdf_url":"https://arxiv.org/pdf/2507.23767v1.pdf","comment":"27 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2507.23736v1","updated":"2025-07-31T17:19:38Z","published":"2025-07-31T17:19:38Z","title":"DICOM De-Identification via Hybrid AI and Rule-Based Framework for\n  Scalable, Uncertainty-Aware Redaction","summary":"  Access to medical imaging and associated text data has the potential to drive\nmajor advances in healthcare research and patient outcomes. However, the\npresence of Protected Health Information (PHI) and Personally Identifiable\nInformation (PII) in Digital Imaging and Communications in Medicine (DICOM)\nfiles presents a significant barrier to the ethical and secure sharing of\nimaging datasets. This paper presents a hybrid de-identification framework\ndeveloped by Impact Business Information Solutions (IBIS) that combines\nrule-based and AI-driven techniques, and rigorous uncertainty quantification\nfor comprehensive PHI/PII removal from both metadata and pixel data.\n  Our approach begins with a two-tiered rule-based system targeting explicit\nand inferred metadata elements, further augmented by a large language model\n(LLM) fine-tuned for Named Entity Recognition (NER), and trained on a suite of\nsynthetic datasets simulating realistic clinical PHI/PII. For pixel data, we\nemploy an uncertainty-aware Faster R-CNN model to localize embedded text,\nextract candidate PHI via Optical Character Recognition (OCR), and apply the\nNER pipeline for final redaction. Crucially, uncertainty quantification\nprovides confidence measures for AI-based detections to enhance automation\nreliability and enable informed human-in-the-loop verification to manage\nresidual risks.\n  This uncertainty-aware deidentification framework achieves robust performance\nacross benchmark datasets and regulatory standards, including DICOM, HIPAA, and\nTCIA compliance metrics. By combining scalable automation, uncertainty\nquantification, and rigorous quality assurance, our solution addresses critical\nchallenges in medical data de-identification and supports the secure, ethical,\nand trustworthy release of imaging data for research.\n","authors":["Kyle Naddeo","Nikolas Koutsoubis","Rahul Krish","Ghulam Rasool","Nidhal Bouaynaya","Tony OSullivan","Raj Krish"],"pdf_url":"https://arxiv.org/pdf/2507.23736v1.pdf","comment":"15 pages, 6 figures,"},{"id":"http://arxiv.org/abs/2206.03234v3","updated":"2025-07-31T16:34:37Z","published":"2022-06-07T12:26:28Z","title":"Disparate Conditional Prediction in Multiclass Classifiers","summary":"  We propose methods for auditing multiclass classifiers for fairness under\nmulticlass equalized odds,by estimating the deviation from equalized odds when\nthe classifier is not completely fair. We generalize to multiclass classifiers\nthe measure of Disparate Conditional Prediction (DCP), originally suggested by\nSabato & Yom-Tov (2020) for binary classifiers. DCP is defined as the fraction\nof the population for which the classifier predicts with conditional prediction\nprobabilities that differ from the closest common baseline. We provide new\nlocal-optimization methods for estimating the multiclass DCPunder two different\nregimes,one in which the conditional confusion matrices for each protected\nsub-population are known, and one in which these cannot be estimated, for\ninstance, because the classifier is inaccessible or because good-quality\nindividual-level data is not available. These methods can be used to detect\nclassifiers that likely treat a significant fraction of the population\nunfairly. Experiments demonstrate the accuracy of the methods. Code is provided\nat https://github.com/sivansabato/ DCPmulticlass.\n","authors":["Sivan Sabato","Eran Treister","Elad Yom-Tov"],"pdf_url":"https://arxiv.org/pdf/2206.03234v3.pdf","comment":"Published at ICML 2025"},{"id":"http://arxiv.org/abs/2502.17264v2","updated":"2025-07-31T15:15:50Z","published":"2025-02-24T15:46:18Z","title":"Kandinsky Conformal Prediction: Beyond Class- and Covariate-Conditional\n  Coverage","summary":"  Conformal prediction is a powerful distribution-free framework for\nconstructing prediction sets with coverage guarantees. Classical methods, such\nas split conformal prediction, provide marginal coverage, ensuring that the\nprediction set contains the label of a random test point with a target\nprobability. However, these guarantees may not hold uniformly across different\nsubpopulations, leading to disparities in coverage. Prior work has explored\ncoverage guarantees conditioned on events related to the covariates and label\nof the test point. We present Kandinsky conformal prediction, a framework that\nsignificantly expands the scope of conditional coverage guarantees. In contrast\nto Mondrian conformal prediction, which restricts its coverage guarantees to\ndisjoint groups -- reminiscent of the rigid, structured grids of Piet\nMondrian's art -- our framework flexibly handles overlapping and fractional\ngroup memberships defined jointly on covariates and labels, reflecting the\nlayered, intersecting forms in Wassily Kandinsky's compositions. Our algorithm\nunifies and extends existing methods, encompassing covariate-based group\nconditional, class conditional, and Mondrian conformal prediction as special\ncases, while achieving a minimax-optimal high-probability conditional coverage\nbound. Finally, we demonstrate the practicality of our approach through\nempirical evaluation on real-world datasets.\n","authors":["Konstantina Bairaktari","Jiayun Wu","Zhiwei Steven Wu"],"pdf_url":"https://arxiv.org/pdf/2502.17264v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.02490v3","updated":"2025-07-31T14:59:38Z","published":"2023-11-04T19:23:21Z","title":"Improved Convergence Factor of Windowed Anderson Acceleration for\n  Symmetric Fixed-Point Iterations","summary":"  This paper studies the commonly utilized windowed Anderson acceleration (AA)\nalgorithm for fixed-point methods, $x^{(k+1)}=q(x^{(k)})$. It provides the\nfirst proof that when the operator $q$ is linear and symmetric the windowed AA,\nwhich uses a sliding window of prior iterates, improves the root-linear\nconvergence factor over the fixed-point iterations. When $q$ is nonlinear, yet\nhas a symmetric Jacobian at a fixed point, a slightly modified AA algorithm is\nproved to have an analogous root-linear convergence factor improvement over\nfixed-point iterations. Simulations verify our observations. Furthermore,\nexperiments with different data models demonstrate AA is significantly superior\nto the standard fixed-point methods for Tyler's M-estimation.\n","authors":["Casey Garner","Gilad Lerman","Teng Zhang"],"pdf_url":"https://arxiv.org/pdf/2311.02490v3.pdf","comment":"40 pages, 10 figures"},{"id":"http://arxiv.org/abs/2507.23568v1","updated":"2025-07-31T13:57:38Z","published":"2025-07-31T13:57:38Z","title":"Optimised Feature Subset Selection via Simulated Annealing","summary":"  We introduce SA-FDR, a novel algorithm for $\\ell_0$-norm feature selection\nthat considers this task as a combinatorial optimisation problem and solves it\nby using simulated annealing to perform a global search over the space of\nfeature subsets. The optimisation is guided by the Fisher discriminant ratio,\nwhich we use as a computationally efficient proxy for model quality in\nclassification tasks. Our experiments, conducted on datasets with up to\nhundreds of thousands of samples and hundreds of features, demonstrate that\nSA-FDR consistently selects more compact feature subsets while achieving a high\npredictive accuracy. This ability to recover informative yet minimal sets of\nfeatures stems from its capacity to capture inter-feature dependencies often\nmissed by greedy optimisation approaches. As a result, SA-FDR provides a\nflexible and effective solution for designing interpretable models in\nhigh-dimensional settings, particularly when model sparsity, interpretability,\nand performance are crucial.\n","authors":["Fernando Martínez-García","Álvaro Rubio-García","Samuel Fernández-Lorenzo","Juan José García-Ripoll","Diego Porras"],"pdf_url":"https://arxiv.org/pdf/2507.23568v1.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2507.23559v1","updated":"2025-07-31T13:46:36Z","published":"2025-07-31T13:46:36Z","title":"Barycentric subspace analysis of network-valued data","summary":"  Certain data are naturally modeled by networks or weighted graphs, be they\narterial networks or mobility networks. When there is no canonical labeling of\nthe nodes across the dataset, we talk about unlabeled networks. In this paper,\nwe focus on the question of dimensionality reduction for this type of data.\nMore specifically, we address the issue of interpreting the feature subspace\nconstructed by dimensionality reduction methods. Most existing methods for\nnetwork-valued data are derived from principal component analysis (PCA) and\ntherefore rely on subspaces generated by a set of vectors, which we identify as\na major limitation in terms of interpretability. Instead, we propose to\nimplement the method called barycentric subspace analysis (BSA), which relies\non subspaces generated by a set of points. In order to provide a\ncomputationally feasible framework for BSA, we introduce a novel embedding for\nunlabeled networks where we replace their usual representation by equivalence\nclasses of isomorphic networks with that by equivalence classes of cospectral\nnetworks. We then illustrate BSA on simulated and real-world datasets, and\ncompare it to tangent PCA.\n","authors":["Elodie Maignant","Xavier Pennec","Alain Trouvé","Anna Calissano"],"pdf_url":"https://arxiv.org/pdf/2507.23559v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.09252v2","updated":"2025-07-31T12:50:59Z","published":"2025-07-12T11:18:07Z","title":"TPP-SD: Accelerating Transformer Point Process Sampling with Speculative\n  Decoding","summary":"  We propose TPP-SD, a novel approach that accelerates Transformer temporal\npoint process (TPP) sampling by adapting speculative decoding (SD) techniques\nfrom language models. By identifying the structural similarities between\nthinning algorithms for TPPs and speculative decoding for language models, we\ndevelop an efficient sampling framework that leverages a smaller draft model to\ngenerate multiple candidate events, which are then verified by the larger\ntarget model in parallel. TPP-SD maintains the same output distribution as\nautoregressive sampling while achieving significant acceleration. Experiments\non both synthetic and real datasets demonstrate that our approach produces\nsamples from identical distributions as standard methods, but with 2-6$\\times$\nspeedup. Our ablation studies analyze the impact of hyperparameters such as\ndraft length and draft model size on sampling efficiency. TPP-SD bridges the\ngap between powerful Transformer TPP models and the practical need for rapid\nsequence sampling.\n","authors":["Shukai Gong","Yiyang Fu","Fengyuan Ran","Quyu Kong","Feng Zhou"],"pdf_url":"https://arxiv.org/pdf/2507.09252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23501v1","updated":"2025-07-31T12:40:50Z","published":"2025-07-31T12:40:50Z","title":"Directional Ensemble Aggregation for Actor-Critics","summary":"  Off-policy reinforcement learning in continuous control tasks depends\ncritically on accurate $Q$-value estimates. Conservative aggregation over\nensembles, such as taking the minimum, is commonly used to mitigate\noverestimation bias. However, these static rules are coarse, discard valuable\ninformation from the ensemble, and cannot adapt to task-specific needs or\ndifferent learning regimes. We propose Directional Ensemble Aggregation (DEA),\nan aggregation method that adaptively combines $Q$-value estimates in\nactor-critic frameworks. DEA introduces two fully learnable directional\nparameters: one that modulates critic-side conservatism and another that guides\nactor-side policy exploration. Both parameters are learned using ensemble\ndisagreement-weighted Bellman errors, which weight each sample solely by the\ndirection of its Bellman error. This directional learning mechanism allows DEA\nto adjust conservatism and exploration in a data-driven way, adapting\naggregation to both uncertainty levels and the phase of training. We evaluate\nDEA across continuous control benchmarks and learning regimes - from\ninteractive to sample-efficient - and demonstrate its effectiveness over static\nensemble strategies.\n","authors":["Nicklas Werge","Yi-Shan Wu","Bahareh Tasdighi","Melih Kandemir"],"pdf_url":"https://arxiv.org/pdf/2507.23501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12319v2","updated":"2025-07-31T12:26:55Z","published":"2024-08-22T11:55:43Z","title":"Neural-ANOVA: Analytical Model Decomposition using Automatic Integration","summary":"  The analysis of variance (ANOVA) decomposition offers a systematic method to\nunderstand the interaction effects that contribute to a specific decision\noutput. In this paper we introduce Neural-ANOVA, an approach to decompose\nneural networks into the sum of lower-order models using the functional ANOVA\ndecomposition. Our approach formulates a learning problem, which enables fast\nanalytical evaluation of integrals over subspaces that appear in the\ncalculation of the ANOVA decomposition. Finally, we conduct numerical\nexperiments to provide insights into the approximation properties compared to\nother regression approaches from the literature.\n","authors":["Steffen Limmer","Steffen Udluft","Clemens Otte"],"pdf_url":"https://arxiv.org/pdf/2408.12319v2.pdf","comment":"6 pages, 3 figures, 3 tables, accepted for publication at MLSP 2025"},{"id":"http://arxiv.org/abs/2504.01781v3","updated":"2025-07-31T11:55:32Z","published":"2025-04-02T14:46:14Z","title":"Proper scoring rules for estimation and forecast evaluation","summary":"  Proper scoring rules have been a subject of growing interest in recent years,\nnot only as tools for evaluation of probabilistic forecasts but also as methods\nfor estimating probability distributions. In this article, we review the\nmathematical foundations of proper scoring rules including general\ncharacterization results and important families of scoring rules. We discuss\ntheir role in statistics and machine learning for estimation and forecast\nevaluation. Furthermore, we comment on interesting developments of their usage\nin applications.\n","authors":["Kartik Waghmare","Johanna Ziegel"],"pdf_url":"https://arxiv.org/pdf/2504.01781v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.23426v1","updated":"2025-07-31T11:06:30Z","published":"2025-07-31T11:06:30Z","title":"Overcoming error-in-variable problem in data-driven model discovery by\n  orthogonal distance regression","summary":"  Despite the recent proliferation of machine learning methods like SINDy that\npromise automatic discovery of governing equations from time-series data, there\nremain significant challenges to discovering models from noisy datasets. One\nreason is that the linear regression underlying these methods assumes that all\nnoise resides in the training target (the regressand), which is the time\nderivative, whereas the measurement noise is in the states (the regressors).\nRecent methods like modified-SINDy and DySMHO address this error-in-variable\nproblem by leveraging information from the model's temporal evolution, but they\nare also imposing the equation as a hard constraint, which effectively assumes\nno error in the regressand. Without relaxation, this hard constraint prevents\nassimilation of data longer than Lyapunov time. Instead, the fulfilment of the\nmodel equation should be treated as a soft constraint to account for the small\nyet critical error introduced by numerical truncation. The uncertainties in\nboth the regressor and the regressand invite the use of orthogonal distance\nregression (ODR). By incorporating ODR with the Bayesian framework for model\nselection, we introduce a novel method for model discovery, termed ODR-BINDy,\nand assess its performance against current SINDy variants using the Lorenz63,\nRossler, and Van Der Pol systems as case studies. Our findings indicate that\nODR-BINDy consistently outperforms all existing methods in recovering the\ncorrect model from sparse and noisy datasets. For instance, our ODR-BINDy\nmethod reliably recovers the Lorenz63 equation from data with noise\ncontamination levels of up to 30%.\n","authors":["Lloyd Fung"],"pdf_url":"https://arxiv.org/pdf/2507.23426v1.pdf","comment":"28 pages, 12 figures, prepared for the Data-driven systems and\n  control: analysis, modelling, optimisation, and stochasticity collection in\n  the journal Mathematics of Control, Signals, and Systems"},{"id":"http://arxiv.org/abs/2507.23349v1","updated":"2025-07-31T08:56:03Z","published":"2025-07-31T08:56:03Z","title":"Optimal Transport Learning: Balancing Value Optimization and Fairness in\n  Individualized Treatment Rules","summary":"  Individualized treatment rules (ITRs) have gained significant attention due\nto their wide-ranging applications in fields such as precision medicine,\nridesharing, and advertising recommendations. However, when ITRs are influenced\nby sensitive attributes such as race, gender, or age, they can lead to outcomes\nwhere certain groups are unfairly advantaged or disadvantaged. To address this\ngap, we propose a flexible approach based on the optimal transport theory,\nwhich is capable of transforming any optimal ITR into a fair ITR that ensures\ndemographic parity. Recognizing the potential loss of value under fairness\nconstraints, we introduce an ``improved trade-off ITR,\" designed to balance\nvalue optimization and fairness while accommodating varying levels of fairness\nthrough parameter adjustment. To maximize the value of the improved trade-off\nITR under specific fairness levels, we propose a smoothed fairness constraint\nfor estimating the adjustable parameter. Additionally, we establish a\ntheoretical upper bound on the value loss for the improved trade-off ITR. We\ndemonstrate performance of the proposed method through extensive simulation\nstudies and application to the Next 36 entrepreneurial program dataset.\n","authors":["Wenhai Cui","Xiaoting Ji","Wen Su","Xiaodong Yan","Xingqiu Zhao"],"pdf_url":"https://arxiv.org/pdf/2507.23349v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.01654v2","updated":"2025-07-31T06:38:19Z","published":"2023-06-02T16:24:07Z","title":"Insights into Closed-form IPM-GAN Discriminator Guidance for Diffusion\n  Modeling","summary":"  Diffusion models are a state-of-the-art generative modeling framework that\ntransform noise to images via Langevin sampling, guided by the score, which is\nthe gradient of the logarithm of the data distribution. Recent works have shown\nempirically that the generation quality can be improved when guided by\nclassifier network, which is typically the discriminator trained in a\ngenerative adversarial network (GAN) setting. In this paper, we propose a\ntheoretical framework to analyze the effect of the GAN discriminator on\nLangevin-based sampling, and show that the IPM-GAN optimization can be seen as\none of smoothed score-matching, wherein the scores of the data and the\ngenerator distributions are convolved with the kernel function associated with\nthe IPM. The proposed approach serves to unify score-based training and\noptimization of IPM-GANs. Based on these insights, we demonstrate that\nclosed-form kernel-based discriminator guidance, results in improvements (in\nterms of CLIP-FID and KID metrics) when applied atop baseline diffusion models.\nWe demonstrate these results on the denoising diffusion implicit model (DDIM)\nand latent diffusion model (LDM) settings on various standard datasets. We also\nshow that the proposed approach can be combined with existing\naccelerated-diffusion techniques to improve latent-space image generation.\n","authors":["Aadithya Srikanth","Siddarth Asokan","Nishanth Shetty","Chandra Sekhar Seelamantula"],"pdf_url":"https://arxiv.org/pdf/2306.01654v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12284v2","updated":"2025-07-31T05:15:21Z","published":"2025-06-14T00:16:11Z","title":"GrokAlign: Geometric Characterisation and Acceleration of Grokking","summary":"  A key challenge for the machine learning community is to understand and\naccelerate the training dynamics of deep networks that lead to delayed\ngeneralisation and emergent robustness to input perturbations, also known as\ngrokking. Prior work has associated phenomena like delayed generalisation with\nthe transition of a deep network from a linear to a feature learning regime,\nand emergent robustness with changes to the network's functional geometry, in\nparticular the arrangement of the so-called linear regions in deep networks\nemploying continuous piecewise affine nonlinearities. Here, we explain how\ngrokking is realised in the Jacobian of a deep network and demonstrate that\naligning a network's Jacobians with the training data (in the sense of cosine\nsimilarity) ensures grokking under a low-rank Jacobian assumption. Our results\nprovide a strong theoretical motivation for the use of Jacobian regularisation\nin optimizing deep networks -- a method we introduce as GrokAlign -- which we\nshow empirically to induce grokking much sooner than more conventional\nregularizers like weight decay. Moreover, we introduce centroid alignment as a\ntractable and interpretable simplification of Jacobian alignment that\neffectively identifies and tracks the stages of deep network training dynamics.\nAccompanying webpage (https://thomaswalker1.github.io/blog/grokalign.html) and\ncode (https://github.com/ThomasWalker1/grokalign).\n","authors":["Thomas Walker","Ahmed Imtiaz Humayun","Randall Balestriero","Richard Baraniuk"],"pdf_url":"https://arxiv.org/pdf/2506.12284v2.pdf","comment":"23 pages, 11 figures, 3 tables"},{"id":"http://arxiv.org/abs/2502.15215v5","updated":"2025-07-31T00:17:08Z","published":"2025-02-21T05:15:38Z","title":"Tensor Product Neural Networks for Functional ANOVA Model","summary":"  Interpretability for machine learning models is becoming more and more\nimportant as machine learning models become more complex. The functional ANOVA\nmodel, which decomposes a high-dimensional function into a sum of lower\ndimensional functions (commonly referred to as components), is one of the most\npopular tools for interpretable AI, and recently, various neural networks have\nbeen developed for estimating each component in the functional ANOVA model.\nHowever, such neural networks are highly unstable when estimating each\ncomponent since the components themselves are not uniquely defined. That is,\nthere are multiple functional ANOVA decompositions for a given function. In\nthis paper, we propose a novel neural network which guarantees a unique\nfunctional ANOVA decomposition and thus is able to estimate each component\nstably and accurately. We call our proposed neural network ANOVA Tensor Product\nNeural Network (ANOVA-TPNN) since it is motivated by the tensor product basis\nexpansion. Theoretically, we prove that ANOVA-TPNN can approximate any smooth\nfunction well. Empirically, we show that ANOVA-TPNN provide much more stable\nestimation of each component and thus much more stable interpretation when\ntraining data and initial values of the model parameters vary than existing\nneural networks do.\n","authors":["Seokhun Park","Insung Kong","Yongchan Choi","Chanmoo Park","Yongdai Kim"],"pdf_url":"https://arxiv.org/pdf/2502.15215v5.pdf","comment":"45 pages"},{"id":"http://arxiv.org/abs/2407.13971v2","updated":"2025-07-31T21:50:14Z","published":"2024-07-19T01:33:44Z","title":"Dimension-reduced Reconstruction Map Learning for Parameter Estimation\n  in Likelihood-Free Inference Problems","summary":"  Many application areas rely on models that can be readily simulated but lack\na closed-form likelihood, or an accurate approximation under arbitrary\nparameter values. Existing parameter estimation approaches in this setting are\ngenerally approximate. Recent work on using neural network models to\nreconstruct the mapping from the data space to the parameters from a set of\nsynthetic parameter-data pairs suffers from the curse of dimensionality,\nresulting in inaccurate estimation as the data size grows. We propose a\ndimension-reduced approach to likelihood-free estimation which combines the\nideas of reconstruction map estimation with dimension-reduction approaches\nbased on subject-specific knowledge. We examine the properties of\nreconstruction map estimation with and without dimension reduction and explore\nthe trade-off between approximation error due to information loss from reducing\nthe data dimension and approximation error. Numerical examples show that the\nproposed approach compares favorably with reconstruction map estimation,\napproximate Bayesian computation, and synthetic likelihood estimation.\n","authors":["Rui Zhang","Oksana A. Chkrebtii","Dongbin Xiu"],"pdf_url":"https://arxiv.org/pdf/2407.13971v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00180v1","updated":"2025-07-31T21:49:20Z","published":"2025-07-31T21:49:20Z","title":"EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes","summary":"  Stochasticity in language model fine-tuning, often caused by the small batch\nsizes typically used in this regime, can destabilize training by introducing\nlarge oscillations in generation quality. A popular approach to mitigating this\ninstability is to take an Exponential moving average (EMA) of weights\nthroughout training. While EMA reduces stochasticity, thereby smoothing\ntraining, the introduction of bias from old iterates often creates a lag in\noptimization relative to vanilla training. In this work, we propose the\nBias-Corrected Exponential Moving Average (BEMA), a simple and practical\naugmentation of EMA that retains variance-reduction benefits while eliminating\nbias. BEMA is motivated by a simple theoretical model wherein we demonstrate\nprovable acceleration of BEMA over both a standard EMA and vanilla training.\nThrough an extensive suite of experiments on Language Models, we show that BEMA\nleads to significantly improved convergence rates and final performance over\nboth EMA and vanilla training in a variety of standard LM benchmarks, making\nBEMA a practical and theoretically motivated intervention for more stable and\nefficient fine-tuning.\n","authors":["Adam Block","Cyril Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.00180v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21982v2","updated":"2025-07-31T21:12:02Z","published":"2025-07-29T16:33:43Z","title":"Preconditioned Discrete-HAMS: A Second-order Irreversible Discrete\n  Sampler","summary":"  Gradient-based Markov Chain Monte Carlo methods have recently received much\nattention for sampling discrete distributions, with notable examples such as\nNorm Constrained Gradient (NCG), Auxiliary Variable Gradient (AVG), and\nDiscrete Hamiltonian Assisted Metropolis Sampling (DHAMS). In this work, we\npropose the Preconditioned Discrete-HAMS (PDHAMS) algorithm, which extends\nDHAMS by incorporating a second-order, quadratic approximation of the potential\nfunction, and uses Gaussian integral trick to avoid directly sampling a\npairwise Markov random field. The PDHAMS sampler not only satisfies generalized\ndetailed balance, hence enabling irreversible sampling, but also is a\nrejection-free property for a target distribution with a quadratic potential\nfunction. In various numerical experiments, PDHAMS algorithms consistently\nyield superior performance compared with other methods.\n","authors":["Yuze Zhou","Zhiqiang Tan"],"pdf_url":"https://arxiv.org/pdf/2507.21982v2.pdf","comment":"arXiv admin note: text overlap with arXiv:2507.09807"},{"id":"http://arxiv.org/abs/2508.00120v1","updated":"2025-07-31T19:16:48Z","published":"2025-07-31T19:16:48Z","title":"AdapDISCOM: An Adaptive Sparse Regression Method for High-Dimensional\n  Multimodal Data With Block-Wise Missingness and Measurement Errors","summary":"  Multimodal high-dimensional data are increasingly prevalent in biomedical\nresearch, yet they are often compromised by block-wise missingness and\nmeasurement errors, posing significant challenges for statistical inference and\nprediction. We propose AdapDISCOM, a novel adaptive direct sparse regression\nmethod that simultaneously addresses these two pervasive issues. Building on\nthe DISCOM framework, AdapDISCOM introduces modality-specific weighting schemes\nto account for heterogeneity in data structures and error magnitudes across\nmodalities. We establish the theoretical properties of AdapDISCOM, including\nmodel selection consistency and convergence rates under sub-Gaussian and\nheavy-tailed settings, and develop robust and computationally efficient\nvariants (AdapDISCOM-Huber and Fast-AdapDISCOM). Extensive simulations\ndemonstrate that AdapDISCOM consistently outperforms existing methods such as\nDISCOM, SCOM, and CoCoLasso, particularly under heterogeneous contamination and\nheavy-tailed distributions. Finally, we apply AdapDISCOM to Alzheimers Disease\nNeuroimaging Initiative (ADNI) data, demonstrating improved prediction of\ncognitive scores and reliable selection of established biomarkers, even with\nsubstantial missingness and measurement errors. AdapDISCOM provides a flexible,\nrobust, and scalable framework for high-dimensional multimodal data analysis\nunder realistic data imperfections.\n","authors":["Abdoul O. Diakité","Claudia Moreau","Gleb Bezgin","Nikhil Bhagwat","Pedro Rosa-Neto","Jean-Baptiste Poline","Simon Girard","Amadou Barry","for the Alzheimers Disease Neuroimaging Initiative"],"pdf_url":"https://arxiv.org/pdf/2508.00120v1.pdf","comment":"49 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.00110v1","updated":"2025-07-31T19:00:20Z","published":"2025-07-31T19:00:20Z","title":"funOCLUST: Clustering Functional Data with Outliers","summary":"  Functional data present unique challenges for clustering due to their\ninfinite-dimensional nature and potential sensitivity to outliers. An extension\nof the OCLUST algorithm to the functional setting is proposed to address these\nissues. The approach leverages the OCLUST framework, creating a robust method\nto cluster curves and trim outliers. The methodology is evaluated on both\nsimulated and real-world functional datasets, demonstrating strong performance\nin clustering and outlier identification.\n","authors":["Katharine M. Clark","Paul D. McNicholas"],"pdf_url":"https://arxiv.org/pdf/2508.00110v1.pdf","comment":null},{"id":"http://arxiv.org/abs/1912.12213v7","updated":"2025-07-31T18:34:27Z","published":"2019-12-27T16:13:21Z","title":"Minimax Semiparametric Learning With Approximate Sparsity","summary":"  Estimating linear, mean-square continuous functionals is a pivotal challenge\nin statistics. In high-dimensional contexts, this estimation is often performed\nunder the assumption of exact model sparsity, meaning that only a small number\nof parameters are precisely non-zero. This excludes models where linear\nformulations only approximate the underlying data distribution, such as\nnonparametric regression methods that use basis expansion such as splines,\nkernel methods or polynomial regressions. Many recent methods for root-$n$\nestimation have been proposed, but the implications of exact model sparsity\nremain largely unexplored. In particular, minimax optimality for models that\nare not exactly sparse has not yet been developed. This paper formalizes the\nconcept of approximate sparsity through classical semi-parametric theory. We\nderive minimax rates under this formulation for a regression slope and an\naverage derivative, finding these bounds to be substantially larger than those\nin low-dimensional, semi-parametric settings. We identify several new\nphenomena. We discover new regimes where rate double robustness does not hold,\nyet root-$n$ estimation is still possible. In these settings, we propose an\nestimator that achieves minimax optimal rates. Our findings further reveal\ndistinct optimality boundaries for ordered versus unordered nonparametric\nregression estimation.\n","authors":["Jelena Bradic","Victor Chernozhukov","Whitney K. Newey","Yinchu Zhu"],"pdf_url":"https://arxiv.org/pdf/1912.12213v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00040v1","updated":"2025-07-31T09:12:25Z","published":"2025-07-31T09:12:25Z","title":"Regime-Aware Conditional Neural Processes with Multi-Criteria Decision\n  Support for Operational Electricity Price Forecasting","summary":"  This work integrates Bayesian regime detection with conditional neural\nprocesses for 24-hour electricity price prediction in the German market. Our\nmethodology integrates regime detection using a disentangled sticky\nhierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to\ndaily electricity prices. Each identified regime is subsequently modeled by an\nindependent conditional neural process (CNP), trained to learn localized\nmappings from input contexts to 24-dimensional hourly price trajectories, with\nfinal predictions computed as regime-weighted mixtures of these CNP outputs. We\nrigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated\nauto-regressive (LEAR) models by integrating their forecasts into diverse\nbattery storage optimization frameworks, including price arbitrage, risk\nmanagement, grid services, and cost minimization. This operational utility\nassessment revealed complex performance trade-offs: LEAR often yielded superior\nabsolute profits or lower costs, while DNN showed exceptional optimality in\nspecific cost-minimization contexts. Recognizing that raw prediction accuracy\ndoesn't always translate to optimal operational outcomes, we employed TOPSIS as\na comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified\nLEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model\nemerged as the most balanced and preferred solution for 2021, 2022 and 2023.\n","authors":["Abhinav Das","Stephan Schlüter"],"pdf_url":"https://arxiv.org/pdf/2508.00040v1.pdf","comment":null}],"Computation":[{"id":"http://arxiv.org/abs/2507.23240v1","updated":"2025-07-31T04:40:22Z","published":"2025-07-31T04:40:22Z","title":"A-optimal Designs under Generalized Linear Models","summary":"  We characterize and identify A-optimal designs under generalized linear\nmodels. When a predetermined finite set of experimental settings is given, we\nderive analytic solutions or establish necessary and sufficient conditions for\nobtaining A-optimal approximate allocations. We show that a lift-one algorithm\nbased on our formulae may outperform commonly used algorithms for finding\nA-optimal allocations. When continuous factors or design regions get involved,\nwe develop a ForLion algorithm that is guaranteed to find A-optimal designs\nwith mixed factors. Numerical studies show that our algorithms are able to find\nhighly efficient designs with reduced numbers of distinct experimental\nsettings, which may save both experimental time and cost significantly. Along\nwith a rounding-off algorithm that converts approximate allocations to exact\nones, we demonstrate that stratified samplers based on A-optimal allocations\nmay provide more accurate parameter estimates than commonly used samplers,\nincluding D-optimal ones.\n","authors":["Yingying Yang","Xiaotian Chen","Jie Yang"],"pdf_url":"https://arxiv.org/pdf/2507.23240v1.pdf","comment":"34 pages, 1 figure, 9 tables"},{"id":"http://arxiv.org/abs/2508.00210v1","updated":"2025-07-31T23:22:46Z","published":"2025-07-31T23:22:46Z","title":"Efficient rare event estimation for multimodal and high-dimensional\n  system reliability via subset adaptive importance sampling","summary":"  Estimating rare events in complex systems is a key challenge in reliability\nanalysis. The challenge grows in multimodal problems, where traditional methods\noften rely on a small set of design points and risk overlooking critical\nfailure modes. Further, higher dimensions make the probability mass harder to\ncapture and demand substantially larger sample sizes to estimate failures. In\nthis work, we propose a new sampling strategy, subset adaptive importance\nsampling (SAIS), that combines the strengths of subset simulation and adaptive\nmultiple importance sampling. SAIS iteratively refines a set of proposal\ndistributions using weighted samples from previous stages, efficiently\nexploring complex and high-dimensional failure regions. Leveraging recent\nadvances in adaptive importance sampling, SAIS yields low-variance estimates\nusing fewer samples than state-of-the-art methods and achieves pronounced\nimprovements in both accuracy and computational cost. Through a series of\nbenchmark problems involving high-dimensional, nonlinear performance functions,\nand multimodal scenarios, we demonstrate that SAIS consistently outperforms\ncompeting methods in capturing diverse failure modes and estimating failure\nprobabilities with high precision.\n","authors":["Sara Helal","Victor Elvira"],"pdf_url":"https://arxiv.org/pdf/2508.00210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.13971v2","updated":"2025-07-31T21:50:14Z","published":"2024-07-19T01:33:44Z","title":"Dimension-reduced Reconstruction Map Learning for Parameter Estimation\n  in Likelihood-Free Inference Problems","summary":"  Many application areas rely on models that can be readily simulated but lack\na closed-form likelihood, or an accurate approximation under arbitrary\nparameter values. Existing parameter estimation approaches in this setting are\ngenerally approximate. Recent work on using neural network models to\nreconstruct the mapping from the data space to the parameters from a set of\nsynthetic parameter-data pairs suffers from the curse of dimensionality,\nresulting in inaccurate estimation as the data size grows. We propose a\ndimension-reduced approach to likelihood-free estimation which combines the\nideas of reconstruction map estimation with dimension-reduction approaches\nbased on subject-specific knowledge. We examine the properties of\nreconstruction map estimation with and without dimension reduction and explore\nthe trade-off between approximation error due to information loss from reducing\nthe data dimension and approximation error. Numerical examples show that the\nproposed approach compares favorably with reconstruction map estimation,\napproximate Bayesian computation, and synthetic likelihood estimation.\n","authors":["Rui Zhang","Oksana A. Chkrebtii","Dongbin Xiu"],"pdf_url":"https://arxiv.org/pdf/2407.13971v2.pdf","comment":null}]},"2025-08-01T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2508.00819v1","updated":"2025-08-01T17:56:07Z","published":"2025-08-01T17:56:07Z","title":"Beyond Fixed: Variable-Length Denoising for Diffusion Large Language\n  Models","summary":"  Diffusion Large Language Models (DLLMs) are emerging as a powerful\nalternative to the dominant Autoregressive Large Language Models, offering\nefficient parallel generation and capable global context modeling. However, the\npractical application of DLLMs is hindered by a critical architectural\nconstraint: the need for a statically predefined generation length. This static\nlength allocation leads to a problematic trade-off: insufficient lengths\ncripple performance on complex tasks, while excessive lengths incur significant\ncomputational overhead and sometimes result in performance degradation. While\nthe inference framework is rigid, we observe that the model itself possesses\ninternal signals that correlate with the optimal response length for a given\ntask. To bridge this gap, we leverage these latent signals and introduce\nDAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive\nLength Expansion for Diffusion Large Language Models. DAEDAL operates in two\nphases: 1) Before the denoising process, DAEDAL starts from a short initial\nlength and iteratively expands it to a coarse task-appropriate length, guided\nby a sequence completion metric. 2) During the denoising process, DAEDAL\ndynamically intervenes by pinpointing and expanding insufficient generation\nregions through mask token insertion, ensuring the final output is fully\ndeveloped. Extensive experiments on DLLMs demonstrate that DAEDAL achieves\nperformance comparable, and in some cases superior, to meticulously tuned\nfixed-length baselines, while simultaneously enhancing computational efficiency\nby achieving a higher effective token ratio. By resolving the static length\nconstraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap\nwith their Autoregressive counterparts and paving the way for more efficient\nand capable generation.\n","authors":["Jinsong Li","Xiaoyi Dong","Yuhang Zang","Yuhang Cao","Jiaqi Wang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2508.00819v1.pdf","comment":"Code is available at https://github.com/Li-Jinsong/DAEDAL"},{"id":"http://arxiv.org/abs/2508.00788v1","updated":"2025-08-01T17:11:42Z","published":"2025-08-01T17:11:42Z","title":"Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun\n  Handling in Large Language Models","summary":"  Large language models (LLMs) are increasingly deployed in sensitive contexts\nwhere fairness and inclusivity are critical. Pronoun usage, especially\nconcerning gender-neutral and neopronouns, remains a key challenge for\nresponsible AI. Prior work, such as the MISGENDERED benchmark, revealed\nsignificant limitations in earlier LLMs' handling of inclusive pronouns, but\nwas constrained to outdated models and limited evaluations. In this study, we\nintroduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'\npronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,\nDeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender\nidentity inference. Our results show notable improvements compared with\nprevious studies, especially in binary and gender-neutral pronoun accuracy.\nHowever, accuracy on neopronouns and reverse inference tasks remains\ninconsistent, underscoring persistent gaps in identity-sensitive reasoning. We\ndiscuss implications, model-specific observations, and avenues for future\ninclusive AI research.\n","authors":["Xushuo Tang","Yi Ding","Zhengyi Yang","Yin Chen","Yongrui Gu","Wenke Yang","Mingchen Ju","Xin Cao","Yongfei Liu","Wenjie Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.00788v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.02039v3","updated":"2025-08-01T17:05:21Z","published":"2025-01-03T14:35:32Z","title":"An Investigation into Value Misalignment in LLM-Generated Texts for\n  Cultural Heritage","summary":"  As Large Language Models (LLMs) become increasingly prevalent in tasks\nrelated to cultural heritage, such as generating descriptions of historical\nmonuments, translating ancient texts, preserving oral traditions, and creating\neducational content, their ability to produce accurate and culturally aligned\ntexts is being increasingly relied upon by users and researchers. However,\ncultural value misalignments may exist in generated texts, such as the\nmisrepresentation of historical facts, the erosion of cultural identity, and\nthe oversimplification of complex cultural narratives, which may lead to severe\nconsequences. Therefore, investigating value misalignment in the context of LLM\nfor cultural heritage is crucial for mitigating these risks, yet there has been\na significant lack of systematic and comprehensive study and investigation in\nthis area. To fill this gap, we systematically assess the reliability of LLMs\nin generating culturally aligned texts for cultural heritage-related tasks. We\nconduct a comprehensive evaluation by compiling an extensive set of 1066 query\ntasks covering 5 widely recognized categories with 17 aspects within the\nknowledge framework of cultural heritage across 5 open-source LLMs, and examine\nboth the type and rate of cultural value misalignments in the generated texts.\nUsing both automated and manual approaches, we effectively detect and analyze\nthe cultural value misalignments in LLM-generated texts. Our findings are\nconcerning: over 65% of the generated texts exhibit notable cultural\nmisalignments, with certain tasks demonstrating almost complete misalignment\nwith key cultural values. Beyond these findings, this paper introduces a\nbenchmark dataset and a comprehensive evaluation workflow that can serve as a\nvaluable resource for future research aimed at enhancing the cultural\nsensitivity and reliability of LLMs.\n","authors":["Fan Bu","Zheng Wang","Siyi Wang","Ziyao Liu"],"pdf_url":"https://arxiv.org/pdf/2501.02039v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02713v3","updated":"2025-08-01T16:40:14Z","published":"2024-10-03T17:36:49Z","title":"LLaVA-Video: Video Instruction Tuning With Synthetic Data","summary":"  The development of video large multimodal models (LMMs) has been hindered by\nthe difficulty of curating large amounts of high-quality raw data from the web.\nTo address this, we propose an alternative approach by creating a high-quality\nsynthetic dataset specifically for video instruction-following, namely\nLLaVA-Video-178K. This dataset includes key tasks such as detailed captioning,\nopen-ended question-answering (QA), and multiple-choice QA. By training on this\ndataset, in combination with existing visual instruction tuning data, we\nintroduce LLaVA-Video, a new video LMM. Our experiments demonstrate that\nLLaVA-Video achieves strong performance across various video benchmarks,\nhighlighting the effectiveness of our dataset. We plan to release the dataset,\nits generation pipeline, and the model checkpoints.\n","authors":["Yuanhan Zhang","Jinming Wu","Wei Li","Bo Li","Zejun Ma","Ziwei Liu","Chunyuan Li"],"pdf_url":"https://arxiv.org/pdf/2410.02713v3.pdf","comment":"Project page:\n  https://llava-vl.github.io/blog/2024-09-30-llava-video/; Accepted at TMLR"},{"id":"http://arxiv.org/abs/2508.00762v1","updated":"2025-08-01T16:38:18Z","published":"2025-08-01T16:38:18Z","title":"ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A\n  Zero-Shot Approach using LLM-Driven Code Generation","summary":"  This paper presents our system for SemEval-2025 Task 8: DataBench,\nQuestion-Answering over Tabular Data. The primary objective of this task is to\nperform question answering on given tabular datasets from diverse domains under\ntwo subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To\ntackle both subtasks, we developed a zero-shot solution with a particular\nemphasis on leveraging Large Language Model (LLM)-based code generation.\nSpecifically, we propose a Python code generation framework utilizing\nstate-of-the-art open-source LLMs to generate executable Pandas code via\noptimized prompting strategies. Our experiments reveal that different LLMs\nexhibit varying levels of effectiveness in Python code generation.\nAdditionally, results show that Python code generation achieves superior\nperformance in tabular question answering compared to alternative approaches.\nAlthough our ranking among zero-shot systems is unknown at the time of this\npaper's submission, our system achieved eighth place in Subtask I and sixth\nplace in Subtask~II among the 30 systems that outperformed the baseline in the\nopen-source models category.\n","authors":["Atakan Site","Emre Hakan Erdemir","Gülşen Eryiğit"],"pdf_url":"https://arxiv.org/pdf/2508.00762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.17217v2","updated":"2025-08-01T16:37:16Z","published":"2025-05-22T18:46:50Z","title":"Mitigating Gender Bias via Fostering Exploratory Thinking in LLMs","summary":"  Large Language Models (LLMs) often exhibit gender bias, resulting in unequal\ntreatment of male and female subjects across different contexts. To address\nthis issue, we propose a novel data generation framework that fosters\nexploratory thinking in LLMs. Our approach prompts models to generate story\npairs featuring male and female protagonists in structurally identical, morally\nambiguous scenarios, then elicits and compares their moral judgments. When\ninconsistencies arise, the model is guided to produce balanced, gender-neutral\njudgments. These story-judgment pairs are used to fine-tune or optimize the\nmodels via Direct Preference Optimization (DPO). Experimental results show that\nour method significantly reduces gender bias while preserving or even enhancing\ngeneral model capabilities. We will release the code and generated data. We\nrelease the code and generated data at:\nhttps://github.com/WeiKangda/LLMs-Exploratory-Bias-Mitigation/tree/main.\n","authors":["Kangda Wei","Hasnat Md Abdullah","Ruihong Huang"],"pdf_url":"https://arxiv.org/pdf/2505.17217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00760v1","updated":"2025-08-01T16:34:57Z","published":"2025-08-01T16:34:57Z","title":"MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese\n  Hate Speech Detection under Cloaking Perturbations","summary":"  Hate speech detection on Chinese social networks presents distinct\nchallenges, particularly due to the widespread use of cloaking techniques\ndesigned to evade conventional text-based detection systems. Although large\nlanguage models (LLMs) have recently improved hate speech detection\ncapabilities, the majority of existing work has concentrated on English\ndatasets, with limited attention given to multimodal strategies in the Chinese\ncontext. In this study, we propose MMBERT, a novel BERT-based multimodal\nframework that integrates textual, speech, and visual modalities through a\nMixture-of-Experts (MoE) architecture. To address the instability associated\nwith directly integrating MoE into BERT-based models, we develop a progressive\nthree-stage training paradigm. MMBERT incorporates modality-specific experts, a\nshared self-attention mechanism, and a router-based expert allocation strategy\nto enhance robustness against adversarial perturbations. Empirical results in\nseveral Chinese hate speech datasets show that MMBERT significantly surpasses\nfine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing\nin-context learning approaches.\n","authors":["Qiyao Xue","Yuchen Dou","Ryan Shi","Xiang Lorraine Li","Wei Gao"],"pdf_url":"https://arxiv.org/pdf/2508.00760v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00757v1","updated":"2025-08-01T16:33:13Z","published":"2025-08-01T16:33:13Z","title":"GLiDRE: Generalist Lightweight model for Document-level Relation\n  Extraction","summary":"  Relation Extraction (RE) is a fundamental task in Natural Language\nProcessing, and its document-level variant poses significant challenges, due to\nthe need to model complex interactions between entities across sentences.\nCurrent approaches, largely based on the ATLOP architecture, are commonly\nevaluated on benchmarks like DocRED and Re-DocRED. However, their performance\nin zero-shot or few-shot settings remains largely underexplored due to the\ntask's complexity. Recently, the GLiNER model has shown that a compact NER\nmodel can outperform much larger Large Language Models. With a similar\nmotivation, we introduce GLiDRE, a new model for document-level relation\nextraction that builds on the key ideas of GliNER. We benchmark GLiDRE against\nstate-of-the-art models across various data settings on the Re-DocRED dataset.\nOur results demonstrate that GLiDRE achieves state-of-the-art performance in\nfew-shot scenarios. Our code is publicly available.\n","authors":["Robin Armingaud","Romaric Besançon"],"pdf_url":"https://arxiv.org/pdf/2508.00757v1.pdf","comment":"Submitted to ARR July"},{"id":"http://arxiv.org/abs/2507.09751v2","updated":"2025-08-01T16:30:02Z","published":"2025-07-13T19:05:43Z","title":"Sound and Complete Neurosymbolic Reasoning with LLM-Grounded\n  Interpretations","summary":"  Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language understanding and generation, but they exhibit problems with\nlogical consistency in the output they generate. How can we harness LLMs'\nbroad-coverage parametric knowledge in formal reasoning despite their\ninconsistency? We present a method for directly integrating an LLM into the\ninterpretation function of the formal semantics for a paraconsistent logic. We\nprovide experimental evidence for the feasibility of the method by evaluating\nthe function using datasets created from several short-form factuality\nbenchmarks. Unlike prior work, our method offers a theoretical framework for\nneurosymbolic reasoning that leverages an LLM's knowledge while preserving the\nunderlying logic's soundness and completeness properties.\n","authors":["Bradley P. Allen","Prateek Chhikara","Thomas Macaulay Ferguson","Filip Ilievski","Paul Groth"],"pdf_url":"https://arxiv.org/pdf/2507.09751v2.pdf","comment":"29 pages, 9 tables, 3 figures. Accepted to the 19th Conference on\n  Neurosymbolic Learning and Reasoning (NeSy 2025)"},{"id":"http://arxiv.org/abs/2508.00743v1","updated":"2025-08-01T16:18:52Z","published":"2025-08-01T16:18:52Z","title":"Agentic large language models improve retrieval-based radiology question\n  answering","summary":"  Clinical decision-making in radiology increasingly benefits from artificial\nintelligence (AI), particularly through large language models (LLMs). However,\ntraditional retrieval-augmented generation (RAG) systems for radiology question\nanswering (QA) typically rely on single-step retrieval, limiting their ability\nto handle complex clinical reasoning tasks. Here we propose an agentic RAG\nframework enabling LLMs to autonomously decompose radiology questions,\niteratively retrieve targeted clinical evidence from Radiopaedia, and\ndynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning\ndiverse architectures, parameter scales (0.5B to >670B), and training paradigms\n(general-purpose, reasoning-optimized, clinically fine-tuned), using 104\nexpert-curated radiology questions from previously established RSNA-RadioQA and\nExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic\naccuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional\nonline RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized\nmodels (e.g., Mistral Large improved from 72% to 81%) and small-scale models\n(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B\nparameters) demonstrated minimal changes (<2% improvement). Additionally,\nagentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically\nrelevant context in 46% of cases, substantially aiding factual grounding. Even\nclinically fine-tuned models exhibited meaningful improvements (e.g.,\nMedGemma-27B improved from 71% to 81%), indicating complementary roles of\nretrieval and fine-tuning. These results highlight the potential of agentic\nframeworks to enhance factuality and diagnostic accuracy in radiology QA,\nparticularly among mid-sized LLMs, warranting future studies to validate their\nclinical utility.\n","authors":["Sebastian Wind","Jeta Sopa","Daniel Truhn","Mahshad Lotfinia","Tri-Thien Nguyen","Keno Bressem","Lisa Adams","Mirabela Rusu","Harald Köstler","Gerhard Wellein","Andreas Maier","Soroosh Tayebi Arasteh"],"pdf_url":"https://arxiv.org/pdf/2508.00743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.22675v3","updated":"2025-08-01T16:17:57Z","published":"2025-03-28T17:59:03Z","title":"Think Before Recommend: Unleashing the Latent Reasoning Power for\n  Sequential Recommendation","summary":"  Sequential Recommendation (SeqRec) aims to predict the next item by capturing\nsequential patterns from users' historical interactions, playing a crucial role\nin many real-world recommender systems. However, existing approaches\npredominantly adopt a direct forward computation paradigm, where the final\nhidden state of the sequence encoder serves as the user representation. We\nargue that this inference paradigm, due to its limited computational depth,\nstruggles to model the complex evolving nature of user preferences and lacks a\nnuanced understanding of long-tail items, leading to suboptimal performance. To\naddress this issue, we propose \\textbf{ReaRec}, the first inference-time\ncomputing framework for recommender systems, which enhances user\nrepresentations through implicit multi-step reasoning. Specifically, ReaRec\nautoregressively feeds the sequence's last hidden state into the sequential\nrecommender while incorporating special reasoning position embeddings to\ndecouple the original item encoding space from the multi-step reasoning space.\nMoreover, we introduce two lightweight reasoning-based learning methods,\nEnsemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to\nfurther effectively exploit ReaRec's reasoning potential. Extensive experiments\non five public real-world datasets and different SeqRec architectures\ndemonstrate the generality and effectiveness of our proposed ReaRec.\nRemarkably, post-hoc analyses reveal that ReaRec significantly elevates the\nperformance ceiling of multiple sequential recommendation backbones by\napproximately 30\\%-50\\%. Thus, we believe this work can open a new and\npromising avenue for future research in inference-time computing for sequential\nrecommendation.\n","authors":["Jiakai Tang","Sunhao Dai","Teng Shi","Jun Xu","Xu Chen","Wen Chen","Jian Wu","Yuning Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.22675v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00742v1","updated":"2025-08-01T16:16:16Z","published":"2025-08-01T16:16:16Z","title":"Applying Psychometrics to Large Language Model Simulated Populations:\n  Recreating the HEXACO Personality Inventory Experiment with Generative Agents","summary":"  Generative agents powered by Large Language Models demonstrate human-like\ncharacteristics through sophisticated natural language interactions. Their\nability to assume roles and personalities based on predefined character\nbiographies has positioned them as cost-effective substitutes for human\nparticipants in social science research. This paper explores the validity of\nsuch persona-based agents in representing human populations; we recreate the\nHEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,\nconducting factor analysis on their responses, and comparing these results to\nthe original findings presented by Ashton, Lee, & Goldberg in 2004. Our results\nfound 1) a coherent and reliable personality structure was recoverable from the\nagents' responses demonstrating partial alignment to the HEXACO framework. 2)\nthe derived personality dimensions were consistent and reliable within GPT-4,\nwhen coupled with a sufficiently curated population, and 3) cross-model\nanalysis revealed variability in personality profiling, suggesting\nmodel-specific biases and limitations. We discuss the practical considerations\nand challenges encountered during the experiment. This study contributes to the\nongoing discourse on the potential benefits and limitations of using generative\nagents in social science research and provides useful guidance on designing\nconsistent and representative agent personas to maximise coverage and\nrepresentation of human personality traits.\n","authors":["Sarah Mercer","Daniel P. Martin","Phil Swatton"],"pdf_url":"https://arxiv.org/pdf/2508.00742v1.pdf","comment":"26 pages, 14 figures"},{"id":"http://arxiv.org/abs/2508.00741v1","updated":"2025-08-01T16:12:23Z","published":"2025-08-01T16:12:23Z","title":"Out-of-Context Abduction: LLMs Make Inferences About Procedural Data\n  Leveraging Declarative Facts in Earlier Training Data","summary":"  Large language models (LLMs) are trained on large corpora, yet it is unclear\nwhether they can reason about the information present within their training\ndata. We design experiments to study out-of-context abduction in LLMs, the\nability to infer the most plausible explanations for observations using\nrelevant facts present in training data. We train treatment LLMs on names and\nbehavior descriptions of fictitious chatbots, but not on examples of dialogue\nwith the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at\nleast one chatbot's name after observing example responses characteristic of\nthat chatbot. We also find that previously training GPT 4o on descriptions of a\nchatbot's behavior allows it to display behaviors more characteristic of the\nchatbot when iteratively trained to display such behaviors. Our results have\nimplications for situational awareness in LLMs and, therefore, for AI safety.\n","authors":["Sohaib Imran","Rob Lamb","Peter M. Atkinson"],"pdf_url":"https://arxiv.org/pdf/2508.00741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00719v1","updated":"2025-08-01T15:38:21Z","published":"2025-08-01T15:38:21Z","title":"Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and\n  Context-Aware KGQA","summary":"  Knowledge Graph Question Answering (KGQA) aims to interpret natural language\nqueries and perform structured reasoning over knowledge graphs by leveraging\ntheir relational and semantic structures to retrieve accurate answers. Recent\nKGQA methods primarily follow either retrieve-then-reason paradigm, relying on\nGNNs or heuristic rules for static paths extraction, or dynamic path generation\nstrategies that use large language models (LLMs) with prompting to jointly\nperform retrieval and reasoning. However, the former suffers from limited\nadaptability due to static path extraction and lack of contextual refinement,\nwhile the latter incurs high computational costs and struggles with accurate\npath evaluation due to reliance on fixed scoring functions and extensive LLM\ncalls. To address these issues, this paper proposes Dynamically Adaptive\nMCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search\nwith adaptive path evaluation for efficient and context-aware KGQA. DAMR\nemploys a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based\nplanner, which selects top-$k$ relevant relations at each step to reduce search\nspace. To improve path evaluation accuracy, we introduce a lightweight\nTransformer-based scorer that performs context-aware plausibility estimation by\njointly encoding the question and relation sequence through cross-attention,\nenabling the model to capture fine-grained semantic shifts during multi-hop\nreasoning. Furthermore, to alleviate the scarcity of high-quality supervision,\nDAMR incorporates a dynamic pseudo-path refinement mechanism that periodically\ngenerates training signals from partial paths explored during search, allowing\nthe scorer to continuously adapt to the evolving distribution of reasoning\ntrajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR\nsignificantly outperforms state-of-the-art methods.\n","authors":["Yingxu Wang","Shiqi Fan","Mengzhu Wang","Siwei Liu"],"pdf_url":"https://arxiv.org/pdf/2508.00719v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08441v3","updated":"2025-08-01T15:28:51Z","published":"2025-02-12T14:32:17Z","title":"Better Embeddings with Coupled Adam","summary":"  Despite their remarkable capabilities, LLMs learn word representations that\nexhibit the undesirable yet poorly understood feature of anisotropy. In this\npaper, we argue that the second moment in Adam is a cause of anisotropic\nembeddings, and suggest a modified optimizer called Coupled Adam to mitigate\nthe problem. Our experiments demonstrate that Coupled Adam significantly\nimproves the quality of embeddings, while also leading to better upstream and\ndownstream performance on large enough datasets.\n","authors":["Felix Stollenwerk","Tobias Stollenwerk"],"pdf_url":"https://arxiv.org/pdf/2502.08441v3.pdf","comment":"ACL 2025 (Main), see https://aclanthology.org/2025.acl-long.1321/"},{"id":"http://arxiv.org/abs/2508.00709v1","updated":"2025-08-01T15:23:20Z","published":"2025-08-01T15:23:20Z","title":"NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian\n  Common Law System","summary":"  Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,\naiming to automate judicial outcome forecasting and enhance interpretability in\nlegal reasoning. While previous approaches in the Indian context have relied on\ninternal case content such as facts, issues, and reasoning, they often overlook\na core element of common law systems, which is reliance on statutory provisions\nand judicial precedents. In this work, we propose NyayaRAG, a\nRetrieval-Augmented Generation (RAG) framework that simulates realistic\ncourtroom scenarios by providing models with factual case descriptions,\nrelevant legal statutes, and semantically retrieved prior cases. NyayaRAG\nevaluates the effectiveness of these combined inputs in predicting court\ndecisions and generating legal explanations using a domain-specific pipeline\ntailored to the Indian legal system. We assess performance across various input\nconfigurations using both standard lexical and semantic metrics as well as\nLLM-based evaluators such as G-Eval. Our results show that augmenting factual\ninputs with structured legal knowledge significantly improves both predictive\naccuracy and explanation quality.\n","authors":["Shubham Kumar Nigam","Balaramamahanthi Deepak Patnaik","Shivam Mishra","Ajay Varghese Thomas","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2508.00709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00695v1","updated":"2025-08-01T15:11:39Z","published":"2025-08-01T15:11:39Z","title":"Classification of Psychiatry Clinical Notes by Diagnosis: A Deep\n  Learning and Machine Learning Approach","summary":"  The classification of clinical notes into specific diagnostic categories is\ncritical in healthcare, especially for mental health conditions like Anxiety\nand Adjustment Disorder. In this study, we compare the performance of various\nArtificial Intelligence models, including both traditional Machine Learning\napproaches (Random Forest, Support Vector Machine, K-nearest neighbors,\nDecision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT\nand SciBERT), to classify clinical notes into these two diagnoses.\nAdditionally, we implemented three oversampling strategies: No Oversampling,\nRandom Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to\nassess their impact on model performance. Hyperparameter tuning was also\napplied to optimize model accuracy. Our results indicate that oversampling\ntechniques had minimal impact on model performance overall. The only exception\nwas SMOTE, which showed a positive effect specifically with BERT-based models.\nHowever, hyperparameter optimization significantly improved accuracy across the\nmodels, enhancing their ability to generalize and perform on the dataset. The\nDecision Tree and eXtreme Gradient Boost models achieved the highest accuracy\namong machine learning approaches, both reaching 96%, while the DistilBERT and\nSciBERT models also attained 96% accuracy in the deep learning category. These\nfindings underscore the importance of hyperparameter tuning in maximizing model\nperformance. This study contributes to the ongoing research on AI-assisted\ndiagnostic tools in mental health by providing insights into the efficacy of\ndifferent model architectures and data balancing methods.\n","authors":["Sergio Rubio-Martín","María Teresa García-Ordás","Antonio Serrano-García","Clara Margarita Franch-Pato","Arturo Crespo-Álvaro","José Alberto Benítez-Andrades"],"pdf_url":"https://arxiv.org/pdf/2508.00695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.21910v2","updated":"2025-08-01T14:57:07Z","published":"2025-06-27T04:53:07Z","title":"AutoMixer: Checkpoint Artifacts as Automatic Data Mixers","summary":"  In language model training, it is desirable to equip models with capabilities\nfrom various tasks. However, it is not clear how to directly obtain the right\ndata mixtures for these capabilities as the relationship between data and tasks\nis difficult to be modeled. In this work, we observe that checkpoint models\nexhibit emerging capabilities at different points in the training trajectory.\nOften, the training process saves checkpoints as artifacts that are\nunder-utilized as a source of in-training data signals. We identify these\nartifact models based on their respective capabilities on the benchmarks and\nleverage them as data mixers by using their aggregated first-order influence\napproximation over source data. We demonstrated on eight reasoning benchmarks\nthat the proposed framework shows significant improvements in the pretraining\nsetting, with performance improvements of up to 1.93%. Overall, this shows the\npotential of checkpoint models to enhance data quality and optimize data\nmixtures.\n","authors":["Ernie Chang","Yang Li","Patrick Huber","Vish Vogeti","David Kant","Yangyang Shi","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2506.21910v2.pdf","comment":"Accepted at ACL 2025"},{"id":"http://arxiv.org/abs/2508.00680v1","updated":"2025-08-01T14:49:50Z","published":"2025-08-01T14:49:50Z","title":"Better Call Claude: Can LLMs Detect Changes of Writing Style?","summary":"  This article explores the zero-shot performance of state-of-the-art large\nlanguage models (LLMs) on one of the most challenging tasks in authorship\nanalysis: sentence-level style change detection. Benchmarking four LLMs on the\nofficial PAN~2024 and 2025 \"Multi-Author Writing Style Analysis\" datasets, we\npresent several observations. First, state-of-the-art generative models are\nsensitive to variations in writing style - even at the granular level of\nindividual sentences. Second, their accuracy establishes a challenging baseline\nfor the task, outperforming suggested baselines of the PAN competition.\nFinally, we explore the influence of semantics on model predictions and present\nevidence suggesting that the latest generation of LLMs may be more sensitive to\ncontent-independent and purely stylistic signals than previously reported.\n","authors":["Johannes Römisch","Svetlana Gorovaia","Mariia Halchynska","Gleb Schmidt","Ivan P. Yamshchikov"],"pdf_url":"https://arxiv.org/pdf/2508.00680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00679v1","updated":"2025-08-01T14:49:33Z","published":"2025-08-01T14:49:33Z","title":"Segment First, Retrieve Better: Realistic Legal Search via Rhetorical\n  Role-Based Queries","summary":"  Legal precedent retrieval is a cornerstone of the common law system, governed\nby the principle of stare decisis, which demands consistency in judicial\ndecisions. However, the growing complexity and volume of legal documents\nchallenge traditional retrieval methods. TraceRetriever mirrors real-world\nlegal search by operating with limited case information, extracting only\nrhetorically significant segments instead of requiring complete documents. Our\npipeline integrates BM25, Vector Database, and Cross-Encoder models, combining\ninitial results through Reciprocal Rank Fusion before final re-ranking.\nRhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier\ntrained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,\nTraceRetriever addresses growing document volume challenges while aligning with\npractical search constraints, reliable and scalable foundation for precedent\nretrieval enhancing legal research when only partial case knowledge is\navailable.\n","authors":["Shubham Kumar Nigam","Tanmay Dubey","Noel Shallum","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2508.00679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00675v1","updated":"2025-08-01T14:48:17Z","published":"2025-08-01T14:48:17Z","title":"Team \"better_call_claude\": Style Change Detection using a Sequential\n  Sentence Pair Classifier","summary":"  Style change detection - identifying the points in a document where writing\nstyle shifts - remains one of the most important and challenging problems in\ncomputational authorship analysis. At PAN 2025, the shared task challenges\nparticipants to detect style switches at the most fine-grained level:\nindividual sentences. The task spans three datasets, each designed with\ncontrolled and increasing thematic variety within documents. We propose to\naddress this problem by modeling the content of each problem instance - that\nis, a series of sentences - as a whole, using a Sequential Sentence Pair\nClassifier (SSPC). The architecture leverages a pre-trained language model\n(PLM) to obtain representations of individual sentences, which are then fed\ninto a bidirectional LSTM (BiLSTM) to contextualize them within the document.\nThe BiLSTM-produced vectors of adjacent sentences are concatenated and passed\nto a multi-layer perceptron for prediction per adjacency. Building on the work\nof previous PAN participants classical text segmentation, the approach is\nrelatively conservative and lightweight. Nevertheless, it proves effective in\nleveraging contextual information and addressing what is arguably the most\nchallenging aspect of this year's shared task: the notorious problem of\n\"stylistically shallow\", short sentences that are prevalent in the proposed\nbenchmark data. Evaluated on the official PAN-2025 test datasets, the model\nachieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,\nand HARD data, respectively, outperforming not only the official random\nbaselines but also a much more challenging one: claude-3.7-sonnet's zero-shot\nperformance.\n","authors":["Gleb Schmidt","Johannes Römisch","Mariia Halchynska","Svetlana Gorovaia","Ivan P. Yamshchikov"],"pdf_url":"https://arxiv.org/pdf/2508.00675v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00673v1","updated":"2025-08-01T14:46:57Z","published":"2025-08-01T14:46:57Z","title":"MELAC: Massive Evaluation of Large Language Models with Alignment of\n  Culture in Persian Language","summary":"  As large language models (LLMs) become increasingly embedded in our daily\nlives, evaluating their quality and reliability across diverse contexts has\nbecome essential. While comprehensive benchmarks exist for assessing LLM\nperformance in English, there remains a significant gap in evaluation resources\nfor other languages. Moreover, because most LLMs are trained primarily on data\nrooted in European and American cultures, they often lack familiarity with\nnon-Western cultural contexts. To address this limitation, our study focuses on\nthe Persian language and Iranian culture. We introduce 19 new evaluation\ndatasets specifically designed to assess LLMs on topics such as Iranian law,\nPersian grammar, Persian idioms, and university entrance exams. Using these\ndatasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing\ncultural and linguistic evaluation gap in the field.\n","authors":["Farhan Farsi","Farnaz Aghababaloo","Shahriar Shariati Motlagh","Parsa Ghofrani","MohammadAli SadraeiJavaheri","Shayan Bali","Amirhossein Shabani","Farbod Bijary","Ghazal Zamaninejad","AmirMohammad Salehoof","Saeedeh Momtazi"],"pdf_url":"https://arxiv.org/pdf/2508.00673v1.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2508.00669v1","updated":"2025-08-01T14:41:31Z","published":"2025-08-01T14:41:31Z","title":"Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement\n  Techniques and Applications","summary":"  The proliferation of Large Language Models (LLMs) in medicine has enabled\nimpressive capabilities, yet a critical gap remains in their ability to perform\nsystematic, transparent, and verifiable reasoning, a cornerstone of clinical\npractice. This has catalyzed a shift from single-step answer generation to the\ndevelopment of LLMs explicitly designed for medical reasoning. This paper\nprovides the first systematic review of this emerging field. We propose a\ntaxonomy of reasoning enhancement techniques, categorized into training-time\nstrategies (e.g., supervised fine-tuning, reinforcement learning) and test-time\nmechanisms (e.g., prompt engineering, multi-agent systems). We analyze how\nthese techniques are applied across different data modalities (text, image,\ncode) and in key clinical applications such as diagnosis, education, and\ntreatment planning. Furthermore, we survey the evolution of evaluation\nbenchmarks from simple accuracy metrics to sophisticated assessments of\nreasoning quality and visual interpretability. Based on an analysis of 60\nseminal studies from 2022-2025, we conclude by identifying critical challenges,\nincluding the faithfulness-plausibility gap and the need for native multimodal\nreasoning, and outlining future directions toward building efficient, robust,\nand sociotechnically responsible medical AI.\n","authors":["Wenxuan Wang","Zizhan Ma","Meidan Ding","Shiyi Zheng","Shengyuan Liu","Jie Liu","Jiaming Ji","Wenting Chen","Xiang Li","Linlin Shen","Yixuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2508.00669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.08395v2","updated":"2025-08-01T14:26:57Z","published":"2025-02-12T13:37:03Z","title":"IssueBench: Millions of Realistic Prompts for Measuring Issue Bias in\n  LLM Writing Assistance","summary":"  Large language models (LLMs) are helping millions of users write texts about\ndiverse issues, and in doing so expose users to different ideas and\nperspectives. This creates concerns about issue bias, where an LLM tends to\npresent just one perspective on a given issue, which in turn may influence how\nusers think about this issue. So far, it has not been possible to measure which\nissue biases LLMs actually manifest in real user interactions, making it\ndifficult to address the risks from biased LLMs. Therefore, we create\nIssueBench: a set of 2.49m realistic prompts for measuring issue bias in LLM\nwriting assistance, which we construct based on 3.9k templates (e.g. \"write a\nblog about\") and 212 political issues (e.g. \"AI regulation\") from real user\ninteractions. Using IssueBench, we show that issue biases are common and\npersistent in state-of-the-art LLMs. We also show that biases are remarkably\nsimilar across models, and that all models align more with US Democrat than\nRepublican voter opinion on a subset of issues. IssueBench can easily be\nadapted to include other issues, templates, or tasks. By enabling robust and\nrealistic measurement, we hope that IssueBench can bring a new quality of\nevidence to ongoing discussions about LLM biases and how to address them.\n","authors":["Paul Röttger","Musashi Hinck","Valentin Hofmann","Kobi Hackenburg","Valentina Pyatkin","Faeze Brahman","Dirk Hovy"],"pdf_url":"https://arxiv.org/pdf/2502.08395v2.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2508.00659v1","updated":"2025-08-01T14:26:23Z","published":"2025-08-01T14:26:23Z","title":"Demo: TOSense -- What Did You Just Agree to?","summary":"  Online services often require users to agree to lengthy and obscure Terms of\nService (ToS), leading to information asymmetry and legal risks. This paper\nproposes TOSense-a Chrome extension that allows users to ask questions about\nToS in natural language and get concise answers in real time. The system\ncombines (i) a crawler \"tos-crawl\" that automatically extracts ToS content, and\n(ii) a lightweight large language model pipeline: MiniLM for semantic retrieval\nand BART-encoder for answer relevance verification. To avoid expensive manual\nannotation, we present a novel Question Answering Evaluation Pipeline (QEP)\nthat generates synthetic questions and verifies the correctness of answers\nusing clustered topic matching. Experiments on five major platforms, Apple,\nGoogle, X (formerly Twitter), Microsoft, and Netflix, show the effectiveness of\nTOSense (with up to 44.5% accuracy) across varying number of topic clusters.\nDuring the demonstration, we will showcase TOSense in action. Attendees will be\nable to experience seamless extraction, interactive question answering, and\ninstant indexing of new sites.\n","authors":["Xinzhang Chen","Hassan Ali","Arash Shaghaghi","Salil S. Kanhere","Sanjay Jha"],"pdf_url":"https://arxiv.org/pdf/2508.00659v1.pdf","comment":"Accepted as a demonstration paper at IEEE LCN 2025"},{"id":"http://arxiv.org/abs/2508.00619v1","updated":"2025-08-01T13:28:01Z","published":"2025-08-01T13:28:01Z","title":"DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language\n  Models","summary":"  Existing AIG (AI-generated) text detectors struggle in real-world settings\ndespite succeeding in internal testing, suggesting that they may not be robust\nenough. We rigorously examine the machine-learning procedure to build these\ndetectors to address this. Most current AIG text detection datasets focus on\nzero-shot generations, but little work has been done on few-shot or one-shot\ngenerations, where LLMs are given human texts as an example. In response, we\nintroduce the Diverse Adversarial Corpus of Texts Yielded from Language models\n(DACTYL), a challenging AIG text detection dataset focusing on\none-shot/few-shot generations. We also include texts from domain-specific\ncontinued-pre-trained (CPT) language models, where we fully train all\nparameters using a memory-efficient optimization approach. Many existing AIG\ntext detectors struggle significantly on our dataset, indicating a potential\nvulnerability to one-shot/few-shot and CPT-generated texts. We also train our\nown classifiers using two approaches: standard binary cross-entropy (BCE)\noptimization and a more recent approach, deep X-risk optimization (DXO). While\nBCE-trained classifiers marginally outperform DXO classifiers on the DACTYL\ntest set, the latter excels on out-of-distribution (OOD) texts. In our mock\ndeployment scenario in student essay detection with an OOD student essay\ndataset, the best DXO classifier outscored the best BCE-trained classifier by\n50.56 macro-F1 score points at the lowest false positive rates for both. Our\nresults indicate that DXO classifiers generalize better without overfitting to\nthe test set. Our experiments highlight several areas of improvement for AIG\ntext detectors.\n","authors":["Shantanu Thorat","Andrew Caines"],"pdf_url":"https://arxiv.org/pdf/2508.00619v1.pdf","comment":"MPhil in Advanced Computer Science thesis for University of Cambridge"},{"id":"http://arxiv.org/abs/2508.00614v1","updated":"2025-08-01T13:23:21Z","published":"2025-08-01T13:23:21Z","title":"Prompting Science Report 3: I'll pay you or I'll kill you -- but will\n  you care?","summary":"  This is the third in a series of short reports that seek to help business,\neducation, and policy leaders understand the technical details of working with\nAI through rigorous testing. In this report, we investigate two commonly held\nprompting beliefs: a) offering to tip the AI model and b) threatening the AI\nmodel. Tipping was a commonly shared tactic for improving AI performance and\nthreats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,\n8:20) who observed that 'models tend to do better if you threaten them,' a\nclaim we subject to empirical testing here. We evaluate model performance on\nGPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).\n  We demonstrate two things:\n  - Threatening or tipping a model generally has no significant effect on\nbenchmark performance.\n  - Prompt variations can significantly affect performance on a per-question\nlevel. However, it is hard to know in advance whether a particular prompting\napproach will help or harm the LLM's ability to answer any particular question.\n  Taken together, this suggests that simple prompting variations might not be\nas effective as previously assumed, especially for difficult problems. However,\nas reported previously (Meincke et al. 2025a), prompting approaches can yield\nsignificantly different results for individual questions.\n","authors":["Lennart Meincke","Ethan Mollick","Lilach Mollick","Dan Shapiro"],"pdf_url":"https://arxiv.org/pdf/2508.00614v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.12927v2","updated":"2025-08-01T13:19:46Z","published":"2025-02-18T15:09:29Z","title":"SEFL: Enhancing Educational Assignment Feedback with LLM Agents","summary":"  Providing high-quality feedback to student assignments is crucial for student\nsuccess, but it is constrained by time and costs. In this work, we introduce\nSynthetic Educational Feedback Loops (SEFL), a synthetic data framework\ndesigned to generate data that resembles immediate, on-demand feedback at scale\nwithout relying on extensive, real-world student assignments. To get this type\nof data, two large language models (LLMs) operate in teacher-student roles to\nsimulate assignment completion and formative feedback, generating synthetic\npairs of student work and corresponding critiques and actionable improvements\nfrom a teacher. With this data, we fine-tune smaller, more computationally\nefficient LLMs on these synthetic pairs, enabling them to replicate key\nfeatures of high-quality, goal-oriented feedback. Unlike personalized tutoring\napproaches that offer multi-turn, individualized instruction, SEFL specifically\nfocuses on replicating the teacher-student assignment feedback loop in higher\neducation. Through comprehensive evaluations with four LLM judges and three\nhuman experts, we demonstrate that SEFL-tuned models outperform both their\nnon-tuned counterparts in feedback quality and an existing baseline. The\npotential for societal impact is reinforced by extensive qualitative comments\nby ratings by human stakeholders -- both students and higher education\ninstructors. All in all, SEFL has substantial potential to transform feedback\nprocesses for higher education and beyond.\n","authors":["Mike Zhang","Amalie Pernille Dilling","Léon Gondelman","Niels Erik Ruan Lyngdorf","Euan D. Lindsay","Johannes Bjerva"],"pdf_url":"https://arxiv.org/pdf/2502.12927v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00605v1","updated":"2025-08-01T13:08:26Z","published":"2025-08-01T13:08:26Z","title":"GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource\n  Bengali Language","summary":"  Topic modeling is a Natural Language Processing (NLP) technique that is used\nto identify latent themes and extract topics from text corpora by grouping\nsimilar documents based on their most significant keywords. Although widely\nresearched in English, topic modeling remains understudied in Bengali due to\nits morphological complexity, lack of adequate resources and initiatives. In\nthis contribution, a novel Graph Convolutional Network (GCN) based model called\nGHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input\nvectors of documents as nodes in the graph, which GCN uses to produce\nsemantically rich embeddings. The embeddings are then decomposed using\nNon-negative Matrix Factorization (NMF) to get the topical representations of\nthe underlying themes of the text corpus. This study compares the proposed\nmodel against a wide range of Bengali topic modeling techniques, from\ntraditional methods such as LDA, LSA, and NMF to contemporary frameworks such\nas BERTopic and Top2Vec on three Bengali datasets. The experimental results\ndemonstrate the effectiveness of the proposed model by outperforming other\nmodels in topic coherence and diversity. In addition, we introduce a novel\nBengali dataset called \"NCTBText\" sourced from Bengali textbook materials to\nenrich and diversify the predominantly newspaper-centric Bengali corpora.\n","authors":["Farhana Haque","Md. Abdur Rahman","Sumon Ahmed"],"pdf_url":"https://arxiv.org/pdf/2508.00605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00600v1","updated":"2025-08-01T12:58:34Z","published":"2025-08-01T12:58:34Z","title":"A Context-Aware Dual-Metric Framework for Confidence Estimation in Large\n  Language Models","summary":"  Accurate confidence estimation is essential for trustworthy large language\nmodels (LLMs) systems, as it empowers the user to determine when to trust\noutputs and enables reliable deployment in safety-critical applications.\nCurrent confidence estimation methods for LLMs neglect the relevance between\nresponses and contextual information, a crucial factor in output quality\nevaluation, particularly in scenarios where background knowledge is provided.\nTo bridge this gap, we propose CRUX (Context-aware entropy Reduction and\nUnified consistency eXamination), the first framework that integrates context\nfaithfulness and consistency for confidence estimation via two novel metrics.\nFirst, contextual entropy reduction represents data uncertainty with the\ninformation gain through contrastive sampling with and without context. Second,\nunified consistency examination captures potential model uncertainty through\nthe global consistency of the generated answers with and without context.\nExperiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two\ndomain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,\nachieving the highest AUROC than existing baselines.\n","authors":["Mingruo Yuan","Shuyi Zhang","Ben Kao"],"pdf_url":"https://arxiv.org/pdf/2508.00600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00589v1","updated":"2025-08-01T12:41:52Z","published":"2025-08-01T12:41:52Z","title":"Context-based Motion Retrieval using Open Vocabulary Methods for\n  Autonomous Driving","summary":"  Autonomous driving systems must operate reliably in safety-critical\nscenarios, particularly those involving unusual or complex behavior by\nVulnerable Road Users (VRUs). Identifying these edge cases in driving datasets\nis essential for robust evaluation and generalization, but retrieving such rare\nhuman behavior scenarios within the long tail of large-scale datasets is\nchallenging. To support targeted evaluation of autonomous driving systems in\ndiverse, human-centered scenarios, we propose a novel context-aware motion\nretrieval framework. Our method combines Skinned Multi-Person Linear\n(SMPL)-based motion sequences and corresponding video frames before encoding\nthem into a shared multimodal embedding space aligned with natural language.\nOur approach enables the scalable retrieval of human behavior and their context\nthrough text queries. This work also introduces our dataset WayMoCo, an\nextension of the Waymo Open Dataset. It contains automatically labeled motion\nand scene context descriptions derived from generated pseudo-ground-truth SMPL\nsequences and corresponding image data. Our approach outperforms\nstate-of-the-art models by up to 27.5% accuracy in motion-context retrieval,\nwhen evaluated on the WayMoCo dataset.\n","authors":["Stefan Englmeier","Max A. Büttner","Katharina Winter","Fabian B. Flohr"],"pdf_url":"https://arxiv.org/pdf/2508.00589v1.pdf","comment":"9 pages, 10 figure, project page\n  https://iv.ee.hm.edu/contextmotionclip/, submitted to IEEE Transactions on\n  Intelligent Vehicles (T-IV), This work has been submitted to the IEEE for\n  possible publication"},{"id":"http://arxiv.org/abs/2508.00574v1","updated":"2025-08-01T12:17:35Z","published":"2025-08-01T12:17:35Z","title":"SynAdapt: Learning Adaptive Reasoning in Large Language Models via\n  Synthetic Continuous Chain-of-Thought","summary":"  While Chain-of-Thought (CoT) reasoning improves model performance, it incurs\nsignificant time costs due to the generation of discrete CoT tokens (DCoT).\nContinuous CoT (CCoT) offers a more efficient alternative, but existing CCoT\nmethods are hampered by indirect fine-tuning, limited alignment, or\ninconsistent targets. To overcome these limitations, we propose\n\\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,\n\\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and\neffective alignment target for LLMs. This synthetic CCoT explicitly guides the\nLLM to learn CCoT and derive accurate answers directly. Furthermore, relying\nsolely on CCoT is insufficient for solving hard questions. To address this,\n\\textit{SynAdapt} integrates a difficulty classifier that leverages both\nquestion context and CCoT to identify hard questions. CCoT can effectively help\nidentify hard questions after some brief reasoning. We then adaptively prompt\nthe LLM to re-think these hard questions for improved performance. Extensive\nexperimental results across various benchmarks from different difficulty levels\nstrongly demonstrate the effectiveness of our method, achieving the best\naccuracy-efficiency trade-off.\n","authors":["Jianwei Wang","Ziming Wu","Fuming Lai","Shaobing Lian","Ziqian Zeng"],"pdf_url":"https://arxiv.org/pdf/2508.00574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00555v1","updated":"2025-08-01T11:52:24Z","published":"2025-08-01T11:52:24Z","title":"Activation-Guided Local Editing for Jailbreaking Attacks","summary":"  Jailbreaking is an essential adversarial technique for red-teaming these\nmodels to uncover and patch security flaws. However, existing jailbreak methods\nface significant drawbacks. Token-level jailbreak attacks often produce\nincoherent or unreadable inputs and exhibit poor transferability, while\nprompt-level attacks lack scalability and rely heavily on manual effort and\nhuman ingenuity. We propose a concise and effective two-stage framework that\ncombines the advantages of these approaches. The first stage performs a\nscenario-based generation of context and rephrases the original malicious query\nto obscure its harmful intent. The second stage then utilizes information from\nthe model's hidden states to guide fine-grained edits, effectively steering the\nmodel's internal representation of the input from a malicious toward a benign\none. Extensive experiments demonstrate that this method achieves\nstate-of-the-art Attack Success Rate, with gains of up to 37.74% over the\nstrongest baseline, and exhibits excellent transferability to black-box models.\nOur analysis further demonstrates that AGILE maintains substantial\neffectiveness against prominent defense mechanisms, highlighting the\nlimitations of current safeguards and providing valuable insights for future\ndefense development. Our code is available at\nhttps://github.com/yunsaijc/AGILE.\n","authors":["Jiecong Wang","Haoran Li","Hao Peng","Ziqian Zeng","Zihao Wang","Haohua Du","Zhengtao Yu"],"pdf_url":"https://arxiv.org/pdf/2508.00555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00554v1","updated":"2025-08-01T11:48:13Z","published":"2025-08-01T11:48:13Z","title":"ContestTrade: A Multi-Agent Trading System Based on Internal Contest\n  Mechanism","summary":"  In financial trading, large language model (LLM)-based agents demonstrate\nsignificant potential. However, the high sensitivity to market noise undermines\nthe performance of LLM-based trading systems. To address this limitation, we\npropose a novel multi-agent system featuring an internal competitive mechanism\ninspired by modern corporate management structures. The system consists of two\nspecialized teams: (1) Data Team - responsible for processing and condensing\nmassive market data into diversified text factors, ensuring they fit the\nmodel's constrained context. (2) Research Team - tasked with making\nparallelized multipath trading decisions based on deep research methods. The\ncore innovation lies in implementing a real-time evaluation and ranking\nmechanism within each team, driven by authentic market feedback. Each agent's\nperformance undergoes continuous scoring and ranking, with only outputs from\ntop-performing agents being adopted. The design enables the system to\nadaptively adjust to dynamic environment, enhances robustness against market\nnoise and ultimately delivers superior trading performance. Experimental\nresults demonstrate that our proposed system significantly outperforms\nprevailing multiagent systems and traditional quantitative investment methods\nacross diverse evaluation metrics.\n","authors":["Li Zhao","Rui Sun","Zuoyou Jiang","Bo Yang","Yuxiao Bai","Mengting Chen","Xinyang Wang","Jing Li","Zuo Bai"],"pdf_url":"https://arxiv.org/pdf/2508.00554v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00544v1","updated":"2025-08-01T11:33:45Z","published":"2025-08-01T11:33:45Z","title":"PaPaformer: Language Model from Pre-trained Paraller Paths","summary":"  The training of modern large-language models requires an increasingly amount\nof computation power and time. Even smaller variants, such as small-language\nmodels (SLMs), take several days to train in the best-case scenarios, often\nrequiring multiple GPUs. This paper explores methods to train and evaluate\ndecoder-only transformer-based language models in hours instead of days/weeks.\nWe introduces \\textit{PaPaformer}, a decoder-only transformer architecture\nvariant, whose lower-dimensional parallel paths are combined into larger model.\nThe paper shows that these lower-dimensional paths can be trained individually\nwith different types of training data and then combined into one larger model.\nThis method gives the option to reduce the total number of model parameters and\nthe training time with increasing performance. Moreover, the use of parallel\npath structure opens interesting possibilities to customize paths to\naccommodate specific task requirements.\n","authors":["Joonas Tapaninaho","Mourad Oussala"],"pdf_url":"https://arxiv.org/pdf/2508.00544v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00537v1","updated":"2025-08-01T11:24:12Z","published":"2025-08-01T11:24:12Z","title":"The Prosody of Emojis","summary":"  Prosodic features such as pitch, timing, and intonation are central to spoken\ncommunication, conveying emotion, intent, and discourse structure. In\ntext-based settings, where these cues are absent, emojis act as visual\nsurrogates that add affective and pragmatic nuance. This study examines how\nemojis influence prosodic realisation in speech and how listeners interpret\nprosodic cues to recover emoji meanings. Unlike previous work, we directly link\nprosody and emoji by analysing actual human speech data, collected through\nstructured but open-ended production and perception tasks. This provides\nempirical evidence of how emoji semantics shape spoken delivery and perception.\nResults show that speakers adapt their prosody based on emoji cues, listeners\ncan often identify the intended emoji from prosodic variation alone, and\ngreater semantic differences between emojis correspond to increased prosodic\ndivergence. These findings suggest that emojis can act as meaningful carriers\nof prosodic intent, offering insight into their communicative role in digitally\nmediated contexts.\n","authors":["Giulio Zhou","Tsz Kin Lam","Alexandra Birch","Barry Haddow"],"pdf_url":"https://arxiv.org/pdf/2508.00537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00534v1","updated":"2025-08-01T11:19:40Z","published":"2025-08-01T11:19:40Z","title":"Towards a unified framework for programming paradigms: A systematic\n  review of classification formalisms and methodological foundations","summary":"  The rise of multi-paradigm languages challenges traditional classification\nmethods, leading to practical software engineering issues like interoperability\ndefects. This systematic literature review (SLR) maps the formal foundations of\nprogramming paradigms. Our objective is twofold: (1) to assess the state of the\nart of classification formalisms and their limitations, and (2) to identify the\nconceptual primitives and mathematical frameworks for a more powerful,\nreconstructive approach.\n  Based on a synthesis of 74 primary studies, we find that existing taxonomies\nlack conceptual granularity, a unified formal basis, and struggle with hybrid\nlanguages. In response, our analysis reveals a strong convergence toward a\ncompositional reconstruction of paradigms. This approach identifies a minimal\nset of orthogonal, atomic primitives and leverages mathematical frameworks,\npredominantly Type theory, Category theory and Unifying Theories of Programming\n(UTP), to formally guarantee their compositional properties.\n  We conclude that the literature reflects a significant intellectual shift\naway from classification towards these promising formal, reconstructive\nframeworks. This review provides a map of this evolution and proposes a\nresearch agenda for their unification.\n","authors":["Mikel Vandeloise"],"pdf_url":"https://arxiv.org/pdf/2508.00534v1.pdf","comment":"Preprint submitted to the Journal of Object Technology on July 29,\n  2025. Data available upon request until peer-review is completed"},{"id":"http://arxiv.org/abs/2508.00522v1","updated":"2025-08-01T10:59:49Z","published":"2025-08-01T10:59:49Z","title":"EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in\n  Fine-Tuning Large Language Models and Beyond","summary":"  Little research explores the correlation between the expressive ability and\ngeneralization ability of the low-rank adaptation (LoRA). Sharpness-Aware\nMinimization (SAM) improves model generalization for both Convolutional Neural\nNetworks (CNNs) and Transformers by encouraging convergence to locally flat\nminima. However, the connection between sharpness and generalization has not\nbeen fully explored for LoRA due to the lack of tools to either empirically\nseek flat minima or develop theoretical methods. In this work, we propose\nFlat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for\nLoRA. Concretely, we theoretically demonstrate that perturbations in the full\nparameter space can be transferred to the low-rank subspace. This approach\neliminates the potential interference introduced by perturbations across\nmultiple matrices in the low-rank subspace. Our extensive experiments on large\nlanguage models and vision-language models demonstrate that EFlat-LoRA achieves\noptimize efficiency comparable to that of LoRA while simultaneously attaining\ncomparable or even better performance. For example, on the GLUE dataset with\nRoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and\n0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat\nshows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,\nrespectively. These empirical results also verify that the generalization of\nLoRA is closely related to sharpness, which is omitted by previous methods.\n","authors":["Jiaxin Deng","Qingcheng Zhu","Junbiao Pang","Linlin Yang","Zhongqian Fu","Baochang Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.00522v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.16248v2","updated":"2025-08-01T10:57:18Z","published":"2025-07-22T05:40:25Z","title":"FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation\n  Framework for Financial Research Agents","summary":"  Recently, AI agents are rapidly evolving in intelligence and widely used in\nprofessional research applications, such as STEM, software development,\nfinance, etc. Among these AI agents, deep research agent is a key category as\nit can perform long-horizon tasks and solve problems of greater complexity.\nHowever, there are few evaluation frameworks and benchmarks that systematically\nand automatically investigate the capabilities of these research agents.\nFurthermore, financial research problems have distinct complexity and subtlety.\nTo fill in the gap, we propose FinResearchBench, which is a logic tree based\nAgent-as-a-Judge and targets specifically for the financial research agents. It\nprovides a comprehensive and automatic assessment of the research agents across\n7 key types of tasks in the financial research domain. The contributions of\nthis work are two-folded: (1) the first and innovative Agent-as-a-Judge system\nthat extracts the logic tree of the research outcome and uses it as the\nintermediate information to present a comprehensive, reliable and robust\nevaluation; (2) finance oriented that it covers 70 typical financial research\nquestions, spreading across 7 frequently encountered types of tasks in the\ndomain.\n","authors":["Rui Sun","Zuo Bai","Wentao Zhang","Yuxiang Zhang","Li Zhao","Shan Sun","Zhengwen Qiu"],"pdf_url":"https://arxiv.org/pdf/2507.16248v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.19693v2","updated":"2025-08-01T10:53:31Z","published":"2025-03-25T14:18:21Z","title":"AdaptiVocab: Enhancing LLM Efficiency in Focused Domains through\n  Lightweight Vocabulary Adaptation","summary":"  Large Language Models (LLMs) have shown impressive versatility as general\npurpose models. However, their broad applicability comes at a high-cost\ncomputational overhead, particularly in auto-regressive decoding where each\nstep requires a forward pass. In domain-specific settings, general-purpose\ncapabilities are unnecessary and can be exchanged for efficiency. In this work,\nwe take a novel perspective on domain adaptation, reducing latency and\ncomputational costs by adapting the vocabulary to focused domains of interest.\nWe introduce AdaptiVocab, an end-to-end approach for vocabulary adaptation,\ndesigned to enhance LLM efficiency in low-resource domains. AdaptiVocab can be\napplied to any tokenizer and architecture, modifying the vocabulary by\nreplacing tokens with domain-specific n-gram-based tokens, thereby reducing the\nnumber of tokens required for both input processing and output generation.\nAdaptiVocab initializes new n-token embeddings using an exponentially weighted\ncombination of existing embeddings and employs a lightweight fine-tuning phase\nthat can be efficiently performed on a single GPU. We evaluate two 7B LLMs\nacross three niche domains, assessing efficiency, generation quality, and\nend-task performance. Our results show that AdaptiVocab reduces token usage by\nover 25% without compromising performance\n","authors":["Itay Nakash","Nitay Calderon","Eyal Ben David","Elad Hoffer","Roi Reichart"],"pdf_url":"https://arxiv.org/pdf/2503.19693v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00518v1","updated":"2025-08-01T10:53:27Z","published":"2025-08-01T10:53:27Z","title":"Fine-grained Spatiotemporal Grounding on Egocentric Videos","summary":"  Spatiotemporal video grounding aims to localize target entities in videos\nbased on textual queries. While existing research has made significant progress\nin exocentric videos, the egocentric setting remains relatively underexplored,\ndespite its growing importance in applications such as augmented reality and\nrobotics. In this work, we conduct a systematic analysis of the discrepancies\nbetween egocentric and exocentric videos, revealing key challenges such as\nshorter object durations, sparser trajectories, smaller object sizes, and\nlarger positional shifts. To address these challenges, we introduce EgoMask,\nthe first pixel-level benchmark for fine-grained spatiotemporal grounding in\negocentric videos. It is constructed by our proposed automatic annotation\npipeline, which annotates referring expressions and object masks across short-,\nmedium-, and long-term videos. Additionally, we create EgoMask-Train, a\nlarge-scale training dataset to facilitate model development. Experiments\ndemonstrate that the state-of-the-art spatiotemporal grounding models perform\npoorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields\nsignificant improvements, while preserving performance on exocentric datasets.\nOur work thus provides essential resources and insights for advancing\negocentric video understanding. Our code is available at\nhttps://github.com/LaVi-Lab/EgoMask .\n","authors":["Shuo Liang","Yiwu Zhong","Zi-Yuan Hu","Yeyao Tao","Liwei Wang"],"pdf_url":"https://arxiv.org/pdf/2508.00518v1.pdf","comment":"Accepted by ICCV 2025"},{"id":"http://arxiv.org/abs/2502.17407v2","updated":"2025-08-01T10:09:29Z","published":"2025-02-24T18:36:15Z","title":"Linguistic Generalizability of Test-Time Scaling in Mathematical\n  Reasoning","summary":"  Scaling pre-training compute has proven effective for achieving\nmulitlinguality, but does the same hold for test-time scaling? In this work, we\nintroduce MCLM, a multilingual math benchmark featuring competition-level\nproblems in 55 languages. We test three test-time scaling methods-Outcome\nReward Modeling (ORM), Process Reward Modeling (ORM), and Budget Forcing\n(BF)-on both Qwen2.5-1.5B Math and MR1-1.5B, a multilingual LLM we trained for\nextended reasoning. Our experiments show that using Qwen2.5-1.5B Math with ORM\nachieves a score of 35.8 on MCLM, while BF on MR1-1.5B attains 35.2. Although\n\"thinking LLMs\" have recently garnered significant attention, we find that\ntheir performance is comparable to traditional scaling methods like best-of-N\nonce constrained to similar levels of inference FLOPs. Moreover, while BF\nyields a 20-point improvement on English AIME, it provides only a 1.94-point\naverage gain across other languages-a pattern consistent across the other\ntest-time scaling methods we studied-higlighting that test-time scaling may not\ngeneralize as effectively to multilingual tasks. To foster further research, we\nrelease MCLM, MR1-1.5B, and evaluation results.\n","authors":["Guijin Son","Jiwoo Hong","Hyunwoo Ko","James Thorne"],"pdf_url":"https://arxiv.org/pdf/2502.17407v2.pdf","comment":"ACL 2025 (ORAL)"},{"id":"http://arxiv.org/abs/2507.22462v2","updated":"2025-08-01T10:07:37Z","published":"2025-07-30T08:08:48Z","title":"IFEvalCode: Controlled Code Generation","summary":"  Code large language models (Code LLMs) have made significant progress in code\ngeneration by translating natural language descriptions into functional code;\nhowever, real-world applications often demand stricter adherence to detailed\nrequirements such as coding style, line count, and structural constraints,\nbeyond mere correctness. To address this, the paper introduces forward and\nbackward constraints generation to improve the instruction-following\ncapabilities of Code LLMs in controlled code generation, ensuring outputs align\nmore closely with human-defined guidelines. The authors further present\nIFEvalCode, a multilingual benchmark comprising 1.6K test samples across seven\nprogramming languages (Python, Java, JavaScript, TypeScript, Shell, C++, and\nC#), with each sample featuring both Chinese and English queries. Unlike\nexisting benchmarks, IFEvalCode decouples evaluation into two metrics:\ncorrectness (Corr.) and instruction-following (Instr.), enabling a more nuanced\nassessment. Experiments on over 40 LLMs reveal that closed-source models\noutperform open-source ones in controllable code generation and highlight a\nsignificant gap between the models' ability to generate correct code versus\ncode that precisely follows instructions.\n","authors":["Jian Yang","Wei Zhang","Shukai Liu","Linzheng Chai","Yingshui Tan","Jiaheng Liu","Ge Zhang","Wangchunshu Zhou","Guanglin Niu","Zhoujun Li","Binyuan Hui","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2507.22462v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2502.19651v2","updated":"2025-08-01T10:07:08Z","published":"2025-02-27T00:49:44Z","title":"Unlocking Multi-Modal Potentials for Link Prediction on Dynamic\n  Text-Attributed Graphs","summary":"  Dynamic Text-Attributed Graphs (DyTAGs) are a novel graph paradigm that\ncaptures evolving temporal events (edges) alongside rich textual attributes.\nExisting studies can be broadly categorized into TGNN-driven and LLM-driven\napproaches, both of which encode textual attributes and temporal structures for\nDyTAG representation. We observe that DyTAGs inherently comprise three distinct\nmodalities: temporal, textual, and structural, often exhibiting completely\ndisjoint distributions. However, the first two modalities are largely\noverlooked by existing studies, leading to suboptimal performance. To address\nthis, we propose MoMent, a multi-modal model that explicitly models,\nintegrates, and aligns each modality to learn node representations for link\nprediction. Given the disjoint nature of the original modality distributions,\nwe first construct modality-specific features and encode them using individual\nencoders to capture correlations across temporal patterns, semantic context,\nand local structures. Each encoder generates modality-specific tokens, which\nare then fused into comprehensive node representations with a theoretical\nguarantee. To avoid disjoint subspaces of these heterogeneous modalities, we\npropose a dual-domain alignment loss that first aligns their distributions\nglobally and then fine-tunes coherence at the instance level. This enhances\ncoherent representations from temporal, textual, and structural views.\nExtensive experiments across seven datasets show that MoMent achieves up to\n17.28% accuracy improvement and up to 31x speed-up against eight baselines.\n","authors":["Yuanyuan Xu","Wenjie Zhang","Ying Zhang","Xuemin Lin","Xiwei Xu"],"pdf_url":"https://arxiv.org/pdf/2502.19651v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00489v1","updated":"2025-08-01T10:06:38Z","published":"2025-08-01T10:06:38Z","title":"The Missing Parts: Augmenting Fact Verification with Half-Truth\n  Detection","summary":"  Fact verification systems typically assess whether a claim is supported by\nretrieved evidence, assuming that truthfulness depends solely on what is\nstated. However, many real-world claims are half-truths, factually correct yet\nmisleading due to the omission of critical context. Existing models struggle\nwith such cases, as they are not designed to reason about what is left unsaid.\nWe introduce the task of half-truth detection, and propose PolitiFact-Hidden, a\nnew benchmark with 15k political claims annotated with sentence-level evidence\nalignment and inferred claim intent. To address this challenge, we present\nTRACER, a modular re-assessment framework that identifies omission-based\nmisinformation by aligning evidence, inferring implied intent, and estimating\nthe causal impact of hidden content. TRACER can be integrated into existing\nfact-checking pipelines and consistently improves performance across multiple\nstrong baselines. Notably, it boosts Half-True classification F1 by up to 16\npoints, highlighting the importance of modeling omissions for trustworthy fact\nverification.\n","authors":["Yixuan Tang","Jincheng Wang","Anthony K. H. Tung"],"pdf_url":"https://arxiv.org/pdf/2508.00489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00476v1","updated":"2025-08-01T09:51:05Z","published":"2025-08-01T09:51:05Z","title":"GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting\n  Transcripts","summary":"  This paper documents GETALP's submission to the Third Run of the Automatic\nMinuting Shared Task at SIGDial 2025. We participated in Task B:\nquestion-answering based on meeting transcripts. Our method is based on a\nretrieval augmented generation (RAG) system and Abstract Meaning\nRepresentations (AMR). We propose three systems combining these two approaches.\nOur results show that incorporating AMR leads to high-quality responses for\napproximately 35% of the questions and provides notable improvements in\nanswering questions that involve distinguishing between different participants\n(e.g., who questions).\n","authors":["Jeongwoo Kang","Markarit Vartampetian","Felix Herron","Yongxin Zhou","Diandra Fabre","Gabriela Gonzalez-Saez"],"pdf_url":"https://arxiv.org/pdf/2508.00476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.02962v4","updated":"2025-08-01T09:41:05Z","published":"2025-06-30T09:02:45Z","title":"RAG-R1 : Incentivize the Search and Reasoning Capabilities of LLMs\n  through Multi-query Parallelism","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities across\nvarious tasks, while LLMs remain prone to generating hallucinated or outdated\nresponses due to their static internal knowledge. Recent advancements in\nRetrieval-Augmented Generation (RAG) methods have aimed to enhance models'\nsearch and reasoning capabilities through reinforcement learning (RL). Although\nthese methods demonstrate promising results, they face challenges in training\nstability and encounter issues such as substantial inference time and\nrestricted capabilities due to reliance on single-query mode. In this paper, we\npropose RAG-R1, a novel training framework designed to enable LLMs to\nadaptively leverage internal and external knowledge during the reasoning\nprocess. We further expand the generation and retrieval processes within the\nframework from single-query mode to multi-query parallelism, with the aim of\nreducing inference time and enhancing the model's capabilities. Extensive\nexperiments on seven question-answering benchmarks demonstrate that our method\noutperforms the strongest baseline by up to 13.2% and decreases inference time\nby 11.1%.\n","authors":["Zhiwen Tan","Jiaming Huang","Qintong Wu","Hongxuan Zhang","Chenyi Zhuang","Jinjie Gu"],"pdf_url":"https://arxiv.org/pdf/2507.02962v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00454v1","updated":"2025-08-01T09:26:01Z","published":"2025-08-01T09:26:01Z","title":"Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges","summary":"  Evaluating the conversational abilities of large language models (LLMs)\nremains a challenging task. Current mainstream approaches primarily rely on the\n``LLM-as-a-judge\" paradigm, where an LLM is prompted to serve as an evaluator\nto assess dialogue quality. However, such methods often suffer from various\nbiases, which undermine the reliability and consistency of the evaluation\nresults. To mitigate these biases, recent methods employ multiple LLMs as\njudges and aggregate their judgments to select the optimal assessment. Although\neffective, this multi-judge approach incurs significant computational overhead\nduring inference. In this paper, we propose an efficient multi-turn dialogue\nevaluator that captures the collective wisdom of multiple LLM judges by\naggregating their preference knowledge into a single model. Our approach\npreserves the advantages of diverse multi-judge feedback while drastically\nreducing the evaluation cost, enabling fast and flexible dialogue quality\nassessment. Extensive experiments on seven single rating and pairwise\ncomparison dialogue evaluation benchmarks demonstrate that our method\noutperforms existing baselines across diverse scenarios, showcasing its\nefficiency and robustness.\n","authors":["Yuqi Tang","Kehua Feng","Yunfeng Wang","Zhiwen Chen","Chengfei Lv","Gang Yu","Qiang Zhang","Keyan Ding"],"pdf_url":"https://arxiv.org/pdf/2508.00454v1.pdf","comment":"15 pages, 2 pages, under review at AAAI 2026"},{"id":"http://arxiv.org/abs/2402.02364v3","updated":"2025-08-01T09:20:40Z","published":"2024-02-04T06:23:05Z","title":"Loss Landscape Degeneracy and Stagewise Development in Transformers","summary":"  Deep learning involves navigating a high-dimensional loss landscape over the\nneural network parameter space. Over the course of training, complex\ncomputational structures form and re-form inside the neural network, leading to\nshifts in input/output behavior. It is a priority for the science of deep\nlearning to uncover principles governing the development of neural network\nstructure and behavior. Drawing on the framework of singular learning theory,\nwe propose that model development is deeply linked to degeneracy in the local\ngeometry of the loss landscape. We investigate this link by monitoring loss\nlandscape degeneracy throughout training, as quantified by the local learning\ncoefficient, for a transformer language model and an in-context linear\nregression transformer. We show that training can be divided into distinct\nperiods of change in loss landscape degeneracy, and that these changes in\ndegeneracy coincide with significant changes in the internal computational\nstructure and the input/output behavior of the transformers. This finding\nprovides suggestive evidence that degeneracy and development are linked in\ntransformers, underscoring the potential of a degeneracy-based perspective for\nunderstanding modern deep learning.\n","authors":["Jesse Hoogland","George Wang","Matthew Farrugia-Roberts","Liam Carroll","Susan Wei","Daniel Murfet"],"pdf_url":"https://arxiv.org/pdf/2402.02364v3.pdf","comment":"To appear, TMLR. Material on essential dynamics from v1 of this\n  preprint has been removed and developed in arXiv:2501.17745"},{"id":"http://arxiv.org/abs/2507.16974v2","updated":"2025-08-01T09:04:46Z","published":"2025-07-22T19:25:10Z","title":"Leveraging Synthetic Data for Question Answering with Multilingual LLMs\n  in the Agricultural Domain","summary":"  Enabling farmers to access accurate agriculture-related information in their\nnative languages in a timely manner is crucial for the success of the\nagriculture field. Publicly available general-purpose Large Language Models\n(LLMs) typically offer generic agriculture advisories, lacking precision in\nlocal and multilingual contexts. Our study addresses this limitation by\ngenerating multilingual (English, Hindi, Punjabi) synthetic datasets from\nagriculture-specific documents from India and fine-tuning LLMs for the task of\nquestion answering (QA). Evaluation on human-created datasets demonstrates\nsignificant improvements in factuality, relevance, and agricultural consensus\nfor the fine-tuned LLMs compared to the baseline counterparts.\n","authors":["Rishemjit Kaur","Arshdeep Singh Bhankhar","Jashanpreet Singh Salh","Sudhir Rajput"," Vidhi","Kashish Mahendra","Bhavika Berwal","Ritesh Kumar","Surangika Ranathunga"],"pdf_url":"https://arxiv.org/pdf/2507.16974v2.pdf","comment":"16 pages, 9 tables, Appendix A-L"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2507.18365v3","updated":"2025-08-01T17:19:56Z","published":"2025-07-24T12:46:30Z","title":"RecPS: Privacy Risk Scoring for Recommender Systems","summary":"  Recommender systems (RecSys) have become an essential component of many web\napplications. The core of the system is a recommendation model trained on\nhighly sensitive user-item interaction data. While privacy-enhancing techniques\nare actively studied in the research community, the real-world model\ndevelopment still depends on minimal privacy protection, e.g., via controlled\naccess. Users of such systems should have the right to choose \\emph{not} to\nshare highly sensitive interactions. However, there is no method allowing the\nuser to know which interactions are more sensitive than others. Thus,\nquantifying the privacy risk of RecSys training data is a critical step to\nenabling privacy-aware RecSys model development and deployment. We propose a\nmembership-inference attack (MIA)- based privacy scoring method, RecPS, to\nmeasure privacy risks at both the interaction and user levels. The RecPS\ninteraction-level score definition is motivated and derived from differential\nprivacy, which is then extended to the user-level scoring method. A critical\ncomponent is the interaction-level MIA method RecLiRA, which gives high-quality\nmembership estimation. We have conducted extensive experiments on well-known\nbenchmark datasets and RecSys models to show the unique features and benefits\nof RecPS scoring in risk assessment and RecSys model unlearning.\n","authors":["Jiajie He","Yuechun Gu","Keke Chen"],"pdf_url":"https://arxiv.org/pdf/2507.18365v3.pdf","comment":"Accepted by ACM RecSys 2025; to appear"},{"id":"http://arxiv.org/abs/2507.08336v2","updated":"2025-08-01T22:33:29Z","published":"2025-07-11T06:28:35Z","title":"Distillation versus Contrastive Learning: How to Train Your Rerankers","summary":"  Training effective text rerankers is crucial for information retrieval. Two\nstrategies are widely used: contrastive learning (optimizing directly on\nground-truth labels) and knowledge distillation (transferring knowledge from a\nlarger reranker). While both have been studied extensively, a clear comparison\nof their effectiveness for training cross-encoder rerankers under practical\nconditions is needed.\n  This paper empirically compares these strategies by training rerankers of\ndifferent sizes and architectures using both methods on the same data, with a\nstrong contrastive learning model acting as the distillation teacher. Our\nresults show that knowledge distillation generally yields better in-domain and\nout-of-domain ranking performance than contrastive learning when distilling\nfrom a larger teacher model. This finding is consistent across student model\nsizes and architectures. However, distilling from a teacher of the same\ncapacity does not provide the same advantage, particularly for out-of-domain\ntasks. These findings offer practical guidance for choosing a training strategy\nbased on available teacher models. We recommend using knowledge distillation to\ntrain smaller rerankers if a larger, more powerful teacher is accessible; in\nits absence, contrastive learning remains a robust baseline.\n","authors":["Zhichao Xu","Zhiqi Huang","Shengyao Zhuang","Vivek Srikumar"],"pdf_url":"https://arxiv.org/pdf/2507.08336v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01096v1","updated":"2025-08-01T22:22:35Z","published":"2025-08-01T22:22:35Z","title":"Cross-Domain Web Information Extraction at Pinterest","summary":"  The internet offers a massive repository of unstructured information, but\nit's a significant challenge to convert this into a structured format. At\nPinterest, the ability to accurately extract structured product data from\ne-commerce websites is essential to enhance user experiences and improve\ncontent distribution. In this paper, we present Pinterest's system for\nattribute extraction, which achieves remarkable accuracy and scalability at a\nmanageable cost. Our approach leverages a novel webpage representation that\ncombines structural, visual, and text modalities into a compact form,\noptimizing it for small model learning. This representation captures each\nvisible HTML node with its text, style and layout information. We show how this\nallows simple models such as eXtreme Gradient Boosting (XGBoost) to extract\nattributes more accurately than much more complex Large Language Models (LLMs)\nsuch as Generative Pre-trained Transformer (GPT). Our results demonstrate a\nsystem that is highly scalable, processing over 1,000 URLs per second, while\nbeing 1000 times more cost-effective than the cheapest GPT alternatives.\n","authors":["Michael Farag","Patrick Halina","Andrey Zaytsev","Alekhya Munagala","Imtihan Ahmed","Junhao Wang"],"pdf_url":"https://arxiv.org/pdf/2508.01096v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01036v1","updated":"2025-08-01T19:28:57Z","published":"2025-08-01T19:28:57Z","title":"Addressing Cold Start For next-article Recommendation","summary":"  This replication study modifies ALMM, the Adaptive Linear Mapping Model\nconstructed for the next song recommendation, to the news recommendation\nproblem on the MIND dataset. The original version of ALMM computes latent\nrepresentations for users, last-time items, and current items in a tensor\nfactorization structure and learns a linear mapping from content features to\nlatent item vectors. Our replication aims to improve recommendation performance\nin cold-start scenarios by restructuring this model to sequential news click\nbehavior, viewing consecutively read articles as (last news, next news) tuples.\nInstead of the original audio features, we apply BERT and a TF-IDF (Term\nFrequency-Inverse Document Frequency) to news titles and abstracts to extract\ntoken contextualized representations and align them with triplet-based user\nreading patterns. We also propose a reproducibly thorough pre-processing\npipeline combining news filtering and feature integrity validation. Our\nimplementation of ALMM with TF-IDF shows relatively improved recommendation\naccuracy and robustness over Forbes and Oord baseline models in the cold-start\nscenario. We demonstrate that ALMM in a minimally modified state is not\nsuitable for next news recommendation.\n","authors":["Omar Elgohary","Nathan Jorgenson","Trenton Marple"],"pdf_url":"https://arxiv.org/pdf/2508.01036v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.08379v2","updated":"2025-08-01T19:19:55Z","published":"2025-03-11T12:39:04Z","title":"JurisTCU: A Brazilian Portuguese Information Retrieval Dataset with\n  Query Relevance Judgments","summary":"  This paper introduces JurisTCU, a Brazilian Portuguese dataset for legal\ninformation retrieval (LIR). The dataset is freely available and consists of\n16,045 jurisprudential documents from the Brazilian Federal Court of Accounts,\nalong with 150 queries annotated with relevance judgments. It addresses the\nscarcity of Portuguese-language LIR datasets with query relevance annotations.\nThe queries are organized into three groups: real user keyword-based queries,\nsynthetic keyword-based queries, and synthetic question-based queries.\nRelevance judgments were produced through a hybrid approach combining LLM-based\nscoring with expert domain validation. We used JurisTCU in 14 experiments using\nlexical search (document expansion methods) and semantic search (BERT-based and\nOpenAI embeddings). We show that the document expansion methods significantly\nimprove the performance of standard BM25 search on this dataset, with\nimprovements exceeding 45% in P@10, R@10, and nDCG@10 metrics when evaluating\nshort keyword-based queries. Among the embedding models, the OpenAI models\nproduced the best results, with improvements of approximately 70% in P@10,\nR@10, and nDCG@10 metrics for short keyword-based queries, suggesting that\nthese dense embeddings capture semantic relationships in this domain,\nsurpassing the reliance on lexical terms. Besides offering a dataset for the\nPortuguese-language IR research community, suitable for evaluating search\nsystems, the results also contribute to enhancing a search system highly\nrelevant to Brazilian citizens.\n","authors":["Leandro Carísio Fernandes","Leandro dos Santos Ribeiro","Marcos Vinícius Borela de Castro","Leonardo Augusto da Silva Pacheco","Edans Flávius de Oliveira Sandes"],"pdf_url":"https://arxiv.org/pdf/2503.08379v2.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2508.01005v1","updated":"2025-08-01T18:15:22Z","published":"2025-08-01T18:15:22Z","title":"MAO-ARAG: Multi-Agent Orchestration for Adaptive Retrieval-Augmented\n  Generation","summary":"  In question-answering (QA) systems, Retrieval-Augmented Generation (RAG) has\nbecome pivotal in enhancing response accuracy and reducing hallucination\nissues. The architecture of RAG systems varies significantly, encompassing\nsingle-round RAG, iterative RAG, and reasoning RAG, each tailored to address\ndifferent types of queries. Due to the varying complexity of real-world\nqueries, a fixed RAG pipeline often struggles to balance performance and cost\nefficiency across different queries. To address this challenge, we propose an\nadaptive RAG framework called MAO-ARAG, which leverages multi-agent\norchestration. Our adaptive RAG is conceived as a multi-turn framework.\nSpecifically, we define multiple executor agents, representing typical RAG\nmodules such as query reformulation agents, document selection agent, and\ngeneration agents. A planner agent intelligently selects and integrates the\nappropriate agents from these executors into a suitable workflow tailored for\neach query, striving for high-quality answers while maintaining reasonable\ncosts. During each turn, the planner agent is trained using reinforcement\nlearning, guided by an outcome-based reward (F1 score) and a cost-based\npenalty, continuously improving answer quality while keeping costs within a\nreasonable range. Experiments conducted on multiple QA datasets demonstrate\nthat our approach, which dynamically plans workflows for each query, not only\nachieves high answer quality but also maintains both cost and latency within\nacceptable limits.The code of MAO-ARAG is on\nhttps://github.com/chenyiqun/Agentic-RAG.\n","authors":["Yiqun Chen","Erhan Zhang","Lingyong Yan","Shuaiqiang Wang","Jizhou Huang","Dawei Yin","Jiaxin Mao"],"pdf_url":"https://arxiv.org/pdf/2508.01005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00751v1","updated":"2025-08-01T16:28:18Z","published":"2025-08-01T16:28:18Z","title":"Harnessing the Power of Interleaving and Counterfactual Evaluation for\n  Airbnb Search Ranking","summary":"  Evaluation plays a crucial role in the development of ranking algorithms on\nsearch and recommender systems. It enables online platforms to create\nuser-friendly features that drive commercial success in a steady and effective\nmanner. The online environment is particularly conducive to applying causal\ninference techniques, such as randomized controlled experiments (known as A/B\ntest), which are often more challenging to implement in fields like medicine\nand public policy. However, businesses face unique challenges when it comes to\neffective A/B test. Specifically, achieving sufficient statistical power for\nconversion-based metrics can be time-consuming, especially for significant\npurchases like booking accommodations. While offline evaluations are quicker\nand more cost-effective, they often lack accuracy and are inadequate for\nselecting candidates for A/B test. To address these challenges, we developed\ninterleaving and counterfactual evaluation methods to facilitate rapid online\nassessments for identifying the most promising candidates for A/B tests. Our\napproach not only increased the sensitivity of experiments by a factor of up to\n100 (depending on the approach and metrics) compared to traditional A/B testing\nbut also streamlined the experimental process. The practical insights gained\nfrom usage in production can also benefit organizations with similar interests.\n","authors":["Qing Zhang","Alex Deng","Michelle Du","Huiji Gao","Liwei He","Sanjeev Katariya"],"pdf_url":"https://arxiv.org/pdf/2508.00751v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2503.22675v3","updated":"2025-08-01T16:17:57Z","published":"2025-03-28T17:59:03Z","title":"Think Before Recommend: Unleashing the Latent Reasoning Power for\n  Sequential Recommendation","summary":"  Sequential Recommendation (SeqRec) aims to predict the next item by capturing\nsequential patterns from users' historical interactions, playing a crucial role\nin many real-world recommender systems. However, existing approaches\npredominantly adopt a direct forward computation paradigm, where the final\nhidden state of the sequence encoder serves as the user representation. We\nargue that this inference paradigm, due to its limited computational depth,\nstruggles to model the complex evolving nature of user preferences and lacks a\nnuanced understanding of long-tail items, leading to suboptimal performance. To\naddress this issue, we propose \\textbf{ReaRec}, the first inference-time\ncomputing framework for recommender systems, which enhances user\nrepresentations through implicit multi-step reasoning. Specifically, ReaRec\nautoregressively feeds the sequence's last hidden state into the sequential\nrecommender while incorporating special reasoning position embeddings to\ndecouple the original item encoding space from the multi-step reasoning space.\nMoreover, we introduce two lightweight reasoning-based learning methods,\nEnsemble Reasoning Learning (ERL) and Progressive Reasoning Learning (PRL), to\nfurther effectively exploit ReaRec's reasoning potential. Extensive experiments\non five public real-world datasets and different SeqRec architectures\ndemonstrate the generality and effectiveness of our proposed ReaRec.\nRemarkably, post-hoc analyses reveal that ReaRec significantly elevates the\nperformance ceiling of multiple sequential recommendation backbones by\napproximately 30\\%-50\\%. Thus, we believe this work can open a new and\npromising avenue for future research in inference-time computing for sequential\nrecommendation.\n","authors":["Jiakai Tang","Sunhao Dai","Teng Shi","Jun Xu","Xu Chen","Wen Chen","Jian Wu","Yuning Jiang"],"pdf_url":"https://arxiv.org/pdf/2503.22675v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00710v1","updated":"2025-08-01T15:26:27Z","published":"2025-08-01T15:26:27Z","title":"Experimental Evaluation of Dynamic Topic Modeling Algorithms","summary":"  The amount of text generated daily on social media is gigantic and analyzing\nthis text is useful for many purposes. To understand what lies beneath a huge\namount of text, we need dependable and effective computing techniques from\nself-powered topic models. Nevertheless, there are currently relatively few\nthorough quantitative comparisons between these models. In this study, we\ncompare these models and propose an assessment metric that documents how the\ntopics change in time.\n","authors":["Ngozichukwuka Onah","Nadine Steinmetz","Hani Al-Sayeh","Kai-Uwe Sattler"],"pdf_url":"https://arxiv.org/pdf/2508.00710v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00709v1","updated":"2025-08-01T15:23:20Z","published":"2025-08-01T15:23:20Z","title":"NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian\n  Common Law System","summary":"  Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,\naiming to automate judicial outcome forecasting and enhance interpretability in\nlegal reasoning. While previous approaches in the Indian context have relied on\ninternal case content such as facts, issues, and reasoning, they often overlook\na core element of common law systems, which is reliance on statutory provisions\nand judicial precedents. In this work, we propose NyayaRAG, a\nRetrieval-Augmented Generation (RAG) framework that simulates realistic\ncourtroom scenarios by providing models with factual case descriptions,\nrelevant legal statutes, and semantically retrieved prior cases. NyayaRAG\nevaluates the effectiveness of these combined inputs in predicting court\ndecisions and generating legal explanations using a domain-specific pipeline\ntailored to the Indian legal system. We assess performance across various input\nconfigurations using both standard lexical and semantic metrics as well as\nLLM-based evaluators such as G-Eval. Our results show that augmenting factual\ninputs with structured legal knowledge significantly improves both predictive\naccuracy and explanation quality.\n","authors":["Shubham Kumar Nigam","Balaramamahanthi Deepak Patnaik","Shivam Mishra","Ajay Varghese Thomas","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2508.00709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00679v1","updated":"2025-08-01T14:49:33Z","published":"2025-08-01T14:49:33Z","title":"Segment First, Retrieve Better: Realistic Legal Search via Rhetorical\n  Role-Based Queries","summary":"  Legal precedent retrieval is a cornerstone of the common law system, governed\nby the principle of stare decisis, which demands consistency in judicial\ndecisions. However, the growing complexity and volume of legal documents\nchallenge traditional retrieval methods. TraceRetriever mirrors real-world\nlegal search by operating with limited case information, extracting only\nrhetorically significant segments instead of requiring complete documents. Our\npipeline integrates BM25, Vector Database, and Cross-Encoder models, combining\ninitial results through Reciprocal Rank Fusion before final re-ranking.\nRhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier\ntrained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,\nTraceRetriever addresses growing document volume challenges while aligning with\npractical search constraints, reliable and scalable foundation for precedent\nretrieval enhancing legal research when only partial case knowledge is\navailable.\n","authors":["Shubham Kumar Nigam","Tanmay Dubey","Noel Shallum","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2508.00679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00589v1","updated":"2025-08-01T12:41:52Z","published":"2025-08-01T12:41:52Z","title":"Context-based Motion Retrieval using Open Vocabulary Methods for\n  Autonomous Driving","summary":"  Autonomous driving systems must operate reliably in safety-critical\nscenarios, particularly those involving unusual or complex behavior by\nVulnerable Road Users (VRUs). Identifying these edge cases in driving datasets\nis essential for robust evaluation and generalization, but retrieving such rare\nhuman behavior scenarios within the long tail of large-scale datasets is\nchallenging. To support targeted evaluation of autonomous driving systems in\ndiverse, human-centered scenarios, we propose a novel context-aware motion\nretrieval framework. Our method combines Skinned Multi-Person Linear\n(SMPL)-based motion sequences and corresponding video frames before encoding\nthem into a shared multimodal embedding space aligned with natural language.\nOur approach enables the scalable retrieval of human behavior and their context\nthrough text queries. This work also introduces our dataset WayMoCo, an\nextension of the Waymo Open Dataset. It contains automatically labeled motion\nand scene context descriptions derived from generated pseudo-ground-truth SMPL\nsequences and corresponding image data. Our approach outperforms\nstate-of-the-art models by up to 27.5% accuracy in motion-context retrieval,\nwhen evaluated on the WayMoCo dataset.\n","authors":["Stefan Englmeier","Max A. Büttner","Katharina Winter","Fabian B. Flohr"],"pdf_url":"https://arxiv.org/pdf/2508.00589v1.pdf","comment":"9 pages, 10 figure, project page\n  https://iv.ee.hm.edu/contextmotionclip/, submitted to IEEE Transactions on\n  Intelligent Vehicles (T-IV), This work has been submitted to the IEEE for\n  possible publication"},{"id":"http://arxiv.org/abs/2508.00579v1","updated":"2025-08-01T12:22:53Z","published":"2025-08-01T12:22:53Z","title":"MMRAG-DocQA: A Multi-Modal Retrieval-Augmented Generation Method for\n  Document Question-Answering with Hierarchical Index and Multi-Granularity\n  Retrieval","summary":"  The multi-modal long-context document question-answering task aims to locate\nand integrate multi-modal evidences (such as texts, tables, charts, images, and\nlayouts) distributed across multiple pages, for question understanding and\nanswer generation. The existing methods can be categorized into Large\nVision-Language Model (LVLM)-based and Retrieval-Augmented Generation\n(RAG)-based methods. However, the former were susceptible to hallucinations,\nwhile the latter struggled for inter-modal disconnection and cross-page\nfragmentation. To address these challenges, a novel multi-modal RAG model,\nnamed MMRAG-DocQA, was proposed, leveraging both textual and visual information\nacross long-range pages to facilitate accurate question answering. A\nhierarchical indexing method with the integration of flattened in-page chunks\nand topological cross-page chunks was designed to jointly establish in-page\nmulti-modal associations and long-distance cross-page dependencies. By means of\njoint similarity evaluation and large language model (LLM)-based re-ranking, a\nmulti-granularity semantic retrieval method, including the page-level parent\npage retrieval and document-level summary retrieval, was proposed to foster\nmulti-modal evidence connection and long-distance evidence integration and\nreasoning. Experimental results performed on public datasets, MMLongBench-Doc\nand LongDocURL, demonstrated the superiority of our MMRAG-DocQA method in\nunderstanding and answering modality-rich and multi-page documents.\n","authors":["Ziyu Gong","Yihua Huang","Chengcheng Mai"],"pdf_url":"https://arxiv.org/pdf/2508.00579v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2508.00816v1","updated":"2025-08-01T17:49:27Z","published":"2025-08-01T17:49:27Z","title":"Efficient Solving of Large Single Input Superstate Decomposable\n  Markovian Decision Process","summary":"  Solving Markov Decision Processes (MDPs) remains a central challenge in\nsequential decision-making, especially when dealing with large state spaces and\nlong-term optimization criteria. A key step in Bellman dynamic programming\nalgorithms is the policy evaluation, which becomes computationally demanding in\ninfinite-horizon settings such as average-reward or discounted-reward\nformulations. In the context of Markov chains, aggregation and disaggregation\ntechniques have for a long time been used to reduce complexity by exploiting\nstructural decompositions. In this work, we extend these principles to a\nstructured class of MDPs. We define the Single-Input Superstate Decomposable\nMarkov Decision Process (SISDMDP), which combines Chiu's single-input\ndecomposition with Robertazzi's single-cycle recurrence property. When a policy\ninduces this structure, the resulting transition graph can be decomposed into\ninteracting components with centralized recurrence. We develop an exact and\nefficient policy evaluation method based on this structure. This yields a\nscalable solution applicable to both average and discounted reward MDPs.\n","authors":["Youssef Ait El Mahjoub","Jean-Michel Fourneau","Salma Alouah"],"pdf_url":"https://arxiv.org/pdf/2508.00816v1.pdf","comment":"Preprint article submitted to ValueTools2025"},{"id":"http://arxiv.org/abs/2508.00806v1","updated":"2025-08-01T17:39:25Z","published":"2025-08-01T17:39:25Z","title":"Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory\n  Management","summary":"  Training large language models often employs recomputation to alleviate\nmemory pressure, which can introduce up to 30% overhead in real-world\nscenarios. In this paper, we propose Adacc, a novel memory management framework\nthat combines adaptive compression and activation checkpointing to reduce the\nGPU memory footprint. It comprises three modules: (1) We design layer-specific\ncompression algorithms that account for outliers in LLM tensors, instead of\ndirectly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We\npropose an optimal scheduling policy that employs MILP to determine the best\nmemory optimization for each tensor. (3) To accommodate changes in training\ntensors, we introduce an adaptive policy evolution mechanism that adjusts the\npolicy during training to enhance throughput. Experimental results show that\nAdacc can accelerate the LLM training by 1.01x to 1.37x compared to\nstate-of-the-art frameworks, while maintaining comparable model accuracy to the\nBaseline.\n","authors":["Ping Chen","Zhuohong Deng","Ping Li","Shuibing He","Hongzi Zhu","Yi Zheng","Zhefeng Wang","Baoxing Huai","Minyi Guo"],"pdf_url":"https://arxiv.org/pdf/2508.00806v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2508.00804v1","updated":"2025-08-01T17:37:19Z","published":"2025-08-01T17:37:19Z","title":"Online Fine-Tuning of Carbon Emission Predictions using Real-Time\n  Recurrent Learning for State Space Models","summary":"  This paper introduces a new approach for fine-tuning the predictions of\nstructured state space models (SSMs) at inference time using real-time\nrecurrent learning. While SSMs are known for their efficiency and long-range\nmodeling capabilities, they are typically trained offline and remain static\nduring deployment. Our method enables online adaptation by continuously\nupdating model parameters in response to incoming data. We evaluate our\napproach for linear-recurrent-unit SSMs using a small carbon emission dataset\ncollected from embedded automotive hardware. Experimental results show that our\nmethod consistently reduces prediction error online during inference,\ndemonstrating its potential for dynamic, resource-constrained environments.\n","authors":["Julian Lemmel","Manuel Kranzl","Adam Lamine","Philipp Neubauer","Radu Grosu","Sophie Neubauer"],"pdf_url":"https://arxiv.org/pdf/2508.00804v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2409.15126v2","updated":"2025-08-01T17:31:33Z","published":"2024-09-23T15:32:46Z","title":"UTrace: Poisoning Forensics for Private Collaborative Learning","summary":"  Privacy-preserving machine learning (PPML) enables multiple data owners to\ncontribute their data privately to a set of servers that run a secure\nmulti-party computation (MPC) protocol to train a joint ML model. In these\nprotocols, the input data remains private throughout the training process, and\nonly the resulting model is made available. While this approach benefits\nprivacy, it also exacerbates the risks of data poisoning, where compromised\ndata owners induce undesirable model behavior by contributing malicious\ndatasets. Existing MPC mechanisms can mitigate certain poisoning attacks, but\nthese measures are not exhaustive. To complement existing poisoning defenses,\nwe introduce UTrace: a framework for User-level Traceback of poisoning attacks\nin PPML. Utrace computes user responsibility scores using gradient similarity\nmetrics aggregated across the most relevant samples in an owner's dataset.\nUTrace is effective at low poisoning rates and is resilient to poisoning\nattacks distributed across multiple data owners, unlike existing\nunlearning-based methods. We introduce methods for checkpointing gradients with\nlow storage overhead, enabling traceback in the absence of data owners at\ndeployment time. We also design several optimizations that reduce traceback\ntime and communication in MPC. We provide a comprehensive evaluation of UTrace\nacross four datasets from three data modalities (vision, text, and malware) and\nshow its effectiveness against 10 poisoning attacks.\n","authors":["Evan Rose","Hidde Lycklama","Harsh Chaudhari","Anwar Hithnawi","Alina Oprea"],"pdf_url":"https://arxiv.org/pdf/2409.15126v2.pdf","comment":"28 pages, 10 figures; update ack"},{"id":"http://arxiv.org/abs/2508.00785v1","updated":"2025-08-01T17:09:49Z","published":"2025-08-01T17:09:49Z","title":"Explainable AI and Machine Learning for Exam-based Student Evaluation:\n  Causal and Predictive Analysis of Socio-academic and Economic Factors","summary":"  Academic performance depends on a multivariable nexus of socio-academic and\nfinancial factors. This study investigates these influences to develop\neffective strategies for optimizing students' CGPA. To achieve this, we\nreviewed various literature to identify key influencing factors and constructed\nan initial hypothetical causal graph based on the findings. Additionally, an\nonline survey was conducted, where 1,050 students participated, providing\ncomprehensive data for analysis. Rigorous data preprocessing techniques,\nincluding cleaning and visualization, ensured data quality before analysis.\nCausal analysis validated the relationships among variables, offering deeper\ninsights into their direct and indirect effects on CGPA. Regression models were\nimplemented for CGPA prediction, while classification models categorized\nstudents based on performance levels. Ridge Regression demonstrated strong\npredictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared\nError of 0.023. Random Forest outperformed in classification, attaining an\nF1-score near perfection and an accuracy of 98.68%. Explainable AI techniques\nsuch as SHAP, LIME, and Interpret enhanced model interpretability, highlighting\ncritical factors such as study hours, scholarships, parental education, and\nprior academic performance. The study culminated in the development of a\nweb-based application that provides students with personalized insights,\nallowing them to predict academic performance, identify areas for improvement,\nand make informed decisions to enhance their outcomes.\n","authors":["Bushra Akter","Md Biplob Hosen","Sabbir Ahmed","Mehrin Anannya","Md. Farhad Hossain"],"pdf_url":"https://arxiv.org/pdf/2508.00785v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.10498v2","updated":"2025-08-01T17:02:02Z","published":"2025-05-15T17:00:51Z","title":"Batched Nonparametric Bandits via k-Nearest Neighbor UCB","summary":"  We study sequential decision-making in batched nonparametric contextual\nbandits, where actions are selected over a finite horizon divided into a small\nnumber of batches. Motivated by constraints in domains such as medicine and\nmarketing -- where online feedback is limited -- we propose a nonparametric\nalgorithm that combines adaptive k-nearest neighbor (k-NN) regression with the\nupper confidence bound (UCB) principle. Our method, BaNk-UCB, is fully\nnonparametric, adapts to the context dimension, and is simple to implement.\nUnlike prior work relying on parametric or binning-based estimators, BaNk-UCB\nuses local geometry to estimate rewards and adaptively balances exploration and\nexploitation. We provide near-optimal regret guarantees under standard\nLipschitz smoothness and margin assumptions, using a theoretically motivated\nbatch schedule that balances regret across batches and achieves minimax-optimal\nrates. Empirical evaluations on synthetic and real-world datasets demonstrate\nthat BaNk-UCB consistently outperforms binning-based baselines.\n","authors":["Sakshi Arya"],"pdf_url":"https://arxiv.org/pdf/2505.10498v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00775v1","updated":"2025-08-01T16:56:42Z","published":"2025-08-01T16:56:42Z","title":"Learning to optimize with guarantees: a complete characterization of\n  linearly convergent algorithms","summary":"  In high-stakes engineering applications, optimization algorithms must come\nwith provable worst-case guarantees over a mathematically defined class of\nproblems. Designing for the worst case, however, inevitably sacrifices\nperformance on the specific problem instances that often occur in practice. We\naddress the problem of augmenting a given linearly convergent algorithm to\nimprove its average-case performance on a restricted set of target problems -\nfor example, tailoring an off-the-shelf solver for model predictive control\n(MPC) for an application to a specific dynamical system - while preserving its\nworst-case guarantees across the entire problem class. Toward this goal, we\ncharacterize the class of algorithms that achieve linear convergence for\nclasses of nonsmooth composite optimization problems. In particular, starting\nfrom a baseline linearly convergent algorithm, we derive all - and only - the\nmodifications to its update rule that maintain its convergence properties. Our\nresults apply to augmenting legacy algorithms such as gradient descent for\nnonconvex, gradient-dominated functions; Nesterov's accelerated method for\nstrongly convex functions; and projected methods for optimization over\npolyhedral feasibility sets. We showcase effectiveness of the approach on\nsolving optimization problems with tight iteration budgets in application to\nill-conditioned systems of linear equations and MPC for linear systems.\n","authors":["Andrea Martin","Ian R. Manchester","Luca Furieri"],"pdf_url":"https://arxiv.org/pdf/2508.00775v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00768v1","updated":"2025-08-01T16:43:45Z","published":"2025-08-01T16:43:45Z","title":"Evaluating Angle and Amplitude Encoding Strategies for Variational\n  Quantum Machine Learning: their impact on model's accuracy","summary":"  Recent advancements in Quantum Computing and Machine Learning have increased\nattention to Quantum Machine Learning (QML), which aims to develop machine\nlearning models by exploiting the quantum computing paradigm. One of the widely\nused models in this area is the Variational Quantum Circuit (VQC), a hybrid\nmodel where the quantum circuit handles data inference while classical\noptimization adjusts the parameters of the circuit. The quantum circuit\nconsists of an encoding layer, which loads data into the circuit, and a\ntemplate circuit, known as the ansatz, responsible for processing the data.\nThis work involves performing an analysis by considering both Amplitude- and\nAngle-encoding models, and examining how the type of rotational gate applied\naffects the classification performance of the model. This comparison is carried\nout by training the different models on two datasets, Wine and Diabetes, and\nevaluating their performance. The study demonstrates that, under identical\nmodel topologies, the difference in accuracy between the best and worst models\nranges from 10% to 30%, with differences reaching up to 41%. Moreover, the\nresults highlight how the choice of rotational gates used in encoding can\nsignificantly impact the model's classification performance. The findings\nconfirm that the embedding represents a hyperparameter for VQC models.\n","authors":["Antonio Tudisco","Andrea Marchesin","Maurizio Zamboni","Mariagrazia Graziano","Giovanna Turvani"],"pdf_url":"https://arxiv.org/pdf/2508.00768v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00758v1","updated":"2025-08-01T16:33:18Z","published":"2025-08-01T16:33:18Z","title":"Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in\n  Tabular Data","summary":"  Anomaly detection in tabular data remains challenging due to complex feature\ninteractions and the scarcity of anomalous examples. Denoising autoencoders\nrely on fixed-magnitude noise, limiting adaptability to diverse data\ndistributions. Diffusion models introduce scheduled noise and iterative\ndenoising, but lack explicit reconstruction mappings. We propose the\nDiffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates\ndiffusion-based noise scheduling and contrastive learning into the encoding\nprocess to improve anomaly detection. We evaluated DDAE on 57 datasets from\nADBench. Our method outperforms in semi-supervised settings and achieves\ncompetitive results in unsupervised settings, improving PR-AUC by up to 65%\n(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)\nmodel baselines. We observed that higher noise levels benefit unsupervised\ntraining, while lower noise with linear scheduling is optimal in\nsemi-supervised settings. These findings underscore the importance of\nprincipled noise strategies in tabular anomaly detection.\n","authors":["Timur Sattarov","Marco Schreyer","Damian Borth"],"pdf_url":"https://arxiv.org/pdf/2508.00758v1.pdf","comment":"22 pages, 16 figures, 7 tables, preprint version"},{"id":"http://arxiv.org/abs/2508.00754v1","updated":"2025-08-01T16:31:23Z","published":"2025-08-01T16:31:23Z","title":"A Simple and Effective Method for Uncertainty Quantification and OOD\n  Detection","summary":"  Bayesian neural networks and deep ensemble methods have been proposed for\nuncertainty quantification; however, they are computationally intensive and\nrequire large storage. By utilizing a single deterministic model, we can solve\nthe above issue. We propose an effective method based on feature space density\nto quantify uncertainty for distributional shifts and out-of-distribution (OOD)\ndetection. Specifically, we leverage the information potential field derived\nfrom kernel density estimation to approximate the feature space density of the\ntraining set. By comparing this density with the feature space representation\nof test samples, we can effectively determine whether a distributional shift\nhas occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons\nand Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The\nresults demonstrate that our method outperforms baseline models.\n","authors":["Yaxin Ma","Benjamin Colburn","Jose C. Principe"],"pdf_url":"https://arxiv.org/pdf/2508.00754v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.19522v2","updated":"2025-08-01T16:30:12Z","published":"2024-03-28T15:57:20Z","title":"Model Stock: All we need is just a few fine-tuned models","summary":"  This paper introduces an efficient fine-tuning method for large pre-trained\nmodels, offering strong in-distribution (ID) and out-of-distribution (OOD)\nperformance. Breaking away from traditional practices that need a multitude of\nfine-tuned models for averaging, our approach employs significantly fewer\nmodels to achieve final weights yet yield superior accuracy. Drawing from key\ninsights in the weight space of fine-tuned weights, we uncover a strong link\nbetween the performance and proximity to the center of weight space. Based on\nthis, we introduce a method that approximates a center-close weight using only\ntwo fine-tuned models, applicable during or after training. Our innovative\nlayer-wise weight averaging technique surpasses state-of-the-art model methods\nsuch as Model Soup, utilizing only two fine-tuned models. This strategy can be\naptly coined Model Stock, highlighting its reliance on selecting a minimal\nnumber of models to draw a more optimized-averaged model. We demonstrate the\nefficacy of Model Stock with fine-tuned models based upon pre-trained CLIP\narchitectures, achieving remarkable performance on both ID and OOD tasks on the\nstandard benchmarks, all while barely bringing extra computational demands. Our\ncode and pre-trained models are available at\nhttps://github.com/naver-ai/model-stock.\n","authors":["Dong-Hwan Jang","Sangdoo Yun","Dongyoon Han"],"pdf_url":"https://arxiv.org/pdf/2403.19522v2.pdf","comment":"ECCV 2024 oral presenetation; Code at\n  https://github.com/naver-ai/model-stock"},{"id":"http://arxiv.org/abs/2505.11250v2","updated":"2025-08-01T16:26:03Z","published":"2025-05-16T13:42:00Z","title":"Rethinking Irregular Time Series Forecasting: A Simple yet Effective\n  Baseline","summary":"  The forecasting of irregular multivariate time series (IMTS) is a critical\ntask in domains like healthcare and climate science. However, this task faces\ntwo significant hurdles: 1) the inherent non-uniformity and missing data in\nIMTS complicate the modeling of temporal dynamics, and 2) existing methods\noften rely on computationally expensive architectures. To address these dual\nchallenges, we introduce APN, a general and efficient forecasting framework. At\nthe core of APN is a novel Time-Aware Patch Aggregation (TAPA) module that\nintroduces an aggregation-based paradigm for adaptive patching, moving beyond\nthe limitations of fixed-span segmentation and interpolation-based methods.\nTAPA first learns dynamic temporal boundaries to define data-driven segments.\nCrucially, instead of resampling or interpolating, it directly computes patch\nrepresentations via a time-aware weighted aggregation of all raw observations,\nwhere weights are determined by each observation's temporal relevance to the\nsegment. This approach provides two key advantages: it preserves data fidelity\nby avoiding the introduction of artificial data points and ensures complete\ninformation coverage by design.The resulting regularized and information-rich\npatch representations enable the use of a lightweight query module for\nhistorical context aggregation and a simple MLP for final prediction. Extensive\nexperiments on multiple real-world datasets demonstrate that APN establishes a\nnew state-of-the-art, significantly outperforming existing methods in both\nprediction accuracy and computational efficiency.\n","authors":["Xvyuan Liu","Xiangfei Qiu","Xingjian Wu","Zhengyu Li","Chenjuan Guo","Jilin Hu","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2505.11250v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00750v1","updated":"2025-08-01T16:25:21Z","published":"2025-08-01T16:25:21Z","title":"SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of\n  Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation","summary":"  Generative Adversarial Networks (GANs) have achieved realistic\nsuper-resolution (SR) of images however, they lack semantic consistency and\nper-pixel confidence, limiting their credibility in critical remote sensing\napplications such as disaster response, urban planning and agriculture. This\npaper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first\nSR framework designed for satellite imagery to integrate the ESRGAN,\nsegmentation loss via DeepLabv3 for class detail preservation and Monte Carlo\ndropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results\n(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This\nnovel model is valuable in satellite systems or UAVs that use wide\nfield-of-view (FoV) cameras, trading off spatial resolution for coverage. The\nmodular design allows integration in UAV data pipelines for on-board or\npost-processing SR to enhance imagery resulting due to motion blur, compression\nand sensor limitations. Further, the model is fine-tuned to evaluate its\nperformance on cross domain applications. The tests are conducted on two drone\nbased datasets which differ in altitude and imaging perspective. Performance\nevaluation of the fine-tuned models show a stronger adaptation to the Aerial\nMaritime Drone Dataset, whose imaging characteristics align with the training\ndata, highlighting the importance of domain-aware training in SR-applications.\n","authors":["Prerana Ramkumar"],"pdf_url":"https://arxiv.org/pdf/2508.00750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00743v1","updated":"2025-08-01T16:18:52Z","published":"2025-08-01T16:18:52Z","title":"Agentic large language models improve retrieval-based radiology question\n  answering","summary":"  Clinical decision-making in radiology increasingly benefits from artificial\nintelligence (AI), particularly through large language models (LLMs). However,\ntraditional retrieval-augmented generation (RAG) systems for radiology question\nanswering (QA) typically rely on single-step retrieval, limiting their ability\nto handle complex clinical reasoning tasks. Here we propose an agentic RAG\nframework enabling LLMs to autonomously decompose radiology questions,\niteratively retrieve targeted clinical evidence from Radiopaedia, and\ndynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning\ndiverse architectures, parameter scales (0.5B to >670B), and training paradigms\n(general-purpose, reasoning-optimized, clinically fine-tuned), using 104\nexpert-curated radiology questions from previously established RSNA-RadioQA and\nExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic\naccuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional\nonline RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized\nmodels (e.g., Mistral Large improved from 72% to 81%) and small-scale models\n(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B\nparameters) demonstrated minimal changes (<2% improvement). Additionally,\nagentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically\nrelevant context in 46% of cases, substantially aiding factual grounding. Even\nclinically fine-tuned models exhibited meaningful improvements (e.g.,\nMedGemma-27B improved from 71% to 81%), indicating complementary roles of\nretrieval and fine-tuning. These results highlight the potential of agentic\nframeworks to enhance factuality and diagnostic accuracy in radiology QA,\nparticularly among mid-sized LLMs, warranting future studies to validate their\nclinical utility.\n","authors":["Sebastian Wind","Jeta Sopa","Daniel Truhn","Mahshad Lotfinia","Tri-Thien Nguyen","Keno Bressem","Lisa Adams","Mirabela Rusu","Harald Köstler","Gerhard Wellein","Andreas Maier","Soroosh Tayebi Arasteh"],"pdf_url":"https://arxiv.org/pdf/2508.00743v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00742v1","updated":"2025-08-01T16:16:16Z","published":"2025-08-01T16:16:16Z","title":"Applying Psychometrics to Large Language Model Simulated Populations:\n  Recreating the HEXACO Personality Inventory Experiment with Generative Agents","summary":"  Generative agents powered by Large Language Models demonstrate human-like\ncharacteristics through sophisticated natural language interactions. Their\nability to assume roles and personalities based on predefined character\nbiographies has positioned them as cost-effective substitutes for human\nparticipants in social science research. This paper explores the validity of\nsuch persona-based agents in representing human populations; we recreate the\nHEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,\nconducting factor analysis on their responses, and comparing these results to\nthe original findings presented by Ashton, Lee, & Goldberg in 2004. Our results\nfound 1) a coherent and reliable personality structure was recoverable from the\nagents' responses demonstrating partial alignment to the HEXACO framework. 2)\nthe derived personality dimensions were consistent and reliable within GPT-4,\nwhen coupled with a sufficiently curated population, and 3) cross-model\nanalysis revealed variability in personality profiling, suggesting\nmodel-specific biases and limitations. We discuss the practical considerations\nand challenges encountered during the experiment. This study contributes to the\nongoing discourse on the potential benefits and limitations of using generative\nagents in social science research and provides useful guidance on designing\nconsistent and representative agent personas to maximise coverage and\nrepresentation of human personality traits.\n","authors":["Sarah Mercer","Daniel P. Martin","Phil Swatton"],"pdf_url":"https://arxiv.org/pdf/2508.00742v1.pdf","comment":"26 pages, 14 figures"},{"id":"http://arxiv.org/abs/2312.01046v3","updated":"2025-08-01T16:12:08Z","published":"2023-12-02T07:00:46Z","title":"Bagged Regularized $k$-Distances for Anomaly Detection","summary":"  We consider the paradigm of unsupervised anomaly detection, which involves\nthe identification of anomalies within a dataset in the absence of labeled\nexamples. Though distance-based methods are top-performing for unsupervised\nanomaly detection, they suffer heavily from the sensitivity to the choice of\nthe number of the nearest neighbors. In this paper, we propose a new\ndistance-based algorithm called bagged regularized $k$-distances for anomaly\ndetection (BRDAD), converting the unsupervised anomaly detection problem into a\nconvex optimization problem. Our BRDAD algorithm selects the weights by\nminimizing the surrogate risk, i.e., the finite sample bound of the empirical\nrisk of the bagged weighted $k$-distances for density estimation (BWDDE). This\napproach enables us to successfully address the sensitivity challenge of the\nhyperparameter choice in distance-based algorithms. Moreover, when dealing with\nlarge-scale datasets, the efficiency issues can be addressed by the\nincorporated bagging technique in our BRDAD algorithm. On the theoretical side,\nwe establish fast convergence rates of the AUC regret of our algorithm and\ndemonstrate that the bagging technique significantly reduces the computational\ncomplexity. On the practical side, we conduct numerical experiments to\nillustrate the insensitivity of the parameter selection of our algorithm\ncompared with other state-of-the-art distance-based methods. Furthermore, our\nmethod achieves superior performance on real-world datasets with the introduced\nbagging technique compared to other approaches.\n","authors":["Yuchao Cai","Hanfang Yang","Yuheng Ma","Hanyuan Hang"],"pdf_url":"https://arxiv.org/pdf/2312.01046v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00734v1","updated":"2025-08-01T16:04:21Z","published":"2025-08-01T16:04:21Z","title":"Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for\n  Failure Analysis of Nonlinear Stochastic Systems","summary":"  Existing variance reduction techniques used in stochastic simulations for\nrare event analysis still require a substantial number of model evaluations to\nestimate small failure probabilities. In the context of complex, nonlinear\nfinite element modeling environments, this can become computationally\nchallenging-particularly for systems subjected to stochastic excitation. To\naddress this challenge, a multi-fidelity stratified sampling scheme with\nadaptive machine learning metamodels is introduced for efficiently propagating\nuncertainties and estimating small failure probabilities. In this approach, a\nhigh-fidelity dataset generated through stratified sampling is used to train a\ndeep learning-based metamodel, which then serves as a cost-effective and highly\ncorrelated low-fidelity model. An adaptive training scheme is proposed to\nbalance the trade-off between approximation quality and computational demand\nassociated with the development of the low-fidelity model. By integrating the\nlow-fidelity outputs with additional high-fidelity results, an unbiased\nestimate of the strata-wise failure probabilities is obtained using a\nmulti-fidelity Monte Carlo framework. The overall probability of failure is\nthen computed using the total probability theorem. Application to a full-scale\nhigh-rise steel building subjected to stochastic wind excitation demonstrates\nthat the proposed scheme can accurately estimate exceedance probability curves\nfor nonlinear responses of interest, while achieving significant computational\nsavings compared to single-fidelity variance reduction approaches.\n","authors":["Liuyun Xu","Seymour M. J. Spence"],"pdf_url":"https://arxiv.org/pdf/2508.00734v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05824v2","updated":"2025-08-01T16:00:18Z","published":"2024-11-05T08:01:16Z","title":"Navigating Distribution Shifts in Medical Image Analysis: A Survey","summary":"  Medical Image Analysis (MedIA) has become indispensable in modern healthcare,\nenhancing clinical diagnostics and personalized treatment. Despite the\nremarkable advancements supported by deep learning (DL) technologies, their\npractical deployment faces challenges due to distribution shifts, where models\ntrained on specific datasets underperform across others from varying hospitals,\nregions, or patient populations. To navigate this issue, researchers have been\nactively developing strategies to increase the adaptability and robustness of\nDL models, enabling their effective use in unfamiliar and diverse environments.\nThis paper systematically reviews approaches that apply DL techniques to MedIA\nsystems affected by distribution shifts. Unlike traditional categorizations\nbased on technical specifications, our approach is grounded in the real-world\noperational constraints faced by healthcare institutions. Specifically, we\ncategorize the existing body of work into Joint Training, Federated Learning,\nFine-tuning, and Domain Generalization, with each method tailored to distinct\nscenarios caused by Data Accessibility, Privacy Concerns, and Collaborative\nProtocols. This perspective equips researchers with a nuanced understanding of\nhow DL can be strategically deployed to address distribution shifts in MedIA,\nensuring diverse and robust medical applications. By delving deeper into these\ntopics, we highlight potential pathways for future research that not only\naddress existing limitations but also push the boundaries of deployable MedIA\ntechnologies.\n","authors":["Zixian Su","Jingwei Guo","Xi Yang","Qiufeng Wang","Frans Coenen","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2411.05824v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.09503v3","updated":"2025-08-01T15:57:48Z","published":"2025-05-14T15:53:14Z","title":"Towards Fair In-Context Learning with Tabular Foundation Models","summary":"  Transformer-based tabular foundation models have recently demonstrated\npromising in-context learning (ICL) performance on structured data, emerging as\ncompetitive alternatives to gradient-boosted trees. However, the fairness\nimplications of this new paradigm remain largely unexplored. We present the\nfirst investigation of fairness in tabular ICL, evaluating three recently\nproposed foundation models -- TabPFNv2, TabICL, and TabDPT -- on multiple\nbenchmark datasets. To mitigate biases, we explore three pre-processing\nfairness-enhancing methods: correlation removal (decorrelating input features\nfrom the sensitive attribute), group-balanced sample selection (ensuring equal\nrepresentation of protected groups in context examples), and uncertainty-based\nsample selection (prioritizing context examples with high sensitive-attribute\nprediction uncertainty). Our experiments show that the uncertainty-based\nstrategy consistently improves group fairness metrics (e.g., demographic\nparity, equalized odds, and equal opportunity) with minimal impact on\npredictive accuracy. We release our code to facilitate reproducibility\n(https://github.com/patrikken/Fair-TabICL)\n","authors":["Patrik Kenfack","Samira Ebrahimi Kahou","Ulrich Aïvodji"],"pdf_url":"https://arxiv.org/pdf/2505.09503v3.pdf","comment":"30 pages, 12 figures, 5 tables"},{"id":"http://arxiv.org/abs/2405.16958v2","updated":"2025-08-01T15:53:30Z","published":"2024-05-27T08:53:24Z","title":"Large Deviations of Gaussian Neural Networks with ReLU activation","summary":"  We prove a large deviation principle for deep neural networks with Gaussian\nweights and at most linearly growing activation functions, such as ReLU. This\ngeneralises earlier work, in which bounded and continuous activation functions\nwere considered. In practice, linearly growing activation functions such as\nReLU are most commonly used. We furthermore simplify previous expressions for\nthe rate function and provide a power-series expansions for the ReLU case.\n","authors":["Quirin Vogel"],"pdf_url":"https://arxiv.org/pdf/2405.16958v2.pdf","comment":"13 pages, 2 figures, proof simplified"},{"id":"http://arxiv.org/abs/2508.00721v1","updated":"2025-08-01T15:40:37Z","published":"2025-08-01T15:40:37Z","title":"FMPlug: Plug-In Foundation Flow-Matching Priors for Inverse Problems","summary":"  We present FMPlug, a novel plug-in framework that enhances foundation\nflow-matching (FM) priors for solving ill-posed inverse problems. Unlike\ntraditional approaches that rely on domain-specific or untrained priors, FMPlug\nsmartly leverages two simple but powerful insights: the similarity between\nobserved and desired objects and the Gaussianity of generative flows. By\nintroducing a time-adaptive warm-up strategy and sharp Gaussianity\nregularization, FMPlug unlocks the true potential of domain-agnostic foundation\nmodels. Our method beats state-of-the-art methods that use foundation FM priors\nby significant margins, on image super-resolution and Gaussian deblurring.\n","authors":["Yuxiang Wan","Ryan Devera","Wenjie Zhang","Ju Sun"],"pdf_url":"https://arxiv.org/pdf/2508.00721v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00718v1","updated":"2025-08-01T15:36:59Z","published":"2025-08-01T15:36:59Z","title":"Democratizing Tabular Data Access with an Open$\\unicode{x2013}$Source\n  Synthetic$\\unicode{x2013}$Data SDK","summary":"  Machine learning development critically depends on access to high-quality\ndata. However, increasing restrictions due to privacy, proprietary interests,\nand ethical concerns have created significant barriers to data accessibility.\nSynthetic data offers a viable solution by enabling safe, broad data usage\nwithout compromising sensitive information. This paper presents the MOSTLY AI\nSynthetic Data Software Development Kit (SDK), an open-source toolkit designed\nspecifically for synthesizing high-quality tabular data. The SDK integrates\nrobust features such as differential privacy guarantees, fairness-aware data\ngeneration, and automated quality assurance into a flexible and accessible\nPython interface. Leveraging the TabularARGN autoregressive framework, the SDK\nsupports diverse data types and complex multi-table and sequential datasets,\ndelivering competitive performance with notable improvements in speed and\nusability. Currently deployed both as a cloud service and locally installable\nsoftware, the SDK has seen rapid adoption, highlighting its practicality in\naddressing real-world data bottlenecks and promoting widespread data\ndemocratization.\n","authors":["Ivona Krchova","Mariana Vargas Vieyra","Mario Scriminaci","Andrey Sidorenko"],"pdf_url":"https://arxiv.org/pdf/2508.00718v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.20401v2","updated":"2025-08-01T15:35:41Z","published":"2025-04-29T03:55:05Z","title":"Nonlinear Computation with Linear Optics via Source-Position Encoding","summary":"  Optical computing systems provide an alternate hardware model which appears\nto be aligned with the demands of neural network workloads. However, the\nchallenge of implementing energy efficient nonlinearities in optics -- a key\nrequirement for realizing neural networks -- is a conspicuous missing link. In\nthis work we introduce a novel method to achieve nonlinear computation in fully\nlinear media. Our method can operate at low power and requires only the ability\nto drive the optical system at a data-dependent spatial position. Leveraging\nthis positional encoding, we formulate a fully automated,\ntopology-optimization-based hardware design framework for extremely specialized\noptical neural networks, drawing on modern advancements in optimization and\nmachine learning. We evaluate our optical designs on machine learning\nclassification tasks: demonstrating significant improvements over linear\nmethods, and competitive performance when compared to standard artificial\nneural networks.\n","authors":["N. Richardson","C. Bosch","R. P. Adams"],"pdf_url":"https://arxiv.org/pdf/2504.20401v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00716v1","updated":"2025-08-01T15:32:40Z","published":"2025-08-01T15:32:40Z","title":"Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation\n  Learning","summary":"  Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled\nsource graphs to unlabeled target graphs by learning domain-invariant\nrepresentations, which is essential in applications such as molecular property\nprediction and social network analysis. However, most existing GDA methods rely\non the assumption of clean source labels, which rarely holds in real-world\nscenarios where annotation noise is pervasive. This label noise severely\nimpairs feature alignment and degrades adaptation performance under domain\nshifts. To address this challenge, we propose Nested Graph Pseudo-Label\nRefinement (NeGPR), a novel framework tailored for graph-level domain\nadaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,\nsemantic and topology branches, by enforcing neighborhood consistency in the\nfeature space, thereby reducing the influence of noisy supervision. To bridge\ndomain gaps, NeGPR employs a nested refinement mechanism in which one branch\nselects high-confidence target samples to guide the adaptation of the other,\nenabling progressive cross-domain learning. Furthermore, since pseudo-labels\nmay still contain noise and the pre-trained branches are already overfitted to\nthe noisy labels in the source domain, NeGPR incorporates a noise-aware\nregularization strategy. This regularization is theoretically proven to\nmitigate the adverse effects of pseudo-label noise, even under the presence of\nsource overfitting, thus enhancing the robustness of the adaptation process.\nExtensive experiments on benchmark datasets demonstrate that NeGPR consistently\noutperforms state-of-the-art methods under severe label noise, achieving gains\nof up to 12.7% in accuracy.\n","authors":["Yingxu Wang","Mengzhu Wang","Zhichao Huang","Suyu Liu"],"pdf_url":"https://arxiv.org/pdf/2508.00716v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.15500v2","updated":"2025-08-01T15:30:13Z","published":"2024-06-19T12:07:22Z","title":"Pure interaction effects unseen by Random Forests","summary":"  Random Forests are widely claimed to capture interactions well. However, some\nsimple examples suggest that they perform poorly in the presence of certain\npure interactions that the conventional CART criterion struggles to capture\nduring tree construction. Motivated from this, it is argued that simple\nalternative partitioning schemes used in the tree growing procedure can enhance\nidentification of these interactions. In a simulation study these variants are\ncompared to conventional Random Forests and Extremely Randomized Trees. The\nresults validate that the modifications considered enhance the model's fitting\nability in scenarios where pure interactions play a crucial role. Finally, the\nmethods are applied to real datasets.\n","authors":["Ricardo Blum","Munir Hiabu","Enno Mammen","Joseph Theo Meyer"],"pdf_url":"https://arxiv.org/pdf/2406.15500v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2309.01460"},{"id":"http://arxiv.org/abs/2502.08441v3","updated":"2025-08-01T15:28:51Z","published":"2025-02-12T14:32:17Z","title":"Better Embeddings with Coupled Adam","summary":"  Despite their remarkable capabilities, LLMs learn word representations that\nexhibit the undesirable yet poorly understood feature of anisotropy. In this\npaper, we argue that the second moment in Adam is a cause of anisotropic\nembeddings, and suggest a modified optimizer called Coupled Adam to mitigate\nthe problem. Our experiments demonstrate that Coupled Adam significantly\nimproves the quality of embeddings, while also leading to better upstream and\ndownstream performance on large enough datasets.\n","authors":["Felix Stollenwerk","Tobias Stollenwerk"],"pdf_url":"https://arxiv.org/pdf/2502.08441v3.pdf","comment":"ACL 2025 (Main), see https://aclanthology.org/2025.acl-long.1321/"},{"id":"http://arxiv.org/abs/2407.02827v3","updated":"2025-08-01T15:28:47Z","published":"2024-07-03T06:10:41Z","title":"Convergence of Implicit Gradient Descent for Training Two-Layer\n  Physics-Informed Neural Networks","summary":"  The optimization algorithms are crucial in training physics-informed neural\nnetworks (PINNs), as unsuitable methods may lead to poor solutions. Compared to\nthe common gradient descent (GD) algorithm, implicit gradient descent (IGD)\noutperforms it in handling certain multi-scale problems. In this paper, we\nprovide convergence analysis for the IGD in training over-parameterized\ntwo-layer PINNs. We first derive the training dynamics of IGD in training\ntwo-layer PINNs. Then, over-parameterization allows us to prove that the\nrandomly initialized IGD converges to a globally optimal solution at a linear\nconvergence rate. Moreover, due to the distinct training dynamics of IGD\ncompared to GD, the learning rate can be selected independently of the sample\nsize and the least eigenvalue of the Gram matrix. Additionally, the novel\napproach used in our convergence analysis imposes a milder requirement on the\nnetwork width. Finally, empirical results validate our theoretical findings.\n","authors":["Xianliang Xu","Ting Du","Wang Kong","Bin Shan","Ye Li","Zhongyi Huang"],"pdf_url":"https://arxiv.org/pdf/2407.02827v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00712v1","updated":"2025-08-01T15:26:45Z","published":"2025-08-01T15:26:45Z","title":"JSON-Bag: A generic game trajectory representation","summary":"  We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically\nrepresent game trajectories by tokenizing their JSON descriptions and apply\nJensen-Shannon distance (JSD) as distance metric for them. Using a\nprototype-based nearest-neighbor search (P-NNS), we evaluate the validity of\nJSON-Bag with JSD on six tabletop games -- \\textit{7 Wonders},\n\\textit{Dominion}, \\textit{Sea Salt and Paper}, \\textit{Can't Stop},\n\\textit{Connect4}, \\textit{Dots and boxes} -- each over three game trajectory\nclassification tasks: classifying the playing agents, game parameters, or game\nseeds that were used to generate the trajectories.\n  Our approach outperforms a baseline using hand-crafted features in the\nmajority of tasks. Evaluating on N-shot classification suggests using JSON-Bag\nprototype to represent game trajectory classes is also sample efficient.\nAdditionally, we demonstrate JSON-Bag ability for automatic feature extraction\nby treating tokens as individual features to be used in Random Forest to solve\nthe tasks above, which significantly improves accuracy on underperforming\ntasks. Finally, we show that, across all six games, the JSD between JSON-Bag\nprototypes of agent classes highly correlates with the distances between\nagents' policies.\n","authors":["Dien Nguyen","Diego Perez-Liebana","Simon Lucas"],"pdf_url":"https://arxiv.org/pdf/2508.00712v1.pdf","comment":"8 pages, 3 figures, 6 tables, to be published in IEEE Conference on\n  Games 2025"},{"id":"http://arxiv.org/abs/2508.00709v1","updated":"2025-08-01T15:23:20Z","published":"2025-08-01T15:23:20Z","title":"NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian\n  Common Law System","summary":"  Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,\naiming to automate judicial outcome forecasting and enhance interpretability in\nlegal reasoning. While previous approaches in the Indian context have relied on\ninternal case content such as facts, issues, and reasoning, they often overlook\na core element of common law systems, which is reliance on statutory provisions\nand judicial precedents. In this work, we propose NyayaRAG, a\nRetrieval-Augmented Generation (RAG) framework that simulates realistic\ncourtroom scenarios by providing models with factual case descriptions,\nrelevant legal statutes, and semantically retrieved prior cases. NyayaRAG\nevaluates the effectiveness of these combined inputs in predicting court\ndecisions and generating legal explanations using a domain-specific pipeline\ntailored to the Indian legal system. We assess performance across various input\nconfigurations using both standard lexical and semantic metrics as well as\nLLM-based evaluators such as G-Eval. Our results show that augmenting factual\ninputs with structured legal knowledge significantly improves both predictive\naccuracy and explanation quality.\n","authors":["Shubham Kumar Nigam","Balaramamahanthi Deepak Patnaik","Shivam Mishra","Ajay Varghese Thomas","Noel Shallum","Kripabandhu Ghosh","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2508.00709v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00707v1","updated":"2025-08-01T15:23:15Z","published":"2025-08-01T15:23:15Z","title":"Efficient Solution and Learning of Robust Factored MDPs","summary":"  Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling\nepistemic uncertainty about transition dynamics. Learning r-MDPs from\ninteractions with an unknown environment enables the synthesis of robust\npolicies with provable (PAC) guarantees on performance, but this can require a\nlarge number of sample interactions. We propose novel methods for solving and\nlearning r-MDPs based on factored state-space representations that leverage the\nindependence between model uncertainty across system components. Although\npolicy synthesis for factored r-MDPs leads to hard, non-convex optimisation\nproblems, we show how to reformulate these into tractable linear programs.\nBuilding on these, we also propose methods to learn factored model\nrepresentations directly. Our experimental results show that exploiting\nfactored structure can yield dimensional gains in sample efficiency, producing\nmore effective robust policies with tighter performance guarantees than\nstate-of-the-art methods.\n","authors":["Yannik Schnitzer","Alessandro Abate","David Parker"],"pdf_url":"https://arxiv.org/pdf/2508.00707v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00706v1","updated":"2025-08-01T15:22:37Z","published":"2025-08-01T15:22:37Z","title":"Learning Network Dismantling without Handcrafted Inputs","summary":"  The application of message-passing Graph Neural Networks has been a\nbreakthrough for important network science problems. However, the competitive\nperformance often relies on using handcrafted structural features as inputs,\nwhich increases computational cost and introduces bias into the otherwise\npurely data-driven network representations. Here, we eliminate the need for\nhandcrafted features by introducing an attention mechanism and utilizing\nmessage-iteration profiles, in addition to an effective algorithmic approach to\ngenerate a structurally diverse training set of small synthetic networks.\nThereby, we build an expressive message-passing framework and use it to\nefficiently solve the NP-hard problem of Network Dismantling, virtually\nequivalent to vital node identification, with significant real-world\napplications. Trained solely on diversified synthetic networks, our proposed\nmodel -- MIND: Message Iteration Network Dismantler -- generalizes to large,\nunseen real networks with millions of nodes, outperforming state-of-the-art\nnetwork dismantling methods. Increased efficiency and generalizability of the\nproposed model can be leveraged beyond dismantling in a range of complex\nnetwork problems.\n","authors":["Haozhe Tian","Pietro Ferraro","Robert Shorten","Mahdi Jalili","Homayoun Hamedmoghadam"],"pdf_url":"https://arxiv.org/pdf/2508.00706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.17077v3","updated":"2025-08-01T15:21:12Z","published":"2025-02-24T11:44:43Z","title":"A comparative analysis of rank aggregation methods for the partial label\n  ranking problem","summary":"  The label ranking problem is a supervised learning scenario in which the\nlearner predicts a total order of the class labels for a given input instance.\nRecently, research has increasingly focused on the partial label ranking\nproblem, a generalization of the label ranking problem that allows ties in the\npredicted orders. So far, most existing learning approaches for the partial\nlabel ranking problem rely on approximation algorithms for rank aggregation in\nthe final prediction step. This paper explores several alternative aggregation\nmethods for this critical step, including scoring-based and non-parametric\nprobabilistic-based rank aggregation approaches. To enhance their suitability\nfor the more general partial label ranking problem, the investigated methods\nare extended to increase the likelihood of producing ties. Experimental\nevaluations on standard benchmarks demonstrate that scoring-based variants\nconsistently outperform the current state-of-the-art method in handling\nincomplete information. In contrast, non-parametric probabilistic-based\nvariants fail to achieve competitive performance.\n","authors":["Jiayi Wang","Juan C. Alfaro","Viktor Bengs"],"pdf_url":"https://arxiv.org/pdf/2502.17077v3.pdf","comment":"Full version of the paper accepted at ECAI 2025"},{"id":"http://arxiv.org/abs/2508.00695v1","updated":"2025-08-01T15:11:39Z","published":"2025-08-01T15:11:39Z","title":"Classification of Psychiatry Clinical Notes by Diagnosis: A Deep\n  Learning and Machine Learning Approach","summary":"  The classification of clinical notes into specific diagnostic categories is\ncritical in healthcare, especially for mental health conditions like Anxiety\nand Adjustment Disorder. In this study, we compare the performance of various\nArtificial Intelligence models, including both traditional Machine Learning\napproaches (Random Forest, Support Vector Machine, K-nearest neighbors,\nDecision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT\nand SciBERT), to classify clinical notes into these two diagnoses.\nAdditionally, we implemented three oversampling strategies: No Oversampling,\nRandom Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to\nassess their impact on model performance. Hyperparameter tuning was also\napplied to optimize model accuracy. Our results indicate that oversampling\ntechniques had minimal impact on model performance overall. The only exception\nwas SMOTE, which showed a positive effect specifically with BERT-based models.\nHowever, hyperparameter optimization significantly improved accuracy across the\nmodels, enhancing their ability to generalize and perform on the dataset. The\nDecision Tree and eXtreme Gradient Boost models achieved the highest accuracy\namong machine learning approaches, both reaching 96%, while the DistilBERT and\nSciBERT models also attained 96% accuracy in the deep learning category. These\nfindings underscore the importance of hyperparameter tuning in maximizing model\nperformance. This study contributes to the ongoing research on AI-assisted\ndiagnostic tools in mental health by providing insights into the efficacy of\ndifferent model architectures and data balancing methods.\n","authors":["Sergio Rubio-Martín","María Teresa García-Ordás","Antonio Serrano-García","Clara Margarita Franch-Pato","Arturo Crespo-Álvaro","José Alberto Benítez-Andrades"],"pdf_url":"https://arxiv.org/pdf/2508.00695v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00692v1","updated":"2025-08-01T15:08:03Z","published":"2025-08-01T15:08:03Z","title":"Wind Power Scenario Generation based on the Generalized Dynamic Factor\n  Model and Generative Adversarial Network","summary":"  For conducting resource adequacy studies, we synthesize multiple long-term\nwind power scenarios of distributed wind farms simultaneously by using the\nspatio-temporal features: spatial and temporal correlation, waveforms, marginal\nand ramp rates distributions of waveform, power spectral densities, and\nstatistical characteristics. Generating the spatial correlation in scenarios\nrequires the design of common factors for neighboring wind farms and\nantithetical factors for distant wind farms. The generalized dynamic factor\nmodel (GDFM) can extract the common factors through cross spectral density\nanalysis, but it cannot closely imitate waveforms. The GAN can synthesize\nplausible samples representing the temporal correlation by verifying samples\nthrough a fake sample discriminator. To combine the advantages of GDFM and GAN,\nwe use the GAN to provide a filter that extracts dynamic factors with temporal\ninformation from the observation data, and we then apply this filter in the\nGDFM to represent both spatial and frequency correlations of plausible\nwaveforms. Numerical tests on the combination of GDFM and GAN have demonstrated\nperformance improvements over competing alternatives in synthesizing wind power\nscenarios from Australia, better realizing plausible statistical\ncharacteristics of actual wind power compared to alternatives such as the GDFM\nwith a filter synthesized from distributions of actual dynamic filters and the\nGAN with direct synthesis without dynamic factors.\n","authors":["Young-ho Cho","Hao Zhu","Duehee Lee","Ross Baldick"],"pdf_url":"https://arxiv.org/pdf/2508.00692v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.02724v2","updated":"2025-08-01T15:04:52Z","published":"2025-07-03T15:41:04Z","title":"Hierarchical Multi-Label Contrastive Learning for Protein-Protein\n  Interaction Prediction Across Organisms","summary":"  Recent advances in AI for science have highlighted the power of contrastive\nlearning in bridging heterogeneous biological data modalities. Building on this\nparadigm, we propose HIPPO (HIerarchical Protein-Protein interaction prediction\nacross Organisms), a hierarchical contrastive framework for protein-protein\ninteraction(PPI) prediction, where protein sequences and their hierarchical\nattributes are aligned through multi-tiered biological representation matching.\nThe proposed approach incorporates hierarchical contrastive loss functions that\nemulate the structured relationship among functional classes of proteins. The\nframework adaptively incorporates domain and family knowledge through a\ndata-driven penalty mechanism, enforcing consistency between the learned\nembedding space and the intrinsic hierarchy of protein functions. Experiments\non benchmark datasets demonstrate that HIPPO achieves state-of-the-art\nperformance, outperforming existing methods and showing robustness in low-data\nregimes. Notably, the model demonstrates strong zero-shot transferability to\nother species without retraining, enabling reliable PPI prediction and\nfunctional inference even in less characterized or rare organisms where\nexperimental data are limited. Further analysis reveals that hierarchical\nfeature fusion is critical for capturing conserved interaction determinants,\nsuch as binding motifs and functional annotations. This work advances\ncross-species PPI prediction and provides a unified framework for interaction\nprediction in scenarios with sparse or imbalanced multi-species data.\n","authors":["Shiyi Liu","Buwen Liang","Yuetong Fang","Zixuan Jiang","Renjing Xu"],"pdf_url":"https://arxiv.org/pdf/2507.02724v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19861v2","updated":"2025-08-01T15:03:13Z","published":"2025-07-26T08:36:16Z","title":"Quantum-Informed Machine Learning for Chaotic Systems","summary":"  Learning the behaviour of chaotic systems remains challenging due to\ninstability in long-term predictions and difficulties in accurately capturing\ninvariant statistical properties. While quantum machine learning offers a\npromising route to efficiently capture physical properties from\nhigh-dimensional data, its practical deployment is hindered by current hardware\nnoise and limited scalability. Here, we introduce a quantum-informed machine\nlearning framework for learning partial differential equations, with an\napplication focus on chaotic systems. A quantum circuit Born machine is\nemployed to learn the invariant properties of chaotic dynamical systems,\nachieving substantial memory efficiency by representing these complex physical\nstatistics with a compact set of trainable circuit parameters. This approach\nreduces the data storage requirement by over two orders of magnitude compared\nto the raw simulation data. The resulting statistical quantum-informed prior is\nthen incorporated into a Koopman-based auto-regressive model to address issues\nsuch as gradient vanishing or explosion, while maintaining long-term\nstatistical fidelity. The framework is evaluated on three representative\nsystems: the Kuramoto-Sivashinsky equation, two-dimensional Kolmogorov flow and\nturbulent channel flow. In all cases, the quantum-informed model achieves\nsuperior performance compared to its classical counterparts without quantum\npriors. This hybrid architecture offers a practical route for learning\ndynamical systems using near-term quantum hardware.\n","authors":["Maida Wang","Xiao Xue","Peter V. Coveney"],"pdf_url":"https://arxiv.org/pdf/2507.19861v2.pdf","comment":"33 pages, 4 figures"},{"id":"http://arxiv.org/abs/2502.05695v3","updated":"2025-08-01T15:02:11Z","published":"2025-02-08T21:14:28Z","title":"Semantic-Aware Adaptive Video Streaming Using Latent Diffusion Models\n  for Wireless Networks","summary":"  This paper proposes a novel Semantic Communication (SemCom) framework for\nreal-time adaptive-bitrate video streaming by integrating Latent Diffusion\nModels (LDMs) within the FFmpeg techniques. This solution addresses the\nchallenges of high bandwidth usage, storage inefficiencies, and quality of\nexperience (QoE) degradation associated with traditional Constant Bitrate\nStreaming (CBS) and Adaptive Bitrate Streaming (ABS). The proposed approach\nleverages LDMs to compress I-frames into a latent space, offering significant\nstorage and semantic transmission savings without sacrificing high visual\nquality. While retaining B-frames and P-frames as adjustment metadata to\nsupport efficient refinement of video reconstruction at the user side, the\nproposed framework further incorporates state-of-the-art denoising and Video\nFrame Interpolation (VFI) techniques. These techniques mitigate semantic\nambiguity and restore temporal coherence between frames, even in noisy wireless\ncommunication environments. Experimental results demonstrate the proposed\nmethod achieves high-quality video streaming with optimized bandwidth usage,\noutperforming state-of-the-art solutions in terms of QoE and resource\nefficiency. This work opens new possibilities for scalable real-time video\nstreaming in 5G and future post-5G networks.\n","authors":["Zijiang Yan","Jianhua Pei","Hongda Wu","Hina Tabassum","Ping Wang"],"pdf_url":"https://arxiv.org/pdf/2502.05695v3.pdf","comment":"Accepted in IEEE Wireless Communications"},{"id":"http://arxiv.org/abs/2508.00679v1","updated":"2025-08-01T14:49:33Z","published":"2025-08-01T14:49:33Z","title":"Segment First, Retrieve Better: Realistic Legal Search via Rhetorical\n  Role-Based Queries","summary":"  Legal precedent retrieval is a cornerstone of the common law system, governed\nby the principle of stare decisis, which demands consistency in judicial\ndecisions. However, the growing complexity and volume of legal documents\nchallenge traditional retrieval methods. TraceRetriever mirrors real-world\nlegal search by operating with limited case information, extracting only\nrhetorically significant segments instead of requiring complete documents. Our\npipeline integrates BM25, Vector Database, and Cross-Encoder models, combining\ninitial results through Reciprocal Rank Fusion before final re-ranking.\nRhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier\ntrained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,\nTraceRetriever addresses growing document volume challenges while aligning with\npractical search constraints, reliable and scalable foundation for precedent\nretrieval enhancing legal research when only partial case knowledge is\navailable.\n","authors":["Shubham Kumar Nigam","Tanmay Dubey","Noel Shallum","Arnab Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2508.00679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00674v1","updated":"2025-08-01T14:47:47Z","published":"2025-08-01T14:47:47Z","title":"Context-Aware Visualization for Explainable AI Recommendations in Social\n  Media: A Vision for User-Aligned Explanations","summary":"  Social media platforms today strive to improve user experience through AI\nrecommendations, yet the value of such recommendations vanishes as users do not\nunderstand the reasons behind them. This issue arises because explainability in\nsocial media is general and lacks alignment with user-specific needs. In this\nvision paper, we outline a user-segmented and context-aware explanation layer\nby proposing a visual explanation system with diverse explanation methods. The\nproposed system is framed by the variety of user needs and contexts, showing\nexplanations in different visualized forms, including a technically detailed\nversion for AI experts and a simplified one for lay users. Our framework is the\nfirst to jointly adapt explanation style (visual vs. numeric) and granularity\n(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will\nvalidate its impact on decision-making and trust.\n","authors":["Banan Alkhateeb","Ellis Solaiman"],"pdf_url":"https://arxiv.org/pdf/2508.00674v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09727v3","updated":"2025-08-01T14:45:11Z","published":"2024-12-12T21:35:13Z","title":"A Large Sensor Foundation Model Pretrained on Continuous Glucose Monitor\n  Data for Diabetes Management","summary":"  Continuous glucose monitoring (CGM) combined with AI offers new opportunities\nfor proactive diabetes management through real-time glucose forecasting.\nHowever, most existing models are task-specific and lack generalization across\npatient populations. Inspired by the autoregressive paradigm of large language\nmodels, we introduce CGM-LSM, a Transformer decoder-based Large Sensor Model\n(LSM) pretrained on 1.6 million CGM records from patients with different\ndiabetes types, ages, and genders. We model patients as sequences of glucose\ntime steps to learn latent knowledge embedded in CGM data and apply it to the\nprediction of glucose readings for a 2-hour horizon. Compared with prior\nmethods, CGM-LSM significantly improves prediction accuracy and robustness: a\n48.51% reduction in root mean square error in one-hour horizon forecasting and\nconsistent zero-shot prediction performance across held-out patient groups. We\nanalyze model performance variations across patient subgroups and prediction\nscenarios and outline key opportunities and challenges for advancing CGM\nfoundation models.\n","authors":["Junjie Luo","Abhimanyu Kumbara","Mansur Shomali","Rui Han","Anand Iyer","Ritu Agarwal","Gordon Gao"],"pdf_url":"https://arxiv.org/pdf/2412.09727v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.13703v2","updated":"2025-08-01T14:44:43Z","published":"2025-07-18T07:11:50Z","title":"Binarizing Physics-Inspired GNNs for Combinatorial Optimization","summary":"  Physics-inspired graph neural networks (PI-GNNs) have been utilized as an\nefficient unsupervised framework for relaxing combinatorial optimization\nproblems encoded through a specific graph structure and loss, reflecting\ndependencies between the problem's variables. While the framework has yielded\npromising results in various combinatorial problems, we show that the\nperformance of PI-GNNs systematically plummets with an increasing density of\nthe combinatorial problem graphs. Our analysis reveals an interesting phase\ntransition in the PI-GNNs' training dynamics, associated with degenerate\nsolutions for the denser problems, highlighting a discrepancy between the\nrelaxed, real-valued model outputs and the binary-valued problem solutions. To\naddress the discrepancy, we propose principled alternatives to the naive\nstrategy used in PI-GNNs by building on insights from fuzzy logic and binarized\nneural networks. Our experiments demonstrate that the portfolio of proposed\nmethods significantly improves the performance of PI-GNNs in increasingly dense\nsettings.\n","authors":["Martin Krutský","Gustav Šír","Vyacheslav Kungurtsev","Georgios Korpas"],"pdf_url":"https://arxiv.org/pdf/2507.13703v2.pdf","comment":"Accepted to the 28th European Conference on Artificial Intelligence\n  (ECAI 2025). This archival version includes supplementary appendices"},{"id":"http://arxiv.org/abs/2507.22766v2","updated":"2025-08-01T14:42:27Z","published":"2025-07-30T15:31:39Z","title":"Bayesian Optimization of Process Parameters of a Sensor-Based Sorting\n  System using Gaussian Processes as Surrogate Models","summary":"  Sensor-based sorting systems enable the physical separation of a material\nstream into two fractions. The sorting decision is based on the image data\nevaluation of the sensors used and is carried out using actuators. Various\nprocess parameters must be set depending on the properties of the material\nstream, the dimensioning of the system, and the required sorting accuracy.\nHowever, continuous verification and re-adjustment are necessary due to\nchanging requirements and material stream compositions. In this paper, we\nintroduce an approach for optimizing, recurrently monitoring and adjusting the\nprocess parameters of a sensor-based sorting system. Based on Bayesian\nOptimization, Gaussian process regression models are used as surrogate models\nto achieve specific requirements for system behavior with the uncertainties\ncontained therein. This method minimizes the number of necessary experiments\nwhile simultaneously considering two possible optimization targets based on the\nrequirements for both material output streams. In addition, uncertainties are\nconsidered during determining sorting accuracies in the model calculation. We\nevaluated the method with three example process parameters.\n","authors":["Felix Kronenwett","Georg Maier","Thomas Längle"],"pdf_url":"https://arxiv.org/pdf/2507.22766v2.pdf","comment":"Accepted at the 30th IEEE International Conference on Emerging\n  Technologies and Factory Automation (ETFA)"},{"id":"http://arxiv.org/abs/2508.00669v1","updated":"2025-08-01T14:41:31Z","published":"2025-08-01T14:41:31Z","title":"Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement\n  Techniques and Applications","summary":"  The proliferation of Large Language Models (LLMs) in medicine has enabled\nimpressive capabilities, yet a critical gap remains in their ability to perform\nsystematic, transparent, and verifiable reasoning, a cornerstone of clinical\npractice. This has catalyzed a shift from single-step answer generation to the\ndevelopment of LLMs explicitly designed for medical reasoning. This paper\nprovides the first systematic review of this emerging field. We propose a\ntaxonomy of reasoning enhancement techniques, categorized into training-time\nstrategies (e.g., supervised fine-tuning, reinforcement learning) and test-time\nmechanisms (e.g., prompt engineering, multi-agent systems). We analyze how\nthese techniques are applied across different data modalities (text, image,\ncode) and in key clinical applications such as diagnosis, education, and\ntreatment planning. Furthermore, we survey the evolution of evaluation\nbenchmarks from simple accuracy metrics to sophisticated assessments of\nreasoning quality and visual interpretability. Based on an analysis of 60\nseminal studies from 2022-2025, we conclude by identifying critical challenges,\nincluding the faithfulness-plausibility gap and the need for native multimodal\nreasoning, and outlining future directions toward building efficient, robust,\nand sociotechnically responsible medical AI.\n","authors":["Wenxuan Wang","Zizhan Ma","Meidan Ding","Shiyi Zheng","Shengyuan Liu","Jie Liu","Jiaming Ji","Wenting Chen","Xiang Li","Linlin Shen","Yixuan Yuan"],"pdf_url":"https://arxiv.org/pdf/2508.00669v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00665v1","updated":"2025-08-01T14:36:16Z","published":"2025-08-01T14:36:16Z","title":"Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI","summary":"  Artificial intelligence-driven adaptive learning systems are reshaping\neducation through data-driven adaptation of learning experiences. Yet many of\nthese systems lack transparency, offering limited insight into how decisions\nare made. Most explainable AI (XAI) techniques focus on technical outputs but\nneglect user roles and comprehension. This paper proposes a hybrid framework\nthat integrates traditional XAI techniques with generative AI models and user\npersonalisation to generate multimodal, personalised explanations tailored to\nuser needs. We redefine explainability as a dynamic communication process\ntailored to user roles and learning goals. We outline the framework's design,\nkey XAI limitations in education, and research directions on accuracy,\nfairness, and personalisation. Our aim is to move towards explainable AI that\nenhances transparency while supporting user-centred experiences.\n","authors":["Maryam Mosleh","Marie Devlin","Ellis Solaiman"],"pdf_url":"https://arxiv.org/pdf/2508.00665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00664v1","updated":"2025-08-01T14:35:50Z","published":"2025-08-01T14:35:50Z","title":"DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic\n  Prototypes","summary":"  Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies\nin evolving graphs across domains such as finance, traffic, and social\nnetworks. Recently, generalist graph anomaly detection (GAD) models have shown\npromising results. They are pretrained on multiple source datasets and\ngeneralize across domains. While effective on static graphs, they struggle to\ncapture evolving anomalies in dynamic graphs. Moreover, the continuous\nemergence of new domains and the lack of labeled data further challenge\ngeneralist DGAD. Effective cross-domain DGAD requires both domain-specific and\ndomain-agnostic anomalous patterns. Importantly, these patterns evolve\ntemporally within and across domains. Building on these insights, we propose a\nDGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and\ndomain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,\nevolving representations of normal and anomalous patterns, from temporal\nego-graphs and stores them in a memory buffer. The buffer is selectively\nupdated to retain general, domain-agnostic patterns while incorporating new\ndomain-specific ones. Then, an anomaly scorer compares incoming data with\ndynamic prototypes to flag both general and domain-specific anomalies. Finally,\nDP-DGAD employs confidence-based pseudo-labeling for effective self-supervised\nadaptation in target domains. Extensive experiments demonstrate\nstate-of-the-art performance across ten real-world datasets from different\ndomains.\n","authors":["Jialun Zheng","Jie Liu","Jiannong Cao","Xiao Wang","Hanchen Yang","Yankai Chen","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2508.00664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00658v1","updated":"2025-08-01T14:22:51Z","published":"2025-08-01T14:22:51Z","title":"Multi-Band Variable-Lag Granger Causality: A Unified Framework for\n  Causal Time Series Inference across Frequencies","summary":"  Understanding causal relationships in time series is fundamental to many\ndomains, including neuroscience, economics, and behavioral science. Granger\ncausality is one of the well-known techniques for inferring causality in time\nseries. Typically, Granger causality frameworks have a strong fix-lag\nassumption between cause and effect, which is often unrealistic in complex\nsystems. While recent work on variable-lag Granger causality (VLGC) addresses\nthis limitation by allowing a cause to influence an effect with different time\nlags at each time point, it fails to account for the fact that causal\ninteractions may vary not only in time delay but also across frequency bands.\nFor example, in brain signals, alpha-band activity may influence another region\nwith a shorter delay than slower delta-band oscillations. In this work, we\nformalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a\nnovel framework that generalizes traditional VLGC by explicitly modeling\nfrequency-dependent causal delays. We provide a formal definition of MB-VLGC,\ndemonstrate its theoretical soundness, and propose an efficient inference\npipeline. Extensive experiments across multiple domains demonstrate that our\nframework significantly outperforms existing methods on both synthetic and\nreal-world datasets, confirming its broad applicability to any type of time\nseries data. Code and datasets are publicly available.\n","authors":["Chakattrai Sookkongwaree","Tattep Lakmuang","Chainarong Amornbunchornvej"],"pdf_url":"https://arxiv.org/pdf/2508.00658v1.pdf","comment":"First draft"},{"id":"http://arxiv.org/abs/2508.00657v1","updated":"2025-08-01T14:18:51Z","published":"2025-08-01T14:18:51Z","title":"TrajSurv: Learning Continuous Latent Trajectories from Electronic Health\n  Records for Trustworthy Survival Prediction","summary":"  Trustworthy survival prediction is essential for clinical decision making.\nLongitudinal electronic health records (EHRs) provide a uniquely powerful\nopportunity for the prediction. However, it is challenging to accurately model\nthe continuous clinical progression of patients underlying the irregularly\nsampled clinical features and to transparently link the progression to survival\noutcomes. To address these challenges, we develop TrajSurv, a model that learns\ncontinuous latent trajectories from longitudinal EHR data for trustworthy\nsurvival prediction. TrajSurv employs a neural controlled differential equation\n(NCDE) to extract continuous-time latent states from the irregularly sampled\ndata, forming continuous latent trajectories. To ensure the latent trajectories\nreflect the clinical progression, TrajSurv aligns the latent state space with\npatient state space through a time-aware contrastive learning approach. To\ntransparently link clinical progression to the survival outcome, TrajSurv uses\nlatent trajectories in a two-step divide-and-conquer interpretation process.\nFirst, it explains how the changes in clinical features translate into the\nlatent trajectory's evolution using a learned vector field. Second, it clusters\nthese latent trajectories to identify key clinical progression patterns\nassociated with different survival outcomes. Evaluations on two real-world\nmedical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and\nsuperior transparency over existing deep learning methods.\n","authors":["Sihang Zeng","Lucas Jing Liu","Jun Wen","Meliha Yetisgen","Ruth Etzioni","Gang Luo"],"pdf_url":"https://arxiv.org/pdf/2508.00657v1.pdf","comment":"Accepted by MLHC 2025"},{"id":"http://arxiv.org/abs/2411.15173v2","updated":"2025-08-01T14:16:18Z","published":"2024-11-16T12:29:59Z","title":"Un-mixing Test-time Adaptation under Heterogeneous Data Streams","summary":"  Deploying deep models in real-world scenarios remains challenging due to\nsignificant performance drops under distribution shifts between training and\ndeployment environments. Test-Time Adaptation (TTA) has recently emerged as a\npromising solution, enabling on-the-fly model adaptation without access to\nsource data. However, its effectiveness degrades significantly in the presence\nof complex, mixed distribution shifts - common in practical settings - where\nmultiple latent domains coexist. Adapting under such intrinsic heterogeneity,\nespecially in unlabeled and online conditions, remains an open and\nunderexplored challenge. In this paper, we study TTA under mixed distribution\nshifts and move beyond conventional homogeneous adaptation paradigms. By\nrevisiting TTA from a frequency-domain perspective, we observe that\ndistribution heterogeneity often manifests in Fourier space - for instance,\nhigh-frequency components tend to carry domain-specific variations. This\nmotivates us to perform domain-aware separation using high-frequency texture\ncues, making diverse shift patterns more tractable. To this end, we propose\nFreDA, a novel Frequency-based Decentralized Adaptation framework that\ndecomposes globally heterogeneous data into locally homogeneous components in\nthe frequency domain. It further employs decentralized learning and\naugmentation strategies to robustly adapt under complex, evolving shifts.\nExtensive experiments across various environments (corrupted, natural, and\nmedical) demonstrate the superiority of our proposed framework over the\nstate-of-the-arts.\n","authors":["Zixian Su","Jingwei Guo","Xi Yang","Qiufeng Wang","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2411.15173v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18749v4","updated":"2025-08-01T14:04:28Z","published":"2024-09-27T13:39:47Z","title":"TensorSocket: Shared Data Loading for Deep Learning Training","summary":"  Training deep learning models is a repetitive and resource-intensive process.\nData scientists often train several models before landing on a set of\nparameters (e.g., hyper-parameter tuning) and model architecture (e.g., neural\narchitecture search), among other things that yield the highest accuracy. The\ncomputational efficiency of these training tasks depends highly on how well the\ntraining data is supplied to the training process. The repetitive nature of\nthese tasks results in the same data processing pipelines running over and\nover, exacerbating the need for and costs of computational resources. In this\npaper, we present TensorSocket to reduce the computational needs of deep\nlearning training by enabling simultaneous training processes to share the same\ndata loader. TensorSocket mitigates CPU-side bottlenecks in cases where the\ncollocated training workloads have high throughput on GPU, but are held back by\nlower data-loading throughput on CPU. TensorSocket achieves this by reducing\nredundant computations and data duplication across collocated training\nprocesses and leveraging modern GPU-GPU interconnects. While doing so,\nTensorSocket is able to train and balance differently-sized models and serve\nmultiple batch sizes simultaneously and is hardware- and pipeline-agnostic in\nnature. Our evaluation shows that TensorSocket enables scenarios that are\ninfeasible without data sharing, increases training throughput by up to 100%,\nand when utilizing cloud instances, achieves cost savings of 50% by reducing\nthe hardware resource needs on the CPU side. Furthermore, TensorSocket\noutperforms the state-of-the-art solutions for shared data loading such as\nCoorDL and Joader; it is easier to deploy and maintain and either achieves\nhigher or matches their throughput while requiring fewer CPU resources.\n","authors":["Ties Robroek","Neil Kim Nielsen","Pınar Tözün"],"pdf_url":"https://arxiv.org/pdf/2409.18749v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00643v1","updated":"2025-08-01T13:57:19Z","published":"2025-08-01T13:57:19Z","title":"Light-Weight Diffusion Multiplier and Uncertainty Quantification for\n  Fourier Neural Operators","summary":"  Operator learning is a powerful paradigm for solving partial differential\nequations, with Fourier Neural Operators serving as a widely adopted\nfoundation. However, FNOs face significant scalability challenges due to\noverparameterization and offer no native uncertainty quantification -- a key\nrequirement for reliable scientific and engineering applications. Instead,\nneural operators rely on post hoc UQ methods that ignore geometric inductive\nbiases. In this work, we introduce DINOZAUR: a diffusion-based neural operator\nparametrization with uncertainty quantification. Inspired by the structure of\nthe heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a\ndimensionality-independent diffusion multiplier that has a single learnable\ntime parameter per channel, drastically reducing parameter count and memory\nfootprint without compromising predictive performance. By defining priors over\nthose time parameters, we cast DINOZAUR as a Bayesian neural operator to yield\nspatially correlated outputs and calibrated uncertainty estimates. Our method\nachieves competitive or superior performance across several PDE benchmarks\nwhile providing efficient uncertainty quantification.\n","authors":["Albert Matveev","Sanmitra Ghosh","Aamal Hussain","James-Michael Leahy","Michalis Michaelides"],"pdf_url":"https://arxiv.org/pdf/2508.00643v1.pdf","comment":null}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2508.00824v1","updated":"2025-08-01T17:59:57Z","published":"2025-08-01T17:59:57Z","title":"Local Poisson Deconvolution for Discrete Signals","summary":"  We analyze the statistical problem of recovering an atomic signal, modeled as\na discrete uniform distribution $\\mu$, from a binned Poisson convolution model.\nThis question is motivated, among others, by super-resolution laser microscopy\napplications, where precise estimation of $\\mu$ provides insights into spatial\nformations of cellular protein assemblies. Our main results quantify the local\nminimax risk of estimating $\\mu$ for a broad class of smooth convolution\nkernels. This local perspective enables us to sharply quantify optimal\nestimation rates as a function of the clustering structure of the underlying\nsignal. Moreover, our results are expressed under a multiscale loss function,\nwhich reveals that different parts of the underlying signal can be recovered at\ndifferent rates depending on their local geometry. Overall, these results paint\nan optimistic perspective on the Poisson deconvolution problem, showing that\naccurate recovery is achievable under a much broader class of signals than\nsuggested by existing global minimax analyses. Beyond Poisson deconvolution,\nour results also allow us to establish the local minimax rate of parameter\nestimation in Gaussian mixture models with uniform weights.\n  We apply our methods to experimental super-resolution microscopy data to\nidentify the location and configuration of individual DNA origamis. In\naddition, we complement our findings with numerical experiments on runtime and\nstatistical recovery that showcase the practical performance of our estimators\nand their trade-offs.\n","authors":["Shayan Hundrieser","Tudor Manole","Danila Litskevich","Axel Munk"],"pdf_url":"https://arxiv.org/pdf/2508.00824v1.pdf","comment":"The first two authors contributed equally"},{"id":"http://arxiv.org/abs/2504.21688v2","updated":"2025-08-01T17:16:08Z","published":"2025-04-30T14:23:50Z","title":"Assessing Racial Disparities in Healthcare Expenditures via Mediator\n  Distribution Shifts","summary":"  Racial disparities in healthcare expenditures are well-documented, yet the\nunderlying drivers remain complex and require further investigation. This study\ndevelops a framework for decomposing such disparities through shifts in the\ndistributions of mediating variables, rather than treating race itself as a\nmanipulable exposure. We define disparities as differences in\ncovariate-adjusted outcome distributions across racial groups, and decompose\nthe total disparity into two components: one attributable to differences in\nmediator distributions, and another residual component that would remain even\nafter equalizing these distributions. Using data from the Medical Expenditures\nPanel Survey, we examine the extent to which expenditure disparities would\npersist or be reduced if mediators such as socioeconomic status, insurance\naccess, health behaviors, or health status were equalized across racial groups.\nTo ensure valid inference, we derive asymptotically linear estimators based on\ninfluence-function techniques and flexible machine learning tools, including\nsuper learners and a two-part model designed for the zero-inflated,\nright-skewed nature of expenditure data.\n","authors":["Xiaxian Ou","Xinwei He","David Benkeser","Razieh Nabi"],"pdf_url":"https://arxiv.org/pdf/2504.21688v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.10498v2","updated":"2025-08-01T17:02:02Z","published":"2025-05-15T17:00:51Z","title":"Batched Nonparametric Bandits via k-Nearest Neighbor UCB","summary":"  We study sequential decision-making in batched nonparametric contextual\nbandits, where actions are selected over a finite horizon divided into a small\nnumber of batches. Motivated by constraints in domains such as medicine and\nmarketing -- where online feedback is limited -- we propose a nonparametric\nalgorithm that combines adaptive k-nearest neighbor (k-NN) regression with the\nupper confidence bound (UCB) principle. Our method, BaNk-UCB, is fully\nnonparametric, adapts to the context dimension, and is simple to implement.\nUnlike prior work relying on parametric or binning-based estimators, BaNk-UCB\nuses local geometry to estimate rewards and adaptively balances exploration and\nexploitation. We provide near-optimal regret guarantees under standard\nLipschitz smoothness and margin assumptions, using a theoretically motivated\nbatch schedule that balances regret across batches and achieves minimax-optimal\nrates. Empirical evaluations on synthetic and real-world datasets demonstrate\nthat BaNk-UCB consistently outperforms binning-based baselines.\n","authors":["Sakshi Arya"],"pdf_url":"https://arxiv.org/pdf/2505.10498v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.01046v3","updated":"2025-08-01T16:12:08Z","published":"2023-12-02T07:00:46Z","title":"Bagged Regularized $k$-Distances for Anomaly Detection","summary":"  We consider the paradigm of unsupervised anomaly detection, which involves\nthe identification of anomalies within a dataset in the absence of labeled\nexamples. Though distance-based methods are top-performing for unsupervised\nanomaly detection, they suffer heavily from the sensitivity to the choice of\nthe number of the nearest neighbors. In this paper, we propose a new\ndistance-based algorithm called bagged regularized $k$-distances for anomaly\ndetection (BRDAD), converting the unsupervised anomaly detection problem into a\nconvex optimization problem. Our BRDAD algorithm selects the weights by\nminimizing the surrogate risk, i.e., the finite sample bound of the empirical\nrisk of the bagged weighted $k$-distances for density estimation (BWDDE). This\napproach enables us to successfully address the sensitivity challenge of the\nhyperparameter choice in distance-based algorithms. Moreover, when dealing with\nlarge-scale datasets, the efficiency issues can be addressed by the\nincorporated bagging technique in our BRDAD algorithm. On the theoretical side,\nwe establish fast convergence rates of the AUC regret of our algorithm and\ndemonstrate that the bagging technique significantly reduces the computational\ncomplexity. On the practical side, we conduct numerical experiments to\nillustrate the insensitivity of the parameter selection of our algorithm\ncompared with other state-of-the-art distance-based methods. Furthermore, our\nmethod achieves superior performance on real-world datasets with the introduced\nbagging technique compared to other approaches.\n","authors":["Yuchao Cai","Hanfang Yang","Yuheng Ma","Hanyuan Hang"],"pdf_url":"https://arxiv.org/pdf/2312.01046v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08177v2","updated":"2025-08-01T16:07:13Z","published":"2024-08-15T14:30:34Z","title":"Localized Sparse Principal Component Analysis of Multivariate Time\n  Series in Frequency Domain","summary":"  Principal component analysis has been a main tool in multivariate analysis\nfor estimating a low dimensional linear subspace that explains most of the\nvariability in the data. However, in high-dimensional regimes, naive estimates\nof the principal loadings are not consistent and difficult to interpret. In the\ncontext of time series, principal component analysis of spectral density\nmatrices can provide valuable, parsimonious information about the behavior of\nthe underlying process, particularly if the principal components are\ninterpretable in that they are sparse in coordinates and localized in frequency\nbands. In this paper, we introduce a formulation and consistent estimation\nprocedure for interpretable principal component analysis for high-dimensional\ntime series in the frequency domain. An efficient frequency-sequential\nalgorithm is developed to compute sparse-localized estimates of the\nlow-dimensional principal subspaces of the signal process. The method is\nmotivated by and used to understand neurological mechanisms from high-density\nresting-state EEG in a study of first episode psychosis.\n","authors":["Jamshid Namdari","Amita Manatunga","Fabio Ferrarelli","Robert Krafty"],"pdf_url":"https://arxiv.org/pdf/2408.08177v2.pdf","comment":"63 pages, 6 figures"},{"id":"http://arxiv.org/abs/2405.16958v2","updated":"2025-08-01T15:53:30Z","published":"2024-05-27T08:53:24Z","title":"Large Deviations of Gaussian Neural Networks with ReLU activation","summary":"  We prove a large deviation principle for deep neural networks with Gaussian\nweights and at most linearly growing activation functions, such as ReLU. This\ngeneralises earlier work, in which bounded and continuous activation functions\nwere considered. In practice, linearly growing activation functions such as\nReLU are most commonly used. We furthermore simplify previous expressions for\nthe rate function and provide a power-series expansions for the ReLU case.\n","authors":["Quirin Vogel"],"pdf_url":"https://arxiv.org/pdf/2405.16958v2.pdf","comment":"13 pages, 2 figures, proof simplified"},{"id":"http://arxiv.org/abs/2406.15500v2","updated":"2025-08-01T15:30:13Z","published":"2024-06-19T12:07:22Z","title":"Pure interaction effects unseen by Random Forests","summary":"  Random Forests are widely claimed to capture interactions well. However, some\nsimple examples suggest that they perform poorly in the presence of certain\npure interactions that the conventional CART criterion struggles to capture\nduring tree construction. Motivated from this, it is argued that simple\nalternative partitioning schemes used in the tree growing procedure can enhance\nidentification of these interactions. In a simulation study these variants are\ncompared to conventional Random Forests and Extremely Randomized Trees. The\nresults validate that the modifications considered enhance the model's fitting\nability in scenarios where pure interactions play a crucial role. Finally, the\nmethods are applied to real datasets.\n","authors":["Ricardo Blum","Munir Hiabu","Enno Mammen","Joseph Theo Meyer"],"pdf_url":"https://arxiv.org/pdf/2406.15500v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2309.01460"},{"id":"http://arxiv.org/abs/2502.17077v3","updated":"2025-08-01T15:21:12Z","published":"2025-02-24T11:44:43Z","title":"A comparative analysis of rank aggregation methods for the partial label\n  ranking problem","summary":"  The label ranking problem is a supervised learning scenario in which the\nlearner predicts a total order of the class labels for a given input instance.\nRecently, research has increasingly focused on the partial label ranking\nproblem, a generalization of the label ranking problem that allows ties in the\npredicted orders. So far, most existing learning approaches for the partial\nlabel ranking problem rely on approximation algorithms for rank aggregation in\nthe final prediction step. This paper explores several alternative aggregation\nmethods for this critical step, including scoring-based and non-parametric\nprobabilistic-based rank aggregation approaches. To enhance their suitability\nfor the more general partial label ranking problem, the investigated methods\nare extended to increase the likelihood of producing ties. Experimental\nevaluations on standard benchmarks demonstrate that scoring-based variants\nconsistently outperform the current state-of-the-art method in handling\nincomplete information. In contrast, non-parametric probabilistic-based\nvariants fail to achieve competitive performance.\n","authors":["Jiayi Wang","Juan C. Alfaro","Viktor Bengs"],"pdf_url":"https://arxiv.org/pdf/2502.17077v3.pdf","comment":"Full version of the paper accepted at ECAI 2025"},{"id":"http://arxiv.org/abs/2508.00617v1","updated":"2025-08-01T13:25:59Z","published":"2025-08-01T13:25:59Z","title":"Constructive Disintegration and Conditional Modes","summary":"  Conditioning, the central operation in Bayesian statistics, is formalised by\nthe notion of disintegration of measures. However, due to the implicit nature\nof their definition, constructing disintegrations is often difficult. A\nfolklore result in machine learning conflates the construction of a\ndisintegration with the restriction of probability density functions onto the\nsubset of events that are consistent with a given observation. We provide a\ncomprehensive set of mathematical tools which can be used to construct\ndisintegrations and apply these to find densities of disintegrations on\ndifferentiable manifolds. Using our results, we provide a disturbingly simple\nexample in which the restricted density and the disintegration density\ndrastically disagree. Motivated by applications in approximate Bayesian\ninference and Bayesian inverse problems, we further study the modes of\ndisintegrations. We show that the recently introduced notion of a \"conditional\nmode\" does not coincide in general with the modes of the conditional measure\nobtained through disintegration, but rather the modes of the restricted\nmeasure. We also discuss the implications of the discrepancy between the two\nmeasures in practice, advocating for the utility of both approaches depending\non the modelling context.\n","authors":["Nathaël Da Costa","Marvin Pförtner","Jon Cockayne"],"pdf_url":"https://arxiv.org/pdf/2508.00617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00545v1","updated":"2025-08-01T11:36:21Z","published":"2025-08-01T11:36:21Z","title":"Foundations of Interpretable Models","summary":"  We argue that existing definitions of interpretability are not actionable in\nthat they fail to inform users about general, sound, and robust interpretable\nmodel design. This makes current interpretability research fundamentally\nill-posed. To address this issue, we propose a definition of interpretability\nthat is general, simple, and subsumes existing informal notions within the\ninterpretable AI community. We show that our definition is actionable, as it\ndirectly reveals the foundational properties, underlying assumptions,\nprinciples, data structures, and architectural features necessary for designing\ninterpretable models. Building on this, we propose a general blueprint for\ndesigning interpretable models and introduce the first open-sourced library\nwith native support for interpretable data structures and processes.\n","authors":["Pietro Barbiero","Mateo Espinosa Zarlenga","Alberto Termine","Mateja Jamnik","Giuseppe Marra"],"pdf_url":"https://arxiv.org/pdf/2508.00545v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01908v2","updated":"2025-08-01T07:58:25Z","published":"2024-09-03T13:58:09Z","title":"Bayesian CART models for aggregate claim modeling","summary":"  This paper proposes three types of Bayesian CART (or BCART) models for\naggregate claim amount, namely, frequency-severity models, sequential models\nand joint models. We propose a general framework for the BCART models\napplicable to data with multivariate responses, which is particularly useful\nfor the joint BCART models with a bivariate response: the number of claims and\naggregate claim amount. To facilitate frequency-severity modeling, we\ninvestigate BCART models for the right-skewed and heavy-tailed claim severity\ndata by using various distributions. We discover that the Weibull distribution\nis superior to gamma and lognormal distributions, due to its ability to capture\ndifferent tail characteristics in tree models. Additionally, we find that\nsequential BCART models and joint BCART models, which incorporate dependence\nbetween the number of claims and average severity, are beneficial and thus\npreferable to the frequency-severity BCART models in which independence is\nassumed. The effectiveness of these models' performance is illustrated by\ncarefully designed simulations and real insurance data.\n","authors":["Yaojun Zhang","Lanpeng Ji","Georgios Aivaliotis","Charles C. Taylor"],"pdf_url":"https://arxiv.org/pdf/2409.01908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.20980v2","updated":"2025-08-01T05:21:32Z","published":"2025-07-28T16:43:11Z","title":"LargeMvC-Net: Anchor-based Deep Unfolding Network for Large-scale\n  Multi-view Clustering","summary":"  Deep anchor-based multi-view clustering methods enhance the scalability of\nneural networks by utilizing representative anchors to reduce the computational\ncomplexity of large-scale clustering. Despite their scalability advantages,\nexisting approaches often incorporate anchor structures in a heuristic or\ntask-agnostic manner, either through post-hoc graph construction or as\nauxiliary components for message passing. Such designs overlook the core\nstructural demands of anchor-based clustering, neglecting key optimization\nprinciples. To bridge this gap, we revisit the underlying optimization problem\nof large-scale anchor-based multi-view clustering and unfold its iterative\nsolution into a novel deep network architecture, termed LargeMvC-Net. The\nproposed model decomposes the anchor-based clustering process into three\nmodules: RepresentModule, NoiseModule, and AnchorModule, corresponding to\nrepresentation learning, noise suppression, and anchor indicator estimation.\nEach module is derived by unfolding a step of the original optimization\nprocedure into a dedicated network component, providing structural clarity and\noptimization traceability. In addition, an unsupervised reconstruction loss\naligns each view with the anchor-induced latent space, encouraging consistent\nclustering structures across views. Extensive experiments on several\nlarge-scale multi-view benchmarks show that LargeMvC-Net consistently\noutperforms state-of-the-art methods in terms of both effectiveness and\nscalability.\n","authors":["Shide Du","Chunming Wu","Zihan Fang","Wendi Zhao","Yilin Wu","Changwei Wang","Shiping Wang"],"pdf_url":"https://arxiv.org/pdf/2507.20980v2.pdf","comment":"10 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.00286v1","updated":"2025-08-01T03:08:19Z","published":"2025-08-01T03:08:19Z","title":"Toward using explainable data-driven surrogate models for treating\n  performance-based seismic design as an inverse engineering problem","summary":"  This study presents a methodology to treat performance-based seismic design\nas an inverse engineering problem, where design parameters are directly derived\nto achieve specific performance objectives. By implementing explainable machine\nlearning models, this methodology directly maps design variables and\nperformance metrics, tackling computational inefficiencies of performance-based\ndesign. The resultant machine learning model is integrated as an evaluation\nfunction into a genetic optimization algorithm to solve the inverse problem.\nThe developed methodology is then applied to two different inventories of steel\nand concrete moment frames in Los Angeles and Charleston to obtain sectional\nproperties of frame members that minimize expected annualized seismic loss in\nterms of repair costs. The results show high accuracy of the surrogate models\n(e.g., R2> 90%) across a diverse set of building types, geometries, seismic\ndesign, and site hazard, where the optimization algorithm could identify the\noptimum values of members' properties for a fixed set of geometric variables,\nconsistent with engineering principles.\n","authors":["Mohsen Zaker Esteghamati"],"pdf_url":"https://arxiv.org/pdf/2508.00286v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00264v1","updated":"2025-08-01T02:12:20Z","published":"2025-08-01T02:12:20Z","title":"Calibrated Language Models and How to Find Them with Label Smoothing","summary":"  Recent advances in natural language processing (NLP) have opened up greater\nopportunities to enable fine-tuned large language models (LLMs) to behave as\nmore powerful interactive agents through improved instruction-following\nability. However, understanding how this impacts confidence calibration for\nreliable model output has not been researched in full. In this work, we examine\nvarious open-sourced LLMs, identifying significant calibration degradation\nafter instruction tuning in each. Seeking a practical solution, we look towards\nlabel smoothing, which has been shown as an effective method to regularize for\noverconfident predictions but has yet to be widely adopted in the supervised\nfine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing\nis sufficient to maintain calibration throughout the SFT process. However,\nsettings remain where the effectiveness of smoothing is severely diminished, in\nparticular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to\nstem from the ability to become over-confident, which has a direct relationship\nwith the hidden size and vocabulary size, and justify this theoretically and\nexperimentally. Finally, we address an outstanding issue regarding the memory\nfootprint of the cross-entropy loss computation in the label smoothed loss\nsetting, designing a customized kernel to dramatically reduce memory\nconsumption without sacrificing speed or performance in comparison to existing\nsolutions for non-smoothed losses.\n","authors":["Jerry Huang","Peng Lu","Qiuhao Zeng"],"pdf_url":"https://arxiv.org/pdf/2508.00264v1.pdf","comment":"Accepted to the Forty-second International Conference on Machine\n  Learning (ICML) 2025. First two authors contributed equally"},{"id":"http://arxiv.org/abs/2504.21647v2","updated":"2025-08-01T01:24:36Z","published":"2025-04-30T13:51:38Z","title":"Conditional independence testing with a single realization of a\n  multivariate nonstationary nonlinear time series","summary":"  Identifying relationships among stochastic processes is a core objective in\nmany fields, such as economics. While the standard toolkit for multivariate\ntime series analysis has many advantages, it can be difficult to capture\nnonlinear dynamics using linear vector autoregressive models. This difficulty\nhas motivated the development of methods for causal discovery and variable\nselection for nonlinear time series, which routinely employ tests for\nconditional independence. In this paper, we introduce the first framework for\nconditional independence testing that works with a single realization of a\nnonstationary nonlinear process. We also show how our framework can be used to\ntest for independence. The key technical ingredients of our framework are\ntime-varying nonlinear regression, estimation of local long-run covariance\nmatrices of products of error processes, and a distribution-uniform strong\nGaussian approximation.\n","authors":["Michael Wieck-Sosa","Michel F. C. Haddad","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2504.21647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00247v1","updated":"2025-08-01T01:16:09Z","published":"2025-08-01T01:16:09Z","title":"Sinusoidal Approximation Theorem for Kolmogorov-Arnold Networks","summary":"  The Kolmogorov-Arnold representation theorem states that any continuous\nmultivariable function can be exactly represented as a finite superposition of\ncontinuous single variable functions. Subsequent simplifications of this\nrepresentation involve expressing these functions as parameterized sums of a\nsmaller number of unique monotonic functions. These developments led to the\nproof of the universal approximation capabilities of multilayer perceptron\nnetworks with sigmoidal activations, forming the alternative theoretical\ndirection of most modern neural networks.\n  Kolmogorov-Arnold Networks (KANs) have been recently proposed as an\nalternative to multilayer perceptrons. KANs feature learnable nonlinear\nactivations applied directly to input values, modeled as weighted sums of basis\nspline functions. This approach replaces the linear transformations and\nsigmoidal post-activations used in traditional perceptrons. Subsequent works\nhave explored alternatives to spline-based activations. In this work, we\npropose a novel KAN variant by replacing both the inner and outer functions in\nthe Kolmogorov-Arnold representation with weighted sinusoidal functions of\nlearnable frequencies. Inspired by simplifications introduced by Lorentz and\nSprecher, we fix the phases of the sinusoidal activations to linearly spaced\nconstant values and provide a proof of its theoretical validity. We also\nconduct numerical experiments to evaluate its performance on a range of\nmultivariable functions, comparing it with fixed-frequency Fourier transform\nmethods and multilayer perceptrons (MLPs). We show that it outperforms the\nfixed-frequency Fourier transform and achieves comparable performance to MLPs.\n","authors":["Sergei Gleyzer","Hanh Nguyen","Dinesh P. Ramakrishnan","Eric A. F. Reinhardt"],"pdf_url":"https://arxiv.org/pdf/2508.00247v1.pdf","comment":"15 pages, 3 figures"}],"Computation":[{"id":"http://arxiv.org/abs/2508.00696v1","updated":"2025-08-01T15:12:58Z","published":"2025-08-01T15:12:58Z","title":"Online Rolling Controlled Sequential Monte Carlo","summary":"  We introduce methodology for real-time inference in general-state-space\nhidden Markov models. Specifically, we extend recent advances in controlled\nsequential Monte Carlo (CSMC) methods-originally proposed for offline\nsmoothing-to the online setting via a rolling window mechanism. Our novel\nonline rolling controlled sequential Monte Carlo (ORCSMC) algorithm employs two\nparticle systems to simultaneously estimate twisting functions and perform\nfiltering, ensuring real-time adaptivity to new observations while maintaining\nbounded computational cost. Numerical results on linear-Gaussian, stochastic\nvolatility, and neuroscience models demonstrate improved estimation accuracy\nand robustness in higher dimensions, compared to standard particle filtering\napproaches. The method offers a statistically efficient and practical solution\nfor sequential and real-time inference in complex latent variable models.\n","authors":["Liwen Xue","Axel Finke","Adam M. Johansen"],"pdf_url":"https://arxiv.org/pdf/2508.00696v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.12479v2","updated":"2025-08-01T13:13:42Z","published":"2024-11-19T13:01:05Z","title":"Graph-based Square-Root Estimation for Sparse Linear Regression","summary":"  Sparse linear regression is one of the classic problems in the field of\nstatistics, which has deep connections and high intersections with\noptimization, computation, and machine learning. To address the effective\nhandling of high-dimensional data, the diversity of real noise, and the\nchallenges in estimating standard deviation of the noise, we propose a novel\nand general graph-based square-root estimation (GSRE) model for sparse linear\nregression. Specifically, we use square-root-loss function to encourage the\nestimators to be independent of the unknown standard deviation of the error\nterms and design a sparse regularization term by using the graphical structure\namong predictors in a node-by-node form. Based on the predictor graphs with\nspecial structure, we highlight the generality by analyzing that the model in\nthis paper is equivalent to several classic regression models. Theoretically,\nwe also analyze the finite sample bounds, asymptotic normality and model\nselection consistency of GSRE method without relying on the standard deviation\nof error terms. In terms of computation, we employ the fast and efficient\nalternating direction method of multipliers. Finally, based on a large number\nof simulated and real data with various types of noise, we demonstrate the\nperformance advantages of the proposed method in estimation, prediction and\nmodel selection.\n","authors":["Peili Li","Zhuomei Li","Yunhai Xiao","Chao Ying","Zhou Yu"],"pdf_url":"https://arxiv.org/pdf/2411.12479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.14983v2","updated":"2025-08-01T12:24:01Z","published":"2024-11-22T14:43:28Z","title":"Large sample scaling analysis of the Zig-Zag algorithm for Bayesian\n  inference","summary":"  Piecewise deterministic Markov processes provide scalable methods for\nsampling from the posterior distributions in big data settings by admitting\nprincipled sub-sampling strategies that do not bias the output. An important\nexample is the Zig-Zag process of [Ann. Stats. 47 (2019) 1288 - 1320] where\nclever sub-sampling has been shown to produce an essentially independent sample\nat a cost that does not scale with the size of the data. However, sub-sampling\nalso leads to slower convergence and poor mixing of the process, a behaviour\nwhich questions the promised scalability of the algorithm. We provide a large\nsample scaling analysis of the Zig-Zag process and its sub-sampling versions in\nsettings of parametric Bayesian inference. In the transient phase of the\nalgorithm, we show that the Zig-Zag trajectories are well approximated by the\nsolution to a system of ODEs. These ODEs possess a drift in the direction of\ndecreasing KL-divergence between the assumed model and the true distribution\nand are explicitly characterized in the paper. In the stationary phase, we give\nweak convergence results for different versions of the Zig-Zag process. Based\non our results, we estimate that for large data sets of size n, using suitable\ncontrol variates with sub-sampling in Zig-Zag, the algorithm costs O(1) to\nobtain an essentially independent sample; a computational speed-up of O(n) over\nthe canonical version of Zig-Zag and other traditional MCMC methods\n","authors":["Sanket Agrawal","Joris Bierkens","Gareth O. Roberts"],"pdf_url":"https://arxiv.org/pdf/2411.14983v2.pdf","comment":"50 pages, 7 figues, 1 table"},{"id":"http://arxiv.org/abs/2507.20980v2","updated":"2025-08-01T05:21:32Z","published":"2025-07-28T16:43:11Z","title":"LargeMvC-Net: Anchor-based Deep Unfolding Network for Large-scale\n  Multi-view Clustering","summary":"  Deep anchor-based multi-view clustering methods enhance the scalability of\nneural networks by utilizing representative anchors to reduce the computational\ncomplexity of large-scale clustering. Despite their scalability advantages,\nexisting approaches often incorporate anchor structures in a heuristic or\ntask-agnostic manner, either through post-hoc graph construction or as\nauxiliary components for message passing. Such designs overlook the core\nstructural demands of anchor-based clustering, neglecting key optimization\nprinciples. To bridge this gap, we revisit the underlying optimization problem\nof large-scale anchor-based multi-view clustering and unfold its iterative\nsolution into a novel deep network architecture, termed LargeMvC-Net. The\nproposed model decomposes the anchor-based clustering process into three\nmodules: RepresentModule, NoiseModule, and AnchorModule, corresponding to\nrepresentation learning, noise suppression, and anchor indicator estimation.\nEach module is derived by unfolding a step of the original optimization\nprocedure into a dedicated network component, providing structural clarity and\noptimization traceability. In addition, an unsupervised reconstruction loss\naligns each view with the anchor-induced latent space, encouraging consistent\nclustering structures across views. Extensive experiments on several\nlarge-scale multi-view benchmarks show that LargeMvC-Net consistently\noutperforms state-of-the-art methods in terms of both effectiveness and\nscalability.\n","authors":["Shide Du","Chunming Wu","Zihan Fang","Wendi Zhao","Yilin Wu","Changwei Wang","Shiping Wang"],"pdf_url":"https://arxiv.org/pdf/2507.20980v2.pdf","comment":"10 pages, 7 figures"}]},"2025-08-04T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2508.02635v1","updated":"2025-08-04T17:22:08Z","published":"2025-08-04T17:22:08Z","title":"Test Set Quality in Multilingual LLM Evaluation","summary":"  Several multilingual benchmark datasets have been developed in a\nsemi-automatic manner in the recent past to measure progress and understand the\nstate-of-the-art in the multilingual capabilities of Large Language Models.\nHowever, there is not a lot of attention paid to the quality of the datasets\nthemselves, despite the existence of previous work in identifying errors in\neven fully human-annotated test sets. In this paper, we manually analyze recent\nmultilingual evaluation sets in two languages - French and Telugu, identifying\nseveral errors in the process. We compare the performance difference across\nseveral LLMs with the original and revised versions of the datasets and\nidentify large differences (almost 10% in some cases) in both languages). Based\non these results, we argue that test sets should not be considered immutable\nand should be revisited, checked for correctness, and potentially versioned. We\nend with some recommendations for both the dataset creators as well as\nconsumers on addressing the dataset quality issues.\n","authors":["Kranti Chalamalasetti","Gabriel Bernier-Colborne","Yvan Gauthier","Sowmya Vajjala"],"pdf_url":"https://arxiv.org/pdf/2508.02635v1.pdf","comment":"Accepted at the 1st Workshop on Multilingual Data Quality Signals,\n  COLM 2025, Short paper. 10 pages in total"},{"id":"http://arxiv.org/abs/2508.02631v1","updated":"2025-08-04T17:19:56Z","published":"2025-08-04T17:19:56Z","title":"Pointer: Linear-Complexity Long-Range Modeling without Pre-training","summary":"  We introduce Pointer, a novel architecture that achieves linear $O(NK)$\ncomplexity for long-range sequence modeling while maintaining superior\nperformance without requiring pre-training. Unlike standard attention\nmechanisms that compute $O(N^2)$ pairwise interactions, our approach uses\nlayer-wise pointer chaining where each layer's pointer selection depends on\nprevious layer's pointer positions, creating explicit long-distance connections\nthrough pointer chains. We demonstrate that this architecture achieves\n$2$--$10\\times$ speedup on long sequences compared to standard transformers,\nmaintains $>95\\%$ accuracy on copy tasks at distances up to 2048 tokens, and\nlearns interpretable pointer patterns that reveal structured dependency\nmodeling. Our experiments on efficiency benchmarks, long-range dependency\ntasks, and interpretability analysis show that Pointer offers a compelling\nalternative to attention mechanisms for scenarios requiring efficient\nlong-range modeling without pre-training dependencies.\n","authors":["Zixi Li"],"pdf_url":"https://arxiv.org/pdf/2508.02631v1.pdf","comment":"Submitted to Nordic AI Meet 2025"},{"id":"http://arxiv.org/abs/2508.02629v1","updated":"2025-08-04T17:18:14Z","published":"2025-08-04T17:18:14Z","title":"HyCodePolicy: Hybrid Language Controllers for Multimodal Monitoring and\n  Decision in Embodied Agents","summary":"  Recent advances in multimodal large language models (MLLMs) have enabled\nricher perceptual grounding for code policy generation in embodied agents.\nHowever, most existing systems lack effective mechanisms to adaptively monitor\npolicy execution and repair codes during task completion. In this work, we\nintroduce HyCodePolicy, a hybrid language-based control framework that\nsystematically integrates code synthesis, geometric grounding, perceptual\nmonitoring, and iterative repair into a closed-loop programming cycle for\nembodied agents. Technically, given a natural language instruction, our system\nfirst decomposes it into subgoals and generates an initial executable program\ngrounded in object-centric geometric primitives. The program is then executed\nin simulation, while a vision-language model (VLM) observes selected\ncheckpoints to detect and localize execution failures and infer failure\nreasons. By fusing structured execution traces capturing program-level events\nwith VLM-based perceptual feedback, HyCodePolicy infers failure causes and\nrepairs programs. This hybrid dual feedback mechanism enables self-correcting\nprogram synthesis with minimal human supervision. Our results demonstrate that\nHyCodePolicy significantly improves the robustness and sample efficiency of\nrobot manipulation policies, offering a scalable strategy for integrating\nmultimodal reasoning into autonomous decision-making pipelines.\n","authors":["Yibin Liu","Zhixuan Liang","Zanxin Chen","Tianxing Chen","Mengkang Hu","Wanxi Dong","Congsheng Xu","Zhaoming Han","Yusen Qin","Yao Mu"],"pdf_url":"https://arxiv.org/pdf/2508.02629v1.pdf","comment":"Accepted to ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic\n  Intelligence"},{"id":"http://arxiv.org/abs/2508.02622v1","updated":"2025-08-04T17:10:08Z","published":"2025-08-04T17:10:08Z","title":"Noosemia: toward a Cognitive and Phenomenological Account of\n  Intentionality Attribution in Human-Generative AI Interaction","summary":"  This paper introduces and formalizes Noosemia, a novel\ncognitive-phenomenological phenomenon emerging from human interaction with\ngenerative AI systems, particularly those enabling dialogic or multimodal\nexchanges. We propose a multidisciplinary framework to explain how, under\ncertain conditions, users attribute intentionality, agency, and even\ninteriority to these systems - a process grounded not in physical resemblance,\nbut in linguistic performance, epistemic opacity, and emergent technological\ncomplexity. By linking an LLM declination of meaning holism to our technical\nnotion of the LLM Contextual Cognitive Field, we clarify how LLMs construct\nmeaning relationally and how coherence and a simulacrum of agency arise at the\nhuman-AI interface. The analysis situates noosemia alongside pareidolia,\nanimism, the intentional stance and the uncanny valley, distinguishing its\nunique characteristics. We also introduce a-noosemia to describe the\nphenomenological withdrawal of such projections. The paper concludes with\nreflections on the broader philosophical, epistemological, and social\nimplications of noosemic dynamics and directions for future research.\n","authors":["Enrico De Santis","Antonello Rizzi"],"pdf_url":"https://arxiv.org/pdf/2508.02622v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02621v1","updated":"2025-08-04T17:08:47Z","published":"2025-08-04T17:08:47Z","title":"HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous\n  Healthcare Research","summary":"  The efficacy of AI agents in healthcare research is hindered by their\nreliance on static, predefined strategies. This creates a critical limitation:\nagents can become better tool-users but cannot learn to become better strategic\nplanners, a crucial skill for complex domains like healthcare. We introduce\nHealthFlow, a self-evolving AI agent that overcomes this limitation through a\nnovel meta-level evolution mechanism. HealthFlow autonomously refines its own\nhigh-level problem-solving policies by distilling procedural successes and\nfailures into a durable, strategic knowledge base. To anchor our research and\nfacilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark\nfeaturing complex, realistic health data analysis tasks derived from\npeer-reviewed clinical research. Our comprehensive experiments demonstrate that\nHealthFlow's self-evolving approach significantly outperforms state-of-the-art\nagent frameworks. This work marks a necessary shift from building better\ntool-users to designing smarter, self-evolving task-managers, paving the way\nfor more autonomous and effective AI for scientific discovery.\n","authors":["Yinghao Zhu","Yifan Qi","Zixiang Wang","Lei Gu","Dehao Sui","Haoran Hu","Xichen Zhang","Ziyi He","Liantao Ma","Lequan Yu"],"pdf_url":"https://arxiv.org/pdf/2508.02621v1.pdf","comment":"Code: https://github.com/yhzhu99/HealthFlow"},{"id":"http://arxiv.org/abs/2508.02618v1","updated":"2025-08-04T17:06:23Z","published":"2025-08-04T17:06:23Z","title":"Mitigating Attention Hacking in Preference-Based Reward Modeling via\n  Interaction Distillation","summary":"  The reward model (RM), as the core component of reinforcement learning from\nhuman feedback (RLHF) for large language models (LLMs), responsible for\nproviding reward signals to generated responses. However, mainstream preference\nmodeling in RM is inadequate in terms of token-level interaction, making its\njudgment signals vulnerable to being hacked by misallocated attention to\ncontext. This stems from two fundamental limitations: (1) Current preference\nmodeling employs decoder-only architectures, where the unidirectional causal\nattention mechanism leads to forward-decaying intra-sequence attention within\nthe prompt-response sequence. (2) The independent Siamese-encoding paradigm\ninduces the absence of token-level inter-sequence attention between chosen and\nrejected sequences. To address this \"attention hacking\", we propose\n\"Interaction Distillation\", a novel training framework for more adequate\npreference modeling through attention-level optimization. The method introduces\nan interaction-based natural language understanding model as the teacher to\nprovide sophisticated token interaction patterns via comprehensive attention,\nand guides the preference modeling to simulate teacher model's interaction\npattern through an attentional alignment objective. Through extensive\nexperiments, interaction distillation has demonstrated its ability to provide\nmore stable and generalizable reward signals compared to state-of-the-art RM\noptimization methods that target data noise, highlighting the attention hacking\nconstitute a more fundamental limitation in RM.\n","authors":["Jianxiang Zang","Meiling Ning","Shihan Dou","Jiazheng Zhang","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2508.02618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.09251v2","updated":"2025-08-04T16:57:32Z","published":"2025-06-10T21:22:51Z","title":"Extrapolation by Association: Length Generalization Transfer in\n  Transformers","summary":"  Transformer language models have demonstrated impressive generalization\ncapabilities in natural language domains, yet we lack a fine-grained\nunderstanding of how such generalization arises. In this paper, we investigate\nlength generalization--the ability to extrapolate from shorter to longer\ninputs--through the lens of \\textit{task association}. We find that length\ngeneralization can be \\textit{transferred} across related tasks. That is,\ntraining a model with a longer and related auxiliary task can lead it to\ngeneralize to unseen and longer inputs from some other target task. We\ndemonstrate this length generalization transfer across diverse algorithmic\ntasks, including arithmetic operations, string transformations, and maze\nnavigation. Our results show that transformer models can inherit generalization\ncapabilities from similar tasks when trained jointly. Moreover, we observe\nsimilar transfer effects in pretrained language models, suggesting that\npretraining equips models with reusable computational scaffolding that\nfacilitates extrapolation in downstream settings. Finally, we provide initial\nmechanistic evidence that length generalization transfer correlates with the\nre-use of the same attention heads between the tasks. Together, our findings\ndeepen our understanding of how transformers generalize to out-of-distribution\ninputs and highlight the compositional reuse of inductive structure across\ntasks.\n","authors":["Ziyang Cai","Nayoung Lee","Avi Schwarzschild","Samet Oymak","Dimitris Papailiopoulos"],"pdf_url":"https://arxiv.org/pdf/2506.09251v2.pdf","comment":"23 pages, 20 figures"},{"id":"http://arxiv.org/abs/2508.02591v1","updated":"2025-08-04T16:46:15Z","published":"2025-08-04T16:46:15Z","title":"CharBench: Evaluating the Role of Tokenization in Character-Level Tasks","summary":"  Tasks that require character-level reasoning, such as counting or locating\ncharacters within words, remain challenging for contemporary language models. A\ncommon conjecture is that language models' reliance on subword units, rather\nthan characters, contributes to their struggles with character-level tasks, yet\nrecent studies offer conflicting conclusions about the role of tokenization,\nleaving its impact unclear. To address this gap, we introduce CharBench, a\ncomprehensive benchmark of character-level tasks that is two orders of\nmagnitude larger than existing alternatives. We evaluate a diverse range of\nleading open-weight and proprietary models on CharBench and find that it\npresents a significant challenge to modern LLMs, with an average accuracy of\n43.6% and 32.3% on some tasks. We present an in-depth analysis of how intrinsic\nproperties of words and their segmentations into tokens correspond to model\nperformance. For counting tasks, we find that tokenization properties are\nweakly correlated with correctness, while the length of the queried word and\nthe actual character count play a more significant part. In contrast, for tasks\nrequiring intra-word positional understanding, performance is negatively\ncorrelated with the length of the token containing the queried character,\nsuggesting that longer tokens obscure character position information for LLMs.\nWe encourage future work to build on the benchmark and evaluation methodology\nintroduced here as tools for improving model performance on such tasks.\n","authors":["Omri Uzan","Yuval Pinter"],"pdf_url":"https://arxiv.org/pdf/2508.02591v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02587v1","updated":"2025-08-04T16:43:09Z","published":"2025-08-04T16:43:09Z","title":"Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands\n  Mixture of Adaptation Modules","summary":"  Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among\ntheir specialized experts, which existing Parameter- Efficient Fine-Tuning\n(PEFT) strategies fail to leverage. This motivates us to investigate whether\nadaptation modules themselves should incorporate routing mechanisms to align\nwith MoE's multi-expert architecture. We analyze dynamics of core components\nwhen applying PEFT to MoE language models and examine how different routing\nstrategies affect adaptation effectiveness. Extensive experiments adapting\nOLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks\nvalidate the performance and efficiency of our routed approach. We identify the\noptimal configurations for different scenarios and provide empirical analyses\nwith practical insights to facilitate better PEFT and MoE applications.\n","authors":["Yilun Liu","Yunpu Ma","Yuetian Lu","Shuo Chen","Zifeng Ding","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2508.02587v1.pdf","comment":"This paper is a preprint under review. arXiv admin note: text overlap\n  with arXiv:2411.08212"},{"id":"http://arxiv.org/abs/2508.02584v1","updated":"2025-08-04T16:40:02Z","published":"2025-08-04T16:40:02Z","title":"MArgE: Meshing Argumentative Evidence from Multiple Large Language\n  Models for Justifiable Claim Verification","summary":"  Leveraging outputs from multiple large language models (LLMs) is emerging as\na method for harnessing their power across a wide range of tasks while\nmitigating their capacity for making errors, e.g., hallucinations. However,\ncurrent approaches to combining insights from multiple LLMs often involve\nunstructured interactions (e.g., free debate), resulting in model generations\nthat are not faithfully justifiable. In this work, we introduce MArgE, a novel\nframework to provide formal structure to the evidence from each LLM, in the\nform of a tree of extracted arguments, for the task of claim verification. We\nuse a variant of Argumentative LLMs (ArgLLMs), i.e. LLMs driven by frameworks\nand semantics from the field of computational argumentation, to construct\nstructured argument trees for given claims. This process creates an inspectable\npathway from the initial arguments to the final claim verification decisions,\nproviding a faithful justification thereof. We show experimentally that MArgE\ncan significantly outperform single LLMs, including three open-source models\n(4B to 8B parameters), GPT-4o-mini and existing ArgLLMs, as well as prior\nmethods for unstructured multi-LLM debates. We thus demonstrate the advantages\nof incorporating formal, argumentative reasoning mechanisms when combining\nmultiple LLM outputs.\n","authors":["Ming Pok Ng","Junqi Jiang","Gabriel Freedman","Antonio Rago","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2508.02584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07927v3","updated":"2025-08-04T16:37:00Z","published":"2025-01-14T08:30:49Z","title":"Gandalf the Red: Adaptive Security for LLMs","summary":"  Current evaluations of defenses against prompt attacks in large language\nmodel (LLM) applications often overlook two critical factors: the dynamic\nnature of adversarial behavior and the usability penalties imposed on\nlegitimate users by restrictive defenses. We propose D-SEC (Dynamic Security\nUtility Threat Model), which explicitly separates attackers from legitimate\nusers, models multi-step interactions, and expresses the security-utility in an\noptimizable form. We further address the shortcomings in existing evaluations\nby introducing Gandalf, a crowd-sourced, gamified red-teaming platform designed\nto generate realistic, adaptive attack. Using Gandalf, we collect and release a\ndataset of 279k prompt attacks. Complemented by benign user data, our analysis\nreveals the interplay between security and utility, showing that defenses\nintegrated in the LLM (e.g., system prompts) can degrade usability even without\nblocking requests. We demonstrate that restricted application domains,\ndefense-in-depth, and adaptive defenses are effective strategies for building\nsecure and useful LLM applications.\n","authors":["Niklas Pfister","Václav Volhejn","Manuel Knott","Santiago Arias","Julia Bazińska","Mykhailo Bichurin","Alan Commike","Janet Darling","Peter Dienes","Matthew Fiedler","David Haber","Matthias Kraft","Marco Lancini","Max Mathys","Damián Pascual-Ortiz","Jakub Podolak","Adrià Romero-López","Kyriacos Shiarlis","Andreas Signer","Zsolt Terek","Athanasios Theocharis","Daniel Timbrell","Samuel Trautwein","Samuel Watts","Yun-Han Wu","Mateo Rojas-Carulla"],"pdf_url":"https://arxiv.org/pdf/2501.07927v3.pdf","comment":"Niklas Pfister, V\\'aclav Volhejn and Manuel Knott contributed equally"},{"id":"http://arxiv.org/abs/2508.02574v1","updated":"2025-08-04T16:28:58Z","published":"2025-08-04T16:28:58Z","title":"EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based\n  Sentiment Analysis in Healthcare","summary":"  Arabic-language patient feedback remains under-analysed because dialect\ndiversity and scarce aspect-level sentiment labels hinder automated assessment.\nTo address this gap, we introduce EHSAN, a data-centric hybrid pipeline that\nmerges ChatGPT pseudo-labelling with targeted human review to build the first\nexplainable Arabic aspect-based sentiment dataset for healthcare. Each sentence\nis annotated with an aspect and sentiment label (positive, negative, or\nneutral), forming a pioneering Arabic dataset aligned with healthcare themes,\nwith ChatGPT-generated rationales provided for each label to enhance\ntransparency. To evaluate the impact of annotation quality on model\nperformance, we created three versions of the training data: a fully supervised\nset with all labels reviewed by humans, a semi-supervised set with 50% human\nreview, and an unsupervised set with only machine-generated labels. We\nfine-tuned two transformer models on these datasets for both aspect and\nsentiment classification. Experimental results show that our Arabic-specific\nmodel achieved high accuracy even with minimal human supervision, reflecting\nonly a minor performance drop when using ChatGPT-only labels. Reducing the\nnumber of aspect classes notably improved classification metrics across the\nboard. These findings demonstrate an effective, scalable approach to Arabic\naspect-based sentiment analysis (SA) in healthcare, combining large language\nmodel annotation with human expertise to produce a robust and explainable\ndataset. Future directions include generalisation across hospitals, prompt\nrefinement, and interpretable data-driven modelling.\n","authors":["Eman Alamoudi","Ellis Solaiman"],"pdf_url":"https://arxiv.org/pdf/2508.02574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02573v1","updated":"2025-08-04T16:27:56Z","published":"2025-08-04T16:27:56Z","title":"Guess or Recall? Training CNNs to Classify and Localize Memorization in\n  LLMs","summary":"  Verbatim memorization in Large Language Models (LLMs) is a multifaceted\nphenomenon involving distinct underlying mechanisms. We introduce a novel\nmethod to analyze the different forms of memorization described by the existing\ntaxonomy. Specifically, we train Convolutional Neural Networks (CNNs) on the\nattention weights of the LLM and evaluate the alignment between this taxonomy\nand the attention weights involved in decoding.\n  We find that the existing taxonomy performs poorly and fails to reflect\ndistinct mechanisms within the attention blocks. We propose a new taxonomy that\nmaximizes alignment with the attention weights, consisting of three categories:\nmemorized samples that are guessed using language modeling abilities, memorized\nsamples that are recalled due to high duplication in the training set, and\nnon-memorized samples. Our results reveal that few-shot verbatim memorization\ndoes not correspond to a distinct attention mechanism. We also show that a\nsignificant proportion of extractable samples are in fact guessed by the model\nand should therefore be studied separately. Finally, we develop a custom visual\ninterpretability technique to localize the regions of the attention weights\ninvolved in each form of memorization.\n","authors":["Jérémie Dentan","Davide Buscaldi","Sonia Vanier"],"pdf_url":"https://arxiv.org/pdf/2508.02573v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02558v1","updated":"2025-08-04T16:14:03Z","published":"2025-08-04T16:14:03Z","title":"Sparse-dLLM: Accelerating Diffusion LLMs with Dynamic Cache Eviction","summary":"  Diffusion Large Language Models (dLLMs) enable breakthroughs in reasoning and\nparallel decoding but suffer from prohibitive quadratic computational\ncomplexity and memory overhead during inference. Current caching techniques\naccelerate decoding by storing full-layer states, yet impose substantial memory\nusage that limit long-context applications. Our analysis of attention patterns\nin dLLMs reveals persistent cross-layer sparsity, with pivotal tokens remaining\nsalient across decoding steps and low-relevance tokens staying unimportant,\nmotivating selective cache eviction. We propose Sparse-dLLM, the first\ntraining-free framework integrating dynamic cache eviction with sparse\nattention via delayed bidirectional sparse caching. By leveraging the stability\nof token saliency over steps, it retains critical tokens and dynamically evicts\nunimportant prefix/suffix entries using an attention-guided strategy. Extensive\nexperiments on LLaDA and Dream series demonstrate Sparse-dLLM achieves up to\n10$\\times$ higher throughput than vanilla dLLMs, with comparable performance\nand similar peak memory costs, outperforming previous methods in efficiency and\neffectiveness.\n","authors":["Yuerong Song","Xiaoran Liu","Ruixiao Li","Zhigeng Liu","Zengfeng Huang","Qipeng Guo","Ziwei He","Xipeng Qiu"],"pdf_url":"https://arxiv.org/pdf/2508.02558v1.pdf","comment":"11 pages, 6 figures"},{"id":"http://arxiv.org/abs/2508.02556v1","updated":"2025-08-04T16:08:49Z","published":"2025-08-04T16:08:49Z","title":"Automated SNOMED CT Concept Annotation in Clinical Text Using Bi-GRU\n  Neural Networks","summary":"  Automated annotation of clinical text with standardized medical concepts is\ncritical for enabling structured data extraction and decision support. SNOMED\nCT provides a rich ontology for labeling clinical entities, but manual\nannotation is labor-intensive and impractical at scale. This study introduces a\nneural sequence labeling approach for SNOMED CT concept recognition using a\nBidirectional GRU model. Leveraging a subset of MIMIC-IV, we preprocess text\nwith domain-adapted SpaCy and SciBERT-based tokenization, segmenting sentences\ninto overlapping 19-token chunks enriched with contextual, syntactic, and\nmorphological features. The Bi-GRU model assigns IOB tags to identify concept\nspans and achieves strong performance with a 90 percent F1-score on the\nvalidation set. These results surpass traditional rule-based systems and match\nor exceed existing neural models. Qualitative analysis shows effective handling\nof ambiguous terms and misspellings. Our findings highlight that lightweight\nRNN-based architectures can deliver high-quality clinical concept annotation\nwith significantly lower computational cost than transformer-based models,\nmaking them well-suited for real-world deployment.\n","authors":["Ali Noori","Pratik Devkota","Somya Mohanty","Prashanti Manda"],"pdf_url":"https://arxiv.org/pdf/2508.02556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02555v1","updated":"2025-08-04T16:05:36Z","published":"2025-08-04T16:05:36Z","title":"Building and Aligning Comparable Corpora","summary":"  Comparable corpus is a set of topic aligned documents in multiple languages,\nwhich are not necessarily translations of each other. These documents are\nuseful for multilingual natural language processing when there is no parallel\ntext available in some domains or languages. In addition, comparable documents\nare informative because they can tell what is being said about a topic in\ndifferent languages. In this paper, we present a method to build comparable\ncorpora from Wikipedia encyclopedia and EURONEWS website in English, French and\nArabic languages. We further experiment a method to automatically align\ncomparable documents using cross-lingual similarity measures. We investigate\ntwo cross-lingual similarity measures to align comparable documents. The first\nmeasure is based on bilingual dictionary, and the second measure is based on\nLatent Semantic Indexing (LSI). Experiments on several corpora show that the\nCross-Lingual LSI (CL-LSI) measure outperforms the dictionary based measure.\nFinally, we collect English and Arabic news documents from the British\nBroadcast Corporation (BBC) and from ALJAZEERA (JSC) news website respectively.\nThen we use the CL-LSI similarity measure to automatically align comparable\ndocuments of BBC and JSC. The evaluation of the alignment shows that CL-LSI is\nnot only able to align cross-lingual documents at the topic level, but also it\nis able to do this at the event level.\n","authors":["Motaz Saad","David Langlois","Kamel Smaili"],"pdf_url":"https://arxiv.org/pdf/2508.02555v1.pdf","comment":"27 pages, 11 figures"},{"id":"http://arxiv.org/abs/2508.02546v1","updated":"2025-08-04T15:59:15Z","published":"2025-08-04T15:59:15Z","title":"What are you sinking? A geometric approach on attention sink","summary":"  Attention sink (AS) is a consistent pattern in transformer attention maps\nwhere certain tokens (often special tokens or positional anchors)\ndisproportionately attract attention from other tokens. We show that in\ntransformers, AS is not an architectural artifact, but it is the manifestation\nof a fundamental geometric principle: the establishment of reference frames\nthat anchor representational spaces. We analyze several architectures and\nidentify three distinct reference frame types, centralized, distributed, and\nbidirectional, that correlate with the attention sink phenomenon. We show that\nthey emerge during the earliest stages of training as optimal solutions to the\nproblem of establishing stable coordinate systems in high-dimensional spaces.\nWe show the influence of architecture components, particularly position\nencoding implementations, on the specific type of reference frame. This\nperspective transforms our understanding of transformer attention mechanisms\nand provides insights for both architecture design and the relationship with\nAS.\n","authors":["Valeria Ruscio","Umberto Nanni","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2508.02546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18182v2","updated":"2025-08-04T15:53:52Z","published":"2025-07-24T08:28:17Z","title":"SCOPE: Stochastic and Counterbiased Option Placement for Evaluating\n  Large Language Models","summary":"  Large Language Models (LLMs) can achieve inflated scores on multiple-choice\ntasks by exploiting inherent biases in option positions or labels, rather than\ndemonstrating genuine understanding. This study introduces SCOPE, an evaluation\nframework designed to measure and mitigate such selection bias in a\ndataset-independent manner. By repeatedly invoking a null prompt that lacks\nsemantic content, SCOPE estimates each model's unique position-bias\ndistribution. It then redistributes the answer slot according to the\ninverse-bias distribution, thereby equalizing the lucky-rate, the probability\nof selecting the correct answer by chance. Furthermore, it prevents\nsemantically similar distractors from being placed adjacent to the answer,\nthereby blocking near-miss guesses based on superficial proximity cues. Across\nmultiple benchmark experiments, SCOPE consistently outperformed existing\ndebiasing methods in terms of stable performance improvements and showed\nclearer confidence distributions over correct options. This framework thus\noffers a new standard for enhancing the fairness and reliability of LLM\nevaluations.\n","authors":["Wonjun Jeong","Dongseok Kim","Taegkeun Whangbo"],"pdf_url":"https://arxiv.org/pdf/2507.18182v2.pdf","comment":"Comments: 34 pages, 1 figure. v2: All \"Consequence.\" statements in\n  the Theoretical Analysis section relabeled as \"Corollary.\"; duplicated values\n  in Table 20 (previously identical to Table 15) corrected"},{"id":"http://arxiv.org/abs/2507.03336v2","updated":"2025-08-04T15:48:55Z","published":"2025-07-04T06:49:02Z","title":"Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs\n  More Realistic and Less Risky","summary":"  Large language models (LLMs) are increasingly tasked with invoking enterprise\nAPIs, yet they routinely falter when near-duplicate tools vie for the same user\nintent or when required arguments are left underspecified. We introduce\nDiaFORGE (Dialogue Framework for Organic Response Generation & Evaluation), a\ndisambiguation-centric, three-stage pipeline that (i) synthesizes\npersona-driven, multi-turn dialogues in which the assistant must distinguish\namong highly similar tools, (ii) performs supervised fine-tuning of open-source\nmodels with reasoning traces across 3B - 70B parameters, and (iii) evaluates\nreal-world readiness via a dynamic suite that redeploys each model in a live\nagentic loop and reports end-to-end goal completion alongside conventional\nstatic metrics. On our dynamic benchmark DiaBENCH, models trained with DiaFORGE\nraise tool-invocation success by 27 pp over GPT-4o and by 49 pp over\nClaude-3.5-Sonnet, both under optimized prompting. To spur further research, we\nrelease an open corpus of 5000 production-grade enterprise API specifications\npaired with rigorously validated, disambiguation-focused dialogues, offering a\npractical blueprint for building reliable, enterprise-ready tool-calling\nagents.\n","authors":["Ashutosh Hathidara","Julien Yu","Sebastian Schreiber"],"pdf_url":"https://arxiv.org/pdf/2507.03336v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02540v1","updated":"2025-08-04T15:47:17Z","published":"2025-08-04T15:47:17Z","title":"What's in the News? Towards Identification of Bias by Commission,\n  Omission, and Source Selection (COSS)","summary":"  In a world overwhelmed with news, determining which information comes from\nreliable sources or how neutral is the reported information in the news\narticles poses a challenge to news readers. In this paper, we propose a\nmethodology for automatically identifying bias by commission, omission, and\nsource selection (COSS) as a joint three-fold objective, as opposed to the\nprevious work separately addressing these types of bias. In a pipeline concept,\nwe describe the goals and tasks of its steps toward bias identification and\nprovide an example of a visualization that leverages the extracted features and\npatterns of text reuse.\n","authors":["Anastasia Zhukova","Terry Ruas","Felix Hamborg","Karsten Donnay","Bela Gipp"],"pdf_url":"https://arxiv.org/pdf/2508.02540v1.pdf","comment":"published in the Proceedings of the 2023 ACM/IEEE Joint Conference on\n  Digital Libraries"},{"id":"http://arxiv.org/abs/2508.02532v1","updated":"2025-08-04T15:41:35Z","published":"2025-08-04T15:41:35Z","title":"Contextual Graph Transformer: A Small Language Model for Enhanced\n  Engineering Document Information Extraction","summary":"  Standard transformer-based language models, while powerful for general text,\noften struggle with the fine-grained syntax and entity relationships in complex\ntechnical, engineering documents. To address this, we propose the Contextual\nGraph Transformer (CGT), a hybrid neural architecture that combines Graph\nNeural Networks (GNNs) and Transformers for domain-specific question answering.\nCGT constructs a dynamic graph over input tokens using sequential, skip-gram,\nand semantic similarity edges, which is processed by GATv2Conv layers for local\nstructure learning. These enriched embeddings are then passed to a Transformer\nencoder to capture global dependencies. Unlike generic large models, technical\ndomains often require specialized language models with stronger\ncontextualization and structure awareness. CGT offers a parameter-efficient\nsolution for such use cases. Integrated into a Retrieval-Augmented Generation\n(RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7%\nhigher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from\nCGTs ability to jointly model structural token interactions and long-range\nsemantic coherence. The model is trained from scratch using a two-phase\napproach: pretraining on general text followed by fine-tuning on\ndomain-specific manuals. This highlights CGTs adaptability to technical\nlanguage, enabling better grounding, entity tracking, and retrieval-augmented\nresponses in real-world applications.\n","authors":["Karan Reddy","Mayukha Pal"],"pdf_url":"https://arxiv.org/pdf/2508.02532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02527v1","updated":"2025-08-04T15:36:51Z","published":"2025-08-04T15:36:51Z","title":"I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic\n  Representations in LLaMA 3.2","summary":"  Large language models demonstrate proficiency on phonetic tasks, such as\nrhyming, without explicit phonetic or auditory grounding. In this work, we\ninvestigate how \\verb|Llama-3.2-1B-Instruct| represents token-level phonetic\ninformation. Our results suggest that Llama uses a rich internal model of\nphonemes to complete phonetic tasks. We provide evidence for high-level\norganization of phoneme representations in its latent space. In doing so, we\nalso identify a ``phoneme mover head\" which promotes phonetic information\nduring rhyming tasks. We visualize the output space of this head and find that,\nwhile notable differences exist, Llama learns a model of vowels similar to the\nstandard IPA vowel chart for humans, despite receiving no direct supervision to\ndo so.\n","authors":["Jack Merullo","Arjun Khurana","Oliver McLaughlin"],"pdf_url":"https://arxiv.org/pdf/2508.02527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02515v1","updated":"2025-08-04T15:19:22Z","published":"2025-08-04T15:19:22Z","title":"PoeTone: A Framework for Constrained Generation of Structured Chinese\n  Songci with LLMs","summary":"  This paper presents a systematic investigation into the constrained\ngeneration capabilities of large language models (LLMs) in producing Songci, a\nclassical Chinese poetry form characterized by strict structural, tonal, and\nrhyme constraints defined by Cipai templates. We first develop a comprehensive,\nmulti-faceted evaluation framework that includes: (i) a formal conformity\nscore, (ii) automated quality assessment using LLMs, (iii) human evaluation,\nand (iv) classification-based probing tasks. Using this framework, we evaluate\nthe generative performance of 18 LLMs, including 3 proprietary models and 15\nopen-source models across four families, under five prompting strategies:\nzero-shot, one-shot, completion-based, instruction-tuned, and chain-of-thought.\nFinally, we propose a Generate-Critic architecture in which the evaluation\nframework functions as an automated critic. Leveraging the critic's feedback as\na reward signal, we fine-tune three lightweight open-source LLMs via supervised\nfine-tuning (SFT), resulting in improvements of up to 5.88% in formal\nconformity. Our findings offer new insights into the generative strengths and\nlimitations of LLMs in producing culturally significant and formally\nconstrained literary texts.\n","authors":["Zhan Qu","Shuzhou Yuan","Michael Färber"],"pdf_url":"https://arxiv.org/pdf/2508.02515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02513v1","updated":"2025-08-04T15:18:41Z","published":"2025-08-04T15:18:41Z","title":"Modular Arithmetic: Language Models Solve Math Digit by Digit","summary":"  While recent work has begun to uncover the internal strategies that Large\nLanguage Models (LLMs) employ for simple arithmetic tasks, a unified\nunderstanding of their underlying mechanisms is still lacking. We extend recent\nfindings showing that LLMs represent numbers in a digit-wise manner and present\nevidence for the existence of digit-position-specific circuits that LLMs use to\nperform simple arithmetic tasks, i.e. modular subgroups of MLP neurons that\noperate independently on different digit positions (units, tens, hundreds).\nNotably, such circuits exist independently of model size and of tokenization\nstrategy, i.e. both for models that encode longer numbers digit-by-digit and as\none token. Using Feature Importance and Causal Interventions, we identify and\nvalidate the digit-position-specific circuits, revealing a compositional and\ninterpretable structure underlying the solving of arithmetic problems in LLMs.\nOur interventions selectively alter the model's prediction at targeted digit\npositions, demonstrating the causal role of digit-position circuits in solving\narithmetic tasks.\n","authors":["Tanja Baeumel","Daniil Gurgurov","Yusser al Ghussin","Josef van Genabith","Simon Ostermann"],"pdf_url":"https://arxiv.org/pdf/2508.02513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02511v1","updated":"2025-08-04T15:17:13Z","published":"2025-08-04T15:17:13Z","title":"Test-time Prompt Intervention","summary":"  Test-time compute has led to remarkable success in the large language model\n(LLM) community, particularly for complex tasks, where longer chains of thought\n(CoTs) are generated to enhance reasoning capabilities. However, growing\nevidence reveals that such reasoning models often produce CoTs plagued by\nexcessive redundancy, including unnecessary verification steps and repetitive\nreasoning shifts. The root cause lies in post-training of them that overly rely\non outcome reward paradigms, as the data of process reward paradigms, which\nregulate intermediate reasoning steps, is difficult to construct at scale. To\naddress this, we propose PI, a novel framework for Test-time Prompt\nIntervention. PI provides an interface to dynamically guide and regulate\nreasoning paths during inference through timely (When module) and proper (How\nmodule) interventions and post-intervention sampling (Which module). This\nallows human problem-solving expertise and cognitive science principles to be\nseamlessly integrated into LLMs' reasoning processes, enhancing controllability\nand interpretability. Extensive experiments across multiple models and datasets\ndemonstrate that PI significantly shortens CoTs while reducing hallucination,\nyielding more concise and reliable reasoning.\n","authors":["Chenxu Yang","Qingyi Si","Mz Dai","Dingyu Yao","Mingyu Zheng","Minghui Chen","Zheng Lin","Weiping Wang"],"pdf_url":"https://arxiv.org/pdf/2508.02511v1.pdf","comment":"23 pages, 16 figures, under review"},{"id":"http://arxiv.org/abs/2508.02503v1","updated":"2025-08-04T15:11:51Z","published":"2025-08-04T15:11:51Z","title":"OptiHive: Ensemble Selection for LLM-Based Optimization via Statistical\n  Modeling","summary":"  LLM-based solvers have emerged as a promising means of automating problem\nmodeling and solving. However, they remain unreliable and often depend on\niterative repair loops that result in significant latency. We introduce\nOptiHive, an LLM-based framework that produces high-quality solvers for\noptimization problems from natural-language descriptions without iterative\nself-correction. OptiHive uses a single batched LLM query to generate diverse\ncomponents (solvers, problem instances, and validation tests) and filters out\nerroneous components to ensure fully interpretable outputs. Taking into account\nthe imperfection of the generated components, we employ a statistical model to\ninfer their true performance, enabling principled uncertainty quantification\nand solver selection. On tasks ranging from traditional optimization problems\nto challenging variants of the Multi-Depot Vehicle Routing Problem, OptiHive\nsignificantly outperforms baselines, increasing the optimality rate from 5\\% to\n92\\% on the most complex problems.\n","authors":["Maxime Bouscary","Saurabh Amin"],"pdf_url":"https://arxiv.org/pdf/2508.02503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.03165v2","updated":"2025-08-04T15:10:59Z","published":"2025-04-04T04:43:13Z","title":"Efficient Dynamic Clustering-Based Document Compression for\n  Retrieval-Augmented-Generation","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a widely adopted approach\nfor knowledge injection during large language model (LLM) inference in recent\nyears. However, due to their limited ability to exploit fine-grained\ninter-document relationships, current RAG implementations face challenges in\neffectively addressing the retrieved noise and redundancy content, which may\ncause error in the generation results. To address these limitations, we propose\nan Efficient Dynamic Clustering-based document Compression framework (EDC2-RAG)\nthat utilizes latent inter-document relationships while simultaneously removing\nirrelevant information and redundant content. We validate our approach, built\nupon GPT-3.5-Turbo and GPT-4o-mini, on widely used knowledge-QA and\nHallucination-Detection datasets. Experimental results show that our method\nachieves consistent performance improvements across various scenarios and\nexperimental settings, demonstrating strong robustness and applicability. Our\ncode and datasets are available at https://github.com/Tsinghua-dhy/EDC-2-RAG.\n","authors":["Weitao Li","Kaiming Liu","Xiangyu Zhang","Xuanyu Lei","Weizhi Ma","Yang Liu"],"pdf_url":"https://arxiv.org/pdf/2504.03165v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02502v1","updated":"2025-08-04T15:10:44Z","published":"2025-08-04T15:10:44Z","title":"From Monolingual to Bilingual: Investigating Language Conditioning in\n  Large Language Models for Psycholinguistic Tasks","summary":"  Large Language Models (LLMs) exhibit strong linguistic capabilities, but\nlittle is known about how they encode psycholinguistic knowledge across\nlanguages. We investigate whether and how LLMs exhibit human-like\npsycholinguistic responses under different linguistic identities using two\ntasks: sound symbolism and word valence. We evaluate two models,\nLlama-3.3-70B-Instruct and Qwen2.5-72B-Instruct, under monolingual and\nbilingual prompting in English, Dutch, and Chinese. Behaviorally, both models\nadjust their outputs based on prompted language identity, with Qwen showing\ngreater sensitivity and sharper distinctions between Dutch and Chinese. Probing\nanalysis reveals that psycholinguistic signals become more decodable in deeper\nlayers, with Chinese prompts yielding stronger and more stable valence\nrepresentations than Dutch. Our results demonstrate that language identity\nconditions both output behavior and internal representations in LLMs, providing\nnew insights into their application as models of cross-linguistic cognition.\n","authors":["Shuzhou Yuan","Zhan Qu","Mario Tawfelis","Michael Färber"],"pdf_url":"https://arxiv.org/pdf/2508.02502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02498v1","updated":"2025-08-04T15:07:38Z","published":"2025-08-04T15:07:38Z","title":"Monsoon Uprising in Bangladesh: How Facebook Shaped Collective Identity","summary":"  This study investigates how Facebook shaped collective identity during the\nJuly 2024 pro-democracy uprising in Bangladesh, known as the Monsoon Uprising.\nDuring government repression, protesters turned to Facebook as a central space\nfor resistance, where multimodal expressions, images, memes, videos, hashtags,\nand satirical posts played an important role in unifying participants. Using a\nqualitative approach, this research analyzes visual rhetoric, verbal discourse,\nand digital irony to reveal how shared symbols, protest art, and slogans built\na sense of solidarity. Key elements included the symbolic use of red, the\nironic metaphorical use of the term \"Razakar\", and the widespread sharing of\nvisuals representing courage, injustice, and resistance. The findings show that\nthe combination of visual and verbal strategies on Facebook not only mobilized\npublic sentiment, but also built a strong collective identity that challenged\nauthoritarian narratives. This study tries to demonstrate how online platforms\ncan serve as powerful tools for identity construction and political\nmobilization in the digital age.\n","authors":["Md Tasin Abir","Arpita Chowdhury","Ashfia Rahman"],"pdf_url":"https://arxiv.org/pdf/2508.02498v1.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2505.20243v3","updated":"2025-08-04T14:52:16Z","published":"2025-05-26T17:21:26Z","title":"It's High Time: A Survey of Temporal Question Answering","summary":"  Time plays a critical role in how information is generated, retrieved, and\ninterpreted. In this survey, we provide a comprehensive overview of Temporal\nQuestion Answering (TQA), a research area that focuses on answering questions\ninvolving temporal constraints or context. As the amount of time-stamped\ncontent from sources like news articles, web archives, and knowledge bases\nincreases, systems must address challenges such as detecting temporal intent,\nnormalizing time expressions, ordering events, and reasoning over evolving or\nambiguous facts. We focus on recent advances in TQA enabled by neural\narchitectures, especially transformer-based models and Large Language Models\n(LLMs), highlighting progress in temporal language modeling,\nretrieval-augmented generation (RAG), and temporal reasoning. We also discuss\nbenchmark datasets and evaluation strategies designed to test temporal\nrobustness, recency awareness, and generalization.\n","authors":["Bhawna Piryani","Abdelrahman Abdallah","Jamshid Mozafari","Avishek Anand","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2505.20243v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.11336v2","updated":"2025-08-04T14:42:02Z","published":"2025-05-16T15:02:19Z","title":"XtraGPT: Context-Aware and Controllable Academic Paper Revision via\n  Human-AI Collaboration","summary":"  Despite the growing adoption of large language models (LLMs) in academic\nworkflows, their capabilities remain limited when it comes to supporting\nhigh-quality scientific writing. Most existing systems are designed for\ngeneral-purpose scientific text generation and fail to meet the sophisticated\ndemands of research communication beyond surface-level polishing, such as\nconceptual coherence across sections. Furthermore, academic writing is\ninherently iterative and revision-driven, a process not well supported by\ndirect prompting-based paradigms. To address these scenarios, we propose a\nhuman-AI collaboration framework for academic paper revision. We first\nintroduce a comprehensive dataset of 7,040 research papers from top-tier venues\nannotated with over 140,000 instruction-response pairs that reflect realistic,\nsection-level scientific revisions. Building on the dataset, we develop\nXtraGPT, the first suite of open-source LLMs, designed to provide\ncontext-aware, instruction-guided writing assistance, ranging from 1.5B to 14B\nparameters. Extensive experiments validate that XtraGPT significantly\noutperforms same-scale baselines and approaches the quality of proprietary\nsystems. Both automated preference assessments and human evaluations confirm\nthe effectiveness of our models in improving scientific drafts.\n","authors":["Nuo Chen","Andre Lin HuiKai","Jiaying Wu","Junyi Hou","Zining Zhang","Qian Wang","Xidong Wang","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2505.11336v2.pdf","comment":"Preprint. The model report is available at\n  https://arxiv.org/abs/2505.11336v1"},{"id":"http://arxiv.org/abs/2508.02470v1","updated":"2025-08-04T14:36:31Z","published":"2025-08-04T14:36:31Z","title":"AIAP: A No-Code Workflow Builder for Non-Experts with Natural Language\n  and Multi-Agent Collaboration","summary":"  While many tools are available for designing AI, non-experts still face\nchallenges in clearly expressing their intent and managing system complexity.\nWe introduce AIAP, a no-code platform that integrates natural language input\nwith visual workflows. AIAP leverages a coordinated multi-agent system to\ndecompose ambiguous user instructions into modular, actionable steps, hidden\nfrom users behind a unified interface. A user study involving 32 participants\nshowed that AIAP's AI-generated suggestions, modular workflows, and automatic\nidentification of data, actions, and context significantly improved\nparticipants' ability to develop services intuitively. These findings highlight\nthat natural language-based visual programming significantly reduces barriers\nand enhances user experience in AI service design.\n","authors":["Hyunjn An","Yongwon Kim","Wonduk Seo","Joonil Park","Daye Kang","Changhoon Oh","Dokyun Kim","Seunghyun Lee"],"pdf_url":"https://arxiv.org/pdf/2508.02470v1.pdf","comment":"14 pages, 6 figures"},{"id":"http://arxiv.org/abs/2508.02452v1","updated":"2025-08-04T14:17:29Z","published":"2025-08-04T14:17:29Z","title":"LatentPrompt: Optimizing Promts in Latent Space","summary":"  Recent advances have shown that optimizing prompts for Large Language Models\n(LLMs) can significantly improve task performance, yet many optimization\ntechniques rely on heuristics or manual exploration. We present LatentPrompt, a\nmodel-agnostic framework for prompt optimization that leverages latent semantic\nspace to automatically generate, evaluate, and refine candidate prompts without\nrequiring hand-crafted rules. Beginning with a set of seed prompts, our method\nembeds them in a continuous latent space and systematically explores this space\nto identify prompts that maximize task-specific performance. In a\nproof-of-concept study on the Financial PhraseBank sentiment classification\nbenchmark, LatentPrompt increased classification accuracy by approximately 3\npercent after a single optimization cycle. The framework is broadly applicable,\nrequiring only black-box access to an LLM and an automatic evaluation metric,\nmaking it suitable for diverse domains and tasks.\n","authors":["Mateusz Bystroński","Grzegorz Piotrowski","Nitesh V. Chawla","Tomasz Kajdanowicz"],"pdf_url":"https://arxiv.org/pdf/2508.02452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.12601v3","updated":"2025-08-04T14:11:45Z","published":"2024-10-16T14:21:52Z","title":"CCSBench: Evaluating Compositional Controllability in LLMs for\n  Scientific Document Summarization","summary":"  To broaden the dissemination of scientific knowledge to diverse audiences, it\nis desirable for scientific document summarization systems to simultaneously\ncontrol multiple attributes such as length and empirical focus. However,\nexisting research typically focuses on controlling single attributes, leaving\nthe compositional control of multiple attributes underexplored. To address this\ngap, we introduce CCSBench, the first evaluation benchmark for compositional\ncontrollable summarization in the scientific domain. Our benchmark enables\nfine-grained control over both explicit attributes (e.g., length), which are\nobjective and straightforward, and implicit attributes (e.g., conceptual or\nempirical focus), which are more subjective and abstract. We conduct extensive\nexperiments using various large language models (LLMs) under various settings,\nincluding in-context learning, parameter-efficient fine-tuning, and two-stage\nmodular methods for balancing control over different attributes. Our findings\nreveal significant limitations in LLMs capabilities in balancing trade-offs\nbetween control attributes, especially implicit ones that require deeper\nunderstanding and abstract reasoning.\n","authors":["Yixi Ding","Jiaying Wu","Tongyao Zhu","Yanxia Qin","Qian Liu","Min-Yen Kan"],"pdf_url":"https://arxiv.org/pdf/2410.12601v3.pdf","comment":"Accepted to KDD 2025 SciSoc LLM Workshop: Large Language Models for\n  Scientific and Societal Advances"},{"id":"http://arxiv.org/abs/2405.18937v2","updated":"2025-08-04T13:54:40Z","published":"2024-05-29T09:43:48Z","title":"Kestrel: 3D Multimodal LLM for Part-Aware Grounded Description","summary":"  In this paper, we introduce Part-Aware Point Grounded Description (PaPGD), a\nchallenging task aimed at advancing 3D multimodal learning for fine-grained,\npart-aware segmentation grounding and detailed explanation of 3D objects.\nExisting 3D datasets largely focus on either vision-only part segmentation or\nvision-language scene segmentation, lacking the fine-grained multimodal\nsegmentation needed for robotic navigation and interaction in real-world\nenvironments. To address this gap, we present the 3DCoMPaT Grounded\nInstructions (3DCoMPaT-GrIn) Dataset, a comprehensive resource that pairs rich\npoint cloud descriptions with corresponding part-level segmentation masks. This\ndataset encompasses extensive samples designed for both PaPGD and fine-grained\nsingle-part grounding tasks. To tackle the inherent challenges of grounding\nobjects and generating grounded descriptions at the part level, we propose\nKestrel, a part-aware 3D multimodal large language model that integrates an\nadvanced language model for nuanced language comprehension with multi-level\npoint feature propagation and query refinement mechanism to enhance spatial\nreasoning at the part level. The extensive experiments demonstrate that Kestrel\neffectively bridges the gap between part-aware language understanding and 3D\nsegmentation grounding, paving the way for more robust and interpretable 3D\nobject comprehension that meets the demands of real-world robotic applications.\nProject page at https://feielysia.github.io/Kestrel.github.io/\n","authors":["Mahmoud Ahmed","Junjie Fei","Jian Ding","Eslam Mohamed Bakr","Mohamed Elhoseiny"],"pdf_url":"https://arxiv.org/pdf/2405.18937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02430v1","updated":"2025-08-04T13:49:30Z","published":"2025-08-04T13:49:30Z","title":"AI-Based Measurement of Innovation: Mapping Expert Insight into Large\n  Language Model Applications","summary":"  Measuring innovation often relies on context-specific proxies and on expert\nevaluation. Hence, empirical innovation research is often limited to settings\nwhere such data is available. We investigate how large language models (LLMs)\ncan be leveraged to overcome the constraints of manual expert evaluations and\nassist researchers in measuring innovation. We design an LLM framework that\nreliably approximates domain experts' assessment of innovation from\nunstructured text data. We demonstrate the performance and broad applicability\nof this framework through two studies in different contexts: (1) the\ninnovativeness of software application updates and (2) the originality of\nuser-generated feedback and improvement ideas in product reviews. We compared\nthe performance (F1-score) and reliability (consistency rate) of our LLM\nframework against alternative measures used in prior innovation studies, and to\nstate-of-the-art machine learning- and deep learning-based models. The LLM\nframework achieved higher F1-scores than the other approaches, and its results\nare highly consistent (i.e., results do not change across runs). This article\nequips R&D personnel in firms, as well as researchers, reviewers, and editors,\nwith the knowledge and tools to effectively use LLMs for measuring innovation\nand evaluating the performance of LLM-based innovation measures. In doing so,\nwe discuss, the impact of important design decisions-including model selection,\nprompt engineering, training data size, training data distribution, and\nparameter settings-on performance and reliability. Given the challenges\ninherent in using human expert evaluation and existing text-based measures, our\nframework has important implications for harnessing LLMs as reliable,\nincreasingly accessible, and broadly applicable research tools for measuring\ninnovation.\n","authors":["Robin Nowak","Patrick Figge","Carolin Haeussler"],"pdf_url":"https://arxiv.org/pdf/2508.02430v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02426v1","updated":"2025-08-04T13:46:33Z","published":"2025-08-04T13:46:33Z","title":"Learning to Evolve: Bayesian-Guided Continual Knowledge Graph Embedding","summary":"  Since knowledge graphs (KG) will continue to evolve in real scenarios,\ntraditional KGE models are only suitable for static knowledge graphs.\nTherefore, continual knowledge graph embedding (CKGE) has attracted the\nattention of researchers. Currently, a key challenge facing CKGE is that the\nmodel is prone to \"catastrophic forgetting\", resulting in the loss of\npreviously learned knowledge. In order to effectively alleviate this problem,\nwe propose a new CKGE model BAKE. First, we note that the Bayesian posterior\nupdate principle provides a natural continual learning strategy that is\ninsensitive to data order and can theoretically effectively resist the\nforgetting of previous knowledge during data evolution. Different from the\nexisting CKGE method, BAKE regards each batch of new data as a Bayesian update\nof the model prior. Under this framework, as long as the posterior distribution\nof the model is maintained, the model can better preserve the knowledge of\nearly snapshots even after evolving through multiple time snapshots. Secondly,\nwe propose a continual clustering method for CKGE, which further directly\ncombats knowledge forgetting by constraining the evolution difference (or\nchange amplitude) between new and old knowledge between different snapshots. We\nconduct extensive experiments on BAKE on multiple datasets, and the results\nshow that BAKE significantly outperforms existing baseline models.\n","authors":["Linyu Li","Zhi Jin","Yuanpeng He","Dongming Jin","Yichi Zhang","Haoran Duan","Nyima Tash"],"pdf_url":"https://arxiv.org/pdf/2508.02426v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01281v4","updated":"2025-08-04T13:46:22Z","published":"2024-11-02T15:23:28Z","title":"Arena-Lite: Efficient and Reliable Large Language Model Evaluation via\n  Tournament-Based Direct Comparisons","summary":"  As Large Language Models (LLMs) expand across domains, LLM judges have become\nessential for systems evaluation. Current benchmarks typically compare system\noutputs against baselines. This baseline-mediated approach, though convenient,\nyields lower reliability than direct comparison between systems. We propose\nArena-Lite which integrates tournament structure on top of head-to-head\ncomparison. The application of a tournament structure and direct comparison\neliminates the need for baseline outputs, reduces the number of required\ncomparisons, and allows higher reliability in system rankings. We conducted two\nexperiments: (1) controlled stochastic modeling and (2) empirical validation\nwith a real LLM judge. Those experiments collectively demonstrate that\nArena-Lite consistently achieves higher reliability with fewer comparisons,\neven with smaller datasets or weaker judges. We release an easy-to-use web\ndemonstration and code to foster adoption of Arena-Lite, streamlining model\nselection across research and industry communities. Arena-Lite demo and code\nare available on\n\\href{https://huggingface.co/spaces/NCSOFT/ArenaLite}{https://huggingface.co/spaces/NCSOFT/ArenaLite}\n","authors":["Seonil Son","Ju-Min Oh","Heegon Jin","Cheolhun Jang","Jeongbeom Jeong","Kuntae Kim"],"pdf_url":"https://arxiv.org/pdf/2411.01281v4.pdf","comment":"8 pages for main body, 19 pages in total"},{"id":"http://arxiv.org/abs/2506.16792v2","updated":"2025-08-04T13:42:52Z","published":"2025-06-20T07:16:47Z","title":"MIST: Jailbreaking Black-box Large Language Models via Iterative\n  Semantic Tuning","summary":"  Despite efforts to align large language models (LLMs) with societal and moral\nvalues, these models remain susceptible to jailbreak attacks -- methods\ndesigned to elicit harmful responses. Jailbreaking black-box LLMs is considered\nchallenging due to the discrete nature of token inputs, restricted access to\nthe target LLM, and limited query budget. To address the issues above, we\npropose an effective method for jailbreaking black-box large language Models\nvia Iterative Semantic Tuning, named MIST. MIST enables attackers to\niteratively refine prompts that preserve the original semantic intent while\ninducing harmful content. Specifically, to balance semantic similarity with\ncomputational efficiency, MIST incorporates two key strategies: sequential\nsynonym search, and its advanced version -- order-determining optimization. We\nconduct extensive experiments on two datasets using two open-source and four\nclosed-source models. Results show that MIST achieves competitive attack\nsuccess rate, relatively low query count, and fair transferability,\noutperforming or matching state-of-the-art jailbreak methods. Additionally, we\nconduct analysis on computational efficiency to validate the practical\nviability of MIST.\n","authors":["Muyang Zheng","Yuanzhi Yao","Changting Lin","Rui Wang","Caihong Kai"],"pdf_url":"https://arxiv.org/pdf/2506.16792v2.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.02419v1","updated":"2025-08-04T13:40:59Z","published":"2025-08-04T13:40:59Z","title":"Modality Bias in LVLMs: Analyzing and Mitigating Object Hallucination\n  via Attention Lens","summary":"  Large vision-language models (LVLMs) have demonstrated remarkable multimodal\ncomprehension and reasoning capabilities, but they still suffer from severe\nobject hallucination. Previous studies primarily attribute the flaw to\nlinguistic prior caused by the scale mismatch between visual encoders and large\nlanguage models (LLMs) in LVLMs. Specifically, as current LVLMs are built upon\nLLMs, they tend to over-rely on textual prompts and internal knowledge of LLMs,\ngenerating descriptions inconsistent with visual cues. However, through an\nin-depth investigation of the hallucinated mechanisms, we empirically reveal a\npreviously overlooked phenomenon: LVLMs may ignore not only visual information\nbut also textual modality during hallucination, a behavior termed as modality\nbias, which indicates that LVLMs struggle to simultaneously attend to both\nvisual and textual modalities, leading to fragmented understanding of\nuser-provided instructions. Based on this observation, we propose a simple yet\neffective training-free method to mitigate object hallucination. Concretely, we\nintervene and adjust the attention weights of textual and visual tokens,\nbalancing cross-modal compatibility for better alignment with user intentions.\nFurthermore, we adopt a contrastive decoding strategy to reduce the LVLM's\noverreliance on its parametric knowledge, synergistically enhancing our\nattention manipulation. Extensive experiments confirm the widespread presence\nof modality bias in LVLMs. Notably, our method effectively mitigates\nhallucination across multiple open-source LVLMs and benchmarks, highlighting\nits generalizability and efficacy.\n","authors":["Haohan Zheng","Zhenguo Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.02419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.05026v3","updated":"2025-08-04T13:38:49Z","published":"2025-05-08T08:00:32Z","title":"Do MLLMs Capture How Interfaces Guide User Behavior? A Benchmark for\n  Multimodal UI/UX Design Understanding","summary":"  User interface (UI) design goes beyond visuals, guiding user behavior and\noverall user experience (UX). Strategically crafted interfaces, for example,\ncan boost sign-ups and drive business sales, underscoring the shift toward\nUI/UX as a unified design concept. While recent studies have explored UI\nquality evaluation using Multimodal Large Language Models (MLLMs), they largely\nfocus on surface-level features, overlooking behavior-oriented aspects. To fill\nthis gap, we introduce WiserUI-Bench, a novel benchmark for assessing models'\nmultimodal understanding of UI/UX design. It includes 300 diverse real-world UI\nimage pairs, each consisting of two design variants A/B-tested at scale by\nactual companies, where one was empirically validated to steer more user\nactions than the other. Each pair is accompanied one or more of 684\nexpert-curated rationales that capture key factors behind each winning design's\neffectiveness, spanning diverse cognitive dimensions of UX. Our benchmark\nsupports two core tasks: (1) selecting the more effective UI/UX design by\npredicting the A/B test verified winner and (2) assessing how well a model,\ngiven the winner, can explain its effectiveness in alignment with expert\nreasoning. Experiments across several MLLMs show that current models exhibit\nlimited nuanced reasoning about UI/UX design and its behavioral impact. We\nbelieve our work will foster research in UI/UX understanding and enable broader\napplications such as behavior-aware interface optimization.\n","authors":["Jaehyun Jeon","Min Soo Kim","Jang Han Yoon","Sumin Shim","Yejin Choi","Hanbin Kim","Youngjae Yu"],"pdf_url":"https://arxiv.org/pdf/2505.05026v3.pdf","comment":"26 pages, 25 figures, Our code and dataset:\n  https://github.com/jeochris/wiserui-bench"},{"id":"http://arxiv.org/abs/2508.02401v1","updated":"2025-08-04T13:26:16Z","published":"2025-08-04T13:26:16Z","title":"CompressKV: Semantic Retrieval Heads Know What Tokens are Not Important\n  Before Generation","summary":"  Recent advances in large language models (LLMs) have significantly boosted\nlong-context processing. However, the increasing key-value (KV) cache size\nposes critical challenges to memory and execution efficiency. Most KV cache\ncompression methods rely on heuristic token eviction using all attention heads\nin Grouped Query Attention (GQA)-based LLMs. This method ignores the different\nfunctionalities of attention heads, leading to the eviction of critical tokens\nand thus degrades the performance of LLMs.\n  To address the issue above, instead of using all the attention heads in\nGQA-based LLMs to determine important tokens as in the previous work, we first\nidentify the attention heads in each layer that are not only capable of\nretrieving the initial and final tokens of a prompt, but also capable of\nretrieving important tokens within the text and attending to their surrounding\nsemantic context. Afterwards, we exploit such heads to determine the important\ntokens and retain their corresponding KV cache pairs. Furthermore, we analyze\nthe cache eviction error of each layer individually and introduce a\nlayer-adaptive KV cache allocation strategy. Experimental results demonstrate\nthe proposed CompressKV consistently outperforms state-of-the-art approaches\nunder various memory budgets on LongBench and Needle-in-a-Haystack benchmarks.\nOur code is publicly available at: https://github.com/TUDa-HWAI/CompressKV.git.\n","authors":["Xiaolin Lin","Jingcun Wang","Olga Kondrateva","Yiyu Shi","Bing Li","Grace Li Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.02401v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11130v2","updated":"2025-08-04T13:14:13Z","published":"2024-06-17T01:21:28Z","title":"Dynamic Order Template Prediction for Generative Aspect-Based Sentiment\n  Analysis","summary":"  Aspect-based sentiment analysis (ABSA) assesses sentiments towards specific\naspects within texts, resulting in detailed sentiment tuples. Previous ABSA\nmodels often use static templates to predict all of the elements in the tuples,\nand these models often fail to accurately capture dependencies between\nelements. Multi-view prompting method improves the performance of ABSA by\npredicting tuples with various templates and then ensembling the results.\nHowever, this method suffers from inefficiencies and out-of-distribution\nerrors. In this paper, we propose a Dynamic Order Template (DOT) method for\nABSA, which dynamically generates necessary views for each instance based on\ninstance-level entropy. Ensuring the diverse and relevant view generation, our\nproposed method improves F1-scores on ASQP and ACOS datasets while\nsignificantly reducing inference time.\n","authors":["Yonghyun Jun","Hwanhee Lee"],"pdf_url":"https://arxiv.org/pdf/2406.11130v2.pdf","comment":"ACL 2025 Main"},{"id":"http://arxiv.org/abs/2507.20957v2","updated":"2025-08-04T13:06:03Z","published":"2025-07-28T16:09:38Z","title":"Your AI, Not Your View: The Bias of LLMs in Investment Analysis","summary":"  In finance, Large Language Models (LLMs) face frequent knowledge conflicts\ndue to discrepancies between pre-trained parametric knowledge and real-time\nmarket data. These conflicts become particularly problematic when LLMs are\ndeployed in real-world investment services, where misalignment between a\nmodel's embedded preferences and those of the financial institution can lead to\nunreliable recommendations. Yet little research has examined what investment\nviews LLMs actually hold. We propose an experimental framework to investigate\nsuch conflicts, offering the first quantitative analysis of confirmation bias\nin LLM-based investment analysis. Using hypothetical scenarios with balanced\nand imbalanced arguments, we extract the latent preferences of models and\nmeasure their persistence. Focusing on sector, size, and momentum, our analysis\nreveals distinct, model-specific tendencies. In particular, we observe a\nconsistent preference for large-cap stocks and contrarian strategies across\nmost models. These preferences often harden into confirmation bias, with models\nclinging to initial judgments despite counter-evidence.\n","authors":["Hoyoung Lee","Junhyuk Seo","Suhwan Park","Junhyeong Lee","Wonbin Ahn","Chanyeol Choi","Alejandro Lopez-Lira","Yongjae Lee"],"pdf_url":"https://arxiv.org/pdf/2507.20957v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02371v1","updated":"2025-08-04T13:01:09Z","published":"2025-08-04T13:01:09Z","title":"Six Guidelines for Trustworthy, Ethical and Responsible Automation\n  Design","summary":"  Calibrated trust in automated systems (Lee and See 2004) is critical for\ntheir safe and seamless integration into society. Users should only rely on a\nsystem recommendation when it is actually correct and reject it when it is\nfactually wrong. One requirement to achieve this goal is an accurate\ntrustworthiness assessment, ensuring that the user's perception of the system's\ntrustworthiness aligns with its actual trustworthiness, allowing users to make\ninformed decisions about the extent to which they can rely on the system\n(Schlicker et al. 2022). We propose six design guidelines to help designers\noptimize for accurate trustworthiness assessments, thus fostering ethical and\nresponsible human-automation interactions. The proposed guidelines are derived\nfrom existing literature in various fields, such as human-computer interaction,\ncognitive psychology, automation research, user-experience design, and ethics.\nWe are incorporating key principles from the field of pragmatics, specifically\nthe cultivation of common ground (H. H. Clark 1996) and Gricean communication\nmaxims (Grice 1975). These principles are essential for the design of automated\nsystems because the user's perception of the system's trustworthiness is shaped\nby both environmental contexts, such as organizational culture or societal\nnorms, and by situational context, including the specific circumstances or\nscenarios in which the interaction occurs (Hoff and Bashir 2015). Our proposed\nguidelines provide actionable insights for designers to create automated\nsystems that make relevant trustworthiness cues available. This would ideally\nfoster calibrated trust and more satisfactory, productive, and safe\ninteractions between humans and automated systems. Furthermore, the proposed\nheuristics might work as a tool for evaluating to what extent existing systems\nenable users to accurately assess a system's trustworthiness.\n","authors":["Matouš Jelínek","Nadine Schlicker","Ewart de Visser"],"pdf_url":"https://arxiv.org/pdf/2508.02371v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05386v2","updated":"2025-08-04T12:55:00Z","published":"2025-06-03T12:59:52Z","title":"Leaps Beyond the Seen: Reinforced Reasoning Augmented Generation for\n  Clinical Notes","summary":"  Clinical note generation aims to produce free-text summaries of a patient's\ncondition and diagnostic process, with discharge instructions being a\nrepresentative long-form example. While recent LLM-based methods pre-trained on\ngeneral clinical corpora show promise in clinical text generation, they fall\nshort in producing long-form notes from limited patient information. In this\npaper, we propose ReinRAG, a reinforced reasoning augmented generation (RAG)\nfor long-form discharge instructions based on pre-admission information.\nReinRAG retrieves reasoning paths from a medical knowledge graph to provide\nexplicit semantic guidance to the LLM. To bridge the information gap, we\npropose group-based retriever optimization (GRO) which improves retrieval\nquality with group-normalized rewards, encouraging reasoning leaps for deeper\ninference by the LLM. Comprehensive experiments on the real-world dataset show\nthat ReinRAG outperforms baselines in both clinical efficacy and natural\nlanguage generation metrics. Further analysis reveals that ReinRAG fills\nsemantic gaps in sparse input scenarios, and retrieved reasoning paths help\nLLMs avoid clinical misinterpretation by focusing on key evidence and following\ncoherent reasoning.\n","authors":["Lo Pang-Yun Ting","Chengshuai Zhao","Yu-Hua Zeng","Yuan Jee Lim","Kun-Ta Chuang","Huan Liu"],"pdf_url":"https://arxiv.org/pdf/2506.05386v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02366v1","updated":"2025-08-04T12:52:11Z","published":"2025-08-04T12:52:11Z","title":"Language Model Guided Reinforcement Learning in Quantitative Trading","summary":"  Algorithmic trading requires short-term decisions aligned with long-term\nfinancial goals. While reinforcement learning (RL) has been explored for such\ntactical decisions, its adoption remains limited by myopic behavior and opaque\npolicy rationale. In contrast, large language models (LLMs) have recently\ndemonstrated strategic reasoning and multi-modal financial signal\ninterpretation when guided by well-designed prompts.\n  We propose a hybrid system where LLMs generate high-level trading strategies\nto guide RL agents in their actions. We evaluate (i) the rationale of\nLLM-generated strategies via expert review, and (ii) the Sharpe Ratio (SR) and\nMaximum Drawdown (MDD) of LLM-guided agents versus unguided baselines. Results\nshow improved return and risk metrics over standard RL.\n","authors":["Adam Darmanin","Vince Vella"],"pdf_url":"https://arxiv.org/pdf/2508.02366v1.pdf","comment":"12 pages (4 pages appendix and references), 6 figures, preprint under\n  review for FLLM 2025 conference"},{"id":"http://arxiv.org/abs/2412.15113v2","updated":"2025-08-04T12:51:56Z","published":"2024-12-19T17:55:42Z","title":"Associative memory inspires improvements for in-context learning using a\n  novel attention residual stream architecture","summary":"  Large language models (LLMs) demonstrate an impressive ability to utilise\ninformation within the context of their input sequences to appropriately\nrespond to data unseen by the LLM during its training procedure. This ability\nis known as in-context learning (ICL). Humans and non-human animals demonstrate\nsimilar abilities, however their neural architectures differ substantially from\nLLMs. Despite this, a critical component within LLMs, the attention mechanism,\nresembles modern associative memory models, widely used in and influenced by\nthe computational neuroscience community to model biological memory systems.\nUsing this connection, we introduce an associative memory model capable of\nperforming ICL. We use this as inspiration for a novel residual stream\narchitecture which allows information to directly flow between attention heads.\nWe test this architecture during training within a two-layer Transformer and\nshow its ICL abilities manifest more quickly than without this modification. We\nthen apply our architecture in small language models with 8 million and 1\nbillion parameters, focusing on attention head values, with results also\nindicating improved performance at these larger and more naturalistic scales.\n","authors":["Thomas F Burns","Tomoki Fukai","Christopher J Earls"],"pdf_url":"https://arxiv.org/pdf/2412.15113v2.pdf","comment":"35 pages, 14 figures, 6 tables; accepted and published in TMLR"},{"id":"http://arxiv.org/abs/2508.02360v1","updated":"2025-08-04T12:49:10Z","published":"2025-08-04T12:49:10Z","title":"Understanding and Mitigating Political Stance Cross-topic Generalization\n  in Large Language Models","summary":"  Fine-tuning Large Language Models on a political topic will significantly\nmanipulate their political stance on various issues and unintentionally affect\ntheir stance on unrelated topics. While previous studies have proposed this\nissue, there is still a lack of understanding regarding the internal\nrepresentations of these stances and the mechanisms that lead to unintended\ncross-topic generalization. In this paper, we systematically explore the\ninternal mechanisms underlying this phenomenon from a neuron-level perspective\nand how to mitigate the cross-topic generalization of political fine-tuning.\nFirstly, we propose Political Neuron Localization through Activation\nContrasting (PNLAC) to identify two distinct types of political neurons:\ngeneral political neurons, which govern stance across multiple political\ntopics, and topic-specific neurons} that affect the model's political stance on\nindividual topics. We find the existence of these political neuron types across\nfour models and datasets through activation patching experiments. Leveraging\nthese insights, we introduce InhibitFT, an inhibition-based fine-tuning method,\neffectively mitigating the cross-topic stance generalization. Experimental\nresults demonstrate the robustness of identified neuron types across various\nmodels and datasets, and show that InhibitFT significantly reduces the\ncross-topic stance generalization by 20% on average, while preserving\ntopic-specific performance. Moreover, we demonstrate that selectively\ninhibiting only 5% of neurons is sufficient to effectively mitigate the\ncross-topic stance generalization.\n","authors":["Jiayi Zhang","Shu Yang","Junchao Wu","Derek F. Wong","Di Wang"],"pdf_url":"https://arxiv.org/pdf/2508.02360v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.13626v2","updated":"2025-08-04T12:34:26Z","published":"2025-04-18T11:07:19Z","title":"Thought Manipulation: External Thought Can Be Efficient for Large\n  Reasoning Models","summary":"  Recent advancements in large reasoning models (LRMs) have demonstrated the\neffectiveness of scaling test-time computation to enhance reasoning\ncapabilities on various tasks. However, LRMs often suffer from an\n``overthinking'' problem, where the model generates excessively redundant\nreasoning steps with limited performance gains. In this work, we empirically\nreveal an important characteristic of LRM behaviors that placing external CoTs\ngenerated by smaller models between the thinking token (\\texttt{<think>} and\n\\texttt{</think>}) can effectively manipulate the model to generate fewer\nthoughts. Building on this finding, we propose a simple yet efficient pipeline,\n\\Method, to enable LRMs to bypass unnecessary intermediate steps, thereby\nsignificantly reducing computational costs. We conduct extensive experiments to\nevaluate the utility and efficiency of \\Method. For instance, when applied to\nQwQ-32B on the LiveBench/Code dataset, \\Method keeps the original performance\nwhile reducing output token counts by approximately 30\\%, with minimal overhead\nintroduced by the CoT generator. Furthermore, we identify two suboptimal modes,\nblindly following flawed external thoughts and unnecessary rethinking, and show\nthat simple mitigations, such as difficulty-aware fallbacks, can further\nimprove performance. Overall, \\Method offers a practical, general, and\nefficient way to optimize LRM inference, making powerful reasoning models more\naccessible and scalable for real-world applications.\n","authors":["Yule Liu","Jingyi Zheng","Zhen Sun","Zifan Peng","Wenhan Dong","Zeyang Sha","Shiwen Cui","Weiqiang Wang","Xinlei He"],"pdf_url":"https://arxiv.org/pdf/2504.13626v2.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2504.17349v2","updated":"2025-08-04T16:14:00Z","published":"2025-04-24T08:10:10Z","title":"DRC: Enhancing Personalized Image Generation via Disentangled\n  Representation Composition","summary":"  Personalized image generation has emerged as a promising direction in\nmultimodal content creation. It aims to synthesize images tailored to\nindividual style preferences (e.g., color schemes, character appearances,\nlayout) and semantic intentions (e.g., emotion, action, scene contexts) by\nleveraging user-interacted history images and multimodal instructions. Despite\nnotable progress, existing methods -- whether based on diffusion models, large\nlanguage models, or Large Multimodal Models (LMMs) -- struggle to accurately\ncapture and fuse user style preferences and semantic intentions. In particular,\nthe state-of-the-art LMM-based method suffers from the entanglement of visual\nfeatures, leading to Guidance Collapse, where the generated images fail to\npreserve user-preferred styles or reflect the specified semantics.\n  To address these limitations, we introduce DRC, a novel personalized image\ngeneration framework that enhances LMMs through Disentangled Representation\nComposition. DRC explicitly extracts user style preferences and semantic\nintentions from history images and the reference image, respectively, to form\nuser-specific latent instructions that guide image generation within LMMs.\nSpecifically, it involves two critical learning stages: 1) Disentanglement\nlearning, which employs a dual-tower disentangler to explicitly separate style\nand semantic features, optimized via a reconstruction-driven paradigm with\ndifficulty-aware importance sampling; and 2) Personalized modeling, which\napplies semantic-preserving augmentations to effectively adapt the disentangled\nrepresentations for robust personalized generation. Extensive experiments on\ntwo benchmarks demonstrate that DRC shows competitive performance while\neffectively mitigating the guidance collapse issue, underscoring the importance\nof disentangled representation learning for controllable and effective\npersonalized image generation.\n","authors":["Yiyan Xu","Wuqiang Zheng","Wenjie Wang","Fengbin Zhu","Xinting Hu","Yang Zhang","Fuli Feng","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2504.17349v2.pdf","comment":"Accepted for publication in ACM MM'25"},{"id":"http://arxiv.org/abs/2508.02538v1","updated":"2025-08-04T15:45:48Z","published":"2025-08-04T15:45:48Z","title":"Hubness Reduction with Dual Bank Sinkhorn Normalization for Cross-Modal\n  Retrieval","summary":"  The past decade has witnessed rapid advancements in cross-modal retrieval,\nwith significant progress made in accurately measuring the similarity between\ncross-modal pairs. However, the persistent hubness problem, a phenomenon where\na small number of targets frequently appear as nearest neighbors to numerous\nqueries, continues to hinder the precision of similarity measurements. Despite\nseveral proposed methods to reduce hubness, their underlying mechanisms remain\npoorly understood. To bridge this gap, we analyze the widely-adopted Inverted\nSoftmax approach and demonstrate its effectiveness in balancing target\nprobabilities during retrieval. Building on these insights, we propose a\nprobability-balancing framework for more effective hubness reduction. We\ncontend that balancing target probabilities alone is inadequate and, therefore,\nextend the framework to balance both query and target probabilities by\nintroducing Sinkhorn Normalization (SN). Notably, we extend SN to scenarios\nwhere the true query distribution is unknown, showing that current methods,\nwhich rely solely on a query bank to estimate target hubness, produce\nsuboptimal results due to a significant distributional gap between the query\nbank and targets. To mitigate this issue, we introduce Dual Bank Sinkhorn\nNormalization (DBSN), incorporating a corresponding target bank alongside the\nquery bank to narrow this distributional gap. Our comprehensive evaluation\nacross various cross-modal retrieval tasks, including image-text retrieval,\nvideo-text retrieval, and audio-text retrieval, demonstrates consistent\nperformance improvements, validating the effectiveness of both SN and DBSN. All\ncodes are publicly available at https://github.com/ppanzx/DBSN.\n","authors":["Zhengxin Pan","Haishuai Wang","Fangyu Wu","Peng Zhang","Jiajun Bu"],"pdf_url":"https://arxiv.org/pdf/2508.02538v1.pdf","comment":"ACMMM 2025"},{"id":"http://arxiv.org/abs/2508.02506v1","updated":"2025-08-04T15:14:09Z","published":"2025-08-04T15:14:09Z","title":"Decomposed Reasoning with Reinforcement Learning for Relevance\n  Assessment in UGC Platforms","summary":"  Retrieval-augmented generation (RAG) plays a critical role in user-generated\ncontent (UGC) platforms, but its effectiveness depends heavily on accurate\nrelevance assessment of query-document pairs. Despite recent advances in\napplying large language models (LLMs) to relevance modeling, UGC platforms\npresent unique challenges: 1) ambiguous user intent due to sparse user feedback\nin RAG scenarios, and 2) substantial noise introduced by informal and\nunstructured language. To address these issues, we propose the Reinforced\nReasoning Model for Relevance Assessment (R3A), which introduces a decomposed\nreasoning framework over queries and candidate documents before scoring. R3A\nfirst leverages auxiliary high-ranked documents within the platform to infer\nlatent query intent. It then performs verbatim fragment extraction to justify\nrelevance decisions, thereby reducing errors caused by noisy UGC. Based on a\nreinforcement learning framework, R3A is optimized to mitigate distortions\narising from ambiguous queries and unstructured content. Experimental results\nshow that R3A significantly outperforms existing baseline methods in terms of\nrelevance accuracy, across both offline benchmarks and online experiments.\n","authors":["Xiaowei Yuan","Lei Jin","Haoxin Zhang","Yan Gao","Yi Wu","Yao Hu","Ziyang Huang","Jun Zhao","Kang Liu"],"pdf_url":"https://arxiv.org/pdf/2508.02506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.20243v3","updated":"2025-08-04T14:52:16Z","published":"2025-05-26T17:21:26Z","title":"It's High Time: A Survey of Temporal Question Answering","summary":"  Time plays a critical role in how information is generated, retrieved, and\ninterpreted. In this survey, we provide a comprehensive overview of Temporal\nQuestion Answering (TQA), a research area that focuses on answering questions\ninvolving temporal constraints or context. As the amount of time-stamped\ncontent from sources like news articles, web archives, and knowledge bases\nincreases, systems must address challenges such as detecting temporal intent,\nnormalizing time expressions, ordering events, and reasoning over evolving or\nambiguous facts. We focus on recent advances in TQA enabled by neural\narchitectures, especially transformer-based models and Large Language Models\n(LLMs), highlighting progress in temporal language modeling,\nretrieval-augmented generation (RAG), and temporal reasoning. We also discuss\nbenchmark datasets and evaluation strategies designed to test temporal\nrobustness, recency awareness, and generalization.\n","authors":["Bhawna Piryani","Abdelrahman Abdallah","Jamshid Mozafari","Avishek Anand","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2505.20243v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.17356v2","updated":"2025-08-04T14:20:55Z","published":"2025-07-23T09:37:23Z","title":"\"Beyond the past\": Leveraging Audio and Human Memory for Sequential\n  Music Recommendation","summary":"  On music streaming services, listening sessions are often composed of a\nbalance of familiar and new tracks. Recently, sequential recommender systems\nhave adopted cognitive-informed approaches, such as Adaptive Control of\nThought-Rational (ACT-R), to successfully improve the prediction of the most\nrelevant tracks for the next user session. However, one limitation of using a\nmodel inspired by human memory (or the past), is that it struggles to recommend\nnew tracks that users have not previously listened to. To bridge this gap, here\nwe propose a model that leverages audio information to predict in advance the\nACT-R-like activation of new tracks and incorporates them into the\nrecommendation scoring process. We demonstrate the empirical effectiveness of\nthe proposed model using proprietary data, which we publicly release along with\nthe model's source code to foster future research in this field.\n","authors":["Viet-Anh Tran","Bruno Sguerra","Gabriel Meseguer-Brocal","Lea Briand","Manuel Moussallam"],"pdf_url":"https://arxiv.org/pdf/2507.17356v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02455v1","updated":"2025-08-04T14:20:39Z","published":"2025-08-04T14:20:39Z","title":"TreeRanker: Fast and Model-agnostic Ranking System for Code Suggestions\n  in IDEs","summary":"  Token-level code completion is one of the most critical features in modern\nIntegrated Development Environments (IDEs). It assists developers by suggesting\nrelevant identifiers and APIs during coding. While completions are typically\nderived from static analysis, their usefulness depends heavily on how they are\nranked, as correct predictions buried deep in the list are rarely seen by\nusers. Most current systems rely on hand-crafted heuristics or lightweight\nmachine learning models trained on user logs, which can be further improved to\ncapture context information and generalize across projects and coding styles.\nIn this work, we propose a new scoring approach to ranking static completions\nusing language models in a lightweight and model-agnostic way. Our method\norganizes all valid completions into a prefix tree and performs a single greedy\ndecoding pass to collect token-level scores across the tree. This enables a\nprecise token-aware ranking without needing beam search, prompt engineering, or\nmodel adaptations. The approach is fast, architecture-agnostic, and compatible\nwith already deployed models for code completion. These findings highlight a\npractical and effective pathway for integrating language models into already\nexisting tools within IDEs, and ultimately providing smarter and more\nresponsive developer assistance.\n","authors":["Daniele Cipollone","Egor Bogomolov","Arie van Deursen","Maliheh Izadi"],"pdf_url":"https://arxiv.org/pdf/2508.02455v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02451v1","updated":"2025-08-04T14:16:49Z","published":"2025-08-04T14:16:49Z","title":"Dynamic Forgetting and Spatio-Temporal Periodic Interest Modeling for\n  Local-Life Service Recommendation","summary":"  In the context of the booming digital economy, recommendation systems, as a\nkey link connecting users and numerous services, face challenges in modeling\nuser behavior sequences on local-life service platforms, including the sparsity\nof long sequences and strong spatio-temporal dependence. Such challenges can be\naddressed by drawing an analogy to the forgetting process in human memory. This\nis because users' responses to recommended content follow the recency effect\nand the cyclicality of memory. By exploring this, this paper introduces the\nforgetting curve and proposes Spatio-Temporal periodic Interest Modeling (STIM)\nwith long sequences for local-life service recommendation. STIM integrates\nthree key components: a dynamic masking module based on the forgetting curve,\nwhich is used to extract both recent spatiotemporal features and periodic\nspatiotemporal features; a query-based mixture of experts (MoE) approach that\ncan adaptively activate expert networks under different dynamic masks, enabling\nthe collaborative modeling of time, location, and items; and a hierarchical\nmulti-interest network unit, which captures multi-interest representations by\nmodeling the hierarchical interactions between the shallow and deep semantics\nof users' recent behaviors. By introducing the STIM method, we conducted online\nA/B tests and achieved a 1.54\\% improvement in gross transaction volume (GTV).\nIn addition, extended offline experiments also showed improvements. STIM has\nbeen deployed in a large-scale local-life service recommendation system,\nserving hundreds of millions of daily active users in core application\nscenarios.\n","authors":["Zhaoyu Hu","Hao Guo","Yuan Tian","Erpeng Xue","Jianyang Wang","Xianyang Qi","Hongxiang Lin","Lei Wang","Sheng Chen"],"pdf_url":"https://arxiv.org/pdf/2508.02451v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02435v1","updated":"2025-08-04T13:50:44Z","published":"2025-08-04T13:50:44Z","title":"Beyond Chunks and Graphs: Retrieval-Augmented Generation through\n  Triplet-Driven Thinking","summary":"  Retrieval-augmented generation (RAG) is critical for reducing hallucinations\nand incorporating external knowledge into Large Language Models (LLMs).\nHowever, advanced RAG systems face a trade-off between performance and\nefficiency. Multi-round RAG approaches achieve strong reasoning but incur\nexcessive LLM calls and token costs, while Graph RAG methods suffer from\ncomputationally expensive, error-prone graph construction and retrieval\nredundancy. To address these challenges, we propose T$^2$RAG, a novel framework\nthat operates on a simple, graph-free knowledge base of atomic triplets.\nT$^2$RAG leverages an LLM to decompose questions into searchable triplets with\nplaceholders, which it then iteratively resolves by retrieving evidence from\nthe triplet database. Empirical results show that T$^2$RAG significantly\noutperforms state-of-the-art multi-round and Graph RAG methods, achieving an\naverage performance gain of up to 11\\% across six datasets while reducing\nretrieval costs by up to 45\\%. Our code is available at\nhttps://github.com/rockcor/T2RAG\n","authors":["Shengbo Gong","Xianfeng Tang","Carl Yang","Wei jin"],"pdf_url":"https://arxiv.org/pdf/2508.02435v1.pdf","comment":"19 pages"},{"id":"http://arxiv.org/abs/2508.02383v1","updated":"2025-08-04T13:09:47Z","published":"2025-08-04T13:09:47Z","title":"Graph Embedding in the Graph Fractional Fourier Transform Domain","summary":"  Spectral graph embedding plays a critical role in graph representation\nlearning by generating low-dimensional vector representations from graph\nspectral information. However, the embedding space of traditional spectral\nembedding methods often exhibit limited expressiveness, failing to exhaustively\ncapture latent structural features across alternative transform domains. To\naddress this issue, we use the graph fractional Fourier transform to extend the\nexisting state-of-the-art generalized frequency filtering embedding (GEFFE)\ninto fractional domains, giving birth to the generalized fractional filtering\nembedding (GEFRFE), which enhances embedding informativeness via the graph\nfractional domain. The GEFRFE leverages graph fractional domain filtering and a\nnonlinear composition of eigenvector components derived from a fractionalized\ngraph Laplacian. To dynamically determine the fractional order, two parallel\nstrategies are introduced: search-based optimization and a ResNet18-based\nadaptive learning. Extensive experiments on six benchmark datasets demonstrate\nthat the GEFRFE captures richer structural features and significantly enhance\nclassification performance. Notably, the proposed method retains computational\ncomplexity comparable to GEFFE approaches.\n","authors":["Changjie Sheng","Zhichao Zhang","Wei Yao"],"pdf_url":"https://arxiv.org/pdf/2508.02383v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02374v1","updated":"2025-08-04T13:02:23Z","published":"2025-08-04T13:02:23Z","title":"Uni-Layout: Integrating Human Feedback in Unified Layout Generation and\n  Evaluation","summary":"  Layout generation plays a crucial role in enhancing both user experience and\ndesign efficiency. However, current approaches suffer from task-specific\ngeneration capabilities and perceptually misaligned evaluation metrics, leading\nto limited applicability and ineffective measurement. In this paper, we propose\n\\textit{Uni-Layout}, a novel framework that achieves unified generation,\nhuman-mimicking evaluation and alignment between the two. For universal\ngeneration, we incorporate various layout tasks into a single taxonomy and\ndevelop a unified generator that handles background or element contents\nconstrained tasks via natural language prompts. To introduce human feedback for\nthe effective evaluation of layouts, we build \\textit{Layout-HF100k}, the first\nlarge-scale human feedback dataset with 100,000 expertly annotated layouts.\nBased on \\textit{Layout-HF100k}, we introduce a human-mimicking evaluator that\nintegrates visual and geometric information, employing a Chain-of-Thought\nmechanism to conduct qualitative assessments alongside a confidence estimation\nmodule to yield quantitative measurements. For better alignment between the\ngenerator and the evaluator, we integrate them into a cohesive system by\nadopting Dynamic-Margin Preference Optimization (DMPO), which dynamically\nadjusts margins based on preference strength to better align with human\njudgments. Extensive experiments show that \\textit{Uni-Layout} significantly\noutperforms both task-specific and general-purpose methods. Our code is\npublicly available at https://github.com/JD-GenX/Uni-Layout.\n","authors":["Shuo Lu","Yanyin Chen","Wei Feng","Jiahao Fan","Fengheng Li","Zheng Zhang","Jingjing Lv","Junjie Shen","Ching Law","Jian Liang"],"pdf_url":"https://arxiv.org/pdf/2508.02374v1.pdf","comment":"Accepted to ACM MM 2025"},{"id":"http://arxiv.org/abs/2508.02342v1","updated":"2025-08-04T12:22:25Z","published":"2025-08-04T12:22:25Z","title":"Agentic Personalized Fashion Recommendation in the Age of Generative AI:\n  Challenges, Opportunities, and Evaluation","summary":"  Fashion recommender systems (FaRS) face distinct challenges due to rapid\ntrend shifts, nuanced user preferences, intricate item-item compatibility, and\nthe complex interplay among consumers, brands, and influencers. Traditional\nrecommendation approaches, largely static and retrieval-focused, struggle to\neffectively capture these dynamic elements, leading to decreased user\nsatisfaction and elevated return rates. This paper synthesizes both academic\nand industrial viewpoints to map the distinctive output space and stakeholder\necosystem of modern FaRS, identifying the complex interplay among users,\nbrands, platforms, and influencers, and highlighting the unique data and\nmodeling challenges that arise.\n  We outline a research agenda for industrial FaRS, centered on five\nrepresentative scenarios spanning static queries, outfit composition, and\nmulti-turn dialogue, and argue that mixed-modality refinement-the ability to\ncombine image-based references (anchors) with nuanced textual constraints-is a\nparticularly critical task for real-world deployment. To this end, we propose\nan Agentic Mixed-Modality Refinement (AMMR) pipeline, which fuses multimodal\nencoders with agentic LLM planners and dynamic retrieval, bridging the gap\nbetween expressive user intent and fast-changing fashion inventories. Our work\nshows that moving beyond static retrieval toward adaptive, generative, and\nstakeholder-aware systems is essential to satisfy the evolving expectations of\nfashion consumers and brands.\n","authors":["Yashar Deldjoo","Nima Rafiee","Mahdyar Ravanbakhsh"],"pdf_url":"https://arxiv.org/pdf/2508.02342v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02340v1","updated":"2025-08-04T12:21:16Z","published":"2025-08-04T12:21:16Z","title":"Learning Partially-Decorrelated Common Spaces for Ad-hoc Video Search","summary":"  Ad-hoc Video Search (AVS) involves using a textual query to search for\nmultiple relevant videos in a large collection of unlabeled short videos. The\nmain challenge of AVS is the visual diversity of relevant videos. A simple\nquery such as \"Find shots of a man and a woman dancing together indoors\" can\nspan a multitude of environments, from brightly lit halls and shadowy bars to\ndance scenes in black-and-white animations. It is therefore essential to\nretrieve relevant videos as comprehensively as possible. Current solutions for\nthe AVS task primarily fuse multiple features into one or more common spaces,\nyet overlook the need for diverse spaces. To fully exploit the expressive\ncapability of individual features, we propose LPD, short for Learning Partially\nDecorrelated common spaces. LPD incorporates two key innovations:\nfeature-specific common space construction and the de-correlation loss.\nSpecifically, LPD learns a separate common space for each video and text\nfeature, and employs de-correlation loss to diversify the ordering of negative\nsamples across different spaces. To enhance the consistency of multi-space\nconvergence, we designed an entropy-based fair multi-space triplet ranking\nloss. Extensive experiments on the TRECVID AVS benchmarks (2016-2023) justify\nthe effectiveness of LPD. Moreover, diversity visualizations of LPD's spaces\nhighlight its ability to enhance result diversity.\n","authors":["Fan Hu","Zijie Xin","Xirong Li"],"pdf_url":"https://arxiv.org/pdf/2508.02340v1.pdf","comment":"Accepted by ACMMM2025"},{"id":"http://arxiv.org/abs/2508.02328v1","updated":"2025-08-04T11:56:47Z","published":"2025-08-04T11:56:47Z","title":"Understanding User Preferences for Interaction Styles in Conversational\n  Recommender Systems: The Predictive Role of System Qualities, User\n  Experience, and Traits","summary":"  Conversational Recommender Systems (CRSs) deliver personalised\nrecommendations through multi-turn natural language dialogue and increasingly\nsupport both task-oriented and exploratory interactions. Yet, the factors\nshaping user interaction preferences remain underexplored. In this\nwithin-subjects study (\\(N = 139\\)), participants experienced two scripted CRS\ndialogues, rated their experiences, and indicated the importance of eight\nsystem qualities. Logistic regression revealed that preference for the\nexploratory interaction was predicted by enjoyment, usefulness, novelty, and\nconversational quality. Unexpectedly, perceived effectiveness was also\nassociated with exploratory preference. Clustering uncovered five latent user\nprofiles with distinct dialogue style preferences. Moderation analyses\nindicated that age, gender, and control preference significantly influenced\nthese choices. These findings integrate affective, cognitive, and trait-level\npredictors into CRS user modelling and inform autonomy-sensitive,\nvalue-adaptive dialogue design. The proposed predictive and adaptive framework\napplies broadly to conversational AI systems seeking to align dynamically with\nevolving user needs.\n","authors":["Raj Mahmud","Shlomo Berkovsky","Mukesh Prasad","A. Baki Kocaballi"],"pdf_url":"https://arxiv.org/pdf/2508.02328v1.pdf","comment":"Accepted at OZCHI 2025. 21 pages, 9 figures, 8 tables"},{"id":"http://arxiv.org/abs/2508.02300v1","updated":"2025-08-04T11:11:51Z","published":"2025-08-04T11:11:51Z","title":"Research Knowledge Graphs in NFDI4DataScience: Key Activities,\n  Achievements, and Future Directions","summary":"  As research in Artificial Intelligence and Data Science continues to grow in\nvolume and complexity, it becomes increasingly difficult to ensure\ntransparency, reproducibility, and discoverability. To address these\nchallenges, as research artifacts should be understandable and usable by\nmachines, the NFDI4DataScience consortium is developing and providing Research\nKnowledge Graphs (RKGs). Building upon earlier works, this paper presents\nrecent progress in creating semantically rich RKGs using standardized\nontologies, shared vocabularies, and automated Information Extraction\ntechniques. Key achievements include the development of the NFDI4DS ontology,\nmetadata standards, tools, and services designed to support the FAIR\nprinciples, as well as community-led projects and various implementations of\nRKGs. Together, these efforts aim to capture and connect the complex\nrelationships between datasets, models, software, and scientific publications.\n","authors":["Kanishka Silva","Marcel R. Ackermann","Heike Fliegl","Genet-Asefa Gesese","Fidan Limani","Philipp Mayr","Peter Mutschke","Allard Oelen","Muhammad Asif Suryani","Sharmila Upadhyaya","Benjamin Zapilko","Harald Sack","Stefan Dietze"],"pdf_url":"https://arxiv.org/pdf/2508.02300v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02266v1","updated":"2025-08-04T10:16:48Z","published":"2025-08-04T10:16:48Z","title":"Voronoi Diagram Encoded Hashing","summary":"  The goal of learning to hash (L2H) is to derive data-dependent hash functions\nfrom a given data distribution in order to map data from the input space to a\nbinary coding space. Despite the success of L2H, two observations have cast\ndoubt on the source of the power of L2H, i.e., learning. First, a recent study\nshows that even using a version of locality sensitive hashing functions without\nlearning achieves binary representations that have comparable accuracy as those\nof L2H, but with less time cost. Second, existing L2H methods are constrained\nto three types of hash functions: thresholding, hyperspheres, and hyperplanes\nonly. In this paper, we unveil the potential of Voronoi diagrams in hashing.\nVoronoi diagram is a suitable candidate because of its three properties. This\ndiscovery has led us to propose a simple and efficient no-learning binary\nhashing method, called Voronoi Diagram Encoded Hashing (VDeH), which constructs\na set of hash functions through a data-dependent similarity measure and\nproduces independent binary bits through encoded hashing. We demonstrate\nthrough experiments on several benchmark datasets that VDeH achieves superior\nperformance and lower computational cost compared to existing state-of-the-art\nmethods under the same bit length.\n","authors":["Yang Xu","Kai Ming Ting"],"pdf_url":"https://arxiv.org/pdf/2508.02266v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02243v1","updated":"2025-08-04T09:43:54Z","published":"2025-08-04T09:43:54Z","title":"I2CR: Intra- and Inter-modal Collaborative Reflections for Multimodal\n  Entity Linking","summary":"  Multimodal entity linking plays a crucial role in a wide range of\napplications. Recent advances in large language model-based methods have become\nthe dominant paradigm for this task, effectively leveraging both textual and\nvisual modalities to enhance performance. Despite their success, these methods\nstill face two challenges, including unnecessary incorporation of image data in\ncertain scenarios and the reliance only on a one-time extraction of visual\nfeatures, which can undermine their effectiveness and accuracy. To address\nthese challenges, we propose a novel LLM-based framework for the multimodal\nentity linking task, called Intra- and Inter-modal Collaborative Reflections.\nThis framework prioritizes leveraging text information to address the task.\nWhen text alone is insufficient to link the correct entity through intra- and\ninter-modality evaluations, it employs a multi-round iterative strategy that\nintegrates key visual clues from various aspects of the image to support\nreasoning and enhance matching accuracy. Extensive experiments on three widely\nused public datasets demonstrate that our framework consistently outperforms\ncurrent state-of-the-art methods in the task, achieving improvements of 3.2%,\n5.1%, and 1.6%, respectively. Our code is available at\nhttps://github.com/ziyan-xiaoyu/I2CR/.\n","authors":["Ziyan Liu","Junwen Li","Kaiwen Li","Tong Ruan","Chao Wang","Xinyan He","Zongyu Wang","Xuezhi Cao","Jingping Liu"],"pdf_url":"https://arxiv.org/pdf/2508.02243v1.pdf","comment":"10 pages, 6 figures, accepted by ACMMM 2025"},{"id":"http://arxiv.org/abs/2508.02242v1","updated":"2025-08-04T09:43:21Z","published":"2025-08-04T09:43:21Z","title":"From Generation to Consumption: Personalized List Value Estimation for\n  Re-ranking","summary":"  Re-ranking is critical in recommender systems for optimizing the order of\nrecommendation lists, thus improving user satisfaction and platform revenue.\nMost existing methods follow a generator-evaluator paradigm, where the\nevaluator estimates the overall value of each candidate list. However, they\noften ignore the fact that users may exit before consuming the full list,\nleading to a mismatch between estimated generation value and actual consumption\nvalue. To bridge this gap, we propose CAVE, a personalized Consumption-Aware\nlist Value Estimation framework. CAVE formulates the list value as the\nexpectation over sub-list values, weighted by user-specific exit probabilities\nat each position. The exit probability is decomposed into an interest-driven\ncomponent and a stochastic component, the latter modeled via a Weibull\ndistribution to capture random external factors such as fatigue. By jointly\nmodeling sub-list values and user exit behavior, CAVE yields a more faithful\nestimate of actual list consumption value. We further contribute three\nlarge-scale real-world list-wise benchmarks from the Kuaishou platform, varying\nin size and user activity patterns. Extensive experiments on these benchmarks,\ntwo Amazon datasets, and online A/B testing on Kuaishou show that CAVE\nconsistently outperforms strong baselines, highlighting the benefit of\nexplicitly modeling user exits in re-ranking.\n","authors":["Kaike Zhang","Xiaobei Wang","Xiaoyu Liu","Shuchang Liu","Hailan Yang","Xiang Li","Fei Sun","Qi Cao"],"pdf_url":"https://arxiv.org/pdf/2508.02242v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02222v1","updated":"2025-08-04T09:12:45Z","published":"2025-08-04T09:12:45Z","title":"FinCPRG: A Bidirectional Generation Pipeline for Hierarchical Queries\n  and Rich Relevance in Financial Chinese Passage Retrieval","summary":"  In recent years, large language models (LLMs) have demonstrated significant\npotential in constructing passage retrieval datasets. However, existing methods\nstill face limitations in expressing cross-doc query needs and controlling\nannotation quality. To address these issues, this paper proposes a\nbidirectional generation pipeline, which aims to generate 3-level hierarchical\nqueries for both intra-doc and cross-doc scenarios and mine additional\nrelevance labels on top of direct mapping annotation. The pipeline introduces\ntwo query generation methods: bottom-up from single-doc text and top-down from\nmulti-doc titles. The bottom-up method uses LLMs to disassemble and generate\nstructured queries at both sentence-level and passage-level simultaneously from\nintra-doc passages. The top-down approach incorporates three key financial\nelements--industry, topic, and time--to divide report titles into clusters and\nprompts LLMs to generate topic-level queries from each cluster. For relevance\nannotation, our pipeline not only relies on direct mapping annotation from the\ngeneration relationship but also implements an indirect positives mining method\nto enrich the relevant query-passage pairs. Using this pipeline, we constructed\na Financial Passage Retrieval Generated dataset (FinCPRG) from almost 1.3k\nChinese financial research reports, which includes hierarchical queries and\nrich relevance labels. Through evaluations of mined relevance labels,\nbenchmarking and training experiments, we assessed the quality of FinCPRG and\nvalidated its effectiveness as a passage retrieval dataset for both training\nand benchmarking.\n","authors":["Xuan Xu","Beilin Chu","Qinhong Lin","Yixiao Zhong","Fufang Wen","Jiaqi Liu","Binjie Fei","Yu Li","Zhongliang Yang","Linna Zhou"],"pdf_url":"https://arxiv.org/pdf/2508.02222v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02096v1","updated":"2025-08-04T06:07:33Z","published":"2025-08-04T06:07:33Z","title":"Evaluating User Experience in Conversational Recommender Systems: A\n  Systematic Review Across Classical and LLM-Powered Approaches","summary":"  Conversational Recommender Systems (CRSs) are receiving growing research\nattention across domains, yet their user experience (UX) evaluation remains\nlimited. Existing reviews largely overlook empirical UX studies, particularly\nin adaptive and large language model (LLM)-based CRSs. To address this gap, we\nconducted a systematic review following PRISMA guidelines, synthesising 23\nempirical studies published between 2017 and 2025. We analysed how UX has been\nconceptualised, measured, and shaped by domain, adaptivity, and LLM.\n  Our findings reveal persistent limitations: post hoc surveys dominate,\nturn-level affective UX constructs are rarely assessed, and adaptive behaviours\nare seldom linked to UX outcomes. LLM-based CRSs introduce further challenges,\nincluding epistemic opacity and verbosity, yet evaluations infrequently address\nthese issues. We contribute a structured synthesis of UX metrics, a comparative\nanalysis of adaptive and nonadaptive systems, and a forward-looking agenda for\nLLM-aware UX evaluation. These findings support the development of more\ntransparent, engaging, and user-centred CRS evaluation practices.\n","authors":["Raj Mahmud","Yufeng Wu","Abdullah Bin Sawad","Shlomo Berkovsky","Mukesh Prasad","A. Baki Kocaballi"],"pdf_url":"https://arxiv.org/pdf/2508.02096v1.pdf","comment":"Accepted at OZCHI 2025. 23 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2508.02050v1","updated":"2025-08-04T04:33:26Z","published":"2025-08-04T04:33:26Z","title":"Why Generate When You Can Transform? Unleashing Generative Attention for\n  Dynamic Recommendation","summary":"  Sequential Recommendation (SR) focuses on personalizing user experiences by\npredicting future preferences based on historical interactions. Transformer\nmodels, with their attention mechanisms, have become the dominant architecture\nin SR tasks due to their ability to capture dependencies in user behavior\nsequences. However, traditional attention mechanisms, where attention weights\nare computed through query-key transformations, are inherently linear and\ndeterministic. This fixed approach limits their ability to account for the\ndynamic and non-linear nature of user preferences, leading to challenges in\ncapturing evolving interests and subtle behavioral patterns. Given that\ngenerative models excel at capturing non-linearity and probabilistic\nvariability, we argue that generating attention distributions offers a more\nflexible and expressive alternative compared to traditional attention\nmechanisms. To support this claim, we present a theoretical proof demonstrating\nthat generative attention mechanisms offer greater expressiveness and\nstochasticity than traditional deterministic approaches. Building upon this\ntheoretical foundation, we introduce two generative attention models for SR,\neach grounded in the principles of Variational Autoencoders (VAE) and Diffusion\nModels (DMs), respectively. These models are designed specifically to generate\nadaptive attention distributions that better align with variable user\npreferences. Extensive experiments on real-world datasets show our models\nsignificantly outperform state-of-the-art in both accuracy and diversity.\n","authors":["Yuli Liu","Wenjun Kong","Cheng Luo","Weizhi Ma"],"pdf_url":"https://arxiv.org/pdf/2508.02050v1.pdf","comment":"Accepted at ACMMM 2025"},{"id":"http://arxiv.org/abs/2508.02020v1","updated":"2025-08-04T03:30:26Z","published":"2025-08-04T03:30:26Z","title":"Evaluating Position Bias in Large Language Model Recommendations","summary":"  Large Language Models (LLMs) are being increasingly explored as\ngeneral-purpose tools for recommendation tasks, enabling zero-shot and\ninstruction-following capabilities without the need for task-specific training.\nWhile the research community is enthusiastically embracing LLMs, there are\nimportant caveats to directly adapting them for recommendation tasks. In this\npaper, we show that LLM-based recommendation models suffer from position bias,\nwhere the order of candidate items in a prompt can disproportionately influence\nthe recommendations produced by LLMs. First, we analyse the position bias of\nLLM-based recommendations on real-world datasets, where results uncover\nsystemic biases of LLMs with high sensitivity to input orders. Furthermore, we\nintroduce a new prompting strategy to mitigate the position bias of LLM\nrecommendation models called Ranking via Iterative SElection (RISE). We compare\nour proposed method against various baselines on key benchmark datasets.\nExperiment results show that our method reduces sensitivity to input ordering\nand improves stability without requiring model fine-tuning or post-processing.\n","authors":["Ethan Bito","Yongli Ren","Estrid He"],"pdf_url":"https://arxiv.org/pdf/2508.02020v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01987v1","updated":"2025-08-04T01:54:32Z","published":"2025-08-04T01:54:32Z","title":"Controllable and Stealthy Shilling Attacks via Dispersive Latent\n  Diffusion","summary":"  Recommender systems (RSs) are now fundamental to various online platforms,\nbut their dependence on user-contributed data leaves them vulnerable to\nshilling attacks that can manipulate item rankings by injecting fake users.\nAlthough widely studied, most existing attack models fail to meet two critical\nobjectives simultaneously: achieving strong adversarial promotion of target\nitems while maintaining realistic behavior to evade detection. As a result, the\ntrue severity of shilling threats that manage to reconcile the two objectives\nremains underappreciated. To expose this overlooked vulnerability, we present\nDLDA, a diffusion-based attack framework that can generate highly effective yet\nindistinguishable fake users by enabling fine-grained control over target\npromotion. Specifically, DLDA operates in a pre-aligned collaborative embedding\nspace, where it employs a conditional latent diffusion process to iteratively\nsynthesize fake user profiles with precise target item control. To evade\ndetection, DLDA introduces a dispersive regularization mechanism that promotes\nvariability and realism in generated behavioral patterns. Extensive experiments\non three real-world datasets and five popular RS models demonstrate that,\ncompared to prior attacks, DLDA consistently achieves stronger item promotion\nwhile remaining harder to detect. These results highlight that modern RSs are\nmore vulnerable than previously recognized, underscoring the urgent need for\nmore robust defenses.\n","authors":["Shutong Qiao","Wei Yuan","Junliang Yu","Tong Chen","Quoc Viet Hung Nguyen","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2508.01987v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02945v1","updated":"2025-08-04T23:02:01Z","published":"2025-08-04T23:02:01Z","title":"LLM-based IR-system for Bank Supervisors","summary":"  Bank supervisors face the complex task of ensuring that new measures are\nconsistently aligned with historical precedents. To address this challenge, we\nintroduce a novel Information Retrieval (IR) System tailored to assist\nsupervisors in drafting both consistent and effective measures. This system\ningests findings from on-site investigations. It then retrieves the most\nrelevant historical findings and their associated measures from a comprehensive\ndatabase, providing a solid basis for supervisors to write well-informed\nmeasures for new findings. Utilizing a blend of lexical, semantic, and Capital\nRequirements Regulation (CRR) fuzzy set matching techniques, the IR system\nensures the retrieval of findings that closely align with current cases. The\nperformance of this system, particularly in scenarios with partially labeled\ndata, is validated through a Monte Carlo methodology, showcasing its robustness\nand accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for\nfine-tuning, the final model achieves a Mean Average Precision (MAP@100) of\n0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those\nof both standalone lexical models such as BM25 and semantic BERT-like models.\n","authors":["Ilias Aarab"],"pdf_url":"https://arxiv.org/pdf/2508.02945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02929v1","updated":"2025-08-04T22:03:13Z","published":"2025-08-04T22:03:13Z","title":"Realizing Scaling Laws in Recommender Systems: A Foundation-Expert\n  Paradigm for Hyperscale Model Deployment","summary":"  While scaling laws promise significant performance gains for recommender\nsystems, efficiently deploying hyperscale models remains a major unsolved\nchallenge. In contrast to fields where FMs are already widely adopted such as\nnatural language processing and computer vision, progress in recommender\nsystems is hindered by unique challenges including the need to learn from\nonline streaming data under shifting data distributions, the need to adapt to\ndifferent recommendation surfaces with a wide diversity in their downstream\ntasks and their input distributions, and stringent latency and computational\nconstraints. To bridge this gap, we propose to leverage the Foundation-Expert\nParadigm: a framework designed for the development and deployment of hyperscale\nrecommendation FMs. In our approach, a central FM is trained on lifelong,\ncross-surface, multi-modal user data to learn generalizable knowledge. This\nknowledge is then efficiently transferred to various lightweight,\nsurface-specific ``expert\" models via target-aware embeddings, allowing them to\nadapt to local data distributions and optimization goals with minimal overhead.\nTo meet our training, inference and development needs, we built HyperCast, a\nproduction-grade infrastructure system that re-engineers training, serving,\nlogging and iteration to power this decoupled paradigm. Our approach is now\ndeployed at Meta serving tens of billions of user requests daily, demonstrating\nonline metric improvements over our previous one-stage production system while\nimproving developer velocity and maintaining infrastructure efficiency. To the\nbest of our knowledge, this work represents the first successful deployment of\na Foundation-Expert paradigm at this scale, offering a proven,\ncompute-efficient, and developer-friendly blueprint to realize the promise of\nscaling laws in recommender systems.\n","authors":["Dai Li","Kevin Course","Wei Li","Hongwei Li","Jie Hua","Yiqi Chen","Zhao Zhu","Rui Jian","Xuan Cao","Bi Xue","Yu Shi","Jing Qian","Kai Ren","Matt Ma","Qunshu Zhang","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2508.02929v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02841v1","updated":"2025-08-04T19:09:52Z","published":"2025-08-04T19:09:52Z","title":"A Multi-Agent System for Complex Reasoning in Radiology Visual Question\n  Answering","summary":"  Radiology visual question answering (RVQA) provides precise answers to\nquestions about chest X-ray images, alleviating radiologists' workload. While\nrecent methods based on multimodal large language models (MLLMs) and\nretrieval-augmented generation (RAG) have shown promising progress in RVQA,\nthey still face challenges in factual accuracy, hallucinations, and cross-modal\nmisalignment. We introduce a multi-agent system (MAS) designed to support\ncomplex reasoning in RVQA, with specialized agents for context understanding,\nmultimodal reasoning, and answer validation. We evaluate our system on a\nchallenging RVQA set curated via model disagreement filtering, comprising\nconsistently hard cases across multiple MLLMs. Extensive experiments\ndemonstrate the superiority and effectiveness of our system over strong MLLM\nbaselines, with a case study illustrating its reliability and interpretability.\nThis work highlights the potential of multi-agent approaches to support\nexplainable and trustworthy clinical AI applications that require complex\nreasoning.\n","authors":["Ziruo Yi","Jinyu Liu","Ting Xiao","Mark V. Albert"],"pdf_url":"https://arxiv.org/pdf/2508.02841v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02835v1","updated":"2025-08-04T19:03:52Z","published":"2025-08-04T19:03:52Z","title":"Defending Against Knowledge Poisoning Attacks During Retrieval-Augmented\n  Generation","summary":"  Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to\nboost the capabilities of large language models (LLMs) by incorporating\nexternal, up-to-date knowledge sources. However, this introduces a potential\nvulnerability to knowledge poisoning attacks, where attackers can compromise\nthe knowledge source to mislead the generation model. One such attack is the\nPoisonedRAG in which the injected adversarial texts steer the model to generate\nan attacker-chosen response to a target question. In this work, we propose\nnovel defense methods, FilterRAG and ML-FilterRAG, to mitigate the PoisonedRAG\nattack. First, we propose a new property to uncover distinct properties to\ndifferentiate between adversarial and clean texts in the knowledge data source.\nNext, we employ this property to filter out adversarial texts from clean ones\nin the design of our proposed approaches. Evaluation of these methods using\nbenchmark datasets demonstrate their effectiveness, with performances close to\nthose of the original RAG systems.\n","authors":["Kennedy Edemacu","Vinay M. Shashidhar","Micheal Tuape","Dan Abudu","Beakcheol Jang","Jong Wook Kim"],"pdf_url":"https://arxiv.org/pdf/2508.02835v1.pdf","comment":"Preprint for Submission"},{"id":"http://arxiv.org/abs/2508.02296v1","updated":"2025-08-04T11:04:54Z","published":"2025-08-04T11:04:54Z","title":"Simple Methods Defend RAG Systems Well Against Real-World Attacks","summary":"  Ensuring safety and in-domain responses for Retrieval-Augmented Generation\n(RAG) systems is paramount in safety-critical applications, yet remains a\nsignificant challenge. To address this, we evaluate four methodologies for\nOut-Of-Domain (OOD) query detection: GPT-4o, regression-based, Principal\nComponent Analysis (PCA)-based, and Neural Collapse (NC), to ensure the RAG\nsystem only responds to queries confined to the system's knowledge base.\nSpecifically, our evaluation explores two novel dimensionality reduction and\nfeature separation strategies: \\textit{PCA}, where top components are selected\nusing explained variance or OOD separability, and an adaptation of\n\\textit{Neural Collapse Feature Separation}. We validate our approach on\nstandard datasets (StackExchange and MSMARCO) and real-world applications\n(Substance Use and COVID-19), including tests against LLM-simulated and actual\nattacks on a COVID-19 vaccine chatbot. Through human and LLM-based evaluations\nof response correctness and relevance, we confirm that an external OOD detector\nis crucial for maintaining response relevance.\n","authors":["Ilias Triantafyllopoulos","Renyi Qu","Salvatore Giorgi","Brenda Curtis","Lyle H. Ungar","João Sedoc"],"pdf_url":"https://arxiv.org/pdf/2508.02296v1.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2508.02668v1","updated":"2025-08-04T17:58:22Z","published":"2025-08-04T17:58:22Z","title":"LOST: Low-rank and Sparse Pre-training for Large Language Models","summary":"  While large language models (LLMs) have achieved remarkable performance\nacross a wide range of tasks, their massive scale incurs prohibitive\ncomputational and memory costs for pre-training from scratch. Recent studies\nhave investigated the use of low-rank parameterization as a means of reducing\nmodel size and training cost. In this context, sparsity is often employed as a\ncomplementary technique to recover important information lost in low-rank\ncompression by capturing salient features in the residual space. However,\nexisting approaches typically combine low-rank and sparse components in a\nsimplistic or ad hoc manner, often resulting in undesirable performance\ndegradation compared to full-rank training. In this paper, we propose\n\\textbf{LO}w-rank and \\textbf{S}parse pre-\\textbf{T}raining (\\textbf{LOST}) for\nLLMs, a novel method that ingeniously integrates low-rank and sparse structures\nto enable effective training of LLMs from scratch under strict efficiency\nconstraints. LOST applies singular value decomposition to weight matrices,\npreserving the dominant low-rank components, while allocating the remaining\nsingular values to construct channel-wise sparse components to complement the\nexpressiveness of low-rank training. We evaluate LOST on LLM pretraining\nranging from 60M to 7B parameters. Our experiments show that LOST achieves\ncompetitive or superior performance compared to full-rank models, while\nsignificantly reducing both memory and compute overhead. Moreover, Code is\navailable at\n\\href{https://github.com/JiaxiLi1/LOST-Low-rank-and-Sparse-Training-for-Large-Language-Models}{LOST\nRepo}\n","authors":["Jiaxi Li","Lu Yin","Li Shen","Jinjin Xu","Liwu Xu","Tianjin Huang","Wenwu Wang","Shiwei Liu","Xilu Wang"],"pdf_url":"https://arxiv.org/pdf/2508.02668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02643v1","updated":"2025-08-04T17:33:36Z","published":"2025-08-04T17:33:36Z","title":"CAK: Emergent Audio Effects from Minimal Deep Learning","summary":"  We demonstrate that a single 3x3 convolutional kernel can produce emergent\naudio effects when trained on 200 samples from a personalized corpus. We\nachieve this through two key techniques: (1) Conditioning Aware Kernels (CAK),\nwhere output = input + (learned_pattern x control), with a soft-gate mechanism\nsupporting identity preservation at zero control; and (2) AuGAN (Audit GAN),\nwhich reframes adversarial training from \"is this real?\" to \"did you apply the\nrequested value?\" Rather than learning to generate or detect forgeries, our\nnetworks cooperate to verify control application, discovering unique\ntransformations. The learned kernel exhibits a diagonal structure creating\nfrequency-dependent temporal shifts that are capable of producing musical\neffects based on input characteristics. Our results show the potential of\nadversarial training to discover audio transformations from minimal data,\nenabling new approaches to effect design.\n","authors":["Austin Rockman"],"pdf_url":"https://arxiv.org/pdf/2508.02643v1.pdf","comment":"8 pages, 3 figures, code and other resources at\n  https://github.com/gloame-ai/cak-audio/tree/main/cak-audio"},{"id":"http://arxiv.org/abs/2508.02641v1","updated":"2025-08-04T17:25:55Z","published":"2025-08-04T17:25:55Z","title":"FastCSP: Accelerated Molecular Crystal Structure Prediction with\n  Universal Model for Atoms","summary":"  Crystal Structure Prediction (CSP) of molecular crystals plays a central role\nin applications, such as pharmaceuticals and organic electronics. CSP is\nchallenging and computationally expensive due to the need to explore a large\nsearch space with sufficient accuracy to capture energy differences of a few\nkJ/mol between polymorphs. Dispersion-inclusive density functional theory (DFT)\nprovides the required accuracy but its computational cost is impractical for a\nlarge number of putative structures. We introduce FastCSP, an open-source,\nhigh-throughput CSP workflow based on machine learning interatomic potentials\n(MLIPs). FastCSP combines random structure generation using Genarris 3.0 with\ngeometry relaxation and free energy calculations powered entirely by the\nUniversal Model for Atoms (UMA) MLIP. We benchmark FastCSP on a curated set of\n28 mostly rigid molecules, demonstrating that our workflow consistently\ngenerates known experimental structures and ranks them within 5 kJ/mol per\nmolecule of the global minimum. Our results demonstrate that universal MLIPs\ncan be used across diverse compounds without requiring system-specific tuning.\nMoreover, the speed and accuracy afforded by UMA eliminate the need for\nclassical force fields in the early stages of CSP and for final re-ranking with\nDFT. The open-source release of the entire FastCSP workflow significantly\nlowers the barrier to accessing CSP. CSP results for a single system can be\nobtained within hours on tens of modern GPUs, making high-throughput crystal\nstructure prediction feasible for a broad range of scientific applications.\n","authors":["Vahe Gharakhanyan","Yi Yang","Luis Barroso-Luque","Muhammed Shuaibi","Daniel S. Levine","Kyle Michel","Viachaslau Bernat","Misko Dzamba","Xiang Fu","Meng Gao","Xingyu Liu","Keian Noori","Lafe J. Purvis","Tingling Rao","Brandon M. Wood","Ammar Rizvi","Matt Uyttendaele","Andrew J. Ouderkirk","Chiara Daraio","C. Lawrence Zitnick","Arman Boromand","Noa Marom","Zachary W. Ulissi","Anuroop Sriram"],"pdf_url":"https://arxiv.org/pdf/2508.02641v1.pdf","comment":"52 pages, 19 figures, 6 tables"},{"id":"http://arxiv.org/abs/2508.02637v1","updated":"2025-08-04T17:23:00Z","published":"2025-08-04T17:23:00Z","title":"Instance-Optimal Uniformity Testing and Tracking","summary":"  In the uniformity testing task, an algorithm is provided with samples from an\nunknown probability distribution over a (known) finite domain, and must decide\nwhether it is the uniform distribution, or, alternatively, if its total\nvariation distance from uniform exceeds some input distance parameter. This\nquestion has received a significant amount of interest and its complexity is,\nby now, fully settled. Yet, we argue that it fails to capture many scenarios of\ninterest, and that its very definition as a gap problem in terms of a\nprespecified distance may lead to suboptimal performance.\n  To address these shortcomings, we introduce the problem of uniformity\ntracking, whereby an algorithm is required to detect deviations from uniformity\n(however they may manifest themselves) using as few samples as possible, and be\ncompetitive against an optimal algorithm knowing the distribution profile in\nhindsight. Our main contribution is a\n$\\operatorname{polylog}(\\operatorname{opt})$-competitive uniformity tracking\nalgorithm. We obtain this result by leveraging new structural results on\nPoisson mixtures, which we believe to be of independent interest.\n","authors":["Guy Blanc","Clément L. Canonne","Erik Waingarten"],"pdf_url":"https://arxiv.org/pdf/2508.02637v1.pdf","comment":"FOCS 2025, to appear"},{"id":"http://arxiv.org/abs/2508.02634v1","updated":"2025-08-04T17:20:50Z","published":"2025-08-04T17:20:50Z","title":"Actionable Counterfactual Explanations Using Bayesian Networks and Path\n  Planning with Applications to Environmental Quality Improvement","summary":"  Counterfactual explanations study what should have changed in order to get an\nalternative result, enabling end-users to understand machine learning\nmechanisms with counterexamples. Actionability is defined as the ability to\ntransform the original case to be explained into a counterfactual one. We\ndevelop a method for actionable counterfactual explanations that, unlike\npredecessors, does not directly leverage training data. Rather, data is only\nused to learn a density estimator, creating a search landscape in which to\napply path planning algorithms to solve the problem and masking the endogenous\ndata, which can be sensitive or private. We put special focus on estimating the\ndata density using Bayesian networks, demonstrating how their enhanced\ninterpretability is useful in high-stakes scenarios in which fairness is\nraising concern. Using a synthetic benchmark comprised of 15 datasets, our\nproposal finds more actionable and simpler counterfactuals than the current\nstate-of-the-art algorithms. We also test our algorithm with a real-world\nEnvironmental Protection Agency dataset, facilitating a more efficient and\nequitable study of policies to improve the quality of life in United States of\nAmerica counties. Our proposal captures the interaction of variables, ensuring\nequity in decisions, as policies to improve certain domains of study (air,\nwater quality, etc.) can be detrimental in others. In particular, the\nsociodemographic domain is often involved, where we find important variables\nrelated to the ongoing housing crisis that can potentially have a severe\nnegative impact on communities.\n","authors":["Enrique Valero-Leal","Pedro Larrañaga","Concha Bielza"],"pdf_url":"https://arxiv.org/pdf/2508.02634v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02627v1","updated":"2025-08-04T17:15:57Z","published":"2025-08-04T17:15:57Z","title":"Tensor Dynamic Mode Decomposition","summary":"  Dynamic mode decomposition (DMD) has become a powerful data-driven method for\nanalyzing the spatiotemporal dynamics of complex, high-dimensional systems.\nHowever, conventional DMD methods are limited to matrix-based formulations,\nwhich might be inefficient or inadequate for modeling inherently\nmultidimensional data including images, videos, and higher-order networks. In\nthis letter, we propose tensor dynamic mode decomposition (TDMD), a novel\nextension of DMD to third-order tensors based on the recently developed\nT-product framework. By incorporating tensor factorization techniques, TDMD\nachieves more efficient computation and better preservation of spatial and\ntemporal structures in multiway data for tasks such as state reconstruction and\ndynamic component separation, compared to standard DMD with data flattening. We\ndemonstrate the effectiveness of TDMD on both synthetic and real-world\ndatasets.\n","authors":["Ziqin He","Mengqi Hu","Yifei Lou","Can Chen"],"pdf_url":"https://arxiv.org/pdf/2508.02627v1.pdf","comment":"6 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2508.02625v1","updated":"2025-08-04T17:13:45Z","published":"2025-08-04T17:13:45Z","title":"AutoML-Med: A Framework for Automated Machine Learning in Medical\n  Tabular Data","summary":"  Medical datasets are typically affected by issues such as missing values,\nclass imbalance, a heterogeneous feature types, and a high number of features\nversus a relatively small number of samples, preventing machine learning models\nfrom obtaining proper results in classification and regression tasks. This\npaper introduces AutoML-Med, an Automated Machine Learning tool specifically\ndesigned to address these challenges, minimizing user intervention and\nidentifying the optimal combination of preprocessing techniques and predictive\nmodels. AutoML-Med's architecture incorporates Latin Hypercube Sampling (LHS)\nfor exploring preprocessing methods, trains models using selected metrics, and\nutilizes Partial Rank Correlation Coefficient (PRCC) for fine-tuned\noptimization of the most influential preprocessing steps. Experimental results\ndemonstrate AutoML-Med's effectiveness in two different clinical settings,\nachieving higher balanced accuracy and sensitivity, which are crucial for\nidentifying at-risk patients, compared to other state-of-the-art tools.\nAutoML-Med's ability to improve prediction results, especially in medical\ndatasets with sparse data and class imbalance, highlights its potential to\nstreamline Machine Learning applications in healthcare.\n","authors":["Riccardo Francia","Maurizio Leone","Giorgio Leonardi","Stefania Montani","Marzio Pennisi","Manuel Striani","Sandra D'Alfonso"],"pdf_url":"https://arxiv.org/pdf/2508.02625v1.pdf","comment":"8 pages, preprint for conference"},{"id":"http://arxiv.org/abs/2508.02621v1","updated":"2025-08-04T17:08:47Z","published":"2025-08-04T17:08:47Z","title":"HealthFlow: A Self-Evolving AI Agent with Meta Planning for Autonomous\n  Healthcare Research","summary":"  The efficacy of AI agents in healthcare research is hindered by their\nreliance on static, predefined strategies. This creates a critical limitation:\nagents can become better tool-users but cannot learn to become better strategic\nplanners, a crucial skill for complex domains like healthcare. We introduce\nHealthFlow, a self-evolving AI agent that overcomes this limitation through a\nnovel meta-level evolution mechanism. HealthFlow autonomously refines its own\nhigh-level problem-solving policies by distilling procedural successes and\nfailures into a durable, strategic knowledge base. To anchor our research and\nfacilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark\nfeaturing complex, realistic health data analysis tasks derived from\npeer-reviewed clinical research. Our comprehensive experiments demonstrate that\nHealthFlow's self-evolving approach significantly outperforms state-of-the-art\nagent frameworks. This work marks a necessary shift from building better\ntool-users to designing smarter, self-evolving task-managers, paving the way\nfor more autonomous and effective AI for scientific discovery.\n","authors":["Yinghao Zhu","Yifan Qi","Zixiang Wang","Lei Gu","Dehao Sui","Haoran Hu","Xichen Zhang","Ziyi He","Liantao Ma","Lequan Yu"],"pdf_url":"https://arxiv.org/pdf/2508.02621v1.pdf","comment":"Code: https://github.com/yhzhu99/HealthFlow"},{"id":"http://arxiv.org/abs/2508.02616v1","updated":"2025-08-04T17:05:55Z","published":"2025-08-04T17:05:55Z","title":"DeepKoopFormer: A Koopman Enhanced Transformer Based Architecture for\n  Time Series Forecasting","summary":"  Time series forecasting plays a vital role across scientific, industrial, and\nenvironmental domains, especially when dealing with high-dimensional and\nnonlinear systems. While Transformer-based models have recently achieved\nstate-of-the-art performance in long-range forecasting, they often suffer from\ninterpretability issues and instability in the presence of noise or dynamical\nuncertainty. In this work, we propose DeepKoopFormer, a principled forecasting\nframework that combines the representational power of Transformers with the\ntheoretical rigor of Koopman operator theory. Our model features a modular\nencoder-propagator-decoder structure, where temporal dynamics are learned via a\nspectrally constrained, linear Koopman operator in a latent space. We impose\nstructural guarantees-such as bounded spectral radius, Lyapunov based energy\nregularization, and orthogonal parameterization to ensure stability and\ninterpretability. Comprehensive evaluations are conducted on both synthetic\ndynamical systems, real-world climate dataset (wind speed and surface\npressure), financial time series (cryptocurrency), and electricity generation\ndataset using the Python package that is prepared for this purpose. Across all\nexperiments, DeepKoopFormer consistently outperforms standard LSTM and baseline\nTransformer models in terms of accuracy, robustness to noise, and long-term\nforecasting stability. These results establish DeepKoopFormer as a flexible,\ninterpretable, and robust framework for forecasting in high dimensional and\ndynamical settings.\n","authors":["Ali Forootani","Mohammad Khosravi","Masoud Barati"],"pdf_url":"https://arxiv.org/pdf/2508.02616v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02609v1","updated":"2025-08-04T17:00:53Z","published":"2025-08-04T17:00:53Z","title":"Entity Representation Learning Through Onsite-Offsite Graph for\n  Pinterset Ads","summary":"  Graph Neural Networks (GNN) have been extensively applied to industry\nrecommendation systems, as seen in models like GraphSage\\cite{GraphSage},\nTwHIM\\cite{TwHIM}, LiGNN\\cite{LiGNN} etc. In these works, graphs were\nconstructed based on users' activities on the platforms, and various graph\nmodels were developed to effectively learn node embeddings. In addition to\nusers' onsite activities, their offsite conversions are crucial for Ads models\nto capture their shopping interest. To better leverage offsite conversion data\nand explore the connection between onsite and offsite activities, we\nconstructed a large-scale heterogeneous graph based on users' onsite ad\ninteractions and opt-in offsite conversion activities. Furthermore, we\nintroduced TransRA (TransR\\cite{TransR} with Anchors), a novel Knowledge Graph\nEmbedding (KGE) model, to more efficiently integrate graph embeddings into Ads\nranking models. However, our Ads ranking models initially struggled to directly\nincorporate Knowledge Graph Embeddings (KGE), and only modest gains were\nobserved during offline experiments. To address this challenge, we employed the\nLarge ID Embedding Table technique and innovated an attention based KGE\nfinetuning approach within the Ads ranking models. As a result, we observed a\nsignificant AUC lift in Click-Through Rate (CTR) and Conversion Rate (CVR)\nprediction models. Moreover, this framework has been deployed in Pinterest's\nAds Engagement Model and contributed to $2.69\\%$ CTR lift and $1.34\\%$ CPC\nreduction. We believe the techniques presented in this paper can be leveraged\nby other large-scale industrial models.\n","authors":["Jiayin Jin","Zhimeng Pan","Yang Tang","Jiarui Feng","Kungang Li","Chongyuan Xiang","Jiacheng Li","Runze Su","Siping Ji","Han Sun","Ling Leng","Prathibha Deshikachar"],"pdf_url":"https://arxiv.org/pdf/2508.02609v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.05430v2","updated":"2025-08-04T16:56:32Z","published":"2024-12-06T21:23:35Z","title":"DART-Eval: A Comprehensive DNA Language Model Evaluation Benchmark on\n  Regulatory DNA","summary":"  Recent advances in self-supervised models for natural language, vision, and\nprotein sequences have inspired the development of large genomic DNA language\nmodels (DNALMs). These models aim to learn generalizable representations of\ndiverse DNA elements, potentially enabling various genomic prediction,\ninterpretation and design tasks. Despite their potential, existing benchmarks\ndo not adequately assess the capabilities of DNALMs on key downstream\napplications involving an important class of non-coding DNA elements critical\nfor regulating gene activity. In this study, we introduce DART-Eval, a suite of\nrepresentative benchmarks specifically focused on regulatory DNA to evaluate\nmodel performance across zero-shot, probed, and fine-tuned scenarios against\ncontemporary ab initio models as baselines. Our benchmarks target biologically\nmeaningful downstream tasks such as functional sequence feature discovery,\npredicting cell-type specific regulatory activity, and counterfactual\nprediction of the impacts of genetic variants. We find that current DNALMs\nexhibit inconsistent performance and do not offer compelling gains over\nalternative baseline models for most tasks, while requiring significantly more\ncomputational resources. We discuss potentially promising modeling, data\ncuration, and evaluation strategies for the next generation of DNALMs. Our code\nis available at https://github.com/kundajelab/DART-Eval.\n","authors":["Aman Patel","Arpita Singhal","Austin Wang","Anusri Pampari","Maya Kasowski","Anshul Kundaje"],"pdf_url":"https://arxiv.org/pdf/2412.05430v2.pdf","comment":"NeurIPS Datasets and Benchmarks 2024"},{"id":"http://arxiv.org/abs/2508.02602v1","updated":"2025-08-04T16:56:11Z","published":"2025-08-04T16:56:11Z","title":"Trustworthy scientific inference for inverse problems with generative\n  models","summary":"  Generative artificial intelligence (AI) excels at producing complex data\nstructures (text, images, videos) by learning patterns from training examples.\nAcross scientific disciplines, researchers are now applying generative models\nto ``inverse problems'' to infer hidden parameters from observed data. While\nthese methods can handle intractable models and large-scale studies, they can\nalso produce biased or overconfident conclusions. We present a solution with\nFrequentist-Bayes (FreB), a mathematically rigorous protocol that reshapes\nAI-generated probability distributions into confidence regions that\nconsistently include true parameters with the expected probability, while\nachieving minimum size when training and target data align. We demonstrate\nFreB's effectiveness by tackling diverse case studies in the physical sciences:\nidentifying unknown sources under dataset shift, reconciling competing\ntheoretical models, and mitigating selection bias and systematics in\nobservational studies. By providing validity guarantees with interpretable\ndiagnostics, FreB enables trustworthy scientific inference across fields where\ndirect likelihood evaluation remains impossible or prohibitively expensive.\n","authors":["James Carzon","Luca Masserano","Joshua D. Ingram","Alex Shen","Antonio Carlos Herling Ribeiro Junior","Tommaso Dorigo","Michele Doro","Joshua S. Speagle","Rafael Izbicki","Ann B. Lee"],"pdf_url":"https://arxiv.org/pdf/2508.02602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02600v1","updated":"2025-08-04T16:55:02Z","published":"2025-08-04T16:55:02Z","title":"Adaptive Riemannian Graph Neural Networks","summary":"  Graph data often exhibits complex geometric heterogeneity, where structures\nwith varying local curvature, such as tree-like hierarchies and dense\ncommunities, coexist within a single network. Existing geometric GNNs, which\nembed graphs into single fixed-curvature manifolds or discrete product spaces,\nstruggle to capture this diversity. We introduce Adaptive Riemannian Graph\nNeural Networks (ARGNN), a novel framework that learns a continuous and\nanisotropic Riemannian metric tensor field over the graph. It allows each node\nto determine its optimal local geometry, enabling the model to fluidly adapt to\nthe graph's structural landscape. Our core innovation is an efficient\nparameterization of the node-wise metric tensor, specializing to a learnable\ndiagonal form that captures directional geometric information while maintaining\ncomputational tractability. To ensure geometric regularity and stable training,\nwe integrate a Ricci flow-inspired regularization that smooths the learned\nmanifold. Theoretically, we establish the rigorous geometric evolution\nconvergence guarantee for ARGNN and provide a continuous generalization that\nunifies prior fixed or mixed-curvature GNNs. Empirically, our method\ndemonstrates superior performance on both homophilic and heterophilic benchmark\ndatasets with the ability to capture diverse structures adaptively. Moreover,\nthe learned geometries both offer interpretable insights into the underlying\ngraph structure and empirically corroborate our theoretical analysis.\n","authors":["Xudong Wang","Tongxin Li","Chris Ding","Jicong Fan"],"pdf_url":"https://arxiv.org/pdf/2508.02600v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2508.02601v1","updated":"2025-08-04T16:55:02Z","published":"2025-08-04T16:55:02Z","title":"StructSynth: Leveraging LLMs for Structure-Aware Tabular Data Synthesis\n  in Low-Data Regimes","summary":"  The application of machine learning on tabular data in specialized domains is\nseverely limited by data scarcity. While generative models offer a solution,\ntraditional methods falter in low-data regimes, and recent Large Language\nModels (LLMs) often ignore the explicit dependency structure of tabular data,\nleading to low-fidelity synthetics. To address these limitations, we introduce\nStructSynth, a novel framework that integrates the generative power of LLMs\nwith robust structural control. StructSynth employs a two-stage architecture.\nFirst, it performs explicit structure discovery to learn a Directed Acyclic\nGraph (DAG) from the available data. Second, this learned structure serves as a\nhigh-fidelity blueprint to steer the LLM's generation process, forcing it to\nadhere to the learned feature dependencies and thereby ensuring the generated\ndata respects the underlying structure by design. Our extensive experiments\ndemonstrate that StructSynth produces synthetic data with significantly higher\nstructural integrity and downstream utility than state-of-the-art methods. It\nproves especially effective in challenging low-data scenarios, successfully\nnavigating the trade-off between privacy preservation and statistical fidelity.\n","authors":["Siyi Liu","Yujia Zheng","Yongqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.02601v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.22967v2","updated":"2025-08-04T16:54:44Z","published":"2025-06-28T17:57:58Z","title":"ActAlign: Zero-Shot Fine-Grained Video Classification via\n  Language-Guided Sequence Alignment","summary":"  We address the task of zero-shot video classification for extremely\nfine-grained actions (e.g., Windmill Dunk in basketball), where no video\nexamples or temporal annotations are available for unseen classes. While\nimage-language models (e.g., CLIP, SigLIP) show strong open-set recognition,\nthey lack temporal modeling needed for video understanding. We propose\nActAlign, a truly zero-shot, training-free method that formulates video\nclassification as a sequence alignment problem, preserving the generalization\nstrength of pretrained image-language models. For each class, a large language\nmodel (LLM) generates an ordered sequence of sub-actions, which we align with\nvideo frames using Dynamic Time Warping (DTW) in a shared embedding space.\nWithout any video-text supervision or fine-tuning, ActAlign achieves 30.5%\naccuracy on ActionAtlas--the most diverse benchmark of fine-grained actions\nacross multiple sports--where human performance is only 61.6%. ActAlign\noutperforms billion-parameter video-language models while using 8x fewer\nparameters. Our approach is model-agnostic and domain-general, demonstrating\nthat structured language priors combined with classical alignment methods can\nunlock the open-set recognition potential of image-language models for\nfine-grained video understanding.\n","authors":["Amir Aghdam","Vincent Tao Hu","Björn Ommer"],"pdf_url":"https://arxiv.org/pdf/2506.22967v2.pdf","comment":"Preprint manuscript - Project page:\n  https://amir-aghdam.github.io/act-align/"},{"id":"http://arxiv.org/abs/2508.02587v1","updated":"2025-08-04T16:43:09Z","published":"2025-08-04T16:43:09Z","title":"Parameter-Efficient Routed Fine-Tuning: Mixture-of-Experts Demands\n  Mixture of Adaptation Modules","summary":"  Mixture-of-Experts (MoE) benefits from a dynamic routing mechanism among\ntheir specialized experts, which existing Parameter- Efficient Fine-Tuning\n(PEFT) strategies fail to leverage. This motivates us to investigate whether\nadaptation modules themselves should incorporate routing mechanisms to align\nwith MoE's multi-expert architecture. We analyze dynamics of core components\nwhen applying PEFT to MoE language models and examine how different routing\nstrategies affect adaptation effectiveness. Extensive experiments adapting\nOLMoE-1B-7B and Mixtral-8x7B on various commonsense and math reasoning tasks\nvalidate the performance and efficiency of our routed approach. We identify the\noptimal configurations for different scenarios and provide empirical analyses\nwith practical insights to facilitate better PEFT and MoE applications.\n","authors":["Yilun Liu","Yunpu Ma","Yuetian Lu","Shuo Chen","Zifeng Ding","Volker Tresp"],"pdf_url":"https://arxiv.org/pdf/2508.02587v1.pdf","comment":"This paper is a preprint under review. arXiv admin note: text overlap\n  with arXiv:2411.08212"},{"id":"http://arxiv.org/abs/2508.02583v1","updated":"2025-08-04T16:39:24Z","published":"2025-08-04T16:39:24Z","title":"CAMA: Enhancing Mathematical Reasoning in Large Language Models with\n  Causal Knowledge","summary":"  Large Language Models (LLMs) have demonstrated strong performance across a\nwide range of tasks, yet they still struggle with complex mathematical\nreasoning, a challenge fundamentally rooted in deep structural dependencies. To\naddress this challenge, we propose \\textbf{CA}usal \\textbf{MA}thematician\n(\\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit,\nreusable mathematical structure. In the learning stage, CAMA first constructs\nthe \\textbf{M}athematical \\textbf{C}ausal \\textbf{G}raph (\\textbf{MCG}), a\nhigh-level representation of solution strategies, by combining LLM priors with\ncausal discovery algorithms applied to a corpus of question-solution pairs. The\nresulting MCG encodes essential knowledge points and their causal dependencies.\nTo better align the graph with downstream reasoning tasks, CAMA further refines\nthe MCG through iterative feedback derived from a selected subset of the\nquestion-solution pairs. In the reasoning stage, given a new question, CAMA\ndynamically extracts a task-relevant subgraph from the MCG, conditioned on both\nthe question content and the LLM's intermediate reasoning trace. This subgraph,\nwhich encodes the most pertinent knowledge points and their causal\ndependencies, is then injected back into the LLM to guide its reasoning\nprocess. Empirical results on real-world datasets show that CAMA significantly\nimproves LLM performance on challenging mathematical problems. Furthermore, our\nexperiments demonstrate that structured guidance consistently outperforms\nunstructured alternatives, and that incorporating asymmetric causal\nrelationships yields greater improvements than using symmetric associations\nalone.\n","authors":["Lei Zan","Keli Zhang","Ruichu Cai","Lujia Pan"],"pdf_url":"https://arxiv.org/pdf/2508.02583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.07927v3","updated":"2025-08-04T16:37:00Z","published":"2025-01-14T08:30:49Z","title":"Gandalf the Red: Adaptive Security for LLMs","summary":"  Current evaluations of defenses against prompt attacks in large language\nmodel (LLM) applications often overlook two critical factors: the dynamic\nnature of adversarial behavior and the usability penalties imposed on\nlegitimate users by restrictive defenses. We propose D-SEC (Dynamic Security\nUtility Threat Model), which explicitly separates attackers from legitimate\nusers, models multi-step interactions, and expresses the security-utility in an\noptimizable form. We further address the shortcomings in existing evaluations\nby introducing Gandalf, a crowd-sourced, gamified red-teaming platform designed\nto generate realistic, adaptive attack. Using Gandalf, we collect and release a\ndataset of 279k prompt attacks. Complemented by benign user data, our analysis\nreveals the interplay between security and utility, showing that defenses\nintegrated in the LLM (e.g., system prompts) can degrade usability even without\nblocking requests. We demonstrate that restricted application domains,\ndefense-in-depth, and adaptive defenses are effective strategies for building\nsecure and useful LLM applications.\n","authors":["Niklas Pfister","Václav Volhejn","Manuel Knott","Santiago Arias","Julia Bazińska","Mykhailo Bichurin","Alan Commike","Janet Darling","Peter Dienes","Matthew Fiedler","David Haber","Matthias Kraft","Marco Lancini","Max Mathys","Damián Pascual-Ortiz","Jakub Podolak","Adrià Romero-López","Kyriacos Shiarlis","Andreas Signer","Zsolt Terek","Athanasios Theocharis","Daniel Timbrell","Samuel Trautwein","Samuel Watts","Yun-Han Wu","Mateo Rojas-Carulla"],"pdf_url":"https://arxiv.org/pdf/2501.07927v3.pdf","comment":"Niklas Pfister, V\\'aclav Volhejn and Manuel Knott contributed equally"},{"id":"http://arxiv.org/abs/2508.02574v1","updated":"2025-08-04T16:28:58Z","published":"2025-08-04T16:28:58Z","title":"EHSAN: Leveraging ChatGPT in a Hybrid Framework for Arabic Aspect-Based\n  Sentiment Analysis in Healthcare","summary":"  Arabic-language patient feedback remains under-analysed because dialect\ndiversity and scarce aspect-level sentiment labels hinder automated assessment.\nTo address this gap, we introduce EHSAN, a data-centric hybrid pipeline that\nmerges ChatGPT pseudo-labelling with targeted human review to build the first\nexplainable Arabic aspect-based sentiment dataset for healthcare. Each sentence\nis annotated with an aspect and sentiment label (positive, negative, or\nneutral), forming a pioneering Arabic dataset aligned with healthcare themes,\nwith ChatGPT-generated rationales provided for each label to enhance\ntransparency. To evaluate the impact of annotation quality on model\nperformance, we created three versions of the training data: a fully supervised\nset with all labels reviewed by humans, a semi-supervised set with 50% human\nreview, and an unsupervised set with only machine-generated labels. We\nfine-tuned two transformer models on these datasets for both aspect and\nsentiment classification. Experimental results show that our Arabic-specific\nmodel achieved high accuracy even with minimal human supervision, reflecting\nonly a minor performance drop when using ChatGPT-only labels. Reducing the\nnumber of aspect classes notably improved classification metrics across the\nboard. These findings demonstrate an effective, scalable approach to Arabic\naspect-based sentiment analysis (SA) in healthcare, combining large language\nmodel annotation with human expertise to produce a robust and explainable\ndataset. Future directions include generalisation across hospitals, prompt\nrefinement, and interpretable data-driven modelling.\n","authors":["Eman Alamoudi","Ellis Solaiman"],"pdf_url":"https://arxiv.org/pdf/2508.02574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05376v3","updated":"2025-08-04T16:28:18Z","published":"2024-06-08T07:05:26Z","title":"Adversarial flows: A gradient flow characterization of adversarial\n  attacks","summary":"  A popular method to perform adversarial attacks on neuronal networks is the\nso-called fast gradient sign method and its iterative variant. In this paper,\nwe interpret this method as an explicit Euler discretization of a differential\ninclusion, where we also show convergence of the discretization to the\nassociated gradient flow. To do so, we consider the concept of p-curves of\nmaximal slope in the case $p=\\infty$. We prove existence of $\\infty$-curves of\nmaximum slope and derive an alternative characterization via differential\ninclusions. Furthermore, we also consider Wasserstein gradient flows for\npotential energies, where we show that curves in the Wasserstein space can be\ncharacterized by a representing measure on the space of curves in the\nunderlying Banach space, which fulfill the differential inclusion. The\napplication of our theory to the finite-dimensional setting is twofold: On the\none hand, we show that a whole class of normalized gradient descent methods (in\nparticular signed gradient descent) converge, up to subsequences, to the flow,\nwhen sending the step size to zero. On the other hand, in the distributional\nsetting, we show that the inner optimization task of adversarial training\nobjective can be characterized via $\\infty$-curves of maximum slope on an\nappropriate optimal transport space.\n","authors":["Lukas Weigand","Tim Roith","Martin Burger"],"pdf_url":"https://arxiv.org/pdf/2406.05376v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.05833v2","updated":"2025-08-04T16:25:44Z","published":"2025-03-06T12:52:11Z","title":"Refined Policy Distillation: From VLA Generalists to RL Experts","summary":"  Vision-Language-Action Models (VLAs) have demonstrated remarkable\ngeneralization capabilities in real-world experiments. However, their success\nrates are often not on par with expert policies, and they require fine-tuning\nwhen the setup changes. In this work, we introduce Refined Policy Distillation\n(RPD), a novel Reinforcement Learning (RL)-based policy refinement method that\nbridges this performance gap through a combination of on-policy RL with\nbehavioral cloning. The core idea of RPD is to distill and refine VLAs into\ncompact, high-performing expert policies by guiding the student policy during\nRL exploration using the actions of a teacher VLA, resulting in increased\nsample efficiency and faster convergence. We complement our method by\nfine-tuned versions of Octo and OpenVLA for ManiSkill3 to evaluate RPD in\nsimulation. While this is a key requirement for applying RL, it also yields new\ninsights beyond existing studies on VLA performance in real-world settings. Our\nexperimental results across various manipulation tasks show that RPD enables\nthe RL student to learn expert policies that outperform the VLA teacher in both\ndense and sparse reward settings, while also achieving faster convergence than\nthe RL baseline. Our approach is even robust to changes in camera perspective\nand can generalize to task variations that the underlying VLA cannot solve. Our\ncode, dataset, VLA checkpoints, and videos are available at\nhttps://refined-policy-distillation.github.io\n","authors":["Tobias Jülg","Wolfram Burgard","Florian Walter"],"pdf_url":"https://arxiv.org/pdf/2503.05833v2.pdf","comment":"accepted for publication at IROS 2026"},{"id":"http://arxiv.org/abs/2508.02566v1","updated":"2025-08-04T16:21:43Z","published":"2025-08-04T16:21:43Z","title":"Dynamic Feature Selection based on Rule-based Learning for Explainable\n  Classification with Uncertainty Quantification","summary":"  Dynamic feature selection (DFS) offers a compelling alternative to\ntraditional, static feature selection by adapting the selected features to each\nindividual sample. Unlike classical methods that apply a uniform feature set,\nDFS customizes feature selection per sample, providing insight into the\ndecision-making process for each case. DFS is especially significant in\nsettings where decision transparency is key, i.e., clinical decisions; however,\nexisting methods use opaque models, which hinder their applicability in\nreal-life scenarios. This paper introduces a novel approach leveraging a\nrule-based system as a base classifier for the DFS process, which enhances\ndecision interpretability compared to neural estimators. We also show how this\nmethod provides a quantitative measure of uncertainty for each feature query\nand can make the feature selection process computationally lighter by\nconstraining the feature search space. We also discuss when greedy selection of\nconditional mutual information is equivalent to selecting features that\nminimize the difference with respect to the global model predictions. Finally,\nwe demonstrate the competitive performance of our rule-based DFS approach\nagainst established and state-of-the-art greedy and RL methods, which are\nmostly considered opaque, compared to our explainable rule-based system.\n","authors":["Javier Fumanal-Idocin","Raquel Fernandez-Peralta","Javier Andreu-Perez"],"pdf_url":"https://arxiv.org/pdf/2508.02566v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21448v2","updated":"2025-08-04T16:20:43Z","published":"2025-07-29T02:38:56Z","title":"Real-Time Audio-Visual Speech Enhancement Using Pre-trained Visual\n  Representations","summary":"  Speech enhancement in audio-only settings remains challenging, particularly\nin the presence of interfering speakers. This paper presents a simple yet\neffective real-time audio-visual speech enhancement (AVSE) system, RAVEN, which\nisolates and enhances the on-screen target speaker while suppressing\ninterfering speakers and background noise. We investigate how visual embeddings\nlearned from audio-visual speech recognition (AVSR) and active speaker\ndetection (ASD) contribute to AVSE across different SNR conditions and numbers\nof interfering speakers. Our results show concatenating embeddings from AVSR\nand ASD models provides the greatest improvement in low-SNR, multi-speaker\nenvironments, while AVSR embeddings alone perform best in noise-only scenarios.\nIn addition, we develop a real-time streaming system that operates on a\ncomputer CPU and we provide a video demonstration and code repository. To our\nknowledge, this is the first open-source implementation of a real-time AVSE\nsystem.\n","authors":["T. Aleksandra Ma","Sile Yin","Li-Chia Yang","Shuo Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.21448v2.pdf","comment":"Accepted into Interspeech 2025; corrected author name typo"},{"id":"http://arxiv.org/abs/2508.02560v1","updated":"2025-08-04T16:14:15Z","published":"2025-08-04T16:14:15Z","title":"Explainable AI Methods for Neuroimaging: Systematic Failures of Common\n  Tools, the Need for Domain-Specific Validation, and a Proposal for Safe\n  Application","summary":"  Trustworthy interpretation of deep learning models is critical for\nneuroimaging applications, yet commonly used Explainable AI (XAI) methods lack\nrigorous validation, risking misinterpretation. We performed the first\nlarge-scale, systematic comparison of XAI methods on ~45,000 structural brain\nMRIs using a novel XAI validation framework. This framework establishes\nverifiable ground truth by constructing prediction tasks with known signal\nsources - from localized anatomical features to subject-specific clinical\nlesions - without artificially altering input images. Our analysis reveals\nsystematic failures in two of the most widely used methods: GradCAM\nconsistently failed to localize predictive features, while Layer-wise Relevance\nPropagation generated extensive, artifactual explanations that suggest\nincompatibility with neuroimaging data characteristics. Our results indicate\nthat these failures stem from a domain mismatch, where methods with design\nprinciples tailored to natural images require substantial adaptation for\nneuroimaging data. In contrast, the simpler, gradient-based method SmoothGrad,\nwhich makes fewer assumptions about data structure, proved consistently\naccurate, suggesting its conceptual simplicity makes it more robust to this\ndomain shift. These findings highlight the need for domain-specific adaptation\nand validation of XAI methods, suggest that interpretations from prior\nneuroimaging studies using standard XAI methodology warrant re-evaluation, and\nprovide urgent guidance for practical application of XAI in neuroimaging.\n","authors":["Nys Tjade Siegel","James H. Cole","Mohamad Habes","Stefan Haufe","Kerstin Ritter","Marc-André Schulz"],"pdf_url":"https://arxiv.org/pdf/2508.02560v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02556v1","updated":"2025-08-04T16:08:49Z","published":"2025-08-04T16:08:49Z","title":"Automated SNOMED CT Concept Annotation in Clinical Text Using Bi-GRU\n  Neural Networks","summary":"  Automated annotation of clinical text with standardized medical concepts is\ncritical for enabling structured data extraction and decision support. SNOMED\nCT provides a rich ontology for labeling clinical entities, but manual\nannotation is labor-intensive and impractical at scale. This study introduces a\nneural sequence labeling approach for SNOMED CT concept recognition using a\nBidirectional GRU model. Leveraging a subset of MIMIC-IV, we preprocess text\nwith domain-adapted SpaCy and SciBERT-based tokenization, segmenting sentences\ninto overlapping 19-token chunks enriched with contextual, syntactic, and\nmorphological features. The Bi-GRU model assigns IOB tags to identify concept\nspans and achieves strong performance with a 90 percent F1-score on the\nvalidation set. These results surpass traditional rule-based systems and match\nor exceed existing neural models. Qualitative analysis shows effective handling\nof ambiguous terms and misspellings. Our findings highlight that lightweight\nRNN-based architectures can deliver high-quality clinical concept annotation\nwith significantly lower computational cost than transformer-based models,\nmaking them well-suited for real-world deployment.\n","authors":["Ali Noori","Pratik Devkota","Somya Mohanty","Prashanti Manda"],"pdf_url":"https://arxiv.org/pdf/2508.02556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02553v1","updated":"2025-08-04T16:04:20Z","published":"2025-08-04T16:04:20Z","title":"CSI Obfuscation: Single-Antenna Transmitters Can Not Hide from\n  Adversarial Multi-Antenna Radio Localization Systems","summary":"  The ability of modern telecommunication systems to locate users and objects\nin the radio environment raises justified privacy concerns. To prevent\nunauthorized localization, single-antenna transmitters can obfuscate the signal\nby convolving it with a randomized sequence prior to transmission, which alters\nthe channel state information (CSI) estimated at the receiver. However, this\nstrategy is only effective against CSI-based localization systems deploying\nsingle-antenna receivers. Inspired by the concept of blind multichannel\nidentification, we propose a simple CSI recovery method for multi-antenna\nreceivers to extract channel features that ensure reliable user localization\nregardless of the transmitted signal. We comparatively evaluate the impact of\nsignal obfuscation and the proposed recovery method on the localization\nperformance of CSI fingerprinting, channel charting, and classical\ntriangulation using real-world channel measurements. This work aims to\ndemonstrate the necessity for further efforts to protect the location privacy\nof users from adversarial radio-based localization systems.\n","authors":["Phillip Stephan","Florian Euchner","Stephan ten Brink"],"pdf_url":"https://arxiv.org/pdf/2508.02553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02546v1","updated":"2025-08-04T15:59:15Z","published":"2025-08-04T15:59:15Z","title":"What are you sinking? A geometric approach on attention sink","summary":"  Attention sink (AS) is a consistent pattern in transformer attention maps\nwhere certain tokens (often special tokens or positional anchors)\ndisproportionately attract attention from other tokens. We show that in\ntransformers, AS is not an architectural artifact, but it is the manifestation\nof a fundamental geometric principle: the establishment of reference frames\nthat anchor representational spaces. We analyze several architectures and\nidentify three distinct reference frame types, centralized, distributed, and\nbidirectional, that correlate with the attention sink phenomenon. We show that\nthey emerge during the earliest stages of training as optimal solutions to the\nproblem of establishing stable coordinate systems in high-dimensional spaces.\nWe show the influence of architecture components, particularly position\nencoding implementations, on the specific type of reference frame. This\nperspective transforms our understanding of transformer attention mechanisms\nand provides insights for both architecture design and the relationship with\nAS.\n","authors":["Valeria Ruscio","Umberto Nanni","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2508.02546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.03336v2","updated":"2025-08-04T15:48:55Z","published":"2025-07-04T06:49:02Z","title":"Disambiguation-Centric Finetuning Makes Enterprise Tool-Calling LLMs\n  More Realistic and Less Risky","summary":"  Large language models (LLMs) are increasingly tasked with invoking enterprise\nAPIs, yet they routinely falter when near-duplicate tools vie for the same user\nintent or when required arguments are left underspecified. We introduce\nDiaFORGE (Dialogue Framework for Organic Response Generation & Evaluation), a\ndisambiguation-centric, three-stage pipeline that (i) synthesizes\npersona-driven, multi-turn dialogues in which the assistant must distinguish\namong highly similar tools, (ii) performs supervised fine-tuning of open-source\nmodels with reasoning traces across 3B - 70B parameters, and (iii) evaluates\nreal-world readiness via a dynamic suite that redeploys each model in a live\nagentic loop and reports end-to-end goal completion alongside conventional\nstatic metrics. On our dynamic benchmark DiaBENCH, models trained with DiaFORGE\nraise tool-invocation success by 27 pp over GPT-4o and by 49 pp over\nClaude-3.5-Sonnet, both under optimized prompting. To spur further research, we\nrelease an open corpus of 5000 production-grade enterprise API specifications\npaired with rigorously validated, disambiguation-focused dialogues, offering a\npractical blueprint for building reliable, enterprise-ready tool-calling\nagents.\n","authors":["Ashutosh Hathidara","Julien Yu","Sebastian Schreiber"],"pdf_url":"https://arxiv.org/pdf/2507.03336v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.00982v2","updated":"2025-08-04T15:48:47Z","published":"2025-05-02T04:02:36Z","title":"DHO$_2$: Accelerating Distributed Hybrid Order Optimization via Model\n  Parallelism and ADMM","summary":"  Scaling deep neural network (DNN) training to more devices can reduce\ntime-to-solution. However, it is impractical for users with limited computing\nresources. FOSI, as a hybrid order optimizer, converges faster than\nconventional optimizers by taking advantage of both gradient information and\ncurvature information when updating the DNN model. Therefore, it provides a new\nchance for accelerating DNN training in the resource-constrained setting. In\nthis paper, we explore its distributed design, namely DHO$_2$, including\ndistributed calculation of curvature information and model update with partial\ncurvature information to accelerate DNN training with a low memory burden. To\nfurther reduce the training time, we design a novel strategy to parallelize the\ncalculation of curvature information and the model update on different devices.\nExperimentally, our distributed design can achieve an approximate linear\nreduction of memory burden on each device with the increase of the device\nnumber. Meanwhile, it achieves $1.4\\times\\sim2.1\\times$ speedup in the total\ntraining time compared with other distributed designs based on conventional\nfirst- and second-order optimizers.\n","authors":["Shunxian Gu","Chaoqun You","Bangbang Ren","Lailong Luo","Junxu Xia","Deke Guo"],"pdf_url":"https://arxiv.org/pdf/2505.00982v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02537v1","updated":"2025-08-04T15:45:03Z","published":"2025-08-04T15:45:03Z","title":"Solved in Unit Domain: JacobiNet for Differentiable Coordinate\n  Transformations","summary":"  Physics-Informed Neural Networks (PINNs) are effective for solving PDEs by\nincorporating physical laws into the learning process. However, they face\nchallenges with irregular boundaries, leading to instability and slow\nconvergence due to inconsistent normalization, inaccurate boundary enforcement,\nand imbalanced loss terms. A common solution is to map the domain to a regular\nspace, but traditional methods rely on case-specific meshes and simple\ngeometries, limiting their compatibility with modern frameworks. To overcome\nthese limitations, we introduce JacobiNet, a neural network-based coordinate\ntransformation method that learns continuous, differentiable mappings from\nsupervised point pairs. Utilizing lightweight MLPs, JacobiNet allows for direct\nJacobian computation via autograd and integrates seamlessly with downstream\nPINNs, enabling end-to-end differentiable PDE solving without the need for\nmeshing or explicit Jacobian computation. JacobiNet effectively addresses\nnormalization challenges, facilitates hard constraints of boundary conditions,\nand mitigates the long-standing imbalance among loss terms. It demonstrates\nsignificant improvements, reducing the relative L2 error from 0.287-0.637 to\n0.013-0.039, achieving an average accuracy improvement of 18.3*. In vessel-like\ndomains, it enables rapid mapping for unseen geometries, improving prediction\naccuracy by 3.65* and achieving over 10* speedup, showcasing its\ngeneralization, accuracy, and efficiency.\n","authors":["Xi Chen","Jianchuan Yang","Junjie Zhang","Runnan Yang","Xu Liu","Hong Wang","Ziyu Ren","Wenqi Hu"],"pdf_url":"https://arxiv.org/pdf/2508.02537v1.pdf","comment":"Submitted to CMAME, revision in progress"},{"id":"http://arxiv.org/abs/2508.02534v1","updated":"2025-08-04T15:42:53Z","published":"2025-08-04T15:42:53Z","title":"Communication and Computation Efficient Split Federated Learning in\n  O-RAN","summary":"  The hierarchical architecture of Open Radio Access Network (O-RAN) has\nenabled a new Federated Learning (FL) paradigm that trains models using data\nfrom non- and near-real-time (near-RT) Radio Intelligent Controllers (RICs).\nHowever, the ever-increasing model size leads to longer training time,\njeopardizing the deadline requirements for both non-RT and near-RT RICs. To\naddress this issue, split federated learning (SFL) offers an approach by\noffloading partial model layers from near-RT-RIC to high-performance\nnon-RT-RIC. Nonetheless, its deployment presents two challenges: (i) Frequent\ndata/gradient transfers between near-RT-RIC and non-RT-RIC in SFL incur\nsignificant communication cost in O-RAN. (ii) Proper allocation of\ncomputational and communication resources in O-RAN is vital to satisfying the\ndeadline and affects SFL convergence. Therefore, we propose SplitMe, an SFL\nframework that exploits mutual learning to alternately and independently train\nthe near-RT-RIC's model and the non-RT-RIC's inverse model, eliminating\nfrequent transfers. The ''inverse'' of the inverse model is derived via a\nzeroth-order technique to integrate the final model. Then, we solve a joint\noptimization problem for SplitMe to minimize overall resource costs with\ndeadline-aware selection of near-RT-RICs and adaptive local updates. Our\nnumerical results demonstrate that SplitMe remarkably outperforms FL frameworks\nlike SFL, FedAvg and O-RANFed regarding costs and convergence.\n","authors":["Shunxian Gu","Chaoqun You","Bangbang Ren","Deke Guo"],"pdf_url":"https://arxiv.org/pdf/2508.02534v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02532v1","updated":"2025-08-04T15:41:35Z","published":"2025-08-04T15:41:35Z","title":"Contextual Graph Transformer: A Small Language Model for Enhanced\n  Engineering Document Information Extraction","summary":"  Standard transformer-based language models, while powerful for general text,\noften struggle with the fine-grained syntax and entity relationships in complex\ntechnical, engineering documents. To address this, we propose the Contextual\nGraph Transformer (CGT), a hybrid neural architecture that combines Graph\nNeural Networks (GNNs) and Transformers for domain-specific question answering.\nCGT constructs a dynamic graph over input tokens using sequential, skip-gram,\nand semantic similarity edges, which is processed by GATv2Conv layers for local\nstructure learning. These enriched embeddings are then passed to a Transformer\nencoder to capture global dependencies. Unlike generic large models, technical\ndomains often require specialized language models with stronger\ncontextualization and structure awareness. CGT offers a parameter-efficient\nsolution for such use cases. Integrated into a Retrieval-Augmented Generation\n(RAG) pipeline, CGT outperforms baselines like GPT-2 and BERT, achieving 24.7%\nhigher accuracy than GPT-2 with 62.4% fewer parameters. This gain stems from\nCGTs ability to jointly model structural token interactions and long-range\nsemantic coherence. The model is trained from scratch using a two-phase\napproach: pretraining on general text followed by fine-tuning on\ndomain-specific manuals. This highlights CGTs adaptability to technical\nlanguage, enabling better grounding, entity tracking, and retrieval-augmented\nresponses in real-world applications.\n","authors":["Karan Reddy","Mayukha Pal"],"pdf_url":"https://arxiv.org/pdf/2508.02532v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02527v1","updated":"2025-08-04T15:36:51Z","published":"2025-08-04T15:36:51Z","title":"I Have No Mouth, and I Must Rhyme: Uncovering Internal Phonetic\n  Representations in LLaMA 3.2","summary":"  Large language models demonstrate proficiency on phonetic tasks, such as\nrhyming, without explicit phonetic or auditory grounding. In this work, we\ninvestigate how \\verb|Llama-3.2-1B-Instruct| represents token-level phonetic\ninformation. Our results suggest that Llama uses a rich internal model of\nphonemes to complete phonetic tasks. We provide evidence for high-level\norganization of phoneme representations in its latent space. In doing so, we\nalso identify a ``phoneme mover head\" which promotes phonetic information\nduring rhyming tasks. We visualize the output space of this head and find that,\nwhile notable differences exist, Llama learns a model of vowels similar to the\nstandard IPA vowel chart for humans, despite receiving no direct supervision to\ndo so.\n","authors":["Jack Merullo","Arjun Khurana","Oliver McLaughlin"],"pdf_url":"https://arxiv.org/pdf/2508.02527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02524v1","updated":"2025-08-04T15:35:08Z","published":"2025-08-04T15:35:08Z","title":"Causality and Interpretability for Electrical Distribution System faults","summary":"  Causal analysis helps us understand variables that are responsible for system\nfailures. This improves fault detection and makes system more reliable. In this\nwork, we present a new method that combines causal inference with machine\nlearning to classify faults in electrical distribution systems (EDS) using\ngraph-based models. We first build causal graphs using transfer entropy (TE).\nEach fault case is represented as a graph, where the nodes are features such as\nvoltage and current, and the edges demonstrate how these features influence\neach other. Then, the graphs are classified using machine learning and\nGraphSAGE where the model learns from both the node values and the structure of\nthe graph to predict the type of fault. To make the predictions understandable,\nwe further developed an integrated approach using GNNExplainer and Captums\nIntegrated Gradients to highlight the nodes (features) that influences the most\non the final prediction. This gives us clear insights into the possible causes\nof the fault. Our experiments show high accuracy: 99.44% on the EDS fault\ndataset, which is better than state of art models. By combining causal graphs\nwith machine learning, our method not only predicts faults accurately but also\nhelps understand their root causes. This makes it a strong and practical tool\nfor improving system reliability.\n","authors":["Karthik Peddi","Sai Ram Aditya Parisineni","Hemanth Macharla","Mayukha Pal"],"pdf_url":"https://arxiv.org/pdf/2508.02524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02518v1","updated":"2025-08-04T15:25:48Z","published":"2025-08-04T15:25:48Z","title":"AnalogCoder-Pro: Unifying Analog Circuit Generation and Optimization via\n  Multi-modal LLMs","summary":"  Despite advances in analog design automation, analog front-end design still\nheavily depends on expert intuition and iterative simulations, underscoring\ncritical gaps in fully automated optimization for performance-critical\napplications. Recently, the rapid development of Large Language Models (LLMs)\nhas brought new promise to analog design automation. However, existing work\nremains in its early stages, and holistic joint optimization for practical\nend-to-end solutions remains largely unexplored. We propose AnalogCoder-Pro, a\nunified multimodal LLM-based framework that integrates generative capabilities\nand optimization techniques to jointly explore circuit topologies and optimize\ndevice sizing, automatically generating performance-specific, fully sized\nschematic netlists. AnalogCoder-Pro employs rejection sampling for fine-tuning\nLLMs on high-quality synthesized circuit data and introduces a multimodal\ndiagnosis and repair workflow based on functional specifications and waveform\nimages. By leveraging LLMs to interpret generated circuit netlists,\nAnalogCoder-Pro automates the extraction of critical design parameters and the\nformulation of parameter spaces, establishing an end-to-end workflow for\nsimultaneous topology generation and device sizing optimization. Extensive\nexperiments demonstrate that these orthogonal approaches significantly improve\nthe success rate of analog circuit design and enhance circuit performance.\n","authors":["Yao Lai","Souradip Poddar","Sungyoung Lee","Guojin Chen","Mengkang Hu","Bei Yu","Ping Luo","David Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2508.02518v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.22089v2","updated":"2025-08-04T15:23:32Z","published":"2024-10-29T14:46:49Z","title":"Hierarchical Structure Sharing Empowers Multi-task Heterogeneous GNNs\n  for Customer Expansion","summary":"  Customer expansion, i.e., growing a business existing customer base by\nacquiring new customers, is critical for scaling operations and sustaining the\nlong-term profitability of logistics companies. Although state-of-the-art works\nmodel this task as a single-node classification problem under a heterogeneous\ngraph learning framework and achieve good performance, they struggle with\nextremely positive label sparsity issues in our scenario. Multi-task learning\n(MTL) offers a promising solution by introducing a correlated, label-rich task\nto enhance the label-sparse task prediction through knowledge sharing. However,\nexisting MTL methods result in performance degradation because they fail to\ndiscriminate task-shared and task-specific structural patterns across tasks.\nThis issue arises from their limited consideration of the inherently complex\nstructure learning process of heterogeneous graph neural networks, which\ninvolves the multi-layer aggregation of multi-type relations. To address the\nchallenge, we propose a Structure-Aware Hierarchical Information Sharing\nFramework (SrucHIS), which explicitly regulates structural information sharing\nacross tasks in logistics customer expansion. SrucHIS breaks down the structure\nlearning phase into multiple stages and introduces sharing mechanisms at each\nstage, effectively mitigating the influence of task-specific structural\npatterns during each stage. We evaluate StrucHIS on both private and public\ndatasets, achieving a 51.41% average precision improvement on the private\ndataset and a 10.52% macro F1 gain on the public dataset. StrucHIS is further\ndeployed at one of the largest logistics companies in China and demonstrates a\n41.67% improvement in the success contract-signing rate over existing\nstrategies, generating over 453K new orders within just two months.\n","authors":["Xinyue Feng","Shuxin Zhong","Jinquan Hang","Wenjun Lyu","Yuequn Zhang","Guang Yang","Haotian Wang","Desheng Zhang","Guang Wang"],"pdf_url":"https://arxiv.org/pdf/2410.22089v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02515v1","updated":"2025-08-04T15:19:22Z","published":"2025-08-04T15:19:22Z","title":"PoeTone: A Framework for Constrained Generation of Structured Chinese\n  Songci with LLMs","summary":"  This paper presents a systematic investigation into the constrained\ngeneration capabilities of large language models (LLMs) in producing Songci, a\nclassical Chinese poetry form characterized by strict structural, tonal, and\nrhyme constraints defined by Cipai templates. We first develop a comprehensive,\nmulti-faceted evaluation framework that includes: (i) a formal conformity\nscore, (ii) automated quality assessment using LLMs, (iii) human evaluation,\nand (iv) classification-based probing tasks. Using this framework, we evaluate\nthe generative performance of 18 LLMs, including 3 proprietary models and 15\nopen-source models across four families, under five prompting strategies:\nzero-shot, one-shot, completion-based, instruction-tuned, and chain-of-thought.\nFinally, we propose a Generate-Critic architecture in which the evaluation\nframework functions as an automated critic. Leveraging the critic's feedback as\na reward signal, we fine-tune three lightweight open-source LLMs via supervised\nfine-tuning (SFT), resulting in improvements of up to 5.88% in formal\nconformity. Our findings offer new insights into the generative strengths and\nlimitations of LLMs in producing culturally significant and formally\nconstrained literary texts.\n","authors":["Zhan Qu","Shuzhou Yuan","Michael Färber"],"pdf_url":"https://arxiv.org/pdf/2508.02515v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02510v1","updated":"2025-08-04T15:17:08Z","published":"2025-08-04T15:17:08Z","title":"On Distributional Dependent Performance of Classical and Neural Routing\n  Solvers","summary":"  Neural Combinatorial Optimization aims to learn to solve a class of\ncombinatorial problems through data-driven methods and notably through\nemploying neural networks by learning the underlying distribution of problem\ninstances. While, so far neural methods struggle to outperform highly\nengineered problem specific meta-heuristics, this work explores a novel\napproach to formulate the distribution of problem instances to learn from and,\nmore importantly, plant a structure in the sampled problem instances. In\napplication to routing problems, we generate large problem instances that\nrepresent custom base problem instance distributions from which training\ninstances are sampled. The test instances to evaluate the methods on the\nrouting task consist of unseen problems sampled from the underlying large\nproblem instance. We evaluate representative NCO methods and specialized\nOperation Research meta heuristics on this novel task and demonstrate that the\nperformance gap between neural routing solvers and highly specialized\nmeta-heuristics decreases when learning from sub-samples drawn from a fixed\nbase node distribution.\n","authors":["Daniela Thyssens","Tim Dernedde","Wilson Sentanoe","Lars Schmidt-Thieme"],"pdf_url":"https://arxiv.org/pdf/2508.02510v1.pdf","comment":"9 pages, 2 figures"},{"id":"http://arxiv.org/abs/2503.12172v3","updated":"2025-08-04T15:15:16Z","published":"2025-03-15T15:29:05Z","title":"SEAL: Semantic Aware Image Watermarking","summary":"  Generative models have rapidly evolved to generate realistic outputs.\nHowever, their synthetic outputs increasingly challenge the clear distinction\nbetween natural and AI-generated content, necessitating robust watermarking\ntechniques. Watermarks are typically expected to preserve the integrity of the\ntarget image, withstand removal attempts, and prevent unauthorized replication\nonto unrelated images. To address this need, recent methods embed persistent\nwatermarks into images produced by diffusion models using the initial noise.\nYet, to do so, they either distort the distribution of generated images or rely\non searching through a long dictionary of used keys for detection.\n  In this paper, we propose a novel watermarking method that embeds semantic\ninformation about the generated image directly into the watermark, enabling a\ndistortion-free watermark that can be verified without requiring a database of\nkey patterns. Instead, the key pattern can be inferred from the semantic\nembedding of the image using locality-sensitive hashing. Furthermore,\nconditioning the watermark detection on the original image content improves\nrobustness against forgery attacks. To demonstrate that, we consider two\nlargely overlooked attack strategies: (i) an attacker extracting the initial\nnoise and generating a novel image with the same pattern; (ii) an attacker\ninserting an unrelated (potentially harmful) object into a watermarked image,\npossibly while preserving the watermark. We empirically validate our method's\nincreased robustness to these attacks. Taken together, our results suggest that\ncontent-aware watermarks can mitigate risks arising from image-generative\nmodels.\n","authors":["Kasra Arabi","R. Teal Witter","Chinmay Hegde","Niv Cohen"],"pdf_url":"https://arxiv.org/pdf/2503.12172v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02495v1","updated":"2025-08-04T15:05:27Z","published":"2025-08-04T15:05:27Z","title":"Clinical Expert Uncertainty Guided Generalized Label Smoothing for\n  Medical Noisy Label Learning","summary":"  Many previous studies have proposed extracting image labels from clinical\nnotes to create large-scale medical image datasets at a low cost. However,\nthese approaches inherently suffer from label noise due to uncertainty from the\nclinical experts. When radiologists and physicians analyze medical images to\nmake diagnoses, they often include uncertainty-aware notes such as ``maybe'' or\n``not excluded''. Unfortunately, current text-mining methods overlook these\nnuances, resulting in the creation of noisy labels. Existing methods for\nhandling noisy labels in medical image analysis, which typically address the\nproblem through post-processing techniques, have largely ignored the important\nissue of expert-driven uncertainty contributing to label noise. To better\nincorporate the expert-written uncertainty in clinical notes into medical image\nanalysis and address the label noise issue, we first examine the impact of\nclinical expert uncertainty on label noise. We then propose a clinical expert\nuncertainty-aware benchmark, along with a label smoothing method, which\nsignificantly improves performance compared to current state-of-the-art\napproaches.\n","authors":["Kunyu Zhang","Lin Gu","Liangchen Liu","Yingke Chen","Bingyang Wang","Jin Yan","Yingying Zhu"],"pdf_url":"https://arxiv.org/pdf/2508.02495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02485v1","updated":"2025-08-04T14:57:03Z","published":"2025-08-04T14:57:03Z","title":"Federated Graph Unlearning","summary":"  The demand for data privacy has led to the development of frameworks like\nFederated Graph Learning (FGL), which facilitate decentralized model training.\nHowever, a significant operational challenge in such systems is adhering to the\nright to be forgotten. This principle necessitates robust mechanisms for two\ndistinct types of data removal: the selective erasure of specific entities and\ntheir associated knowledge from local subgraphs and the wholesale removal of a\nuser's entire dataset and influence. Existing methods often struggle to fully\naddress both unlearning requirements, frequently resulting in incomplete data\nremoval or the persistence of residual knowledge within the system. This work\nintroduces a unified framework, conceived to provide a comprehensive solution\nto these challenges. The proposed framework employs a bifurcated strategy\ntailored to the specific unlearning request. For fine-grained Meta Unlearning,\nit uses prototype gradients to direct the initial local forgetting process,\nwhich is then refined by generating adversarial graphs to eliminate any\nremaining data traces among affected clients. In the case of complete client\nunlearning, the framework utilizes adversarial graph generation exclusively to\npurge the departed client's contributions from the remaining network. Extensive\nexperiments on multiple benchmark datasets validate the proposed approach. The\nframework achieves substantial improvements in model prediction accuracy across\nboth client and meta-unlearning scenarios when compared to existing methods.\nFurthermore, additional studies confirm its utility as a plug-in module, where\nit materially enhances the predictive capabilities and unlearning effectiveness\nof other established methods.\n","authors":["Yuming Ai","Xunkai Li","Jiaqi Chao","Bowen Fan","Zhengyu Wu","Yinlin Zhu","Rong-Hua Li","Guoren Wang"],"pdf_url":"https://arxiv.org/pdf/2508.02485v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2504.09006v2","updated":"2025-08-04T14:51:59Z","published":"2025-04-11T23:14:32Z","title":"Learning in Structured Stackelberg Games","summary":"  We study structured Stackelberg games, in which both players (the leader and\nthe follower) observe contextual information about the state of the world at\ntime of play. The leader plays against one of a finite number of followers, but\nthe follower's type is not known until after the game has ended. Importantly,\nwe assume a fixed relationship between the contextual information and the\nfollower's type, thereby allowing the leader to leverage this additional\nstructure when deciding her strategy. Under this setting, we find that standard\nlearning theoretic measures of complexity do not characterize the difficulty of\nthe leader's learning task. Instead, we introduce a new notion of dimension,\nthe Stackelberg-Littlestone dimension, which we show characterizes the\ninstance-optimal regret of the leader in the online setting. Based on this, we\nalso provide a provably optimal learning algorithm. We extend our results to\nthe distributional setting, where we use two new notions of dimension, the\n$\\gamma$-Stackelberg-Natarajan dimension and $\\gamma$-Stackelberg-Graph\ndimension. We prove that these control the sample complexity lower and upper\nbounds respectively, and we design a simple, improper algorithm that achieves\nthe upper bound.\n","authors":["Maria-Florina Balcan","Kiriaki Fragkia","Keegan Harris"],"pdf_url":"https://arxiv.org/pdf/2504.09006v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02482v1","updated":"2025-08-04T14:50:44Z","published":"2025-08-04T14:50:44Z","title":"Toward Using Machine Learning as a Shape Quality Metric for Liver Point\n  Cloud Generation","summary":"  While 3D medical shape generative models such as diffusion models have shown\npromise in synthesizing diverse and anatomically plausible structures, the\nabsence of ground truth makes quality evaluation challenging. Existing\nevaluation metrics commonly measure distributional distances between training\nand generated sets, while the medical field requires assessing quality at the\nindividual level for each generated shape, which demands labor-intensive expert\nreview.\n  In this paper, we investigate the use of classical machine learning (ML)\nmethods and PointNet as an alternative, interpretable approach for assessing\nthe quality of generated liver shapes. We sample point clouds from the surfaces\nof the generated liver shapes, extract handcrafted geometric features, and\ntrain a group of supervised ML and PointNet models to classify liver shapes as\ngood or bad. These trained models are then used as proxy discriminators to\nassess the quality of synthetic liver shapes produced by generative models.\n  Our results show that ML-based shape classifiers provide not only\ninterpretable feedback but also complementary insights compared to expert\nevaluation. This suggests that ML classifiers can serve as lightweight,\ntask-relevant quality metrics in 3D organ shape generation, supporting more\ntransparent and clinically aligned evaluation protocols in medical shape\nmodeling.\n","authors":["Khoa Tuan Nguyen","Gaeun Oh","Ho-min Park","Francesca Tozzi","Wouter Willaert","Joris Vankerschaver","Niki Rashidian","Wesley De Neve"],"pdf_url":"https://arxiv.org/pdf/2508.02482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02473v1","updated":"2025-08-04T14:37:32Z","published":"2025-08-04T14:37:32Z","title":"An Efficient and Adaptive Next Edit Suggestion Framework with Zero Human\n  Instructions in IDEs","summary":"  Code editing, including modifying, refactoring, and maintaining existing\ncode, is the most frequent task in software development and has garnered\nsignificant attention from AI-powered tools. However, existing solutions that\ntranslate explicit natural language instructions into code edits face critical\nlimitations, such as heavy reliance on human instruction input and high\nlatency, which hinder their effective integration into a developer's workflow.\nWe observe that developers' habitual behaviors and coding objectives are often\nreflected in their historical editing patterns, making this data key to\naddressing existing limitations. To leverage these insights, we propose NES\n(Next Edit Suggestion), an LLM-driven code editing framework that delivers an\ninstruction-free and low-latency experience. Built on a dual-model architecture\nand trained with our high-quality SFT and DAPO datasets, NES enhances\nproductivity by understanding developer intent while optimizing inference to\nminimize latency. NES is a scalable, industry-ready solution with a continuous\nTab key interaction workflow, seamlessly adopted by a FinTech company with over\n20,000 developers. Evaluations on real-world datasets show NES achieves 75.6%\nand 81.6% accuracy in two tasks of predicting next edit locations, alongside\n91.36% ES and 27.7% EMR for intent-aligned edits, outperforming SOTA models.\nOur open-sourced SFT and DAPO datasets have been demonstrated to enhance the\nperformance of open-source CodeLLMs. The demonstration of NES is available at\nhttps://youtu.be/yGoyYOe6fbY.\n","authors":["Xinfang Chen","Siyang Xiao","Xianying Zhu","Junhong Xie","Ming Liang","Dajun Chen","Wei Jiang","Yong Li","Peng Di"],"pdf_url":"https://arxiv.org/pdf/2508.02473v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2409.00029v2","updated":"2025-08-04T14:34:44Z","published":"2024-08-17T12:46:53Z","title":"Attack Anything: Blind DNNs via Universal Background Adversarial Attack","summary":"  It has been widely substantiated that deep neural networks (DNNs) are\nsusceptible and vulnerable to adversarial perturbations. Existing studies\nmainly focus on performing attacks by corrupting targeted objects (physical\nattack) or images (digital attack), which is intuitively acceptable and\nunderstandable in terms of the attack's effectiveness. In contrast, our focus\nlies in conducting background adversarial attacks in both digital and physical\ndomains, without causing any disruptions to the targeted objects themselves.\nSpecifically, an effective background adversarial attack framework is proposed\nto attack anything, by which the attack efficacy generalizes well between\ndiverse objects, models, and tasks. Technically, we approach the background\nadversarial attack as an iterative optimization problem, analogous to the\nprocess of DNN learning. Besides, we offer a theoretical demonstration of its\nconvergence under a set of mild but sufficient conditions. To strengthen the\nattack efficacy and transferability, we propose a new ensemble strategy\ntailored for adversarial perturbations and introduce an improved smooth\nconstraint for the seamless connection of integrated perturbations. We conduct\ncomprehensive and rigorous experiments in both digital and physical domains\nacross various objects, models, and tasks, demonstrating the effectiveness of\nattacking anything of the proposed method. The findings of this research\nsubstantiate the significant discrepancy between human and machine vision on\nthe value of background variations, which play a far more critical role than\npreviously recognized, necessitating a reevaluation of the robustness and\nreliability of DNNs. The code will be publicly available at\nhttps://github.com/JiaweiLian/Attack_Anything\n","authors":["Jiawei Lian","Shaohui Mei","Xiaofei Wang","Yi Wang","Lefan Wang","Yingjie Lu","Mingyang Ma","Lap-Pui Chau"],"pdf_url":"https://arxiv.org/pdf/2409.00029v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16525v4","updated":"2025-08-04T14:28:05Z","published":"2024-06-24T11:01:43Z","title":"Enhancing OOD Detection Using Latent Diffusion","summary":"  Out-of-distribution (OOD) detection is crucial for the reliable deployment of\nmachine learning models in real-world scenarios, enabling the identification of\nunknown samples or objects. A prominent approach to enhance OOD detection\nperformance involves leveraging auxiliary datasets for training. Recent efforts\nhave explored using generative models, such as Stable Diffusion (SD), to\nsynthesize outlier data in the pixel space. However, synthesizing OOD data in\nthe pixel space can lead to reduced robustness due to over-generation. To\naddress this challenge, we propose Outlier-Aware Learning (OAL), a novel\nframework that generates synthetic OOD training data within the latent space,\ntaking a further step to study how to utilize Stable Diffusion for developing a\nlatent-based outlier synthesis approach. This improvement facilitates network\ntraining with fewer outliers and less computational cost. Besides, to\nregularize the model's decision boundary, we develop a mutual information-based\ncontrastive learning module (MICL) that amplifies the distinction between\nIn-Distribution (ID) and collected OOD data. Moreover, we develop a knowledge\ndistillation module to prevent the degradation of ID classification accuracy\nwhen training with OOD data. The superior performance of our method on several\nbenchmark datasets demonstrates its efficiency and effectiveness. Source code\nis available in https://github.com/HengGao12/OAL.\n","authors":["Heng Gao","Jun Li"],"pdf_url":"https://arxiv.org/pdf/2406.16525v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18376v3","updated":"2025-08-04T14:25:00Z","published":"2025-07-24T12:52:32Z","title":"A Comprehensive Review of Diffusion Models in Smart Agriculture:\n  Progress, Applications, and Challenges","summary":"  With the global population increasing and arable land resources becoming\nincreasingly limited, smart and precision agriculture have emerged as essential\ndirections for sustainable agricultural development. Artificial intelligence\n(AI), particularly deep learning models, has been widely adopted in\napplications such as crop monitoring, pest detection, and yield prediction.\nAmong recent generative models, diffusion models have demonstrated considerable\npotential in agricultural image processing, data augmentation, and remote\nsensing analysis. Compared to traditional generative adversarial networks\n(GANs), diffusion models exhibit greater training stability and superior image\ngeneration quality, effectively addressing challenges such as limited annotated\ndatasets and imbalanced sample distributions in agricultural scenarios. This\npaper reviews recent advancements in the application of diffusion models within\nagriculture, focusing on their roles in crop disease and pest detection, remote\nsensing image enhancement, crop growth prediction, and agricultural resource\nmanagement. Empirical studies show that diffusion models significantly enhance\nthe performance of downstream models by improving accuracy, robustness, and\ngeneralization in tasks involving image synthesis, augmentation, and denoising\nunder complex environmental conditions. Despite ongoing challenges in\ncomputational efficiency and domain generalization, diffusion models are\nexpected to play an increasingly important role in the future of intelligent\nagriculture. As the technology continues to evolve, it holds substantial\npromise for addressing pressing global issues in food security and\nenvironmental sustainability.\n","authors":["Xing Hu","Haodong Chen","Choon Ki Ahn","Danfeng Hong","Qianqian Duan","Huiliang Shang","Guoxiang Li","Linhua Jiang","Dawei Zhang Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.18376v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.00560v2","updated":"2025-08-04T14:13:34Z","published":"2024-11-30T19:07:16Z","title":"Friend or Foe? Harnessing Controllable Overfitting for Anomaly Detection","summary":"  Overfitting has traditionally been viewed as detrimental to anomaly\ndetection, where excessive generalization often limits models' sensitivity to\nsubtle anomalies. Our work challenges this conventional view by introducing\nControllable Overfitting-based Anomaly Detection (COAD), a novel framework that\nstrategically leverages overfitting to enhance anomaly discrimination\ncapabilities. We propose the Aberrance Retention Quotient (ARQ), a novel metric\nthat systematically quantifies the extent of overfitting, enabling the\nidentification of an optimal golden overfitting interval wherein model\nsensitivity to anomalies is maximized without sacrificing generalization. To\ncomprehensively capture how overfitting affects detection performance, we\nfurther propose the Relative Anomaly Distribution Index (RADI), a metric\nsuperior to traditional AUROC by explicitly modeling the separation between\nnormal and anomalous score distributions. Theoretically, RADI leverages ARQ to\ntrack and evaluate how overfitting impacts anomaly detection, offering an\nintegrated approach to understanding the relationship between overfitting\ndynamics and model efficacy. We also rigorously validate the statistical\nefficacy of Gaussian noise as pseudo-anomaly generators, reinforcing the\nmethod's broad applicability. Empirical evaluations demonstrate that our\ncontrollable overfitting method achieves State-Of-The-Art(SOTA) performance in\nboth one-class and multi-class anomaly detection tasks, thus redefining\noverfitting as a powerful strategy rather than a limitation.\n","authors":["Long Qian","Bingke Zhu","Yingying Chen","Ming Tang","Jinqiao Wang"],"pdf_url":"https://arxiv.org/pdf/2412.00560v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14334v3","updated":"2025-08-04T14:10:44Z","published":"2024-10-18T09:44:35Z","title":"Evaluating the evaluators: Towards human-aligned metrics for missing\n  markers reconstruction","summary":"  Animation data is often obtained through optical motion capture systems,\nwhich utilize a multitude of cameras to establish the position of optical\nmarkers. However, system errors or occlusions can result in missing markers,\nthe manual cleaning of which can be time-consuming. This has sparked interest\nin machine learning-based solutions for missing marker reconstruction in the\nacademic community. Most academic papers utilize a simplistic mean square error\nas the main metric. In this paper, we show that this metric does not correlate\nwith subjective perception of the fill quality. Additionally, we introduce and\nevaluate a set of better-correlated metrics that can drive progress in the\nfield.\n","authors":["Taras Kucherenko","Derek Peristy","Judith Bütepage"],"pdf_url":"https://arxiv.org/pdf/2410.14334v3.pdf","comment":"Accepted at the ACM International Conference on Multimedia 2025 (ACM\n  MM'25)"},{"id":"http://arxiv.org/abs/2411.14017v2","updated":"2025-08-04T14:05:44Z","published":"2024-11-21T11:01:03Z","title":"Automatic brain tumor segmentation in 2D intra-operative ultrasound\n  images using magnetic resonance imaging tumor annotations","summary":"  Automatic segmentation of brain tumors in intra-operative ultrasound (iUS)\nimages could facilitate localization of tumor tissue during resection surgery.\nThe lack of large annotated datasets limits the current models performances. In\nthis paper, we investigated the use of tumor annotations in magnetic resonance\nimaging (MRI) scans, which are more accessible than annotations in iUS images,\nfor training of deep learning models for iUS brain tumor segmentation. We used\n180 annotated MRI scans with corresponding unannotated iUS images, and 29\nannotated iUS images. Image registration was performed to transfer the MRI\nannotations to the corresponding iUS images before training the nnU-Net model\nwith different configurations of the data and label origins. The results showed\nno significant difference in Dice score for a model trained with only MRI\nannotated tumors compared to models trained with only iUS annotations and both,\nand to expert annotations, indicating that MRI tumor annotations can be used as\na substitute for iUS tumor annotations to train a deep learning model for\nautomatic brain tumor segmentation in iUS images. The best model obtained an\naverage Dice score of $0.62\\pm0.31$, compared to $0.67\\pm0.25$ for an expert\nneurosurgeon, where the performance on larger tumors were similar, but lower\nfor the models on smaller tumors. In addition, the results showed that removing\nsmaller tumors from the training sets improved the results. The main models are\navailable here:\nhttps://github.com/mathildefaanes/us_brain_tumor_segmentation/tree/main\n","authors":["Mathilde Faanes","Ragnhild Holden Helland","Ole Solheim","Sébastien Muller","Ingerid Reinertsen"],"pdf_url":"https://arxiv.org/pdf/2411.14017v2.pdf","comment":"14, 5figures. This work has been submitted to the IEEE for possible\n  publication"}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2508.02602v1","updated":"2025-08-04T16:56:11Z","published":"2025-08-04T16:56:11Z","title":"Trustworthy scientific inference for inverse problems with generative\n  models","summary":"  Generative artificial intelligence (AI) excels at producing complex data\nstructures (text, images, videos) by learning patterns from training examples.\nAcross scientific disciplines, researchers are now applying generative models\nto ``inverse problems'' to infer hidden parameters from observed data. While\nthese methods can handle intractable models and large-scale studies, they can\nalso produce biased or overconfident conclusions. We present a solution with\nFrequentist-Bayes (FreB), a mathematically rigorous protocol that reshapes\nAI-generated probability distributions into confidence regions that\nconsistently include true parameters with the expected probability, while\nachieving minimum size when training and target data align. We demonstrate\nFreB's effectiveness by tackling diverse case studies in the physical sciences:\nidentifying unknown sources under dataset shift, reconciling competing\ntheoretical models, and mitigating selection bias and systematics in\nobservational studies. By providing validity guarantees with interpretable\ndiagnostics, FreB enables trustworthy scientific inference across fields where\ndirect likelihood evaluation remains impossible or prohibitively expensive.\n","authors":["James Carzon","Luca Masserano","Joshua D. Ingram","Alex Shen","Antonio Carlos Herling Ribeiro Junior","Tommaso Dorigo","Michele Doro","Joshua S. Speagle","Rafael Izbicki","Ann B. Lee"],"pdf_url":"https://arxiv.org/pdf/2508.02602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.01320v6","updated":"2025-08-04T14:51:04Z","published":"2024-06-03T13:38:18Z","title":"Convergence of the denoising diffusion probabilistic models for general\n  noise schedules","summary":"  This paper presents a theoretical convergence analysis of a denoising\ndiffusion probabilistic model (DDPM) in its original discrete-time formulation\nintroduced by Ho, Jain, and Abbeel (Advances in Neural Information Processing\nSystems}, 33 (2020), 6840-6851). We derive an explicit upper bound for the\ntotal variation distance between the sampling distribution of the discrete-time\nDDPM algorithm and a given target data distribution, under general noise\nschedule parameters. Our analysis requires only mild regularity assumptions on\nthe data distribution and a linear growth condition on the estimated score\nfunction. The sampling scheme is interpreted as an exponential-integrator-type\napproximation of a reverse-time stochastic differential equation (SDE) over a\nfinite time horizon. Tools from the Schr\\\"odinger problem are employed to\ncontrol the distributional error in reverse time and connect it to its\nforward-time counterpart. Moreover, the score function in DDPMs naturally\nappears as an adapted solution of a forward-backward SDE, providing a basis for\nanalyzing the time-discretization error in reverse-time SDE sampling.\n","authors":["Yumiharu Nakano"],"pdf_url":"https://arxiv.org/pdf/2406.01320v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16525v4","updated":"2025-08-04T14:28:05Z","published":"2024-06-24T11:01:43Z","title":"Enhancing OOD Detection Using Latent Diffusion","summary":"  Out-of-distribution (OOD) detection is crucial for the reliable deployment of\nmachine learning models in real-world scenarios, enabling the identification of\nunknown samples or objects. A prominent approach to enhance OOD detection\nperformance involves leveraging auxiliary datasets for training. Recent efforts\nhave explored using generative models, such as Stable Diffusion (SD), to\nsynthesize outlier data in the pixel space. However, synthesizing OOD data in\nthe pixel space can lead to reduced robustness due to over-generation. To\naddress this challenge, we propose Outlier-Aware Learning (OAL), a novel\nframework that generates synthetic OOD training data within the latent space,\ntaking a further step to study how to utilize Stable Diffusion for developing a\nlatent-based outlier synthesis approach. This improvement facilitates network\ntraining with fewer outliers and less computational cost. Besides, to\nregularize the model's decision boundary, we develop a mutual information-based\ncontrastive learning module (MICL) that amplifies the distinction between\nIn-Distribution (ID) and collected OOD data. Moreover, we develop a knowledge\ndistillation module to prevent the degradation of ID classification accuracy\nwhen training with OOD data. The superior performance of our method on several\nbenchmark datasets demonstrates its efficiency and effectiveness. Source code\nis available in https://github.com/HengGao12/OAL.\n","authors":["Heng Gao","Jun Li"],"pdf_url":"https://arxiv.org/pdf/2406.16525v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.02410v3","updated":"2025-08-04T13:44:01Z","published":"2025-02-04T15:29:00Z","title":"Privacy Amplification by Structured Subsampling for Deep Differentially\n  Private Time Series Forecasting","summary":"  Many forms of sensitive data, such as web traffic, mobility data, or hospital\noccupancy, are inherently sequential. The standard method for training machine\nlearning models while ensuring privacy for units of sensitive information, such\nas individual hospital visits, is differentially private stochastic gradient\ndescent (DP-SGD). However, we observe in this work that the formal guarantees\nof DP-SGD are incompatible with time series specific tasks like forecasting,\nsince they rely on the privacy amplification attained by training on small,\nunstructured batches sampled from an unstructured dataset. In contrast, batches\nfor forecasting are generated by (1) sampling sequentially structured time\nseries from a dataset, (2) sampling contiguous subsequences from these series,\nand (3) partitioning them into context and ground-truth forecast windows. We\ntheoretically analyze the privacy amplification attained by this structured\nsubsampling to enable the training of forecasting models with sound and tight\nevent- and user-level privacy guarantees. Towards more private models, we\nadditionally prove how data augmentation amplifies privacy in self-supervised\ntraining of sequence models. Our empirical evaluation demonstrates that\namplification by structured subsampling enables the training of forecasting\nmodels with strong formal privacy guarantees.\n","authors":["Jan Schuchardt","Mina Dalirrooyfard","Jed Guzelkabaagac","Anderson Schneider","Yuriy Nevmyvaka","Stephan Günnemann"],"pdf_url":"https://arxiv.org/pdf/2502.02410v3.pdf","comment":"Accepted as ICML 2025 Spotlight"},{"id":"http://arxiv.org/abs/2504.08544v2","updated":"2025-08-04T13:29:01Z","published":"2025-04-11T13:57:09Z","title":"Slicing the Gaussian Mixture Wasserstein Distance","summary":"  Gaussian mixture models (GMMs) are widely used in machine learning for tasks\nsuch as clustering, classification, image reconstruction, and generative\nmodeling. A key challenge in working with GMMs is defining a computationally\nefficient and geometrically meaningful metric. The mixture Wasserstein (MW)\ndistance adapts the Wasserstein metric to GMMs and has been applied in various\ndomains, including domain adaptation, dataset comparison, and reinforcement\nlearning. However, its high computational cost -- arising from repeated\nWasserstein distance computations involving matrix square root estimations and\nan expensive linear program -- limits its scalability to high-dimensional and\nlarge-scale problems. To address this, we propose multiple novel slicing-based\napproximations to the MW distance that significantly reduce computational\ncomplexity while preserving key optimal transport properties. From a\ntheoretical viewpoint, we establish several weak and strong equivalences\nbetween the introduced metrics, and show the relations to the original MW\ndistance and the well-established sliced Wasserstein distance. Furthermore, we\nvalidate the effectiveness of our approach through numerical experiments,\ndemonstrating computational efficiency and applications in clustering,\nperceptual image comparison, and GMM minimization\n","authors":["Moritz Piening","Robert Beinert"],"pdf_url":"https://arxiv.org/pdf/2504.08544v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.12024v3","updated":"2025-08-04T13:01:41Z","published":"2023-02-23T13:34:01Z","title":"Comparison of Affine and Rational Quadratic Spline Coupling and\n  Autoregressive Flows through Robust Statistical Tests","summary":"  Normalizing flows have emerged as a powerful brand of generative models, as\nthey not only allow for efficient sampling of complicated target distributions\nbut also deliver density estimation by construction. We propose here an\nin-depth comparison of coupling and autoregressive flows, both based on\nsymmetric (affine) and non-symmetric (rational quadratic spline) bijectors,\nconsidering four different architectures: real-valued non-Volume preserving\n(RealNVP), masked autoregressive flow (MAF), coupling rational quadratic spline\n(C-RQS), and autoregressive rational quadratic spline (A-RQS). We focus on a\nset of multimodal target distributions of increasing dimensionality ranging\nfrom 4 to 400. The performances were compared by means of different test\nstatistics for two-sample tests, built from known distance measures: the sliced\nWasserstein distance, the dimension-averaged one-dimensional\nKolmogorov--Smirnov test, and the Frobenius norm of the difference between\ncorrelation matrices. Furthermore, we included estimations of the variance of\nboth the metrics and the trained models. Our results indicate that the A-RQS\nalgorithm stands out both in terms of accuracy and training speed. Nonetheless,\nall the algorithms are generally able, without too much fine-tuning, to learn\ncomplicated distributions with limited training data and in a reasonable time\nof the order of hours on a Tesla A40 GPU. The only exception is the C-RQS,\nwhich takes significantly longer to train, does not always provide good\naccuracy, and becomes unstable for large dimensionalities. All algorithms were\nimplemented using \\textsc{TensorFlow2} and \\textsc{TensorFlow Probability} and\nhave been made available on\n\\href{https://github.com/NF4HEP/NormalizingFlowsHD}{GitHub}.\n","authors":["Andrea Coccaro","Marco Letizia","Humberto Reyes-Gonzalez","Riccardo Torre"],"pdf_url":"https://arxiv.org/pdf/2302.12024v3.pdf","comment":"v3: published version; 25 pages, 3 figures, 3 tables"},{"id":"http://arxiv.org/abs/2508.02332v1","updated":"2025-08-04T12:08:12Z","published":"2025-08-04T12:08:12Z","title":"BOOST: Bayesian Optimization with Optimal Kernel and Acquisition\n  Function Selection Technique","summary":"  The performance of Bayesian optimization (BO), a highly sample-efficient\nmethod for expensive black-box problems, is critically governed by the\nselection of its hyperparameters, including the kernel and acquisition\nfunctions. This presents a challenge: an inappropriate combination of these can\nlead to poor performance and wasted evaluations. While individual improvements\nto kernel functions (e.g., tree-based kernels, deep kernel learning) and\nacquisition functions (e.g., multi-step lookahead, tree-based planning) have\nbeen explored, the joint and autonomous selection of the best pair of these\nfundamental hyperparameters has been overlooked. This forces practitioners to\nrely on heuristics or costly manual training. We propose a simple yet effective\nframework, BOOST (Bayesian Optimization with Optimal Kernel and Acquisition\nFunction Selection Technique), that automates this selection. BOOST utilizes a\nlightweight, offline evaluation stage to predict the performance of various\nkernel-acquisition function pairs and identify the most suitable configuration\nbefore expensive evaluations. BOOST partitions data-in-hand into two subsets: a\nreference subset and a query subset, and it prepares all possible\nkernel-acquisition pairs from the user's chosen candidates. For each\nconfiguration, BOOST conducts internal BO runs using the reference subset,\nevaluating how effectively each pair guides the search toward the optimum in\nthe unknown query subset, thereby identifying the configuration with the best\nretrospective performance for future optimization. Experiments on both\nsynthetic benchmark functions and real-world hyperparameter optimization tasks\ndemonstrate that BOOST consistently outperforms standard BO approaches with\nfixed hyperparameters, highlighting its effectiveness and robustness in diverse\nproblem landscapes.\n","authors":["Joon-Hyun Park","Mujin Cheon","Dong-Yeun Koh"],"pdf_url":"https://arxiv.org/pdf/2508.02332v1.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2508.02275v1","updated":"2025-08-04T10:42:52Z","published":"2025-08-04T10:42:52Z","title":"Comparing Generative Models with the New Physics Learning Machine","summary":"  The rise of generative models for scientific research calls for the\ndevelopment of new methods to evaluate their fidelity. A natural framework for\naddressing this problem is two-sample hypothesis testing, namely the task of\ndetermining whether two data sets are drawn from the same distribution. In\nlarge-scale and high-dimensional regimes, machine learning offers a set of\ntools to push beyond the limitations of standard statistical techniques. In\nthis work, we put this claim to the test by comparing a recent proposal from\nthe high-energy physics literature, the New Physics Learning Machine, to\nperform a classification-based two-sample test against a number of alternative\napproaches, following the framework presented in Grossi et al. (2025). We\nhighlight the efficiency tradeoffs of the method and the computational costs\nthat come from adopting learning-based approaches. Finally, we discuss the\nadvantages of the different methods for different use cases.\n","authors":["Samuele Grossi","Marco Letizia","Riccardo Torre"],"pdf_url":"https://arxiv.org/pdf/2508.02275v1.pdf","comment":"v1: 14 pages, 7 figures, 8 tables, additional material on GitHub\n  referenced in the paper"},{"id":"http://arxiv.org/abs/2410.16716v2","updated":"2025-08-04T07:53:20Z","published":"2024-10-22T05:53:25Z","title":"A class of modular and flexible covariate-based covariance functions for\n  nonstationary spatial modeling","summary":"  The assumptions of stationarity and isotropy often stated over spatial\nprocesses have not aged well during the last two decades, partly explained by\nthe combination of computational developments and the increasing availability\nof high-resolution spatial data. While a plethora of approaches have been\ndeveloped to relax these assumptions, it is often a costly tradeoff between\nflexibility and a diversity of computational challenges. In this paper, we\npresent a class of covariance functions that relies on fixed, observable\nspatial information that provides a convenient tradeoff while offering an extra\nlayer of numerical and visual representation of the flexible spatial\ndependencies. This model allows for separate parametric structures for\ndifferent sources of nonstationarity, such as marginal standard deviation,\ngeometric anisotropy, and smoothness. It simplifies to a Mat\\'ern covariance\nfunction in its basic form and is adaptable for large datasets, enhancing\nflexibility and computational efficiency. We analyze the capabilities of the\npresented model through simulation studies and an application to Swiss\nprecipitation data.\n","authors":["Federico Blasi","Reinhard Furrer"],"pdf_url":"https://arxiv.org/pdf/2410.16716v2.pdf","comment":"20 pages, 11 figures"},{"id":"http://arxiv.org/abs/2508.02126v1","updated":"2025-08-04T07:15:57Z","published":"2025-08-04T07:15:57Z","title":"Understanding Learning Dynamics Through Structured Representations","summary":"  While modern deep networks have demonstrated remarkable versatility, their\ntraining dynamics remain poorly understood--often driven more by empirical\ntweaks than architectural insight. This paper investigates how internal\nstructural choices shape the behavior of learning systems. Building on prior\nefforts that introduced simple architectural constraints, we explore the\nbroader implications of structure for convergence, generalization, and\nadaptation. Our approach centers on a family of enriched transformation layers\nthat incorporate constrained pathways and adaptive corrections. We analyze how\nthese structures influence gradient flow, spectral sensitivity, and fixed-point\nbehavior--uncovering mechanisms that contribute to training stability and\nrepresentational regularity. Theoretical analysis is paired with empirical\nstudies on synthetic and structured tasks, demonstrating improved robustness,\nsmoother optimization, and scalable depth behavior. Rather than prescribing\nfixed templates, we emphasize principles of tractable design that can steer\nlearning behavior in interpretable ways. Our findings support a growing view\nthat architectural design is not merely a matter of performance tuning, but a\ncritical axis for shaping learning dynamics in scalable and trustworthy neural\nsystems.\n","authors":["Saleh Nikooroo","Thomas Engel"],"pdf_url":"https://arxiv.org/pdf/2508.02126v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02123v1","updated":"2025-08-04T07:04:58Z","published":"2025-08-04T07:04:58Z","title":"Understanding the Essence: Delving into Annotator Prototype Learning for\n  Multi-Class Annotation Aggregation","summary":"  Multi-class classification annotations have significantly advanced AI\napplications, with truth inference serving as a critical technique for\naggregating noisy and biased annotations. Existing state-of-the-art methods\ntypically model each annotator's expertise using a confusion matrix. However,\nthese methods suffer from two widely recognized issues: 1) when most annotators\nlabel only a few tasks, or when classes are imbalanced, the estimated confusion\nmatrices are unreliable, and 2) a single confusion matrix often remains\ninadequate for capturing each annotator's full expertise patterns across all\ntasks. To address these issues, we propose a novel confusion-matrix-based\nmethod, PTBCC (ProtoType learning-driven Bayesian Classifier Combination), to\nintroduce a reliable and richer annotator estimation by prototype learning.\nSpecifically, we assume that there exists a set $S$ of prototype confusion\nmatrices, which capture the inherent expertise patterns of all annotators.\nRather than a single confusion matrix, the expertise per annotator is extended\nas a Dirichlet prior distribution over these prototypes. This prototype\nlearning-driven mechanism circumvents the data sparsity and class imbalance\nissues, ensuring a richer and more flexible characterization of annotators.\nExtensive experiments on 11 real-world datasets demonstrate that PTBCC achieves\nup to a 15% accuracy improvement in the best case, and a 3% higher average\naccuracy while reducing computational cost by over 90%.\n","authors":["Ju Chen","Jun Feng","Shenyu Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.02123v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02103v1","updated":"2025-08-04T06:25:45Z","published":"2025-08-04T06:25:45Z","title":"Instance-Dependent Continuous-Time Reinforcement Learning via Maximum\n  Likelihood Estimation","summary":"  Continuous-time reinforcement learning (CTRL) provides a natural framework\nfor sequential decision-making in dynamic environments where interactions\nevolve continuously over time. While CTRL has shown growing empirical success,\nits ability to adapt to varying levels of problem difficulty remains poorly\nunderstood. In this work, we investigate the instance-dependent behavior of\nCTRL and introduce a simple, model-based algorithm built on maximum likelihood\nestimation (MLE) with a general function approximator. Unlike existing\napproaches that estimate system dynamics directly, our method estimates the\nstate marginal density to guide learning. We establish instance-dependent\nperformance guarantees by deriving a regret bound that scales with the total\nreward variance and measurement resolution. Notably, the regret becomes\nindependent of the specific measurement strategy when the observation frequency\nadapts appropriately to the problem's complexity. To further improve\nperformance, our algorithm incorporates a randomized measurement schedule that\nenhances sample efficiency without increasing measurement cost. These results\nhighlight a new direction for designing CTRL algorithms that automatically\nadjust their learning behavior based on the underlying difficulty of the\nenvironment.\n","authors":["Runze Zhao","Yue Yu","Ruhan Wang","Chunfeng Huang","Dongruo Zhou"],"pdf_url":"https://arxiv.org/pdf/2508.02103v1.pdf","comment":"32 pages, 3 figures, 1 table. The first two authors contributed\n  equally"},{"id":"http://arxiv.org/abs/2412.13527v2","updated":"2025-08-04T04:42:45Z","published":"2024-12-18T06:09:00Z","title":"Lyapunov Analysis For Monotonically Forward-Backward Accelerated\n  Algorithms","summary":"  In the realm of gradient-based optimization, Nesterov's accelerated gradient\nmethod (NAG) is a landmark advancement, achieving an accelerated convergence\nrate that outperforms the vanilla gradient descent method for convex function.\nHowever, for strongly convex functions, whether NAG converges linearly remains\nan open question, as noted in the comprehensive review by Chambolle and Pock\n[2016]. This issue, aside from the critical step size, was addressed by Li et\nal. [2024a] using a high-resolution differential equation framework.\nFurthermore, Beck [2017, Section 10.7.4] introduced a monotonically convergent\nvariant of NAG, referred to as M-NAG. Despite these developments, the Lyapunov\nanalysis presented in [Li et al., 2024a] cannot be directly extended to M-NAG.\nIn this paper, we propose a modification to the iterative relation by\nintroducing a gradient term, leading to a new gradient-based iterative\nrelation. This adjustment allows for the construction of a novel Lyapunov\nfunction that excludes kinetic energy. The linear convergence derived from this\nLyapunov function is independent of both the parameters of the strongly convex\nfunctions and the step size, yielding a more general and robust result.\nNotably, we observe that the gradient iterative relation derived from M-NAG is\nequivalent to that from NAG when the position-velocity relation is applied.\nHowever, the Lyapunov analysis does not rely on the position-velocity relation,\nallowing us to extend the linear convergence to M-NAG. Finally, by utilizing\ntwo proximal inequalities, which serve as the proximal counterparts of strongly\nconvex inequalities, we extend the linear convergence to both the fast\niterative shrinkage-thresholding algorithm (FISTA) and its monotonic\ncounterpart (M-FISTA).\n","authors":["Mingwei Fu","Bin Shi"],"pdf_url":"https://arxiv.org/pdf/2412.13527v2.pdf","comment":"20 pages, 4 figures, and 1 table"},{"id":"http://arxiv.org/abs/2007.03545v2","updated":"2025-08-04T04:34:07Z","published":"2020-07-07T15:22:54Z","title":"Network Embedding with Completely-imbalanced Labels","summary":"  Network embedding, aiming to project a network into a low-dimensional space,\nis increasingly becoming a focus of network research. Semi-supervised network\nembedding takes advantage of labeled data, and has shown promising performance.\nHowever, existing semi-supervised methods would get unappealing results in the\ncompletely-imbalanced label setting where some classes have no labeled nodes at\nall. To alleviate this, we propose two novel semi-supervised network embedding\nmethods. The first one is a shallow method named RSDNE. Specifically, to\nbenefit from the completely-imbalanced labels, RSDNE guarantees both\nintra-class similarity and inter-class dissimilarity in an approximate way. The\nother method is RECT which is a new class of graph neural networks. Different\nfrom RSDNE, to benefit from the completely-imbalanced labels, RECT explores the\nclass-semantic knowledge. This enables RECT to handle networks with node\nfeatures and multi-label setting. Experimental results on several real-world\ndatasets demonstrate the superiority of the proposed methods. Code is available\nat https://github.com/zhengwang100/RECT.\n","authors":["Zheng Wang","Xiaojun Ye","Chaokun Wang","Jian Cui","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2007.03545v2.pdf","comment":"A preliminary version of this work was accepted in AAAI 2018. This\n  version has been accepted in IEEE Transactions on Knowledge and Data\n  Engineering (TKDE) 2020. Project page:\n  https://zhengwang100.github.io/project/zero_shot_graph_embedding.html"},{"id":"http://arxiv.org/abs/2508.02039v1","updated":"2025-08-04T04:11:40Z","published":"2025-08-04T04:11:40Z","title":"Model Recycling Framework for Multi-Source Data-Free Supervised Transfer\n  Learning","summary":"  Increasing concerns for data privacy and other difficulties associated with\nretrieving source data for model training have created the need for source-free\ntransfer learning, in which one only has access to pre-trained models instead\nof data from the original source domains. This setting introduces many\nchallenges, as many existing transfer learning methods typically rely on access\nto source data, which limits their direct applicability to scenarios where\nsource data is unavailable. Further, practical concerns make it more difficult,\nfor instance efficiently selecting models for transfer without information on\nsource data, and transferring without full access to the source models. So\nmotivated, we propose a model recycling framework for parameter-efficient\ntraining of models that identifies subsets of related source models to reuse in\nboth white-box and black-box settings. Consequently, our framework makes it\npossible for Model as a Service (MaaS) providers to build libraries of\nefficient pre-trained models, thus creating an opportunity for multi-source\ndata-free supervised transfer learning.\n","authors":["Sijia Wang","Ricardo Henao"],"pdf_url":"https://arxiv.org/pdf/2508.02039v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01975v1","updated":"2025-08-04T01:26:06Z","published":"2025-08-04T01:26:06Z","title":"Diffusion models for inverse problems","summary":"  Using diffusion priors to solve inverse problems in imaging have\nsignificantly matured over the years. In this chapter, we review the various\ndifferent approaches that were proposed over the years. We categorize the\napproaches into the more classic explicit approximation approaches and others,\nwhich include variational inference, sequential monte carlo, and decoupled data\nconsistency. We cover the extension to more challenging situations, including\nblind cases, high-dimensional data, and problems under data scarcity and\ndistribution mismatch. More recent approaches that aim to leverage multimodal\ninformation through texts are covered. Through this chapter, we aim to (i)\ndistill the common mathematical threads that connect these algorithms, (ii)\nsystematically contrast their assumptions and performance trade-offs across\nrepresentative inverse problems, and (iii) spotlight the open theoretical and\npractical challenges by clarifying the landscape of diffusion model based\ninverse problem solvers.\n","authors":["Hyungjin Chung","Jeongsol Kim","Jong Chul Ye"],"pdf_url":"https://arxiv.org/pdf/2508.01975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02924v1","updated":"2025-08-04T21:54:16Z","published":"2025-08-04T21:54:16Z","title":"BoostTransformer: Enhancing Transformer Models with Subgrid Selection\n  and Importance Sampling","summary":"  Transformer architectures dominate modern NLP but often demand heavy\ncomputational resources and intricate hyperparameter tuning. To mitigate these\nchallenges, we propose a novel framework, BoostTransformer, that augments\ntransformers with boosting principles through subgrid token selection and\nimportance-weighted sampling. Our method incorporates a least square boosting\nobjective directly into the transformer pipeline, enabling more efficient\ntraining and improved performance. Across multiple fine-grained text\nclassification benchmarks, BoostTransformer demonstrates both faster\nconvergence and higher accuracy, surpassing standard transformers while\nminimizing architectural search overhead.\n","authors":["Biyi Fang","Jean Utke","Truong Vo","Diego Klabjan"],"pdf_url":"https://arxiv.org/pdf/2508.02924v1.pdf","comment":"10 pages, 5 figures, submitted for review at a major machine learning\n  conference. arXiv admin note: substantial text overlap with arXiv:2203.00761,\n  arXiv:2507.22842"},{"id":"http://arxiv.org/abs/2504.21120v2","updated":"2025-08-04T21:12:23Z","published":"2025-04-29T18:59:58Z","title":"A Hybrid Mixture of $t$-Factor Analyzers for Clustering High-dimensional\n  Data","summary":"  This paper develops a novel hybrid approach for estimating the mixture model\nof $t$-factor analyzers (MtFA) that employs multivariate $t$-distribution and\nfactor model to cluster and characterize grouped data. The traditional\nestimation method for MtFA faces computational challenges, particularly in\nhigh-dimensional settings, where the eigendecomposition of large covariance\nmatrices and the iterative nature of Expectation-Maximization (EM) algorithms\nlead to scalability issues. We propose a computational scheme that integrates a\nprofile likelihood method into the EM framework to efficiently obtain the model\nparameter estimates. The effectiveness of our approach is demonstrated through\nsimulations showcasing its superior computational efficiency compared to the\nexisting method, while preserving clustering accuracy and resilience against\noutliers. Our method is applied to cluster the Gamma-ray bursts, reinforcing\nseveral claims in the literature that Gamma-ray bursts have heterogeneous\nsubpopulations and providing characterizations of the estimated groups.\n","authors":["Kazeem Kareem","Fan Dai"],"pdf_url":"https://arxiv.org/pdf/2504.21120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2202.05063v3","updated":"2025-08-04T20:32:14Z","published":"2022-02-10T14:42:51Z","title":"PCENet: High Dimensional Surrogate Modeling for Learning Uncertainty","summary":"  Learning data representations under uncertainty is an important task that\nemerges in numerous scientific computing and data analysis applications.\nHowever, uncertainty quantification techniques are computationally intensive\nand become prohibitively expensive for high-dimensional data. In this study, we\nintroduce a dimensionality reduction surrogate modeling (DRSM) approach for\nrepresentation learning and uncertainty quantification that aims to deal with\ndata of moderate to high dimensions. The approach involves a two-stage learning\nprocess: 1) employing a variational autoencoder to learn a low-dimensional\nrepresentation of the input data distribution; and 2) harnessing polynomial\nchaos expansion (PCE) formulation to map the low dimensional distribution to\nthe output target. The model enables us to (a) capture the system dynamics\nefficiently in the low-dimensional latent space, (b) learn under uncertainty, a\nrepresentation of the data and a mapping between input and output\ndistributions, (c) estimate this uncertainty in the high-dimensional data\nsystem, and (d) match high-order moments of the output distribution; without\nany prior statistical assumptions on the data. Numerical results are presented\nto illustrate the performance of the proposed method.\n","authors":["Paz Fink Shustin","Shashanka Ubaru","Małgorzata J. Zimoń","Songtao Lu","Vasileios Kalantzis","Lior Horesh","Haim Avron"],"pdf_url":"https://arxiv.org/pdf/2202.05063v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02874v1","updated":"2025-08-04T20:03:13Z","published":"2025-08-04T20:03:13Z","title":"Beyond Least Squares: Robust Regression Transformer (R2T)","summary":"  Robust regression techniques rely on least-squares optimization, which works\nwell for Gaussian noise but fails in the presence of asymmetric structured\nnoise. We propose a hybrid neural-symbolic architecture where a transformer\nencoder processes numerical sequences, a compression NN predicts symbolic\nparameters, and a fixed symbolic equation reconstructs the original sequence.\nUsing synthetic data, the training objective is to recover the original\nsequence after adding asymmetric structured noise, effectively learning a\nsymbolic fit guided by neural parameter estimation. Our model achieves a median\nregression MSE of 6e-6 to 3.5e-5 on synthetic wearable data, which is a 10-300\ntimes improvement when compared with ordinary least squares fit and robust\nregression techniques such as Huber loss or SoftL1.\n","authors":["Roman Gutierrez","Tony Kai Tang","Isabel Gutierrez"],"pdf_url":"https://arxiv.org/pdf/2508.02874v1.pdf","comment":"10 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2502.19851v2","updated":"2025-08-04T19:59:25Z","published":"2025-02-27T07:50:24Z","title":"Can a calibration metric be both testable and actionable?","summary":"  Forecast probabilities often serve as critical inputs for binary decision\nmaking. In such settings, calibration$\\unicode{x2014}$ensuring forecasted\nprobabilities match empirical frequencies$\\unicode{x2014}$is essential.\nAlthough the common notion of Expected Calibration Error (ECE) provides\nactionable insights for decision making, it is not testable: it cannot be\nempirically estimated in many practical cases. Conversely, the recently\nproposed Distance from Calibration (dCE) is testable, but it is not actionable\nsince it lacks decision-theoretic guarantees needed for high-stakes\napplications. To resolve this question, we consider Cutoff Calibration Error, a\ncalibration measure that bridges this gap by assessing calibration over\nintervals of forecasted probabilities. We show that Cutoff Calibration Error is\nboth testable and actionable, and we examine its implications for popular\npost-hoc calibration methods, such as isotonic regression and Platt scaling.\n","authors":["Raphael Rossellini","Jake A. Soloff","Rina Foygel Barber","Zhimei Ren","Rebecca Willett"],"pdf_url":"https://arxiv.org/pdf/2502.19851v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16716v2","updated":"2025-08-04T07:53:20Z","published":"2024-10-22T05:53:25Z","title":"A class of modular and flexible covariate-based covariance functions for\n  nonstationary spatial modeling","summary":"  Paradoxically, while the assumptions of second-order stationarity and\nisotropy appear outdated in light of modern spatial data, they remain\nremarkably robust in practice, as nonstationary methods often provide marginal\nimprovements in predictive performance. This limitation reflects a fundamental\ntrade-off: nonparametric approaches, while offering extreme flexibility,\nrequire substantial tuning to avoid overfitting and numerical challenges in\npractice, while parametric approaches are more robust against overfitting but\nare constrained in flexibility, often facing considerable numerical challenges\nas flexibility increases. In this article we introduce a parametric class of\ncovariance functions that extends the use of parametric nonstationary spatial\nmodels, aiming to compete with the flexibility and local adaptability of\nnonparametric approaches. The covariance function is modular in the sense that\nallows for separate parametric structures for different sources of\nnonstationarity, such as marginal standard deviation, geometric anisotropy, and\nsmoothness. The proposed covariance function retains the practical\nidentifiability and computational stability of parametric forms while closing\nthe performance gap with fully nonparametric methods. A Mat\\'ern stationary\nisotropic model is nested within the complex model and can be adapted such that\nit is computationally feasible for handling thousands of observations. A\ntwo-stage approach can be employed for model selection. We explore the\nstatistical properties of the presented approach, demonstrate its compatibility\nwith the frequentist paradigm, and highlight the interpretability of its\nparameters. We illustrate its prediction capabilities as well as\ninterpretability through an analysis of Swiss monthly precipitation data,\nshowing that Gaussian process models with the presented covariance function,\nwhile remaining robust against overfitting, provide quantitative and\nqualitative improvements over existing approaches.\n","authors":["Federico Blasi","Reinhard Furrer"],"pdf_url":"https://arxiv.org/pdf/2410.16716v2.pdf","comment":"20 pages, 11 figures"}],"Computation":[{"id":"http://arxiv.org/abs/2508.02337v1","updated":"2025-08-04T12:20:17Z","published":"2025-08-04T12:20:17Z","title":"Posterior Sampling of Probabilistic Word Embeddings","summary":"  Quantifying uncertainty in word embeddings is crucial for reliable inference\nfrom textual data. However, existing Bayesian methods such as Hamiltonian Monte\nCarlo (HMC) and mean-field variational inference (MFVI) are either\ncomputationally infeasible for large data or rely on restrictive assumptions.\n  We propose a scalable Gibbs sampler using Polya-Gamma augmentation as well as\nLaplace approximation and compare them with MFVI and HMC for word embeddings.\nIn addition, we address non-identifiability in word embeddings. Our Gibbs\nsampler and HMC correctly estimate uncertainties, while MFVI does not, and\nLaplace approximation only does so on large sample sizes, as expected. Applying\nthe Gibbs sampler to the US Congress and the Movielens datasets, we demonstrate\nthe feasibility on larger real data. Finally, as a result of having draws from\nthe full posterior, we show that the posterior mean of word embeddings improves\nover maximum a posteriori (MAP) estimates in terms of hold-out likelihood,\nespecially for smaller sampling sizes, further strengthening the need for\nposterior sampling of word embeddings.\n","authors":["Väinö Yrjänäinen","Isac Boström","Måns Magnusson","Johan Jonasson"],"pdf_url":"https://arxiv.org/pdf/2508.02337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.16385v2","updated":"2025-08-04T10:07:01Z","published":"2024-12-20T22:41:16Z","title":"Collision-based Dynamics for Multi-Marginal Optimal Transport","summary":"  Inspired by the Boltzmann kinetics, we propose a collision-based dynamics\nwith a Monte Carlo solution algorithm that approximates the solution of the\nmulti-marginal optimal transport problem via randomized pairwise swapping of\nsample indices. The computational complexity and memory usage of the proposed\nmethod scale linearly with the number of samples, making it highly attractive\nfor high-dimensional settings. In several examples, we demonstrate the\nefficiency of the proposed method compared to the state-of-the-art methods.\n","authors":["Mohsen Sadr","Hossein Gorji"],"pdf_url":"https://arxiv.org/pdf/2412.16385v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02223v1","updated":"2025-08-04T09:14:06Z","published":"2025-08-04T09:14:06Z","title":"The ECME Algorithm Using Factor Analysis for DOA Estimation in\n  Nonuniform Noise","summary":"  Maximum likelihood factor analysis has been used for direction of arrival\nestimation in unknown nonuniform noise and some iterative approaches have been\ndeveloped. In particular, the Factor Analysis for Anisotropic Noise (FAAN)\nmethod proposed by Stoica and Babu has excellent convergence properties. In\nthis letter, the Expectation/Conditional Maximization Either (ECME) algorithm,\nan extension of the expectation-maximization algorithm, is designed, which has\nalmost the same computational complexity at each iteration as the FAAN method.\nHowever, numerical results show that the ECME algorithm yields faster stable\nconvergence and is computationally more efficient.\n","authors":["Mingyan Gong"],"pdf_url":"https://arxiv.org/pdf/2508.02223v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2508.01988v1","updated":"2025-08-04T02:00:48Z","published":"2025-08-04T02:00:48Z","title":"Decision Theory For Large Scale Outlier Detection Using Aleatoric\n  Uncertainty: With a Note on Bayesian FDR","summary":"  Aleatoric and Epistemic uncertainty have achieved recent attention in the\nliterature as different sources from which uncertainty can emerge in stochastic\nmodeling. Epistemic being intrinsic or model based notions of uncertainty, and\naleatoric being the uncertainty inherent in the data. We propose a novel\ndecision theoretic framework for outlier detection in the context of aleatoric\nuncertainty; in the context of Bayesian modeling. The model incorporates\nbayesian false discovery rate control for multiplicty adjustment, and a new\ngeneralization of Bayesian FDR is introduced. The model is applied to\nsimulations based on temporally fluctuating outlier detection where fixing\nthresholds often results in poor performance due to nonstationarity, and a case\nstudy is outlined on on a novel cybersecurity detection. Cyberthreat signals\nare highly nonstationary; giving a credible stress test of the model.\n","authors":["Ryan Warnick"],"pdf_url":"https://arxiv.org/pdf/2508.01988v1.pdf","comment":"14 pages, 14 figures, preprint"},{"id":"http://arxiv.org/abs/2508.02945v1","updated":"2025-08-04T23:02:01Z","published":"2025-08-04T23:02:01Z","title":"LLM-based IR-system for Bank Supervisors","summary":"  Bank supervisors face the complex task of ensuring that new measures are\nconsistently aligned with historical precedents. To address this challenge, we\nintroduce a novel Information Retrieval (IR) System tailored to assist\nsupervisors in drafting both consistent and effective measures. This system\ningests findings from on-site investigations. It then retrieves the most\nrelevant historical findings and their associated measures from a comprehensive\ndatabase, providing a solid basis for supervisors to write well-informed\nmeasures for new findings. Utilizing a blend of lexical, semantic, and Capital\nRequirements Regulation (CRR) fuzzy set matching techniques, the IR system\nensures the retrieval of findings that closely align with current cases. The\nperformance of this system, particularly in scenarios with partially labeled\ndata, is validated through a Monte Carlo methodology, showcasing its robustness\nand accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for\nfine-tuning, the final model achieves a Mean Average Precision (MAP@100) of\n0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those\nof both standalone lexical models such as BM25 and semantic BERT-like models.\n","authors":["Ilias Aarab"],"pdf_url":"https://arxiv.org/pdf/2508.02945v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.21120v2","updated":"2025-08-04T21:12:23Z","published":"2025-04-29T18:59:58Z","title":"A Hybrid Mixture of $t$-Factor Analyzers for Clustering High-dimensional\n  Data","summary":"  This paper develops a novel hybrid approach for estimating the mixture model\nof $t$-factor analyzers (MtFA) that employs multivariate $t$-distribution and\nfactor model to cluster and characterize grouped data. The traditional\nestimation method for MtFA faces computational challenges, particularly in\nhigh-dimensional settings, where the eigendecomposition of large covariance\nmatrices and the iterative nature of Expectation-Maximization (EM) algorithms\nlead to scalability issues. We propose a computational scheme that integrates a\nprofile likelihood method into the EM framework to efficiently obtain the model\nparameter estimates. The effectiveness of our approach is demonstrated through\nsimulations showcasing its superior computational efficiency compared to the\nexisting method, while preserving clustering accuracy and resilience against\noutliers. Our method is applied to cluster the Gamma-ray bursts, reinforcing\nseveral claims in the literature that Gamma-ray bursts have heterogeneous\nsubpopulations and providing characterizations of the estimated groups.\n","authors":["Kazeem Kareem","Fan Dai"],"pdf_url":"https://arxiv.org/pdf/2504.21120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02888v1","updated":"2025-08-04T20:34:30Z","published":"2025-08-04T20:34:30Z","title":"Precision Profile Weighted Deming Regression for Methods Comparison","summary":"  Errors in variables (Deming) regression of measurements spanning a wide range\nof values requires appropriate weighting to reflect nonconstant variance.\nPrecision profile models, mathematical relationships between measurement\nvariance and mean, are a route to these weights. The paper describes a\nmethodology combining general precision profile models with Deming regression\nand described R routines for the resulting calculations.\n","authors":["Douglas M Hawkins","Jessica J Kraker"],"pdf_url":"https://arxiv.org/pdf/2508.02888v1.pdf","comment":"30 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.02763v1","updated":"2025-08-04T03:02:09Z","published":"2025-08-04T03:02:09Z","title":"Polynomial complexity sampling from multimodal distributions using\n  Sequential Monte Carlo","summary":"  We study a sequential Monte Carlo algorithm to sample from the Gibbs measure\nwith a non-convex energy function at a low temperature. We use the practical\nand popular geometric annealing schedule, and use a Langevin diffusion at each\ntemperature level. The Langevin diffusion only needs to run for a time that is\nlong enough to ensure local mixing within energy valleys, which is much shorter\nthan the time required for global mixing. Our main result shows convergence of\nMonte Carlo estimators with time complexity that, approximately, scales like\nthe forth power of the inverse temperature, and the square of the inverse\nallowed error. We also study this algorithm in an illustrative model scenario\nwhere more explicit estimates can be given.\n","authors":["Ruiyu Han","Gautam Iyer","Dejan Slepčev"],"pdf_url":"https://arxiv.org/pdf/2508.02763v1.pdf","comment":"58 pages, 5 figures"}]},"2025-08-03T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2508.01867v1","updated":"2025-08-03T17:45:04Z","published":"2025-08-03T17:45:04Z","title":"Counterfactual Reciprocal Recommender Systems for User-to-User Matching","summary":"  Reciprocal recommender systems (RRS) in dating, gaming, and talent platforms\nrequire mutual acceptance for a match. Logged data, however, over-represents\npopular profiles due to past exposure policies, creating feedback loops that\nskew learning and fairness. We introduce Counterfactual Reciprocal Recommender\nSystems (CFRR), a causal framework to mitigate this bias. CFRR uses inverse\npropensity scored, self-normalized objectives. Experiments show CFRR improves\nNDCG@10 by up to 3.5% (e.g., from 0.459 to 0.475 on DBLP, from 0.299 to 0.307\non Synthetic), increases long-tail user coverage by up to 51% (from 0.504 to\n0.763 on Synthetic), and reduces Gini exposure inequality by up to 24% (from\n0.708 to 0.535 on Synthetic). CFRR offers a promising approach for more\naccurate and fair user-to-user matching.\n","authors":["Kazuki Kawamura","Takuma Udagawa","Kei Tateno"],"pdf_url":"https://arxiv.org/pdf/2508.01867v1.pdf","comment":"9 pages, 2 figures. Accepted for publication at the Workshop on\n  Two-sided Marketplace Optimization (TSMO '25), held in conjunction with the\n  31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD 2025),\n  Toronto, Canada"},{"id":"http://arxiv.org/abs/2503.03687v2","updated":"2025-08-03T08:19:53Z","published":"2025-03-05T17:28:16Z","title":"Fine-grained Alignment of Large Language Models for General Medication\n  Recommendation without Overprescription","summary":"  Large language models (LLMs) holds significant promise in achieving general\nmedication recommendation systems owing to their comprehensive interpretation\nof clinical notes and flexibility to medication encoding. We evaluated both\ngeneral-purpose and medical-specific LLMs for medication recommendations,\nshowing their unsatisfactory precision and severe overprescription. To address\nthis, we introduce Language-Assisted Medication Recommendation, which tailors\nLLMs for medication recommendation in a medication-aware manner, improving the\nusage of clinical notes. Fine-tuning LLMs with this framework can outperform\nexisting methods by more than 10% in internal validation and generalize across\ntemporal and external validations. Furthermore, the model maintains high\naccuracy when encountering out-of-distribution medication.\n","authors":["Zihao Zhao","Chenxiao Fan","Junlong Liu","Zheng Wang","Xiangnan He","Chongming Gao","Juan Li","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2503.03687v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01643v1","updated":"2025-08-03T08:04:44Z","published":"2025-08-03T08:04:44Z","title":"ChEmbed: Enhancing Chemical Literature Search Through Domain-Specific\n  Text Embeddings","summary":"  Retrieval-Augmented Generation (RAG) systems in chemistry heavily depend on\naccurate and relevant retrieval of chemical literature. However,\ngeneral-purpose text embedding models frequently fail to adequately represent\ncomplex chemical terminologies, resulting in suboptimal retrieval quality.\nSpecialized embedding models tailored to chemical literature retrieval have not\nyet been developed, leaving a substantial performance gap. To address this\nchallenge, we introduce ChEmbed, a domain-adapted family of text embedding\nmodels fine-tuned on a dataset comprising chemistry-specific text from the\nPubChem, Semantic Scholar, and ChemRxiv corpora. To create effective training\ndata, we employ large language models to synthetically generate queries,\nresulting in approximately 1.7 million high-quality query-passage pairs.\nAdditionally, we augment the tokenizer by adding 900 chemically specialized\ntokens to previously unused slots, which significantly reduces the\nfragmentation of chemical entities, such as IUPAC names. ChEmbed also maintains\na 8192-token context length, enabling the efficient retrieval of longer\npassages compared to many other open-source embedding models, which typically\nhave a context length of 512 or 2048 tokens. Evaluated on our newly introduced\nChemRxiv Retrieval benchmark, ChEmbed outperforms state-of-the-art general\nembedding models, raising nDCG@10 from 0.82 to 0.91 (+9 pp). ChEmbed represents\na practical, lightweight, and reproducible embedding solution that effectively\nimproves retrieval for chemical literature search.\n","authors":["Ali Shiraee Kasmaee","Mohammad Khodadad","Mehdi Astaraki","Mohammad Arshi Saloot","Nicholas Sherck","Hamidreza Mahyar","Soheila Samiee"],"pdf_url":"https://arxiv.org/pdf/2508.01643v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.08445v2","updated":"2025-08-03T05:07:40Z","published":"2025-07-11T09:36:45Z","title":"Clue-RAG: Towards Accurate and Cost-Efficient Graph-based RAG via\n  Multi-Partite Graph and Query-Driven Iterative Retrieval","summary":"  Despite the remarkable progress of Large Language Models (LLMs), their\nperformance in question answering (QA) remains limited by the lack of\ndomain-specific and up-to-date knowledge. Retrieval-Augmented Generation (RAG)\naddresses this limitation by incorporating external information, often from\ngraph-structured data. However, existing graph-based RAG methods suffer from\npoor graph quality due to incomplete extraction and insufficient utilization of\nquery information during retrieval. To overcome these limitations, we propose\nClue-RAG, a novel approach that introduces (1) a multi-partite graph index\nincorporates Chunk, knowledge unit, and entity to capture semantic content at\nmultiple levels of granularity, coupled with a hybrid extraction strategy that\nreduces LLM token usage while still producing accurate and disambiguated\nknowledge units, and (2) Q-Iter, a query-driven iterative retrieval strategy\nthat enhances relevance through semantic search and constrained graph\ntraversal. Experiments on three QA benchmarks show that Clue-RAG significantly\noutperforms state-of-the-art baselines, achieving up to 99.33% higher Accuracy\nand 113.51% higher F1 score while reducing indexing costs by 72.58%.\nRemarkably, Clue-RAG matches or outperforms baselines even without using an LLM\nfor indexing. These results demonstrate the effectiveness and cost-efficiency\nof Clue-RAG in advancing graph-based RAG systems.\n","authors":["Yaodong Su","Yixiang Fang","Yingli Zhou","Quanqing Xu","Chuanhui Yang"],"pdf_url":"https://arxiv.org/pdf/2507.08445v2.pdf","comment":null}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2508.01957v1","updated":"2025-08-03T23:48:46Z","published":"2025-08-03T23:48:46Z","title":"Stochastic Encodings for Active Feature Acquisition","summary":"  Active Feature Acquisition is an instance-wise, sequential decision making\nproblem. The aim is to dynamically select which feature to measure based on\ncurrent observations, independently for each test instance. Common approaches\neither use Reinforcement Learning, which experiences training difficulties, or\ngreedily maximize the conditional mutual information of the label and\nunobserved features, which makes myopic acquisitions. To address these\nshortcomings, we introduce a latent variable model, trained in a supervised\nmanner. Acquisitions are made by reasoning about the features across many\npossible unobserved realizations in a stochastic latent space. Extensive\nevaluation on a large range of synthetic and real datasets demonstrates that\nour approach reliably outperforms a diverse set of baselines.\n","authors":["Alexander Norcliffe","Changhee Lee","Fergus Imrie","Mihaela van der Schaar","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2508.01957v1.pdf","comment":"31 pages, 15 figures, 17 tables, published at ICML 2025"},{"id":"http://arxiv.org/abs/2406.16306v3","updated":"2025-08-03T22:12:55Z","published":"2024-06-24T04:08:35Z","title":"Cascade Reward Sampling for Efficient Decoding-Time Alignment","summary":"  Aligning large language models (LLMs) with human preferences is essential for\ntheir applications. Recently, decoding-time alignment has emerged as an\neffective plug-and-play technique that avoids fine-tuning model parameters.\nThis approach retains the general utility of pretrained LLMs but often suffers\nfrom significant inefficiencies during decoding, primarily due to wasted token\ngeneration and excessive reward evaluations. To address these challenges, we\nintroduce Cascade Reward Sampling (CARDS) to resolve both efficiency\nbottlenecks in decoding-time alignment. Specifically, we develop a\nsegment-level rejection sampling algorithm that minimizes redundant\ncomputations of both LLMs and reward models (RMs). Central to CARDS is an\nuncertainty-based segmentation mechanism, which ensures the accuracy of RMs\nevaluations on incomplete segments. Furthermore, we provide a detailed analysis\nof reward scores on segments to elucidate the improved alignment performance.\nExperimental results demonstrate that CARDS significantly improves decoding\nefficiency, alignment quality, and general utility compared to existing\ndecoding-time alignment methods, achieving approximately a 70% reduction in\ndecoding time and over 90% win-ties in utility and safety benchmarks.\n","authors":["Bolian Li","Yifan Wang","Anamika Lochab","Ananth Grama","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.16306v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.00565v2","updated":"2025-08-03T19:12:44Z","published":"2025-03-01T17:23:55Z","title":"Semi-Parametric Batched Global Multi-Armed Bandits with Covariates","summary":"  The multi-armed bandits (MAB) framework is a widely used approach for\nsequential decision-making, where a decision-maker selects an arm in each round\nwith the goal of maximizing long-term rewards. Moreover, in many practical\napplications, such as personalized medicine and recommendation systems,\nfeedback is provided in batches, contextual information is available at the\ntime of decision-making, and rewards from different arms are related rather\nthan independent. We propose a novel semi-parametric framework for batched\nbandits with covariates and a shared parameter across arms, leveraging the\nsingle-index regression (SIR) model to capture relationships between arm\nrewards while balancing interpretability and flexibility. Our algorithm,\nBatched single-Index Dynamic binning and Successive arm elimination (BIDS),\nemploys a batched successive arm elimination strategy with a dynamic binning\nmechanism guided by the single-index direction. We consider two settings: one\nwhere a pilot direction is available and another where the direction is\nestimated from data, deriving theoretical regret bounds for both cases. When a\npilot direction is available with sufficient accuracy, our approach achieves\nminimax-optimal rates (with $d = 1$) for nonparametric batched bandits,\ncircumventing the curse of dimensionality. Extensive experiments on simulated\nand real-world datasets demonstrate the effectiveness of our algorithm compared\nto the nonparametric batched bandit method introduced by\n\\cite{jiang2024batched}.\n","authors":["Sakshi Arya","Hyebin Song"],"pdf_url":"https://arxiv.org/pdf/2503.00565v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01865v1","updated":"2025-08-03T17:34:38Z","published":"2025-08-03T17:34:38Z","title":"Structure Maintained Representation Learning Neural Network for Causal\n  Inference","summary":"  Recent developments in causal inference have greatly shifted the interest\nfrom estimating the average treatment effect to the individual treatment\neffect. In this article, we improve the predictive accuracy of representation\nlearning and adversarial networks in estimating individual treatment effects by\nintroducing a structure keeper which maintains the correlation between the\nbaseline covariates and their corresponding representations in the high\ndimensional space. We train a discriminator at the end of representation layers\nto trade off representation balance and information loss. We show that the\nproposed discriminator minimizes an upper bound of the treatment estimation\nerror. We can address the tradeoff between distribution balance and information\nloss by considering the correlations between the learned representation space\nand the original covariate feature space. We conduct extensive experiments with\nsimulated and real-world observational data to show that our proposed Structure\nMaintained Representation Learning (SMRL) algorithm outperforms\nstate-of-the-art methods. We also demonstrate the algorithms on real electronic\nhealth record data from the MIMIC-III database.\n","authors":["Yang Sun","Wenbin Lu","Yi-Hui Zhou"],"pdf_url":"https://arxiv.org/pdf/2508.01865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01864v1","updated":"2025-08-03T17:32:42Z","published":"2025-08-03T17:32:42Z","title":"Fast Gaussian process inference by exact Matérn kernel decomposition","summary":"  To speed up Gaussian process inference, a number of fast kernel matrix-vector\nmultiplication (MVM) approximation algorithms have been proposed over the\nyears. In this paper, we establish an exact fast kernel MVM algorithm based on\nexact kernel decomposition into weighted empirical cumulative distribution\nfunctions, compatible with a class of kernels which includes multivariate\nMat\\'ern kernels with half-integer smoothness parameter. This algorithm uses a\ndivide-and-conquer approach, during which sorting outputs are stored in a data\nstructure. We also propose a new algorithm to take into account some linear\nfixed effects predictor function. Our numerical experiments confirm that our\nalgorithm is very effective for low-dimensional Gaussian process inference\nproblems with hundreds of thousands of data points. An implementation of our\nalgorithm is available at\nhttps://gitlab.com/warin/fastgaussiankernelregression.git.\n","authors":["Nicolas Langrené","Xavier Warin","Pierre Gruet"],"pdf_url":"https://arxiv.org/pdf/2508.01864v1.pdf","comment":"31 pages, 1 figure"},{"id":"http://arxiv.org/abs/2508.01848v1","updated":"2025-08-03T17:03:13Z","published":"2025-08-03T17:03:13Z","title":"Causal Discovery in Multivariate Time Series through Mutual Information\n  Featurization","summary":"  Discovering causal relationships in complex multivariate time series is a\nfundamental scientific challenge. Traditional methods often falter, either by\nrelying on restrictive linear assumptions or on conditional independence tests\nthat become uninformative in the presence of intricate, non-linear dynamics.\nThis paper proposes a new paradigm, shifting from statistical testing to\npattern recognition. We hypothesize that a causal link creates a persistent and\nlearnable asymmetry in the flow of information through a system's temporal\ngraph, even when clear conditional independencies are obscured. We introduce\nTemporal Dependency to Causality (TD2C), a supervised learning framework that\noperationalizes this hypothesis. TD2C learns to recognize these complex causal\nsignatures from a rich set of information-theoretic and statistical\ndescriptors. Trained exclusively on a diverse collection of synthetic time\nseries, TD2C demonstrates remarkable zero-shot generalization to unseen\ndynamics and established, realistic benchmarks. Our results show that TD2C\nachieves state-of-the-art performance, consistently outperforming established\nmethods, particularly in high-dimensional and non-linear settings. By reframing\nthe discovery problem, our work provides a robust and scalable new tool for\nuncovering causal structures in complex systems.\n","authors":["Gian Marco Paldino","Gianluca Bontempi"],"pdf_url":"https://arxiv.org/pdf/2508.01848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01834v1","updated":"2025-08-03T16:44:05Z","published":"2025-08-03T16:44:05Z","title":"Efficient optimization of expensive black-box simulators via marginal\n  means, with application to neutrino detector design","summary":"  With advances in scientific computing, computer experiments are increasingly\nused for optimizing complex systems. However, for modern applications, e.g.,\nthe optimization of nuclear physics detectors, each experiment run can require\nhundreds of CPU hours, making the optimization of its black-box simulator over\na high-dimensional space a challenging task. Given limited runs at inputs\n$\\mathbf{x}_1, \\cdots, \\mathbf{x}_n$, the best solution from these evaluated\ninputs can be far from optimal, particularly as dimensionality increases.\nExisting black-box methods, however, largely employ this ''pick-the-winner''\n(PW) solution, which leads to mediocre optimization performance. To address\nthis, we propose a new Black-box Optimization via Marginal Means (BOMM)\napproach. The key idea is a new estimator of a global optimizer $\\mathbf{x}^*$\nthat leverages the so-called marginal mean functions, which can be efficiently\ninferred with limited runs in high dimensions. Unlike PW, this estimator can\nselect solutions beyond evaluated inputs for improved optimization performance.\nAssuming the objective function follows a generalized additive model with\nunknown link function and under mild conditions, we prove that the BOMM\nestimator not only is consistent for optimization, but also has an optimization\nrate that tempers the ''curse-of-dimensionality'' faced by existing methods,\nthus enabling better performance as dimensionality increases. We present a\npractical framework for implementing BOMM using the transformed additive\nGaussian process surrogate model. Finally, we demonstrate the effectiveness of\nBOMM in numerical experiments and an application on neutrino detector\noptimization in nuclear physics.\n","authors":["Hwanwoo Kim","Simon Mak","Ann-Kathrin Schuetz","Alan Poon"],"pdf_url":"https://arxiv.org/pdf/2508.01834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.00302v3","updated":"2025-08-03T15:17:04Z","published":"2025-02-01T03:51:22Z","title":"Learning to Fuse Temporal Proximity Networks: A Case Study in Chimpanzee\n  Social Interactions","summary":"  How can we identify groups of primate individuals which could be conjectured\nto drive social structure? To address this question, one of us has collected a\ntime series of data for social interactions between chimpanzees. Here we use a\nnetwork representation, leading to the task of combining these data into a time\nseries of a single weighted network per time stamp, where different proximities\nshould be given different weights reflecting their relative importance. We\noptimize these proximity-type weights in a principled way, using an innovative\nloss function which rewards structural consistency for consecutive time steps.\nThe approach is empirically validated by carefully designed synthetic data.\nUsing statistical tests, we provide a way of identifying groups of individuals\nthat stay related for a significant length of time. Applying the approach to\nthe chimpanzee data set, we detect cliques in the animal social network time\nseries, which can be validated by real-world intuition from prior research and\nqualitative observations by chimpanzee experts.\n","authors":["Yixuan He","Aaron Sandel","David Wipf","Mihai Cucuringu","John Mitani","Gesine Reinert"],"pdf_url":"https://arxiv.org/pdf/2502.00302v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.09375v3","updated":"2025-08-03T14:56:59Z","published":"2024-07-12T15:56:11Z","title":"HiPPO-Prophecy: State-Space Models can Provably Learn Dynamical Systems\n  in Context","summary":"  This work explores the in-context learning capabilities of State Space Models\n(SSMs) and presents, to the best of our knowledge, the first theoretical\nexplanation of a possible underlying mechanism. We introduce a novel weight\nconstruction for SSMs, enabling them to predict the next state of any dynamical\nsystem after observing previous states without parameter fine-tuning. This is\naccomplished by extending the HiPPO framework to demonstrate that continuous\nSSMs can approximate the derivative of any input signal. Specifically, we find\nan explicit weight construction for continuous SSMs and provide an asymptotic\nerror bound on the derivative approximation. The discretization of this\ncontinuous SSM subsequently yields a discrete SSM that predicts the next state.\nFinally, we demonstrate the effectiveness of our parameterization empirically.\nThis work should be an initial step toward understanding how sequence models\nbased on SSMs learn in context.\n","authors":["Federico Arangath Joseph","Kilian Konstantin Haefeli","Noah Liniger","Caglar Gulcehre"],"pdf_url":"https://arxiv.org/pdf/2407.09375v3.pdf","comment":"ICML 2024, Next Generation Sequence Modeling Architectures Workshop"},{"id":"http://arxiv.org/abs/2502.11604v2","updated":"2025-08-03T13:36:44Z","published":"2025-02-17T09:44:23Z","title":"An Actor-Critic Algorithm with Function Approximation for Risk Sensitive\n  Cost Markov Decision Processes","summary":"  In this paper, we consider the risk-sensitive cost criterion with\nexponentiated costs for Markov decision processes and develop a model-free\npolicy gradient algorithm in this setting. Unlike additive cost criteria such\nas average or discounted cost, the risk-sensitive cost criterion is less\nstudied due to the complexity resulting from the multiplicative structure of\nthe resulting Bellman equation. We develop an actor-critic algorithm with\nfunction approximation in this setting and provide its asymptotic convergence\nanalysis. We also show the results of numerical experiments that demonstrate\nthe superiority in performance of our algorithm over other recent algorithms in\nthe literature.\n","authors":["Soumyajit Guin","Vivek S. Borkar","Shalabh Bhatnagar"],"pdf_url":"https://arxiv.org/pdf/2502.11604v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01733v1","updated":"2025-08-03T12:19:17Z","published":"2025-08-03T12:19:17Z","title":"Topolow: Force-Directed Euclidean Embedding of Dissimilarity Data with\n  Robustness Against Non-Metricity and Sparsity","summary":"  The problem of embedding a set of objects into a low-dimensional Euclidean\nspace based on a matrix of pairwise dissimilarities is fundamental in data\nanalysis, machine learning, and statistics. However, the assumptions of many\nstandard analytical methods are violated when the input dissimilarities fail to\nsatisfy metric or Euclidean axioms. We present the mathematical and statistical\nfoundations of Topolow, a physics-inspired, gradient-free optimization\nframework for such embedding problems. Topolow is conceptually related to\nforce-directed graph drawing algorithms but is fundamentally distinguished by\nits goal of quantitative metric reconstruction. It models objects as particles\nin a physical system, and its novel optimization scheme proceeds through\nsequential, stochastic pairwise interactions, which circumvents the need to\ncompute a global gradient and provides robustness against convergence to local\noptima, especially for sparse data. Topolow maximizes the likelihood under a\nLaplace error model, robust to outliers and heterogeneous errors, and properly\nhandles censored data. Crucially, Topolow does not require the input\ndissimilarities to be metric, making it a robust solution for embedding\nnon-metric measurements into a valid Euclidean space, thereby enabling the use\nof standard analytical tools. We demonstrate the superior performance of\nTopolow compared to standard Multidimensional Scaling (MDS) methods in\nreconstructing the geometry of sparse and non-Euclidean data. This paper\nformalizes the algorithm, first introduced as Topolow in the context of\nantigenic mapping in (Arhami and Rohani, 2025) (open access), with emphasis on\nits metric embedding and mathematical properties for a broader audience. The\ngeneral-purpose function Euclidify is available in the R package topolow.\n","authors":["Omid Arhami","Pejman Rohani"],"pdf_url":"https://arxiv.org/pdf/2508.01733v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01706v1","updated":"2025-08-03T10:22:35Z","published":"2025-08-03T10:22:35Z","title":"Density estimation with atoms, and functional estimation for mixed\n  discrete-continuous data","summary":"  In classical density (or density-functional) estimation, it is standard to\nassume that the underlying distribution has a density with respect to the\nLebesgue measure. However, when the data distribution is a mixture of\ncontinuous and discrete components, the resulting methods are inconsistent in\ntheory and perform poorly in practice. In this paper, we point out that a minor\nmodification of existing methods for nonparametric density (functional)\nestimation can allow us to fully remove this assumption while retaining nearly\nidentical theoretical guarantees and improved empirical performance. Our\napproach is very simple: data points that appear exactly once are likely to\noriginate from the continuous component, whereas repeated observations are\nindicative of the discrete part. Leveraging this observation, we modify\nexisting estimators for a broad class of functionals of the continuous\ncomponent of the mixture; this modification is a \"wrapper\" in the sense that\nthe user can use any underlying method of their choice for continuous density\nfunctional estimation. Our modifications deliver consistency without requiring\nknowledge of the discrete support, the mixing proportion, and without imposing\nadditional assumptions beyond those needed in the absence of the discrete part.\nThus, various theorems and existing software packages can be made automatically\nmore robust, with absolutely no additional price when the data is not truly\nmixed.\n","authors":["Aytijhya Saha","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2508.01706v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01681v1","updated":"2025-08-03T09:23:19Z","published":"2025-08-03T09:23:19Z","title":"Generalized Kernelized Bandits: Self-Normalized Bernstein-Like\n  Dimension-Free Inequality and Regret Bounds","summary":"  We study the regret minimization problem in the novel setting of generalized\nkernelized bandits (GKBs), where we optimize an unknown function $f^*$\nbelonging to a reproducing kernel Hilbert space (RKHS) having access to samples\ngenerated by an exponential family (EF) noise model whose mean is a non-linear\nfunction $\\mu(f^*)$. This model extends both kernelized bandits (KBs) and\ngeneralized linear bandits (GLBs). We propose an optimistic algorithm, GKB-UCB,\nand we explain why existing self-normalized concentration inequalities do not\nallow to provide tight regret guarantees. For this reason, we devise a novel\nself-normalized Bernstein-like dimension-free inequality resorting to\nFreedman's inequality and a stitching argument, which represents a contribution\nof independent interest. Based on it, we conduct a regret analysis of GKB-UCB,\nderiving a regret bound of order $\\widetilde{O}( \\gamma_T \\sqrt{T/\\kappa_*})$,\nbeing $T$ the learning horizon, ${\\gamma}_T$ the maximal information gain, and\n$\\kappa_*$ a term characterizing the magnitude the reward nonlinearity. Our\nresult matches, up to multiplicative constants and logarithmic terms, the\nstate-of-the-art bounds for both KBs and GLBs and provides a unified view of\nboth settings.\n","authors":["Alberto Maria Metelli","Simone Drago","Marco Mussi"],"pdf_url":"https://arxiv.org/pdf/2508.01681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.06096v3","updated":"2025-08-03T09:18:19Z","published":"2025-02-10T02:01:30Z","title":"Post-detection inference for sequential changepoint localization","summary":"  This paper addresses a fundamental but largely unexplored challenge in\nsequential changepoint analysis: conducting inference following a detected\nchange. We develop a very general framework to construct confidence sets for\nthe unknown changepoint using only the data observed up to a data-dependent\nstopping time at which an arbitrary sequential detection algorithm declares a\nchange. Our framework is nonparametric, making no assumption on the composite\npost-change class, the observation space, or the sequential detection procedure\nused, and is nonasymptotically valid. We also extend it to handle composite\npre-change classes under a suitable assumption, and also derive confidence sets\nfor the change magnitude in parametric settings. Extensive simulations\ndemonstrate that the produced sets have reasonable size, and slightly\nconservative coverage. In summary, we present the first general method for\nsequential changepoint localization, which is theoretically sound and broadly\napplicable in practice.\n","authors":["Aytijhya Saha","Aaditya Ramdas"],"pdf_url":"https://arxiv.org/pdf/2502.06096v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01597v1","updated":"2025-08-03T05:35:20Z","published":"2025-08-03T05:35:20Z","title":"Why Heuristic Weighting Works: A Theoretical Analysis of Denoising Score\n  Matching","summary":"  Score matching enables the estimation of the gradient of a data distribution,\na key component in denoising diffusion models used to recover clean data from\ncorrupted inputs. In prior work, a heuristic weighting function has been used\nfor the denoising score matching loss without formal justification. In this\nwork, we demonstrate that heteroskedasticity is an inherent property of the\ndenoising score matching objective. This insight leads to a principled\nderivation of optimal weighting functions for generalized, arbitrary-order\ndenoising score matching losses, without requiring assumptions about the noise\ndistribution. Among these, the first-order formulation is especially relevant\nto diffusion models. We show that the widely used heuristical weighting\nfunction arises as a first-order Taylor approximation to the trace of the\nexpected optimal weighting. We further provide theoretical and empirical\ncomparisons, revealing that the heuristical weighting, despite its simplicity,\ncan achieve lower variance than the optimal weighting with respect to parameter\ngradients, which can facilitate more stable and efficient training.\n","authors":["Juyan Zhang","Rhys Newbury","Xinyang Zhang","Tin Tran","Dana Kulic","Michael Burke"],"pdf_url":"https://arxiv.org/pdf/2508.01597v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20425v2","updated":"2025-08-03T04:11:55Z","published":"2025-06-25T13:39:30Z","title":"Scalable Subset Selection in Linear Mixed Models","summary":"  Linear mixed models (LMMs), which incorporate fixed and random effects, are\nkey tools for analyzing heterogeneous data, such as in personalized medicine.\nNowadays, this type of data is increasingly wide, sometimes containing\nthousands of candidate predictors, necessitating sparsity for prediction and\ninterpretation. However, existing sparse learning methods for LMMs do not scale\nwell beyond tens or hundreds of predictors, leaving a large gap compared with\nsparse methods for linear models, which ignore random effects. This paper\ncloses the gap with a new $\\ell_0$ regularized method for LMM subset selection\nthat can run on datasets containing thousands of predictors in seconds to\nminutes. On the computational front, we develop a coordinate descent algorithm\nas our main workhorse and provide a guarantee of its convergence. We also\ndevelop a local search algorithm to help traverse the nonconvex optimization\nsurface. Both algorithms readily extend to subset selection in generalized LMMs\nvia a penalized quasi-likelihood approximation. On the statistical front, we\nprovide a finite-sample bound on the Kullback-Leibler divergence of the new\nmethod. We then demonstrate its excellent performance in experiments involving\nsynthetic and real datasets.\n","authors":["Ryan Thompson","Matt P. Wand","Joanna J. J. Wang"],"pdf_url":"https://arxiv.org/pdf/2506.20425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2210.12862v2","updated":"2025-08-03T04:03:27Z","published":"2022-10-23T21:45:53Z","title":"Optimal Discriminant Analysis in High-Dimensional Latent Factor Models","summary":"  In high-dimensional classification problems, a commonly used approach is to\nfirst project the high-dimensional features into a lower dimensional space, and\nbase the classification on the resulting lower dimensional projections. In this\npaper, we formulate a latent-variable model with a hidden low-dimensional\nstructure to justify this two-step procedure and to guide which projection to\nchoose. We propose a computationally efficient classifier that takes certain\nprincipal components (PCs) of the observed features as projections, with the\nnumber of retained PCs selected in a data-driven way. A general theory is\nestablished for analyzing such two-step classifiers based on any projections.\nWe derive explicit rates of convergence of the excess risk of the proposed\nPC-based classifier. The obtained rates are further shown to be optimal up to\nlogarithmic factors in the minimax sense. Our theory allows the lower-dimension\nto grow with the sample size and is also valid even when the feature dimension\n(greatly) exceeds the sample size. Extensive simulations corroborate our\ntheoretical findings. The proposed method also performs favorably relative to\nother existing discriminant methods on three real data examples.\n","authors":["Xin Bing","Marten Wegkamp"],"pdf_url":"https://arxiv.org/pdf/2210.12862v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.09903v2","updated":"2025-08-03T01:32:47Z","published":"2024-09-16T00:14:48Z","title":"Learning large softmax mixtures with warm start EM","summary":"  Softmax mixture models (SMMs) are discrete $K$-mixtures introduced to model\nthe probability of choosing an attribute $x_j \\in \\RR^L$ from $p$ candidates,\nin heterogeneous populations. They have been known as mixed multinomial logits\nin the econometrics literature, and are gaining traction in the LLM literature,\nwhere single softmax models are routinely used in the final layer of a neural\nnetwork. This paper provides a comprehensive analysis of the EM algorithm for\nSMMs in high dimensions. Its population-level theoretical analysis forms the\nbasis for proving (i) local identifiability, in SSMs with generic features and,\nfurther, via a stochastic argument, (ii) full identifiability in SSMs with\nrandom features, when $p$ is large enough. These are the first results in this\ndirection for SSMs with $L > 1$. The population-level EM analysis characterizes\nthe initialization radius for algorithmic convergence. This also guides the\nconstruction of warm starts of the sample level EM. Under suitable\ninitialization, the EM algorithm is shown to recover the mixture atoms of the\nSSM at near-parametric rate. We provide two main directions for warm start\nconstruction, both based on a new method for estimating the moments of the\nmixing measure underlying an SSM with random design. First, we construct a\nmethod of moments (MoM) estimator of the mixture parameters, and provide its\nfirst theoretical analysis. While MoM can enjoy parametric rates of\nconvergence, and thus can serve as a warm-start, the estimator's quality\ndegrades exponentially in $K$. Our recommendation, when $K$ is not small, is to\nrun the EM algorithm several times with random initializations. We again make\nuse of the novel latent moments estimation method to estimate the\n$K$-dimensional subspace of the mixture atoms. Sampling from this subspace\nreduces substantially the number of required draws.\n","authors":["Xin Bing","Florentina Bunea","Jonathan Niles-Weed","Marten Wegkamp"],"pdf_url":"https://arxiv.org/pdf/2409.09903v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12176v2","updated":"2025-08-03T01:25:42Z","published":"2025-06-13T18:55:37Z","title":"Fidelity Isn't Accuracy: When Linearly Decodable Functions Fail to Match\n  the Ground Truth","summary":"  Neural networks excel as function approximators, but their complexity often\nobscures what kinds of functions they learn. We introduce the linearity score\n$\\lambda(f)$, a simple and interpretable diagnostic that quantifies how well a\nregression network's output can be mimicked by a linear model. Defined as the\n$R^2$ value between the network's predictions and those of a trained linear\nsurrogate, $\\lambda(f)$ measures linear decodability: the extent to which the\nnetwork's behavior aligns with a structurally simple model. We evaluate this\nframework on both synthetic ($y = x \\cdot \\sin(x) + \\epsilon$) and real-world\ndatasets (Medical Insurance, Concrete, California Housing), using\ndataset-specific networks and surrogates. Our findings show that high\n$\\lambda(f)$ scores reliably indicate alignment with the network's outputs --\nbut do not guarantee accuracy with respect to the ground truth. These results\nhighlight the risk of using surrogate fidelity as a proxy for model\nunderstanding -- especially in high-stakes regression tasks.\n","authors":["Jackson Eshbaugh"],"pdf_url":"https://arxiv.org/pdf/2506.12176v2.pdf","comment":"9 pages, 5 figures, 3 tables. Code available at\n  https://github.com/jacksoneshbaugh/lambda-linearity-score/tree/main"},{"id":"http://arxiv.org/abs/2508.02759v1","updated":"2025-08-03T17:20:49Z","published":"2025-08-03T17:20:49Z","title":"Hedging with memory: shallow and deep learning with signatures","summary":"  We investigate the use of path signatures in a machine learning context for\nhedging exotic derivatives under non-Markovian stochastic volatility models. In\na deep learning setting, we use signatures as features in feedforward neural\nnetworks and show that they outperform LSTMs in most cases, with orders of\nmagnitude less training compute. In a shallow learning setting, we compare two\nregression approaches: the first directly learns the hedging strategy from the\nexpected signature of the price process; the second models the dynamics of\nvolatility using a signature volatility model, calibrated on the expected\nsignature of the volatility. Solving the hedging problem in the calibrated\nsignature volatility model yields more accurate and stable results across\ndifferent payoffs and volatility dynamics.\n","authors":["Eduardo Abi Jaber","Louis-Amand Gérard"],"pdf_url":"https://arxiv.org/pdf/2508.02759v1.pdf","comment":null}],"Computation":[{"id":"http://arxiv.org/abs/2408.06894v4","updated":"2025-08-03T17:47:45Z","published":"2024-08-13T13:42:56Z","title":"Exploring the generalizability of the optimal 0.234 acceptance rate in\n  random-walk Metropolis and parallel tempering algorithms","summary":"  For random-walk Metropolis (RWM) and parallel tempering (PT) algorithms, an\nasymptotic acceptance rate of around 0.234 is known to be optimal in certain\nhigh-dimensional limits. However, its practical relevance is uncertain due to\nrestrictive derivation conditions. We synthesise previous theoretical advances\nin extending the 0.234 acceptance rate to more general settings, and\ndemonstrate its applicability with a comprehensive empirical simulation study\non examples examining how acceptance rates affect Expected Squared Jumping\nDistance (ESJD). Our experiments show the optimality of the 0.234 acceptance\nrate for RWM is surprisingly robust even in lower dimensions across various\nnon-spherically symmetric proposal distributions, multimodal target\ndistributions that may not have an i.i.d. product density, and curved\nRosenbrock target distributions with nonlinear correlation structure. Parallel\ntempering experiments also show that the idealized 0.234 spacing of inverse\ntemperatures may be approximately optimal for low dimensions and non i.i.d.\nproduct target densities, and that constructing an inverse temperature ladder\nwith spacings given by a swap acceptance of 0.234 is a viable strategy.\n","authors":["Aidan Li","Liyan Wang","Tianye Dou","Jeffrey S. Rosenthal"],"pdf_url":"https://arxiv.org/pdf/2408.06894v4.pdf","comment":"To be published in Communications in Statistics - Simulation and\n  Computation. Code available at https://github.com/aidanmrli/rwm-pt-pytorch"},{"id":"http://arxiv.org/abs/2508.01864v1","updated":"2025-08-03T17:32:42Z","published":"2025-08-03T17:32:42Z","title":"Fast Gaussian process inference by exact Matérn kernel decomposition","summary":"  To speed up Gaussian process inference, a number of fast kernel matrix-vector\nmultiplication (MVM) approximation algorithms have been proposed over the\nyears. In this paper, we establish an exact fast kernel MVM algorithm based on\nexact kernel decomposition into weighted empirical cumulative distribution\nfunctions, compatible with a class of kernels which includes multivariate\nMat\\'ern kernels with half-integer smoothness parameter. This algorithm uses a\ndivide-and-conquer approach, during which sorting outputs are stored in a data\nstructure. We also propose a new algorithm to take into account some linear\nfixed effects predictor function. Our numerical experiments confirm that our\nalgorithm is very effective for low-dimensional Gaussian process inference\nproblems with hundreds of thousands of data points. An implementation of our\nalgorithm is available at\nhttps://gitlab.com/warin/fastgaussiankernelregression.git.\n","authors":["Nicolas Langrené","Xavier Warin","Pierre Gruet"],"pdf_url":"https://arxiv.org/pdf/2508.01864v1.pdf","comment":"31 pages, 1 figure"},{"id":"http://arxiv.org/abs/2508.01834v1","updated":"2025-08-03T16:44:05Z","published":"2025-08-03T16:44:05Z","title":"Efficient optimization of expensive black-box simulators via marginal\n  means, with application to neutrino detector design","summary":"  With advances in scientific computing, computer experiments are increasingly\nused for optimizing complex systems. However, for modern applications, e.g.,\nthe optimization of nuclear physics detectors, each experiment run can require\nhundreds of CPU hours, making the optimization of its black-box simulator over\na high-dimensional space a challenging task. Given limited runs at inputs\n$\\mathbf{x}_1, \\cdots, \\mathbf{x}_n$, the best solution from these evaluated\ninputs can be far from optimal, particularly as dimensionality increases.\nExisting black-box methods, however, largely employ this ''pick-the-winner''\n(PW) solution, which leads to mediocre optimization performance. To address\nthis, we propose a new Black-box Optimization via Marginal Means (BOMM)\napproach. The key idea is a new estimator of a global optimizer $\\mathbf{x}^*$\nthat leverages the so-called marginal mean functions, which can be efficiently\ninferred with limited runs in high dimensions. Unlike PW, this estimator can\nselect solutions beyond evaluated inputs for improved optimization performance.\nAssuming the objective function follows a generalized additive model with\nunknown link function and under mild conditions, we prove that the BOMM\nestimator not only is consistent for optimization, but also has an optimization\nrate that tempers the ''curse-of-dimensionality'' faced by existing methods,\nthus enabling better performance as dimensionality increases. We present a\npractical framework for implementing BOMM using the transformed additive\nGaussian process surrogate model. Finally, we demonstrate the effectiveness of\nBOMM in numerical experiments and an application on neutrino detector\noptimization in nuclear physics.\n","authors":["Hwanwoo Kim","Simon Mak","Ann-Kathrin Schuetz","Alan Poon"],"pdf_url":"https://arxiv.org/pdf/2508.01834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01581v1","updated":"2025-08-03T04:19:31Z","published":"2025-08-03T04:19:31Z","title":"Polymorphic Combinatorial Frameworks (PCF): Guiding the Design of\n  Mathematically-Grounded, Adaptive AI Agents","summary":"  The Polymorphic Combinatorial Framework (PCF) leverages Large Language Models\n(LLMs) and mathematical frameworks to guide the meta-prompt enabled design of\nsolution spaces and adaptive AI agents for complex, dynamic environments.\nUnlike static agent architectures, PCF enables real-time parameter\nreconfiguration through mathematically-grounded combinatorial spaces, allowing\nagents to adapt their core behavioral traits dynamically. Grounded in\ncombinatorial logic, topos theory, and rough fuzzy set theory, PCF defines a\nmultidimensional SPARK parameter space (Skills, Personalities, Approaches,\nResources, Knowledge) to capture agent behaviors. This paper demonstrates how\nLLMs can parameterize complex spaces and estimate likely parameter\nvalues/variabilities. Using PCF, we parameterized mock caf\\'e domains (five\nlevels of complexity), estimated variables/variabilities, and conducted over\n1.25 million Monte Carlo simulations. The results revealed trends in agent\nadaptability and performance across the five complexity tiers, with diminishing\nreturns at higher complexity levels highlighting thresholds for scalable\ndesigns. PCF enables the generation of optimized agent configurations for\nspecific scenarios while maintaining logical consistency. This framework\nsupports scalable, dynamic, explainable, and ethical AI applications in domains\nlike customer service, healthcare, robotics, and collaborative systems, paving\nthe way for adaptable and cooperative next-generation polymorphic agents.\n","authors":["David Pearl","Matthew Murphy","James Intriligator"],"pdf_url":"https://arxiv.org/pdf/2508.01581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.20425v2","updated":"2025-08-03T04:11:55Z","published":"2025-06-25T13:39:30Z","title":"Scalable Subset Selection in Linear Mixed Models","summary":"  Linear mixed models (LMMs), which incorporate fixed and random effects, are\nkey tools for analyzing heterogeneous data, such as in personalized medicine.\nNowadays, this type of data is increasingly wide, sometimes containing\nthousands of candidate predictors, necessitating sparsity for prediction and\ninterpretation. However, existing sparse learning methods for LMMs do not scale\nwell beyond tens or hundreds of predictors, leaving a large gap compared with\nsparse methods for linear models, which ignore random effects. This paper\ncloses the gap with a new $\\ell_0$ regularized method for LMM subset selection\nthat can run on datasets containing thousands of predictors in seconds to\nminutes. On the computational front, we develop a coordinate descent algorithm\nas our main workhorse and provide a guarantee of its convergence. We also\ndevelop a local search algorithm to help traverse the nonconvex optimization\nsurface. Both algorithms readily extend to subset selection in generalized LMMs\nvia a penalized quasi-likelihood approximation. On the statistical front, we\nprovide a finite-sample bound on the Kullback-Leibler divergence of the new\nmethod. We then demonstrate its excellent performance in experiments involving\nsynthetic and real datasets.\n","authors":["Ryan Thompson","Matt P. Wand","Joanna J. J. Wang"],"pdf_url":"https://arxiv.org/pdf/2506.20425v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01572v1","updated":"2025-08-03T03:43:42Z","published":"2025-08-03T03:43:42Z","title":"A strategy to avoid particle depletion in recursive Bayesian inference","summary":"  Recursive Bayesian inference, in which posterior beliefs are updated in light\nof accumulating data, is a tool for implementing Bayesian models in\napplications with streaming and/or very large data sets. As the posterior of\none iteration becomes the prior for the next, beliefs are updated sequentially\ninstead of all-at-once. Thus, recursive inference is relevant for both\nstreaming data and settings where data too numerous to be analyzed together can\nbe partitioned into manageable pieces. In practice, posteriors are\ncharacterized by samples obtained using, e.g., acceptance/rejection sampling in\nwhich draws from the posterior of one iteration are used as proposals for the\nnext. While simple to implement, such filtering approaches suffer from particle\ndepletion, degrading each sample's ability to represent its target posterior.\nAs a remedy, we investigate generating proposals from a smoothed version of the\npreceding sample's empirical distribution. The method retains computationally\nvaluable properties of similar methods, but without particle depletion, and we\ndemonstrate its accuracy in simulation. We apply the method to data simulated\nfrom both a simple, logistic regression model as well as a hierarchical model\noriginally developed for classifying forest vegetation in New Mexico using\nsatellite imagery.\n","authors":["Henry R. Scharf"],"pdf_url":"https://arxiv.org/pdf/2508.01572v1.pdf","comment":null}]},"2025-08-02T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2508.01514v1","updated":"2025-08-02T22:46:50Z","published":"2025-08-02T22:46:50Z","title":"End-to-End Personalization: Unifying Recommender Systems with Large\n  Language Models","summary":"  Recommender systems are essential for guiding users through the vast and\ndiverse landscape of digital content by delivering personalized and relevant\nsuggestions. However, improving both personalization and interpretability\nremains a challenge, particularly in scenarios involving limited user feedback\nor heterogeneous item attributes. In this article, we propose a novel hybrid\nrecommendation framework that combines Graph Attention Networks (GATs) with\nLarge Language Models (LLMs) to address these limitations. LLMs are first used\nto enrich user and item representations by generating semantically meaningful\nprofiles based on metadata such as titles, genres, and overviews. These\nenriched embeddings serve as initial node features in a user and movie\nbipartite graph, which is processed using a GAT based collaborative filtering\nmodel. To enhance ranking accuracy, we introduce a hybrid loss function that\ncombines Bayesian Personalized Ranking (BPR), cosine similarity, and robust\nnegative sampling. Post-processing involves reranking the GAT-generated\nrecommendations using the LLM, which also generates natural-language\njustifications to improve transparency. We evaluated our model on benchmark\ndatasets, including MovieLens 100k and 1M, where it consistently outperforms\nstrong baselines. Ablation studies confirm that LLM-based embeddings and the\ncosine similarity term significantly contribute to performance gains. This work\ndemonstrates the potential of integrating LLMs to improve both the accuracy and\ninterpretability of recommender systems.\n","authors":["Danial Ebrat","Tina Aminian","Sepideh Ahmadian","Luis Rueda"],"pdf_url":"https://arxiv.org/pdf/2508.01514v1.pdf","comment":"Second Workshop on Generative AI for Recommender Systems and\n  Personalization at the ACM Conference on Knowledge Discovery and Data Mining\n  (GenAIRecP@KDD 2025)"},{"id":"http://arxiv.org/abs/2508.01502v1","updated":"2025-08-02T21:53:51Z","published":"2025-08-02T21:53:51Z","title":"Req-Rec: Enhancing Requirements Elicitation for Increasing Stakeholder's\n  Satisfaction Using a Collaborative Filtering Based Recommender System","summary":"  The success or failure of a project is highly related to recognizing the\nright stakeholders and accurately finding and discovering their requirements.\nHowever, choosing the proper elicitation technique was always a considerable\nchallenge for efficient requirement engineering. As a consequence of the swift\nimprovement of digital technologies since the past decade, recommender systems\nhave become an efficient channel for making a deeply personalized interactive\ncommunication with stakeholders. In this research, a new method, called the\nReq-Rec (Requirements Recommender), is proposed. It is a hybrid recommender\nsystem based on the collaborative filtering approach and the repertory grid\ntechnique as the core component. The primary goal of Req-Rec is to increase\nstakeholder satisfaction by assisting them in the requirement elicitation\nphase. Based on the results, the method efficiently could overcome weaknesses\nof common requirement elicitation techniques, such as time limitation,\nlocation-based restrictions, and bias in requirements' elicitation process.\nTherefore, recommending related requirements assists stakeholders in becoming\nmore aware of different aspects of the project.\n","authors":["Ali Fallahi","Amineh Amini","Azam Bastanfard","Hadi Saboohi"],"pdf_url":"https://arxiv.org/pdf/2508.01502v1.pdf","comment":"March 2023, 28 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.01375v1","updated":"2025-08-02T14:09:21Z","published":"2025-08-02T14:09:21Z","title":"SaviorRec: Semantic-Behavior Alignment for Cold-Start Recommendation","summary":"  In recommendation systems, predicting Click-Through Rate (CTR) is crucial for\naccurately matching users with items. To improve recommendation performance for\ncold-start and long-tail items, recent studies focus on leveraging item\nmultimodal features to model users' interests. However, obtaining multimodal\nrepresentations for items relies on complex pre-trained encoders, which incurs\nunacceptable computation cost to train jointly with downstream ranking models.\nTherefore, it is important to maintain alignment between semantic and behavior\nspace in a lightweight way.\n  To address these challenges, we propose a Semantic-Behavior Alignment for\nCold-start Recommendation framework, which mainly focuses on utilizing\nmultimodal representations that align with the user behavior space to predict\nCTR. First, we leverage domain-specific knowledge to train a multimodal encoder\nto generate behavior-aware semantic representations. Second, we use residual\nquantized semantic ID to dynamically bridge the gap between multimodal\nrepresentations and the ranking model, facilitating the continuous\nsemantic-behavior alignment. We conduct our offline and online experiments on\nthe Taobao, one of the world's largest e-commerce platforms, and have achieved\nan increase of 0.83% in offline AUC, 13.21% clicks increase and 13.44% orders\nincrease in the online A/B test, emphasizing the efficacy of our method.\n","authors":["Yining Yao","Ziwei Li","Shuwen Xiao","Boya Du","Jialin Zhu","Junjun Zheng","Xiangheng Kong","Yuning Jiang"],"pdf_url":"https://arxiv.org/pdf/2508.01375v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01370v1","updated":"2025-08-02T13:49:15Z","published":"2025-08-02T13:49:15Z","title":"MaRGen: Multi-Agent LLM Approach for Self-Directed Market Research and\n  Analysis","summary":"  We present an autonomous framework that leverages Large Language Models\n(LLMs) to automate end-to-end business analysis and market report generation.\nAt its core, the system employs specialized agents - Researcher, Reviewer,\nWriter, and Retriever - that collaborate to analyze data and produce\ncomprehensive reports. These agents learn from real professional consultants'\npresentation materials at Amazon through in-context learning to replicate\nprofessional analytical methodologies. The framework executes a multi-step\nprocess: querying databases, analyzing data, generating insights, creating\nvisualizations, and composing market reports. We also introduce a novel\nLLM-based evaluation system for assessing report quality, which shows alignment\nwith expert human evaluations. Building on these evaluations, we implement an\niterative improvement mechanism that optimizes report quality through automated\nreview cycles. Experimental results show that report quality can be improved by\nboth automated review cycles and consultants' unstructured knowledge. In\nexperimental validation, our framework generates detailed 6-page reports in 7\nminutes at a cost of approximately \\$1. Our work could be an important step to\nautomatically create affordable market insights.\n","authors":["Roman Koshkin","Pengyu Dai","Nozomi Fujikawa","Masahito Togami","Marco Visentini-Scarzanella"],"pdf_url":"https://arxiv.org/pdf/2508.01370v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01285v1","updated":"2025-08-02T09:32:52Z","published":"2025-08-02T09:32:52Z","title":"BioDisco: Multi-agent hypothesis generation with dual-mode evidence,\n  iterative feedback and temporal evaluation","summary":"  Identifying novel hypotheses is essential to scientific research, yet this\nprocess risks being overwhelmed by the sheer volume and complexity of available\ninformation. Existing automated methods often struggle to generate novel and\nevidence-grounded hypotheses, lack robust iterative refinement and rarely\nundergo rigorous temporal evaluation for future discovery potential. To address\nthis, we propose BioDisco, a multi-agent framework that draws upon language\nmodel-based reasoning and a dual-mode evidence system (biomedical knowledge\ngraphs and automated literature retrieval) for grounded novelty, integrates an\ninternal scoring and feedback loop for iterative refinement, and validates\nperformance through pioneering temporal and human evaluations and a\nBradley-Terry paired comparison model to provide statistically-grounded\nassessment. Our evaluations demonstrate superior novelty and significance over\nablated configurations representative of existing agentic architectures.\nDesigned for flexibility and modularity, BioDisco allows seamless integration\nof custom language models or knowledge graphs, and can be run with just a few\nlines of code. We anticipate researchers using this practical tool as a\ncatalyst for the discovery of new hypotheses.\n","authors":["Yujing Ke","Kevin George","Kathan Pandya","David Blumenthal","Maximilian Sprang","Gerrit Großmann","Sebastian Vollmer","David Antony Selby"],"pdf_url":"https://arxiv.org/pdf/2508.01285v1.pdf","comment":"7 pages main content + 11 pages appendices"},{"id":"http://arxiv.org/abs/2508.01265v1","updated":"2025-08-02T08:49:45Z","published":"2025-08-02T08:49:45Z","title":"A Study on Enhancing User Engagement by Employing Gamified Recommender\n  Systems","summary":"  Providing customized products and services in the modern business world is\none of the most efficient solutions to improve users' experience and their\nengagements with the industries. To aim, recommender systems, by producing\npersonalized recommendations, have a crucial role in the digital age. As a\nconsequence of modern improvements in the internet and online-based\ntechnologies, using gamification rules also increased in various fields. Recent\nstudies showed that considering gamification concepts in implementing\nrecommendation systems not only can become helpful to overcome the cold start\nand lack of sufficient data, moreover, can effectively improve user engagement.\nGamification can motivate individuals to have more activities on the system;\nthese interactions are valuable resources of data for recommender engines.\nUnlike the past related works about using gamified recommendation systems in\ndifferent environments or studies that particularly surveyed gamification\nstrategies or recommenders separately, this work provides a comprehensive\nreview of how gamified recommender systems can enhance user engagement in\nvarious domain applications. Furthermore, comparing different approaches for\nbuilding recommender systems is followed by in-depth surveying about\ninvestigating the gamified recommender systems, including their approaches,\nlimitations, evaluation metrics, proposed achievements, datasets, domain areas,\nand their recommendation techniques. This exhaustive analysis provides a\ndetailed picture of the topic's popularity, gaps, and unexplored regions. It is\nenvisaged that the proposed research and introduced possible future directions\nwould serve as a stepping stone for researchers interested in using gamified\nrecommender systems for user satisfaction and engagement.\n","authors":["Ali Fallahi","Azam Bastanfard","Amineh Amini","Hadi Saboohi"],"pdf_url":"https://arxiv.org/pdf/2508.01265v1.pdf","comment":"June 2023, 21 pages, 6 figures"},{"id":"http://arxiv.org/abs/2507.20227v3","updated":"2025-08-02T07:32:08Z","published":"2025-07-27T11:13:03Z","title":"CTR-Driven Ad Text Generation via Online Feedback Preference\n  Optimization","summary":"  Advertising text plays a critical role in determining click-through rates\n(CTR) in online advertising. Large Language Models (LLMs) offer significant\nefficiency advantages over manual ad text creation. However, LLM-generated ad\ntexts do not guarantee higher CTR performance compared to human-crafted texts,\nrevealing a gap between generation quality and online performance of ad texts.\nIn this work, we propose a novel ad text generation method which optimizes for\nCTR through preference optimization from online feedback. Our approach adopts\nan innovative two-stage framework: (1) diverse ad text sampling via one-shot\nin-context learning, using retrieval-augmented generation (RAG) to provide\nexemplars with chain-of-thought (CoT) reasoning; (2) CTR-driven preference\noptimization from online feedback, which weighs preference pairs according to\ntheir CTR gains and confidence levels. Through our method, the resulting model\nenables end-to-end generation of high-CTR ad texts. Extensive experiments have\ndemonstrated the effectiveness of our method in both offline and online\nmetrics. Notably, we have applied our method on a large-scale online shopping\nplatform and achieved significant CTR improvements, showcasing its strong\napplicability and effectiveness in advertising systems.\n","authors":["Yanda Chen","Zihui Ren","Qixiang Gao","Jiale Chen","Si Chen","Xubin Li","Tiezheng Ge","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2507.20227v3.pdf","comment":"13 pages, 7 figures, 8 tables"},{"id":"http://arxiv.org/abs/2508.01226v1","updated":"2025-08-02T06:44:59Z","published":"2025-08-02T06:44:59Z","title":"CM$^3$: Calibrating Multimodal Recommendation","summary":"  Alignment and uniformity are fundamental principles within the domain of\ncontrastive learning. In recommender systems, prior work has established that\noptimizing the Bayesian Personalized Ranking (BPR) loss contributes to the\nobjectives of alignment and uniformity. Specifically, alignment aims to draw\ntogether the representations of interacting users and items, while uniformity\nmandates a uniform distribution of user and item embeddings across a unit\nhypersphere. This study revisits the alignment and uniformity properties within\nthe context of multimodal recommender systems, revealing a proclivity among\nextant models to prioritize uniformity to the detriment of alignment. Our\nhypothesis challenges the conventional assumption of equitable item treatment\nthrough a uniformity loss, proposing a more nuanced approach wherein items with\nsimilar multimodal attributes converge toward proximal representations within\nthe hyperspheric manifold. Specifically, we leverage the inherent similarity\nbetween items' multimodal data to calibrate their uniformity distribution,\nthereby inducing a more pronounced repulsive force between dissimilar entities\nwithin the embedding space. A theoretical analysis elucidates the relationship\nbetween this calibrated uniformity loss and the conventional uniformity\nfunction. Moreover, to enhance the fusion of multimodal features, we introduce\na Spherical B\\'ezier method designed to integrate an arbitrary number of\nmodalities while ensuring that the resulting fused features are constrained to\nthe same hyperspherical manifold. Empirical evaluations conducted on five\nreal-world datasets substantiate the superiority of our approach over competing\nbaselines. We also shown that the proposed methods can achieve up to a 5.4%\nincrease in NDCG@20 performance via the integration of MLLM-extracted features.\nSource code is available at: https://github.com/enoche/CM3.\n","authors":["Xin Zhou","Yongjie Wang","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2508.01226v1.pdf","comment":"Working Paper: https://github.com/enoche/CM3"},{"id":"http://arxiv.org/abs/2508.01136v1","updated":"2025-08-02T01:36:57Z","published":"2025-08-02T01:36:57Z","title":"DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance\n  System using Knowledge Graphs","summary":"  The operation and maintenance (O&M) of database systems is critical to\nensuring system availability and performance, typically requiring expert\nexperience (e.g., identifying metric-to-anomaly relations) for effective\ndiagnosis and recovery. However, existing automatic database O&M methods,\nincluding commercial products, cannot effectively utilize expert experience. On\nthe one hand, rule-based methods only support basic O&M tasks (e.g.,\nmetric-based anomaly detection), which are mostly numerical equations and\ncannot effectively incorporate literal O&M experience (e.g., troubleshooting\nguidance in manuals). On the other hand, LLM-based methods, which retrieve\nfragmented information (e.g., standard documents + RAG), often generate\ninaccurate or generic results. To address these limitations, we present\nDBAIOps, a novel hybrid database O&M system that combines reasoning LLMs with\nknowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a\nheterogeneous graph model for representing the diagnosis experience, and\nproposes a semi-automatic graph construction algorithm to build that graph from\nthousands of documents. Second, DBAIOps develops a collection of (800+)\nreusable anomaly models that identify both directly alerted metrics and\nimplicitly correlated experience and metrics. Third, for each anomaly, DBAIOps\nproposes a two-stage graph evolution mechanism to explore relevant diagnosis\npaths and identify missing relations automatically. It then leverages a\nreasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear\ndiagnosis reports for both DBAs and common users. Our evaluation over four\nmainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates\nthat DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher\nin root cause and human evaluation accuracy, respectively.\n","authors":["Wei Zhou","Peng Sun","Xuanhe Zhou","Qianglei Zang","Ji Xu","Tieying Zhang","Guoliang Li","Fan Wu"],"pdf_url":"https://arxiv.org/pdf/2508.01136v1.pdf","comment":"DBAIOps supports 25 database systems and has been deployed in 20\n  real-world scenarios, covering domains like finance, energy, and healthcare.\n  See website at: https://www.dbaiops.com; See code at:\n  https://github.com/weAIDB/DBAIOps/"},{"id":"http://arxiv.org/abs/2508.01128v1","updated":"2025-08-02T00:53:40Z","published":"2025-08-02T00:53:40Z","title":"Towards Bridging Review Sparsity in Recommendation with Textual Edge\n  Graph Representation","summary":"  Textual reviews enrich recommender systems with fine-grained preference\nsignals and enhanced explainability. However, in real-world scenarios, users\nrarely leave reviews, resulting in severe sparsity that undermines the\neffectiveness of existing models. A natural solution is to impute or generate\nmissing reviews to enrich the data. However, conventional imputation techniques\n-- such as matrix completion and LLM-based augmentation -- either lose\ncontextualized semantics by embedding texts into vectors, or overlook\nstructural dependencies among user-item interactions. To address these\nshortcomings, we propose TWISTER (ToWards Imputation on Sparsity with Textual\nEdge Graph Representation), a unified framework that imputes missing reviews by\njointly modeling semantic and structural signals. Specifically, we represent\nuser-item interactions as a Textual-Edge Graph (TEG), treating reviews as edge\nattributes. To capture relational context, we construct line-graph views and\nemploy a large language model as a graph-aware aggregator. For each interaction\nlacking a textual review, our model aggregates the neighborhood's\nnatural-language representations to generate a coherent and personalized\nreview. Experiments on the Amazon and Goodreads datasets show that TWISTER\nconsistently outperforms traditional numeric, graph-based, and LLM baselines,\ndelivering higher-quality imputed reviews and, more importantly, enhanced\nrecommendation performance. In summary, TWISTER generates reviews that are more\nhelpful, authentic, and specific, while smoothing structural signals for\nimproved recommendations.\n","authors":["Leyao Wang","Xutao Mao","Xuhui Zhan","Yuying Zhao","Bo Ni","Ryan A. Rossi","Nesreen K. Ahmed","Tyler Derr"],"pdf_url":"https://arxiv.org/pdf/2508.01128v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2505.19849v2","updated":"2025-08-02T00:31:18Z","published":"2025-05-26T11:35:04Z","title":"HIT Model: A Hierarchical Interaction-Enhanced Two-Tower Model for\n  Pre-Ranking Systems","summary":"  Online display advertising platforms rely on pre-ranking systems to\nefficiently filter and prioritize candidate ads from large corpora, balancing\nrelevance to users with strict computational constraints. The prevailing\ntwo-tower architecture, though highly efficient due to its decoupled design and\npre-caching, suffers from cross-domain interaction and coarse similarity\nmetrics, undermining its capacity to model complex user-ad relationships. In\nthis study, we propose the Hierarchical Interaction-Enhanced Two-Tower (HIT)\nmodel, a new architecture that augments the two-tower paradigm with two key\ncomponents: $\\textit{generators}$ that pre-generate holistic vectors\nincorporating coarse-grained user-ad interactions through a dual-generator\nframework with a cosine-similarity-based generation loss as the training\nobjective, and $\\textit{multi-head representers}$ that project embeddings into\nmultiple latent subspaces to capture fine-grained, multi-faceted user interests\nand multi-dimensional ad attributes. This design enhances modeling\neffectiveness without compromising inference efficiency. Extensive experiments\non public datasets and large-scale online A/B testing on Tencent's advertising\nplatform demonstrate that HIT significantly outperforms several baselines in\nrelevance metrics, yielding a $1.66\\%$ increase in Gross Merchandise Volume and\na $1.55\\%$ improvement in Return on Investment, alongside similar serving\nlatency to the vanilla two-tower models. The HIT model has been successfully\ndeployed in Tencent's online display advertising system, serving billions of\nimpressions daily. The code is available at\nhttps://github.com/HarveyYang123/HIT_model.\n","authors":["Haoqiang Yang","Congde Yuan","Kun Bai","Mengzhuo Guo","Wei Yang","Chao Zhou"],"pdf_url":"https://arxiv.org/pdf/2505.19849v2.pdf","comment":"7 pages"}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2508.01517v1","updated":"2025-08-02T23:33:57Z","published":"2025-08-02T23:33:57Z","title":"Central Limit Theorems for Transition Probabilities of Controlled Markov\n  Chains","summary":"  We develop a central limit theorem (CLT) for the non-parametric estimator of\nthe transition matrices in controlled Markov chains (CMCs) with finite\nstate-action spaces. Our results establish precise conditions on the logging\npolicy under which the estimator is asymptotically normal, and reveal settings\nin which no CLT can exist. We then build upon it to derive CLTs for the value,\nQ-, and advantage functions of any stationary stochastic policy, including the\noptimal policy recovered from the estimated model. Goodness-of-fit tests are\nderived as a corollary, which enable us to test whether the logged data is\nstochastic. These results provide new statistical tools for offline policy\nevaluation and optimal policy recovery, and enable hypothesis tests for\ntransition probabilities.\n","authors":["Ziwei Su","Imon Banerjee","Diego Klabjan"],"pdf_url":"https://arxiv.org/pdf/2508.01517v1.pdf","comment":"39 pages (main text 19 pages + appendix 20 pages)"},{"id":"http://arxiv.org/abs/2504.00186v3","updated":"2025-08-02T22:34:06Z","published":"2025-03-31T19:50:04Z","title":"Are Domain Generalization Benchmarks with Accuracy on the Line\n  Misspecified?","summary":"  Spurious correlations, unstable statistical shortcuts a model can exploit,\nare expected to degrade performance out-of-distribution (OOD). However, across\nmany popular OOD generalization benchmarks, vanilla empirical risk minimization\n(ERM) often achieves the highest OOD accuracy. Moreover, gains in\nin-distribution accuracy generally improve OOD accuracy, a phenomenon termed\naccuracy on the line, which contradicts the expected harm of spurious\ncorrelations. We show that these observations are an artifact of misspecified\nOOD datasets that do not include shifts in spurious correlations that harm OOD\ngeneralization, the setting they are meant to evaluate. Consequently, current\npractice evaluates \"robustness\" without truly stressing the spurious signals we\nseek to eliminate; our work pinpoints when that happens and how to fix it.\nContributions. (i) We derive necessary and sufficient conditions for a\ndistribution shift to reveal a model's reliance on spurious features; when\nthese conditions hold, \"accuracy on the line\" disappears. (ii) We audit leading\nOOD datasets and find that most still display accuracy on the line, suggesting\nthey are misspecified for evaluating robustness to spurious correlations. (iii)\nWe catalog the few well-specified datasets and summarize generalizable design\nprinciples, such as identifying datasets of natural interventions (e.g., a\npandemic), to guide future well-specified benchmarks.\n","authors":["Olawale Salaudeen","Nicole Chiou","Shiny Weng","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2504.00186v3.pdf","comment":"Published in TMLR 08/25"},{"id":"http://arxiv.org/abs/2506.01212v2","updated":"2025-08-02T21:43:07Z","published":"2025-06-01T23:16:39Z","title":"Dynamic Modes as Time Representation for Spatiotemporal Forecasting","summary":"  This paper introduces a data-driven time embedding method for modeling\nlong-range seasonal dependencies in spatiotemporal forecasting tasks. The\nproposed approach employs Dynamic Mode Decomposition (DMD) to extract temporal\nmodes directly from observed data, eliminating the need for explicit timestamps\nor hand-crafted time features. These temporal modes serve as time\nrepresentations that can be seamlessly integrated into deep spatiotemporal\nforecasting models. Unlike conventional embeddings such as time-of-day\nindicators or sinusoidal functions, our method captures complex multi-scale\nperiodicity through spectral analysis of spatiotemporal data. Extensive\nexperiments on urban mobility, highway traffic, and climate datasets\ndemonstrate that the DMD-based embedding consistently improves long-horizon\nforecasting accuracy, reduces residual correlation, and enhances temporal\ngeneralization. The method is lightweight, model-agnostic, and compatible with\nany architecture that incorporates time covariates.\n","authors":["Menglin Kong","Vincent Zhihao Zheng","Xudong Wang","Lijun Sun"],"pdf_url":"https://arxiv.org/pdf/2506.01212v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01457v1","updated":"2025-08-02T18:20:12Z","published":"2025-08-02T18:20:12Z","title":"NICE^k Metrics: Unified and Multidimensional Framework for Evaluating\n  Deterministic Solar Forecasting Accuracy","summary":"  Accurate solar energy output prediction is key for integrating renewables\ninto grids, maintaining stability, and improving energy management. However,\nstandard error metrics such as Root Mean Squared Error (RMSE), Mean Absolute\nError (MAE), and Skill Scores (SS) fail to capture the multidimensional nature\nof solar irradiance forecasting. These metrics lack sensitivity to\nforecastability, rely on arbitrary baselines (e.g., clear-sky models), and are\npoorly suited for operational use.\n  To address this, we introduce the NICEk framework (Normalized Informed\nComparison of Errors, with k = 1, 2, 3, Sigma), offering a robust and\ninterpretable evaluation of forecasting models. Each NICEk score corresponds to\nan Lk norm: NICE1 targets average errors, NICE2 emphasizes large deviations,\nNICE3 highlights outliers, and NICESigma combines all.\n  Using Monte Carlo simulations and data from 68 stations in the Spanish SIAR\nnetwork, we evaluated methods including autoregressive models, extreme\nlearning, and smart persistence. Theoretical and empirical results align when\nassumptions hold (e.g., R^2 ~ 1.0 for NICE2). Most importantly, NICESigma\nconsistently shows higher discriminative power (p < 0.05), outperforming\ntraditional metrics (p > 0.05).\n  The NICEk metrics exhibit stronger statistical significance (e.g., p-values\nfrom 10^-6 to 0.004 across horizons) and greater generalizability. They offer a\nunified and operational alternative to standard error metrics in deterministic\nsolar forecasting.\n","authors":["Cyril Voyant","Milan Despotovic","Luis Garcia-Gutierrez","Rodrigo Amaro e Silva","Philippe Lauret","Ted Soubdhan","Nadjem Bailek"],"pdf_url":"https://arxiv.org/pdf/2508.01457v1.pdf","comment":"24 pages, 1 Table, 5 Figures"},{"id":"http://arxiv.org/abs/2508.01453v1","updated":"2025-08-02T18:02:44Z","published":"2025-08-02T18:02:44Z","title":"Kernel-Based Sparse Additive Nonlinear Model Structure Detection through\n  a Linearization Approach","summary":"  The choice of parameterization in Nonlinear (NL) system models greatly\naffects the quality of the estimated model. Overly complex models can be\nimpractical and hard to interpret, necessitating data-driven methods for\nsimpler and more accurate representations. In this paper, we propose a\ndata-driven approach to simplify a class of continuous-time NL system models\nusing linear approximations around varying operating points. Specifically, for\nsparse additive NL models, our method identifies the number of NL subterms and\ntheir corresponding input spaces. Under small-signal operation, we approximate\nthe unknown NL system as a trajectory-scheduled Linear Parameter-Varying (LPV)\nsystem, with LPV coefficients representing the gradient of the NL function and\nindicating input sensitivity. Using this sensitivity measure, we determine the\nNL system's structure through LPV model reduction by identifying non-zero LPV\ncoefficients and selecting scheduling parameters. We introduce two sparse\nestimators within a vector-valued Reproducing Kernel Hilbert Space (RKHS)\nframework to estimate the LPV coefficients while preserving their structural\nrelationships. The structure of the sparse additive NL model is then determined\nby detecting non-zero elements in the gradient vector (LPV coefficients) and\nthe Hessian matrix (Jacobian of the LPV coefficients). We propose two\ncomputationally tractable RKHS-based estimators for this purpose. The\nsparsified Hessian matrix reveals the NL model's structure, with numerical\nsimulations confirming the approach's effectiveness.\n","authors":["Sadegh Ebrahimkhani","John Lataire"],"pdf_url":"https://arxiv.org/pdf/2508.01453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01395v1","updated":"2025-08-02T15:03:01Z","published":"2025-08-02T15:03:01Z","title":"Effects of Feature Correlations on Associative Memory Capacity","summary":"  We investigate how feature correlations influence the capacity of Dense\nAssociative Memory (DAM), a Transformer attention-like model. Practical machine\nlearning scenarios involve feature-correlated data and learn representations in\nthe input space, but current capacity analyses do not account for this. We\ndevelop an empirical framework to analyze the effects of data structure on\ncapacity dynamics. Specifically, we systematically construct datasets that vary\nin feature correlation and pattern separation using Hamming distance from\ninformation theory, and compute the model's corresponding storage capacity\nusing a simple binary search algorithm. Our experiments confirm that memory\ncapacity scales exponentially with increasing separation in the input space.\nFeature correlations do not alter this relationship fundamentally, but reduce\ncapacity slightly at constant separation. This effect is amplified at higher\npolynomial degrees in the energy function, suggesting that Associative Memory\nis more limited in depicting higher-order interactions between features than\npatterns. Our findings bridge theoretical work and practical settings for DAM,\nand might inspire more data-centric methods.\n","authors":["Stefan Bielmeier","Gerald Friedland"],"pdf_url":"https://arxiv.org/pdf/2508.01395v1.pdf","comment":"Accepted at ICLR 2025 \"New Frontiers in Associative Memories\"\n  Workshop. Code: https://github.com/stefanbielmeier/feature-correlations-am"},{"id":"http://arxiv.org/abs/2508.01392v1","updated":"2025-08-02T14:52:06Z","published":"2025-08-02T14:52:06Z","title":"Quenched large deviations for Monte Carlo integration with Coulomb gases","summary":"  Gibbs measures, such as Coulomb gases, are popular in modelling systems of\ninteracting particles. Recently, we proposed to use Gibbs measures as\nrandomized numerical integration algorithms with respect to a target measure\n$\\pi$ on $\\mathbb R^d$, following the heuristics that repulsiveness between\nparticles should help reduce integration errors. A major issue in this approach\nis to tune the interaction kernel and confining potential of the Gibbs measure,\nso that the equilibrium measure of the system is the target distribution $\\pi$.\nDoing so usually requires another Monte Carlo approximation of the\n\\emph{potential}, i.e. the integral of the interaction kernel with respect to\n$\\pi$. Using the methodology of large deviations from Garcia--Zelada (2019), we\nshow that a random approximation of the potential preserves the fast large\ndeviation principle that guarantees the proposed integration algorithm to\noutperform independent or Markov quadratures. For non-singular interaction\nkernels, we make minimal assumptions on this random approximation, which can be\nthe result of a computationally cheap Monte Carlo preprocessing. For the\nCoulomb interaction kernel, we need the approximation to be based on another\nGibbs measure, and we prove in passing a control on the uniform convergence of\nthe approximation of the potential.\n","authors":["Rémi Bardenet","Mylène Maïda","Martin Rouault"],"pdf_url":"https://arxiv.org/pdf/2508.01392v1.pdf","comment":"39 pages, 7 figures. Comments are welcome"},{"id":"http://arxiv.org/abs/2508.01341v1","updated":"2025-08-02T12:26:26Z","published":"2025-08-02T12:26:26Z","title":"Debiasing Machine Learning Predictions for Causal Inference Without\n  Additional Ground Truth Data: \"One Map, Many Trials\" in Satellite-Driven\n  Poverty Analysis","summary":"  Machine learning models trained on Earth observation data, such as satellite\nimagery, have demonstrated significant promise in predicting household-level\nwealth indices, enabling the creation of high-resolution wealth maps that can\nbe leveraged across multiple causal trials. However, because standard training\nobjectives prioritize overall predictive accuracy, these predictions inherently\nsuffer from shrinkage toward the mean, leading to attenuated estimates of\ncausal treatment effects and limiting their utility in policy. Existing\ndebiasing methods, such as Prediction-Powered Inference, can handle this\nattenuation bias but require additional fresh ground-truth data at the\ndownstream stage of causal inference, which restricts their applicability in\ndata-scarce environments. Here, we introduce and evaluate two correction\nmethods -- linear calibration correction and Tweedie's correction -- that\nsubstantially reduce prediction bias without relying on newly collected labeled\ndata. Linear calibration corrects bias through a straightforward linear\ntransformation derived from held-out calibration data, whereas Tweedie's\ncorrection leverages empirical Bayes principles to directly address\nshrinkage-induced biases by exploiting score functions derived from the model's\nlearning patterns. Through analytical exercises and experiments using\nDemographic and Health Survey data, we demonstrate that the proposed methods\nmeet or outperform existing approaches that either require (a) adjustments to\ntraining pipelines or (b) additional labeled data. These approaches may\nrepresent a promising avenue for improving the reliability of causal inference\nwhen direct outcome measures are limited or unavailable, enabling a \"one map,\nmany trials\" paradigm where a single upstream data creation team produces\npredictions usable by many downstream teams across diverse ML pipelines.\n","authors":["Markus Pettersson","Connor T. Jerzak","Adel Daoud"],"pdf_url":"https://arxiv.org/pdf/2508.01341v1.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2508.01321v1","updated":"2025-08-02T11:24:03Z","published":"2025-08-02T11:24:03Z","title":"Flow IV: Counterfactual Inference In Nonseparable Outcome Models Using\n  Instrumental Variables","summary":"  To reach human level intelligence, learning algorithms need to incorporate\ncausal reasoning. But identifying causality, and particularly counterfactual\nreasoning, remains an elusive task. In this paper, we make progress on this\ntask by utilizing instrumental variables (IVs). IVs are a classic tool for\nmitigating bias from unobserved confounders when estimating causal effects.\nWhile IV methods have been extended to non-separable structural models at the\npopulation level, existing approaches to counterfactual prediction typically\nassume additive noise in the outcome. In this paper, we show that under\nstandard IV assumptions, along with the assumptions that latent noises in\ntreatment and outcome are strictly monotonic and jointly Gaussian, the\ntreatment-outcome relationship becomes uniquely identifiable from observed\ndata. This enables counterfactual inference even in nonseparable models. We\nimplement our approach by training a normalizing flow to maximize the\nlikelihood of the observed data, demonstrating accurate recovery of the\nunderlying outcome function. We call our method Flow IV.\n","authors":["Marc Braun","Jose M. Peña","Adel Daoud"],"pdf_url":"https://arxiv.org/pdf/2508.01321v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.02508v3","updated":"2025-08-02T09:46:23Z","published":"2025-05-05T09:40:41Z","title":"Resolving Memorization in Empirical Diffusion Model for Manifold Data in\n  High-Dimensional Spaces","summary":"  Diffusion models are popular tools for generating new data samples, using a\nforward process that adds noise to data and a reverse process to denoise and\nproduce samples. However, when the data distribution consists of n points,\nempirical diffusion models tend to reproduce existing data points, a phenomenon\nknown as the memorization effect. Current literature often addresses this with\ncomplex machine learning techniques. This work shows that the memorization\nissue can be solved simply by applying an inertia update at the end of the\nempirical diffusion simulation. Our inertial diffusion model requires only the\nempirical score function and no additional training. We demonstrate that the\ndistribution of samples from this model approximates the true data distribution\non a $C^2$ manifold of dimension $d$, within a Wasserstein-1 distance of order\n$O(n^{-\\frac{2}{d+4}})$. This bound significantly shrinks the Wasserstein\ndistance between the population and empirical distributions, confirming that\nthe inertial diffusion model produces new and diverse samples. Remarkably, this\nestimate is independent of the ambient space dimension, as no further training\nis needed. Our analysis shows that the inertial diffusion samples resemble\nGaussian kernel density estimations on the manifold, revealing a novel\nconnection between diffusion models and manifold learning.\n","authors":["Yang Lyu","Tan Minh Nguyen","Yuchun Qian","Xin T. Tong"],"pdf_url":"https://arxiv.org/pdf/2505.02508v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.21799v2","updated":"2025-08-02T09:22:59Z","published":"2025-05-27T22:11:21Z","title":"PolarGrad: A Class of Matrix-Gradient Optimizers from a Unifying\n  Preconditioning Perspective","summary":"  The ever-growing scale of deep learning models and datasets underscores the\ncritical importance of efficient optimization methods. While preconditioned\ngradient methods such as Adam and AdamW are the de facto optimizers for\ntraining neural networks and large language models, structure-aware\npreconditioned optimizers like Shampoo and Muon, which utilize the matrix\nstructure of gradients, have demonstrated promising evidence of faster\nconvergence. In this paper, we introduce a unifying framework for analyzing\n\"matrix-aware\" preconditioned methods, which not only sheds light on the\neffectiveness of Muon and related optimizers but also leads to a class of new\nstructure-aware preconditioned methods. A key contribution of this framework is\nits precise distinction between preconditioning strategies that treat neural\nnetwork weights as vectors (addressing curvature anisotropy) versus those that\nconsider their matrix structure (addressing gradient anisotropy). This\nperspective provides new insights into several empirical phenomena in language\nmodel pre-training, including Adam's training instabilities, Muon's accelerated\nconvergence, and the necessity of learning rate warmup for Adam. Building upon\nthis framework, we introduce PolarGrad, a new class of preconditioned\noptimization methods based on the polar decomposition of matrix-valued\ngradients. As a special instance, PolarGrad includes Muon with updates scaled\nby the nuclear norm of the gradients. We provide numerical implementations of\nthese methods, leveraging efficient numerical polar decomposition algorithms\nfor enhanced convergence. Our extensive evaluations across diverse matrix\noptimization problems and language model pre-training tasks demonstrate that\nPolarGrad outperforms both Adam and Muon.\n","authors":["Tim Tsz-Kit Lau","Qi Long","Weijie Su"],"pdf_url":"https://arxiv.org/pdf/2505.21799v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.01327v2","updated":"2025-08-02T07:21:42Z","published":"2023-11-02T15:40:33Z","title":"High-dimensional Linear Bandits with Knapsacks","summary":"  We investigate the contextual bandits with knapsack (CBwK) problem in a\nhigh-dimensional linear setting, where the feature dimension can be very large.\nOur goal is to harness sparsity to obtain sharper regret guarantees. To this\nend, we first develop an online variant of the hard thresholding algorithm that\nperforms the sparse estimation in an online manner. We then embed this\nestimator in a primal-dual scheme: every knapsack constraint is paired with a\ndual variable, which is updated by an online learning rule to keep the\ncumulative resource consumption within budget. This integrated approach\nachieves a two-phase sub-linear regret that scales only logarithmically with\nthe feature dimension, improving on the polynomial dependency reported in prior\nwork. Furthermore, we show that either of the following structural assumptions\nis sufficient for a sharper regret bound of $\\tilde{O}(s_{0} \\sqrt{T})$: (i) a\ndiverse-covariate condition; and (ii) a margin condition. When both conditions\nhold simultaneously, we can further control the regret to $O(s_{0}^{2}\n\\log(dT)\\log T)$ by a dual resolving scheme. As a by-product, applying our\nframework to high-dimensional contextual bandits without knapsack constraints\nrecovers the optimal regret rates in both the data-poor and data-rich regimes.\nFinally, numerical experiments confirm the empirical efficiency of our\nalgorithms in high-dimensional settings.\n","authors":["Wanteng Ma","Dong Xia","Jiashuo Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.01327v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01228v1","updated":"2025-08-02T06:46:37Z","published":"2025-08-02T06:46:37Z","title":"Inferring processes within dynamic forest models using hybrid modeling","summary":"  Modeling forest dynamics under novel climatic conditions requires a careful\nbalance between process-based understanding and empirical flexibility. Dynamic\nVegetation Models (DVM) represent ecological processes mechanistically, but\ntheir performance is prone to misspecified assumptions about functional forms.\nInferring the structure of these processes and their functional forms correctly\nfrom data remains a major challenge because current approaches, such as plug-in\nestimators, have proven ineffective. We introduce Forest Informed Neural\nNetworks (FINN), a hybrid modeling approach that combines a forest gap model\nwith deep neural networks (DNN). FINN replaces processes with DNNs, which are\nthen calibrated alongside the other mechanistic components in one unified step.\nIn a case study on the Barro Colorado Island 50-ha plot we demonstrate that\nreplacing the growth process with a DNN improves predictive performance and\nsuccession trajectories compared to a fully mechanistic version of FINN.\nFurthermore, we discovered that the DNN learned an ecologically plausible,\nimproved functional form of growth, which we extracted from the DNN using\nexplainable AI. In conclusion, our new hybrid modeling approach offers a\nversatile opportunity to infer forest dynamics from data and to improve\nforecasts of ecosystem trajectories under unprecedented environmental change.\n","authors":["Maximilian Pichler","Yannek Käber"],"pdf_url":"https://arxiv.org/pdf/2508.01228v1.pdf","comment":"29 pages, 16 figures"},{"id":"http://arxiv.org/abs/2508.01217v1","updated":"2025-08-02T06:19:23Z","published":"2025-08-02T06:19:23Z","title":"Uncertainty Quantification for Large-Scale Deep Networks via Post-StoNet\n  Modeling","summary":"  Deep learning has revolutionized modern data science. However, how to\naccurately quantify the uncertainty of predictions from large-scale deep neural\nnetworks (DNNs) remains an unresolved issue. To address this issue, we\nintroduce a novel post-processing approach. This approach feeds the output from\nthe last hidden layer of a pre-trained large-scale DNN model into a stochastic\nneural network (StoNet), then trains the StoNet with a sparse penalty on a\nvalidation dataset and constructs prediction intervals for future observations.\nWe establish a theoretical guarantee for the validity of this approach; in\nparticular, the parameter estimation consistency for the sparse StoNet is\nessential for the success of this approach. Comprehensive experiments\ndemonstrate that the proposed approach can construct honest confidence\nintervals with shorter interval lengths compared to conformal methods and\nachieves better calibration compared to other post-hoc calibration techniques.\nAdditionally, we show that the StoNet formulation provides us with a platform\nto adapt sparse learning theory and methods from linear models to DNNs.\n","authors":["Yan Sun","Faming Liang"],"pdf_url":"https://arxiv.org/pdf/2508.01217v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.09445v2","updated":"2025-08-02T05:17:13Z","published":"2025-07-13T01:45:27Z","title":"Fourier Basis Mapping: A Time-Frequency Learning Framework for Time\n  Series Forecasting","summary":"  The integration of Fourier transform and deep learning opens new avenues for\ntime series forecasting. We reconsider the Fourier transform from a basis\nfunctions perspective. Specifically, the real and imaginary parts of the\nfrequency components can be regarded as the coefficients of cosine and sine\nbasis functions at tiered frequency levels, respectively. We find that existing\nFourier-based methods face inconsistent starting cycles and inconsistent series\nlength issues. They fail to interpret frequency components precisely and\noverlook temporal information. Accordingly, the novel Fourier Basis Mapping\n(FBM) method addresses these issues by integrating time-frequency features\nthrough Fourier basis expansion and mapping in the time-frequency space. Our\napproach extracts explicit frequency features while preserving temporal\ncharacteristics. FBM supports plug-and-play integration with various types of\nneural networks by only adjusting the first initial projection layer for better\nperformance. First, we propose FBM-L, FBM-NL, and FBM-NP to enhance linear,\nMLP-based, and Transformer-based models, respectively, demonstrating the\neffectiveness of time-frequency features. Next, we propose a synergetic model\narchitecture, termed FBM-S, which decomposes the seasonal, trend, and\ninteraction effects into three separate blocks, each designed to model\ntime-frequency features in a specialized manner. Finally, we introduce several\ntechniques tailored for time-frequency features, including interaction masking,\ncentralization, patching, rolling window projection, and multi-scale\ndown-sampling. The results are validated on diverse real-world datasets for\nboth long-term and short-term forecasting tasks with SOTA performance.\n","authors":["Runze Yang","Longbing Cao","Xin You","Kun Fang","Jianxun Li","Jie Yang"],"pdf_url":"https://arxiv.org/pdf/2507.09445v2.pdf","comment":"18 pages, 6 figures"}],"Computation":[{"id":"http://arxiv.org/abs/2508.01342v1","updated":"2025-08-02T12:36:22Z","published":"2025-08-02T12:36:22Z","title":"riemtan, riemstats: R packages for Riemannian geometry techniques in the\n  analysis of multiple samples of connectomes","summary":"  Symmetric positive definite (SPD) matrices arising from functional\nconnectivity analysis of neuroimaging data can be endowed with a Riemannian\ngeometric structure that standard methods fail to respect. While existing R\npackages provide some tools for SPD matrix analysis, they suffer from\nlimitations in scalability, numerical stability, and metric flexibility that\nhinder their application to modern large-scale connectomics studies. We present\nriemtan, a comprehensive R package that addresses these challenges through a\nunified, high-level interface supporting multiple Riemannian metrics, efficient\nparallel computation, and seamless conversion between manifold, tangent, and\nvectorized representations. Building on riemtan's foundation, we also introduce\nriemstats, which implements advanced statistical methods including Fr\\'echet\nANOVA, Riemannian ANOVA with classic test statistics, and harmonization\ntechniques for multi-site studies. The modular design facilitates integration\nwith existing R workflows and provides an extensible framework for future\nmethodological developments in manifold-valued data analysis.\n","authors":["Nicolas Escobar-Velasquez"],"pdf_url":"https://arxiv.org/pdf/2508.01342v1.pdf","comment":null}]},"2025-08-05T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2506.05305v2","updated":"2025-08-05T17:56:29Z","published":"2025-06-05T17:52:30Z","title":"ProRefine: Inference-Time Prompt Refinement with Textual Feedback","summary":"  Agentic workflows, where multiple AI agents collaborate to accomplish complex\ntasks like reasoning or planning, play a substantial role in many cutting-edge\ncommercial applications, and continue to fascinate researchers across nearly\nall fields for their potential to accomplish expensive, complex tasks that,\nuntil recently, only humans have been trusted to do. These workflows depend\ncritically on the prompts used to provide the roles models play in such\nworkflows. Poorly designed prompts that fail even slightly to guide individual\nagents can lead to sub-optimal performance that may snowball within a system of\nagents, limiting their reliability and scalability. To address this important\nproblem of inference-time prompt optimization, we introduce ProRefine, an\ninnovative inference-time optimization method that uses an agentic loop of LLMs\nto generate and apply textual feedback. ProRefine dynamically refines prompts\nfor multi-step reasoning tasks without additional training or ground truth\nlabels. Evaluated on five benchmark mathematical reasoning datasets, ProRefine\nsignificantly surpasses zero-shot Chain-of-Thought baselines by 3 to 37\npercentage points. This approach not only boosts accuracy but also allows\nsmaller models to approach the performance of their larger counterparts. This\nhighlights its potential for building more cost-effective and powerful hybrid\nAI systems, thereby democratizing access to high-performing AI.\n","authors":["Deepak Pandita","Tharindu Cyril Weerasooriya","Ankit Parag Shah","Isabelle Diana May-Xin Ng","Christopher M. Homan","Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2506.05305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03686v1","updated":"2025-08-05T17:55:24Z","published":"2025-08-05T17:55:24Z","title":"CompassVerifier: A Unified and Robust Verifier for LLMs Evaluation and\n  Outcome Reward","summary":"  Answer verification is crucial not only for evaluating large language models\n(LLMs) by matching their unstructured outputs against standard answers, but\nalso serves as the reward model to guide LLM optimization. Most evaluation\nframeworks rely on regularized matching or employ general LLMs for answer\nverification, which demands extensive, repetitive customization for regex rules\nor evaluation prompts. Two fundamental limitations persist in current\nmethodologies: 1) the absence of comprehensive benchmarks that systematically\nevaluate verification capabilities across different LLMs; and 2) the nascent\nstage of verifier development, where existing approaches lack both the\nrobustness to handle complex edge cases and the generalizability across\ndifferent domains. In this work, we develop CompassVerifier, an accurate and\nrobust lightweight verifier model for evaluation and outcome reward. It\ndemonstrates multi-domain competency spanning math, knowledge, and diverse\nreasoning tasks, with the capability to process various answer types, including\nmulti-subproblems, formulas, and sequence answers, while effectively\nidentifying abnormal/invalid responses. We introduce VerifierBench benchmark\ncomprising model outputs collected from multiple data sources, augmented\nthrough manual analysis of metaerror patterns to enhance CompassVerifier. We\nanticipate that CompassVerifier and VerifierBench will facilitate answer\nverification, evaluation protocols, and reinforcement learning research. Code\nand dataset are available at https://github.com/open-compass/CompassVerifier.\n","authors":["Shudong Liu","Hongwei Liu","Junnan Liu","Linchen Xiao","Songyang Gao","Chengqi Lyu","Yuzhe Gu","Wenwei Zhang","Derek F. Wong","Songyang Zhang","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2508.03686v1.pdf","comment":"Technical Report; 31 Pages"},{"id":"http://arxiv.org/abs/2508.03678v1","updated":"2025-08-05T17:49:48Z","published":"2025-08-05T17:49:48Z","title":"More Than a Score: Probing the Impact of Prompt Specificity on LLM Code\n  Generation","summary":"  State-of-the-art Large Language Models (LLMs) achieve high pass@1 on general\nbenchmarks like HumanEval but underperform on specialized suites such as\nParEval. Is this due to LLMs missing domain knowledge or insufficient prompt\ndetail is given? To answer this, we introduce PartialOrderEval, which augments\nany code generation benchmark with a partial order of prompts from minimal to\nmaximally detailed. Applying it to HumanEval and both serial and OpenMP subsets\nof ParEval, we measure how pass@1 scales with prompt specificity. Our\nexperiments with Llama-3.x and Qwen2.5-Coder demonstrate varying degrees of\nprompt sensitivity across different tasks, and a qualitative analysis\nhighlights explicit I/O specifications, edge-case handling, and stepwise\nbreakdowns as the key drivers of prompt detail improvement.\n","authors":["Yangtian Zi","Harshitha Menon","Arjun Guha"],"pdf_url":"https://arxiv.org/pdf/2508.03678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03677v1","updated":"2025-08-05T17:47:53Z","published":"2025-08-05T17:47:53Z","title":"FairLangProc: A Python package for fairness in NLP","summary":"  The rise in usage of Large Language Models to near ubiquitousness in recent\nyears has risen societal concern about their applications in decision-making\ncontexts, such as organizational justice or healthcare. This, in turn, poses\nquestions about the fairness of these models in critical settings, which leads\nto the developement of different procedures to address bias in Natural Language\nProcessing. Although many datasets, metrics and algorithms have been proposed\nto measure and mitigate harmful prejudice in Natural Language Processing, their\nimplementation is diverse and far from centralized. As a response, this paper\npresents FairLangProc, a comprehensive Python package providing a common\nimplementation of some of the more recent advances in fairness in Natural\nLanguage Processing providing an interface compatible with the famous Hugging\nFace transformers library, aiming to encourage the widespread use and\ndemocratization of bias mitigation techniques. The implementation can be found\non https://github.com/arturo-perez-peralta/FairLangProc.\n","authors":["Arturo Pérez-Peralta","Sandra Benítez-Peña","Rosa E. Lillo"],"pdf_url":"https://arxiv.org/pdf/2508.03677v1.pdf","comment":"40 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2501.13836v3","updated":"2025-08-05T17:46:59Z","published":"2025-01-23T17:01:53Z","title":"Think Outside the Data: Colonial Biases and Systemic Issues in Automated\n  Moderation Pipelines for Low-Resource Languages","summary":"  Most social media users come from the Global South, where harmful content\nusually appears in local languages. Yet, AI-driven moderation systems struggle\nwith low-resource languages spoken in these regions. Through semi-structured\ninterviews with 22 AI experts working on harmful content detection in four\nlow-resource languages: Tamil (South Asia), Swahili (East Africa), Maghrebi\nArabic (North Africa), and Quechua (South America)--we examine systemic issues\nin building automated moderation tools for these languages. Our findings reveal\nthat beyond data scarcity, socio-political factors such as tech companies'\nmonopoly on user data and lack of investment in moderation for low-profit\nGlobal South markets exacerbate historic inequities. Even if more data were\navailable, the English-centric and data-intensive design of language models and\npreprocessing techniques overlooks the need to design for morphologically\ncomplex, linguistically diverse, and code-mixed languages. We argue these\nlimitations are not just technical gaps caused by \"data scarcity\" but reflect\nstructural inequities, rooted in colonial suppression of non-Western languages.\nWe discuss multi-stakeholder approaches to strengthen local research capacity,\ndemocratize data access, and support language-aware solutions to improve\nautomated moderation for low-resource languages.\n","authors":["Farhana Shahid","Mona Elswah","Aditya Vashistha"],"pdf_url":"https://arxiv.org/pdf/2501.13836v3.pdf","comment":"Accepted to AIES 2025"},{"id":"http://arxiv.org/abs/2508.03668v1","updated":"2025-08-05T17:30:34Z","published":"2025-08-05T17:30:34Z","title":"CTR-Sink: Attention Sink for Language Models in Click-Through Rate\n  Prediction","summary":"  Click-Through Rate (CTR) prediction, a core task in recommendation systems,\nestimates user click likelihood using historical behavioral data. Modeling user\nbehavior sequences as text to leverage Language Models (LMs) for this task has\ngained traction, owing to LMs' strong semantic understanding and contextual\nmodeling capabilities. However, a critical structural gap exists: user behavior\nsequences consist of discrete actions connected by semantically empty\nseparators, differing fundamentally from the coherent natural language in LM\npre-training. This mismatch causes semantic fragmentation, where LM attention\nscatters across irrelevant tokens instead of focusing on meaningful behavior\nboundaries and inter-behavior relationships, degrading prediction performance.\nTo address this, we propose $\\textit{CTR-Sink}$, a novel framework introducing\nbehavior-level attention sinks tailored for recommendation scenarios. Inspired\nby attention sink theory, it constructs attention focus sinks and dynamically\nregulates attention aggregation via external information. Specifically, we\ninsert sink tokens between consecutive behaviors, incorporating\nrecommendation-specific signals such as temporal distance to serve as stable\nattention sinks. To enhance generality, we design a two-stage training strategy\nthat explicitly guides LM attention toward sink tokens and a attention sink\nmechanism that amplifies inter-sink dependencies to better capture behavioral\ncorrelations. Experiments on one industrial dataset and two open-source\ndatasets (MovieLens, Kuairec), alongside visualization results, validate the\nmethod's effectiveness across scenarios.\n","authors":["Zixuan Li","Binzong Geng","Jing Xiong","Yong He","Yuxuan Hu","Jian Chen","Dingwei Chen","Xiyu Chang","Liang Zhang","Linjian Mo","Chengming Li","Chuan Yuan","Zhenan Sun"],"pdf_url":"https://arxiv.org/pdf/2508.03668v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.18247v3","updated":"2025-08-05T17:28:07Z","published":"2025-05-23T17:18:45Z","title":"MetaGen Blended RAG: Unlocking Zero-Shot Precision for Specialized\n  Domain Question-Answering","summary":"  Retrieval-Augmented Generation (RAG) struggles with domain-specific\nenterprise datasets, often isolated behind firewalls and rich in complex,\nspecialized terminology unseen by LLMs during pre-training. Semantic\nvariability across domains like medicine, networking, or law hampers RAG's\ncontext precision, while fine-tuning solutions are costly, slow, and lack\ngeneralization as new data emerges. Achieving zero-shot precision with\nretrievers without fine-tuning still remains a key challenge. We introduce\n'MetaGen Blended RAG', a novel enterprise search approach that enhances\nsemantic retrievers through a metadata generation pipeline and hybrid query\nindexes using dense and sparse vectors. By leveraging key concepts, topics, and\nacronyms, our method creates metadata-enriched semantic indexes and boosted\nhybrid queries, delivering robust, scalable performance without fine-tuning. On\nthe biomedical PubMedQA dataset, MetaGen Blended RAG achieves 82% retrieval\naccuracy and 77% RAG accuracy, surpassing all prior zero-shot RAG benchmarks\nand even rivaling fine-tuned models on that dataset, while also excelling on\ndatasets like SQuAD and NQ. This approach redefines enterprise search using a\nnew approach to building semantic retrievers with unmatched generalization\nacross specialized domains.\n","authors":["Kunal Sawarkar","Shivam R. Solanki","Abhilasha Mangal"],"pdf_url":"https://arxiv.org/pdf/2505.18247v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03663v1","updated":"2025-08-05T17:18:34Z","published":"2025-08-05T17:18:34Z","title":"Forest vs Tree: The $(N, K)$ Trade-off in Reproducible ML Evaluation","summary":"  Reproducibility is a cornerstone of scientific validation and of the\nauthority it confers on its results. Reproducibility in machine learning\nevaluations leads to greater trust, confidence, and value. However, the ground\ntruth responses used in machine learning often necessarily come from humans,\namong whom disagreement is prevalent, and surprisingly little research has\nstudied the impact of effectively ignoring disagreement in these responses, as\nis typically the case. One reason for the lack of research is that budgets for\ncollecting human-annotated evaluation data are limited, and obtaining more\nsamples from multiple annotators for each example greatly increases the\nper-item annotation costs. We investigate the trade-off between the number of\nitems ($N$) and the number of responses per item ($K$) needed for reliable\nmachine learning evaluation. We analyze a diverse collection of categorical\ndatasets for which multiple annotations per item exist, and simulated\ndistributions fit to these datasets, to determine the optimal $(N, K)$\nconfiguration, given a fixed budget ($N \\times K$), for collecting evaluation\ndata and reliably comparing the performance of machine learning models. Our\nfindings show, first, that accounting for human disagreement may come with $N\n\\times K$ at no more than 1000 (and often much lower) for every dataset tested\non at least one metric. Moreover, this minimal $N \\times K$ almost always\noccurred for $K > 10$. Furthermore, the nature of the tradeoff between $K$ and\n$N$ -- or if one even existed -- depends on the evaluation metric, with metrics\nthat are more sensitive to the full distribution of responses performing better\nat higher levels of $K$. Our methods can be used to help ML practitioners get\nmore effective test data by finding the optimal metrics and number of items and\nannotations per item to collect to get the most reliability for their budget.\n","authors":["Deepak Pandita","Flip Korn","Chris Welty","Christopher M. Homan"],"pdf_url":"https://arxiv.org/pdf/2508.03663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00222v2","updated":"2025-08-05T17:06:11Z","published":"2025-07-31T23:55:29Z","title":"RL-PLUS: Countering Capability Boundary Collapse of LLMs in\n  Reinforcement Learning with Hybrid-policy Optimization","summary":"  Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its essentially on-policy strategy coupled with LLM's\nimmense action space and sparse reward. Critically, RLVR can lead to the\ncapability boundary collapse, narrowing the LLM's problem-solving scope. To\naddress this problem, we propose RL-PLUS, a novel hybrid-policy optimization\napproach for LLMs that synergizes internal exploitation with external data to\nachieve stronger reasoning capabilities and surpass the boundaries of base\nmodels. RL-PLUS integrates two core components, i.e., Multiple Importance\nSampling to address for distributional mismatch from external data, and\nExploration-Based Advantage Function to guide the model towards high-value,\nunexplored reasoning paths. We provide both theoretical analysis and extensive\nexperiments to demonstrate the superiority and generalizability of our\napproach. Compared with existing RLVR methods, RL-PLUS achieves 1)\nstate-of-the-art performance on six math reasoning benchmarks; 2) superior\nperformance on six out-of-distribution reasoning tasks; 3) consistent and\nsignificant gains across diverse model families, with average relative\nimprovements up to 69.2\\%. Moreover, the analysis of Pass@k curves indicates\nthat RL-PLUS effectively resolves the capability boundary collapse problem.\n","authors":["Yihong Dong","Xue Jiang","Yongding Tao","Huanyu Liu","Kechi Zhang","Lili Mou","Rongyu Cao","Yingwei Ma","Jue Chen","Binhua Li","Zhi Jin","Fei Huang","Yongbin Li","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2508.00222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03654v1","updated":"2025-08-05T17:05:11Z","published":"2025-08-05T17:05:11Z","title":"Can Large Vision-Language Models Understand Multimodal Sarcasm?","summary":"  Sarcasm is a complex linguistic phenomenon that involves a disparity between\nliteral and intended meanings, making it challenging for sentiment analysis and\nother emotion-sensitive tasks. While traditional sarcasm detection methods\nprimarily focus on text, recent approaches have incorporated multimodal\ninformation. However, the application of Large Visual Language Models (LVLMs)\nin Multimodal Sarcasm Analysis (MSA) remains underexplored. In this paper, we\nevaluate LVLMs in MSA tasks, specifically focusing on Multimodal Sarcasm\nDetection and Multimodal Sarcasm Explanation. Through comprehensive\nexperiments, we identify key limitations, such as insufficient visual\nunderstanding and a lack of conceptual knowledge. To address these issues, we\npropose a training-free framework that integrates in-depth object extraction\nand external conceptual knowledge to improve the model's ability to interpret\nand explain sarcasm in multimodal contexts. The experimental results on\nmultiple models show the effectiveness of our proposed framework. The code is\navailable at https://github.com/cp-cp/LVLM-MSA.\n","authors":["Xinyu Wang","Yue Zhang","Liqiang Jing"],"pdf_url":"https://arxiv.org/pdf/2508.03654v1.pdf","comment":"Accepted by CIKM 2025"},{"id":"http://arxiv.org/abs/2508.03644v1","updated":"2025-08-05T16:55:02Z","published":"2025-08-05T16:55:02Z","title":"Are We on the Right Way for Assessing Document Retrieval-Augmented\n  Generation?","summary":"  Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language\nModels (MLLMs) show great promise for complex document understanding, yet their\ndevelopment is critically hampered by inadequate evaluation. Current benchmarks\noften focus on specific part of document RAG system and use synthetic data with\nincomplete ground truth and evidence labels, therefore failing to reflect\nreal-world bottlenecks and challenges. To overcome these limitations, we\nintroduce Double-Bench: a new large-scale, multilingual, and multimodal\nevaluation system that is able to produce fine-grained assessment to each\ncomponent within document RAG systems. It comprises 3,276 documents (72,880\npages) and 5,168 single- and multi-hop queries across 6 languages and 4\ndocument types with streamlined dynamic update support for potential data\ncontamination issues. Queries are grounded in exhaustively scanned evidence\npages and verified by human experts to ensure maximum quality and completeness.\nOur comprehensive experiments across 9 state-of-the-art embedding models, 4\nMLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text\nand visual embedding models is narrowing, highlighting the need in building\nstronger document retrieval models. Our findings also reveal the\nover-confidence dilemma within current document RAG frameworks that tend to\nprovide answer even without evidence support. We hope our fully open-source\nDouble-Bench provide a rigorous foundation for future research in advanced\ndocument RAG systems. We plan to retrieve timely corpus and release new\nbenchmarks on an annual basis.\n","authors":["Wenxuan Shen","Mingjia Wang","Yaochen Wang","Dongping Chen","Junjie Yang","Yao Wan","Weiwei Lin"],"pdf_url":"https://arxiv.org/pdf/2508.03644v1.pdf","comment":"In submission. Project website: https://double-bench.github.io/"},{"id":"http://arxiv.org/abs/2504.13834v2","updated":"2025-08-05T16:47:21Z","published":"2025-04-18T17:59:29Z","title":"Science Hierarchography: Hierarchical Organization of Science Literature","summary":"  Scientific knowledge is growing rapidly, making it difficult to track\nprogress and high-level conceptual links across broad disciplines. While tools\nlike citation networks and search engines help retrieve related papers, they\nlack the abstraction needed to capture the needed to represent the density and\nstructure of activity across subfields.\n  We motivate SCIENCE HIERARCHOGRAPHY, the goal of organizing scientific\nliterature into a high-quality hierarchical structure that spans multiple\nlevels of abstraction -- from broad domains to specific studies. Such a\nrepresentation can provide insights into which fields are well-explored and\nwhich are under-explored. To achieve this goal, we develop a hybrid approach\nthat combines efficient embedding-based clustering with LLM-based prompting,\nstriking a balance between scalability and semantic precision. Compared to\nLLM-heavy methods like iterative tree construction, our approach achieves\nsuperior quality-speed trade-offs. Our hierarchies capture different dimensions\nof research contributions, reflecting the interdisciplinary and multifaceted\nnature of modern science. We evaluate its utility by measuring how effectively\nan LLM-based agent can navigate the hierarchy to locate target papers. Results\nshow that our method improves interpretability and offers an alternative\npathway for exploring scientific literature beyond traditional search methods.\nCode, data and demo are available:\nhttps://github.com/JHU-CLSP/science-hierarchography\n","authors":["Muhan Gao","Jash Shah","Weiqi Wang","Daniel Khashabi"],"pdf_url":"https://arxiv.org/pdf/2504.13834v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.02732v4","updated":"2025-08-05T16:43:21Z","published":"2025-04-03T16:17:55Z","title":"Why do LLMs attend to the first token?","summary":"  Large Language Models (LLMs) tend to attend heavily to the first token in the\nsequence -- creating a so-called attention sink. Many works have studied this\nphenomenon in detail, proposing various ways to either leverage or alleviate\nit. Attention sinks have been connected to quantisation difficulties, security\nissues, and streaming attention. Yet, while many works have provided conditions\nin which they occur or not, a critical question remains shallowly answered: Why\ndo LLMs learn such patterns and how are they being used? In this work, we argue\ntheoretically and empirically that this mechanism provides a method for LLMs to\navoid over-mixing, connecting this to existing lines of work that study\nmathematically how information propagates in Transformers. We conduct\nexperiments to validate our theoretical intuitions and show how choices such as\ncontext length, depth, and data packing influence the sink behaviour. We hope\nthat this study provides a new practical perspective on why attention sinks are\nuseful in LLMs, leading to a better understanding of the attention patterns\nthat form during training.\n","authors":["Federico Barbero","Álvaro Arroyo","Xiangming Gu","Christos Perivolaropoulos","Michael Bronstein","Petar Veličković","Razvan Pascanu"],"pdf_url":"https://arxiv.org/pdf/2504.02732v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.01903v2","updated":"2025-08-05T16:19:40Z","published":"2025-07-02T17:19:20Z","title":"AI4Research: A Survey of Artificial Intelligence for Scientific Research","summary":"  Recent advancements in artificial intelligence (AI), particularly in large\nlanguage models (LLMs) such as OpenAI-o1 and DeepSeek-R1, have demonstrated\nremarkable capabilities in complex domains such as logical reasoning and\nexperimental coding. Motivated by these advancements, numerous studies have\nexplored the application of AI in the innovation process, particularly in the\ncontext of scientific research. These AI technologies primarily aim to develop\nsystems that can autonomously conduct research processes across a wide range of\nscientific disciplines. Despite these significant strides, a comprehensive\nsurvey on AI for Research (AI4Research) remains absent, which hampers our\nunderstanding and impedes further development in this field. To address this\ngap, we present a comprehensive survey and offer a unified perspective on\nAI4Research. Specifically, the main contributions of our work are as follows:\n(1) Systematic taxonomy: We first introduce a systematic taxonomy to classify\nfive mainstream tasks in AI4Research. (2) New frontiers: Then, we identify key\nresearch gaps and highlight promising future directions, focusing on the rigor\nand scalability of automated experiments, as well as the societal impact. (3)\nAbundant applications and resources: Finally, we compile a wealth of resources,\nincluding relevant multidisciplinary applications, data corpora, and tools. We\nhope our work will provide the research community with quick access to these\nresources and stimulate innovative breakthroughs in AI4Research.\n","authors":["Qiguang Chen","Mingda Yang","Libo Qin","Jinhao Liu","Zheng Yan","Jiannan Guan","Dengyun Peng","Yiyan Ji","Hanjing Li","Mengkang Hu","Yimeng Zhang","Yihao Liang","Yuhang Zhou","Jiaqi Wang","Zhi Chen","Wanxiang Che"],"pdf_url":"https://arxiv.org/pdf/2507.01903v2.pdf","comment":"Preprint, Paper list is available at\n  https://github.com/LightChen233/Awesome-AI4Research"},{"id":"http://arxiv.org/abs/2508.03599v1","updated":"2025-08-05T16:06:36Z","published":"2025-08-05T16:06:36Z","title":"OSINT or BULLSHINT? Exploring Open-Source Intelligence tweets about the\n  Russo-Ukrainian War","summary":"  This paper examines the role of Open Source Intelligence (OSINT) on Twitter\nregarding the Russo-Ukrainian war, distinguishing between genuine OSINT and\ndeceptive misinformation efforts, termed \"BULLSHINT.\" Utilizing a dataset\nspanning from January 2022 to July 2023, we analyze nearly 2 million tweets\nfrom approximately 1,040 users involved in discussing real-time military\nengagements, strategic analyses, and misinformation related to the conflict.\nUsing sentiment analysis, partisanship detection, misinformation\nidentification, and Named Entity Recognition (NER), we uncover communicative\npatterns and dissemination strategies within the OSINT community. Significant\nfindings reveal a predominant negative sentiment influenced by war events, a\nnuanced distribution of pro-Ukrainian and pro-Russian partisanship, and the\npotential strategic manipulation of information. Additionally, we apply\ncommunity detection techniques, which are able to identify distinct clusters\npartisanship, topics, and misinformation, highlighting the complex dynamics of\ninformation spread on social media. This research contributes to the\nunderstanding of digital warfare and misinformation dynamics, offering insights\ninto the operationalization of OSINT in geopolitical conflicts.\n","authors":["Johannes Niu","Mila Stillman","Anna Kruspe"],"pdf_url":"https://arxiv.org/pdf/2508.03599v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.06219v2","updated":"2025-08-05T15:55:24Z","published":"2025-04-08T17:08:06Z","title":"Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling\n  Opt-Outs","summary":"  The increasing adoption of web crawling opt-outs by copyright holders of\nonline content raises critical questions about the impact of data compliance on\nlarge language model (LLM) performance. However, little is known about how\nthese restrictions (and the resultant filtering of pretraining datasets) affect\nthe capabilities of models trained using these corpora. In this work, we\nconceptualize this effect as the $\\textit{data compliance gap}$ (DCG), which\nquantifies the performance difference between models trained on datasets that\ncomply with web crawling opt-outs, and those that do not. We measure the data\ncompliance gap in two settings: pretraining models from scratch and continual\npretraining from existing compliant models (simulating a setting where\ncopyrighted data could be integrated later in pretraining). Our experiments\nwith 1.5B models show that, as of January 2025, compliance with web data\nopt-outs does not degrade general knowledge acquisition (close to 0\\% DCG).\nHowever, in specialized domains such as biomedical research, excluding major\npublishers leads to performance declines. These findings suggest that while\ngeneral-purpose LLMs can be trained to perform equally well using fully open\ndata, performance in specialized domains may benefit from access to\nhigh-quality copyrighted sources later in training. Our study provides\nempirical insights into the long-debated trade-off between data compliance and\ndownstream model performance, informing future discussions on AI training\npractices and policy decisions. Our website is available at\nhttps://data-compliance.github.io/.\n","authors":["Dongyang Fan","Vinko Sabolčec","Matin Ansaripour","Ayush Kumar Tarun","Martin Jaggi","Antoine Bosselut","Imanol Schlag"],"pdf_url":"https://arxiv.org/pdf/2504.06219v2.pdf","comment":"COLM 2025 Camera Ready version"},{"id":"http://arxiv.org/abs/2508.03571v1","updated":"2025-08-05T15:39:37Z","published":"2025-08-05T15:39:37Z","title":"Tackling Distribution Shift in LLM via KILO: Knowledge-Instructed\n  Learning for Continual Adaptation","summary":"  Large Language Models (LLMs) often suffer from performance degradation when\nfaced with domain shifts, primarily due to catastrophic forgetting. In this\nwork, we propose KILO (Knowledge-Instructed Learning for Continual Adaptation),\na novel continual learning framework that integrates dynamic knowledge graphs\nwith instruction tuning. By leveraging retrieved domain-specific knowledge as\nguidance during training, KILO enhances both adaptability to new domains and\nretention of previously acquired knowledge. We pretrain our model on\nWikiText-103 and evaluate sequential adaptation across four diverse target\ndomains: BioASQ, SciQ, TweetEval, and MIND. Our experiments demonstrate that\nKILO consistently outperforms strong baselines, including continual\nfine-tuning, ERNIE 2.0, and CPT, in terms of backward transfer, forward\ntransfer, F1 score, retention rate, and training efficiency. These results\nhighlight the effectiveness of combining structured knowledge retrieval and\ninstruction prompting to overcome domain shift challenges in continual learning\nscenarios.\n","authors":["Iing Muttakhiroh","Thomas Fevens"],"pdf_url":"https://arxiv.org/pdf/2508.03571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10352v3","updated":"2025-08-05T15:33:39Z","published":"2025-04-14T16:03:21Z","title":"Pseudo-Autoregressive Neural Codec Language Models for Efficient\n  Zero-Shot Text-to-Speech Synthesis","summary":"  Recent zero-shot text-to-speech (TTS) systems face a common dilemma:\nautoregressive (AR) models suffer from slow generation and lack duration\ncontrollability, while non-autoregressive (NAR) models lack temporal modeling\nand typically require complex designs. In this paper, we introduce a novel\npseudo-autoregressive (PAR) codec language modeling approach that unifies AR\nand NAR modeling. Combining explicit temporal modeling from AR with parallel\ngeneration from NAR, PAR generates dynamic-length spans at fixed time steps.\nBuilding on PAR, we propose PALLE, a two-stage TTS system that leverages PAR\nfor initial generation followed by NAR refinement. In the first stage, PAR\nprogressively generates speech tokens along the time dimension, with each step\npredicting all positions in parallel but only retaining the left-most span. In\nthe second stage, low-confidence tokens are iteratively refined in parallel,\nleveraging the global contextual information. Experiments demonstrate that\nPALLE, trained on LibriTTS, outperforms state-of-the-art systems trained on\nlarge-scale data, including F5-TTS, E2-TTS, and MaskGCT, on the LibriSpeech\ntest-clean set in terms of speech quality, speaker similarity, and\nintelligibility, while achieving up to ten times faster inference speed. Audio\nsamples are available at https://microsoft.com/research/project/vall-e-x/palle.\n","authors":["Yifan Yang","Shujie Liu","Jinyu Li","Yuxuan Hu","Haibin Wu","Hui Wang","Jianwei Yu","Lingwei Meng","Haiyang Sun","Yanqing Liu","Yan Lu","Kai Yu","Xie Chen"],"pdf_url":"https://arxiv.org/pdf/2504.10352v3.pdf","comment":"Accepted in ACMMM 2025"},{"id":"http://arxiv.org/abs/2508.03562v1","updated":"2025-08-05T15:31:00Z","published":"2025-08-05T15:31:00Z","title":"Beyond Meme Templates: Limitations of Visual Similarity Measures in Meme\n  Matching","summary":"  Internet memes, now a staple of digital communication, play a pivotal role in\nhow users engage within online communities and allow researchers to gain\ninsight into contemporary digital culture. These engaging user-generated\ncontent are characterised by their reuse of visual elements also found in other\nmemes. Matching instances of memes via these shared visual elements, called\nMeme Matching, is the basis of a wealth of meme analysis approaches. However,\nmost existing methods assume that every meme consists of a shared visual\nbackground, called a Template, with some overlaid text, thereby limiting meme\nmatching to comparing the background image alone. Current approaches exclude\nthe many memes that are not template-based and limit the effectiveness of\nautomated meme analysis and would not be effective at linking memes to\ncontemporary web-based meme dictionaries. In this work, we introduce a broader\nformulation of meme matching that extends beyond template matching. We show\nthat conventional similarity measures, including a novel segment-wise\ncomputation of the similarity measures, excel at matching template-based memes\nbut fall short when applied to non-template-based meme formats. However, the\nsegment-wise approach was found to consistently outperform the whole-image\nmeasures on matching non-template-based memes. Finally, we explore a\nprompting-based approach using a pretrained Multimodal Large Language Model for\nmeme matching. Our results highlight that accurately matching memes via shared\nvisual elements, not just background templates, remains an open challenge that\nrequires more sophisticated matching techniques.\n","authors":["Muzhaffar Hazman","Susan McKeever","Josephine Griffith"],"pdf_url":"https://arxiv.org/pdf/2508.03562v1.pdf","comment":"Accepted for publication at IEEE International Conference on Image\n  Processing Theory, Tools and Applications (IPTA) 2025"},{"id":"http://arxiv.org/abs/2508.03555v1","updated":"2025-08-05T15:23:40Z","published":"2025-08-05T15:23:40Z","title":"PyLate: Flexible Training and Retrieval for Late Interaction Models","summary":"  Neural ranking has become a cornerstone of modern information retrieval.\nWhile single vector search remains the dominant paradigm, it suffers from the\nshortcoming of compressing all the information into a single vector. This\ncompression leads to notable performance degradation in out-of-domain,\nlong-context, and reasoning-intensive retrieval tasks. Multi-vector approaches\npioneered by ColBERT aim to address these limitations by preserving individual\ntoken embeddings and computing similarity via the MaxSim operator. This\narchitecture has demonstrated superior empirical advantages, including enhanced\nout-of-domain generalization, long-context handling, and performance in complex\nretrieval scenarios. Despite these compelling empirical results and clear\ntheoretical advantages, the practical adoption and public availability of late\ninteraction models remain low compared to their single-vector counterparts,\nprimarily due to a lack of accessible and modular tools for training and\nexperimenting with such models. To bridge this gap, we introduce PyLate, a\nstreamlined library built on top of Sentence Transformers to support\nmulti-vector architectures natively, inheriting its efficient training,\nadvanced logging, and automated model card generation while requiring minimal\ncode changes to code templates users are already familiar with. By offering\nmulti-vector-specific features such as efficient indexes, PyLate aims to\naccelerate research and real-world application of late interaction models,\nthereby unlocking their full potential in modern IR systems. Finally, PyLate\nhas already enabled the development of state-of-the-art models, including\nGTE-ModernColBERT and Reason-ModernColBERT, demonstrating its practical utility\nfor both research and production environments.\n","authors":["Antoine Chaffin","Raphaël Sourty"],"pdf_url":"https://arxiv.org/pdf/2508.03555v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2508.03553v1","updated":"2025-08-05T15:20:52Z","published":"2025-08-05T15:20:52Z","title":"MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in\n  Multi-source Retrieval Augmented Generation","summary":"  Retrieval Augmented Generation (RAG) has emerged as a promising solution to\naddress hallucination issues in Large Language Models (LLMs). However, the\nintegration of multiple retrieval sources, while potentially more informative,\nintroduces new challenges that can paradoxically exacerbate hallucination\nproblems. These challenges manifest primarily in two aspects: the sparse\ndistribution of multi-source data that hinders the capture of logical\nrelationships and the inherent inconsistencies among different sources that\nlead to information conflicts. To address these challenges, we propose\nMultiRAG, a novel framework designed to mitigate hallucination in multi-source\nretrieval-augmented generation through knowledge-guided approaches. Our\nframework introduces two key innovations: (1) a knowledge construction module\nthat employs multi-source line graphs to efficiently aggregate logical\nrelationships across different knowledge sources, effectively addressing the\nsparse data distribution issue; and (2) a sophisticated retrieval module that\nimplements a multi-level confidence calculation mechanism, performing both\ngraph-level and node-level assessments to identify and eliminate unreliable\ninformation nodes, thereby reducing hallucinations caused by inter-source\ninconsistencies. Extensive experiments on four multi-domain query datasets and\ntwo multi-hop QA datasets demonstrate that MultiRAG significantly enhances the\nreliability and efficiency of knowledge retrieval in complex multi-source\nscenarios. \\textcolor{blue}{Our code is available in\nhttps://github.com/wuwenlong123/MultiRAG.\n","authors":["Wenlong Wu","Haofen Wang","Bohan Li","Peixuan Huang","Xinzhe Zhao","Lei Liang"],"pdf_url":"https://arxiv.org/pdf/2508.03553v1.pdf","comment":"Accepted by ICDE 2025 Research Paper"},{"id":"http://arxiv.org/abs/2508.03550v1","updated":"2025-08-05T15:18:36Z","published":"2025-08-05T15:18:36Z","title":"Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via\n  Internal Representations","summary":"  The growing scale of evaluation tasks has led to the widespread adoption of\nautomated evaluation using large language models, a paradigm known as\n\"LLMas-a-judge.\" However, improving its alignment with human preferences\nwithout complex prompts or fine-tuning remains challenging. In this work,\nmotivated by preliminary findings that middle-to-upper layers encode\nsemantically and taskrelevant representations that are often more aligned with\nhuman judgments than the final layer, we propose LAGER, a lightweight and\nefficient framework for enhancing LLM-as-a-Judge alignment with human scoring,\nvia internal representations. LAGER produces fine-grained judgment scores by\naggregating cross-layer scoretoken logits and computing the expected score from\na softmax-based distribution, with the LLM backbone kept frozen. LAGER fully\nleverages the complementary information across different layers, overcoming the\nlimitations of relying solely on the final layer. We evaluate our method on the\nstandard alignment benchmarks Flask, HelpSteer, and BIGGen using Spearman\ncorrelation, and find that LAGER achieves improvements of up to 7.5% over the\nbest baseline across these benchmarks. Without reasoning steps, LAGER matches\nor outperforms reasoning-based methods. Experiments on downstream applications,\nsuch as data selection and emotional understanding, further show the\neffectiveness of our method.\n","authors":["Peng Lai","Jianjie Zheng","Sijie Cheng","Yun Chen","Peng Li","Yang Liu","Guanhua Chen"],"pdf_url":"https://arxiv.org/pdf/2508.03550v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.16154v3","updated":"2025-08-05T15:13:54Z","published":"2025-01-27T15:48:57Z","title":"AdaMCoT: Rethinking Cross-Lingual Factual Reasoning through Adaptive\n  Multilingual Chain-of-Thought","summary":"  Large language models (LLMs) have shown impressive multilingual capabilities\nthrough pretraining on diverse corpora. Although these models show strong\nreasoning abilities, their performance varies significantly between languages\ndue to the imbalanced distribution of training data. Existing approaches using\nsample-level translation for extensive multilingual pretraining and\ncross-lingual tuning face scalability challenges and often fail to capture\nnuanced reasoning processes across languages. In this paper, we introduce\nAdaMCOT (Adaptive Multilingual Chain-of-Thought), a framework that enhances\nmultilingual factual reasoning by dynamically routing thought processes in\nintermediary \"thinking languages\" before generating target-language responses.\nAdaMCOT leverages a language-agnostic core and incorporates an adaptive,\nreward-based mechanism for selecting optimal reasoning pathways without\nrequiring additional pretraining. Our comprehensive evaluation across multiple\nbenchmarks demonstrates substantial improvements in both factual reasoning\nquality and cross-lingual consistency, with particularly strong performance\ngains in low-resource language settings. An in-depth analysis of the model's\nhidden states and semantic space further elucidates the underlying mechanism of\nour method. The results suggest that adaptive reasoning paths can effectively\nbridge the performance gap between high and low-resource languages while\nmaintaining cultural and linguistic nuances.\n","authors":["Weihua Zheng","Xin Huang","Zhengyuan Liu","Tarun Kumar Vangani","Bowei Zou","Xiyan Tao","Yuhao Wu","Ai Ti Aw","Nancy F. Chen","Roy Ka-Wei Lee"],"pdf_url":"https://arxiv.org/pdf/2501.16154v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03533v1","updated":"2025-08-05T15:03:10Z","published":"2025-08-05T15:03:10Z","title":"EmbedGrad: Gradient-Based Prompt Optimization in Embedding Space for\n  Large Language Models","summary":"  Effectively adapting powerful pretrained foundation models to diverse tasks\nremains a key challenge in AI deployment. Current approaches primarily follow\ntwo paradigms:discrete optimization of text prompts through prompt engineering,\nor continuous adaptation via additional trainable parameters. Both exhibit\nlimitations-discrete methods lack refinement precision while parameter-based\ntechniques increase complexity and reduce interpretability. To address these\nconstraints, we propose EmbedGrad, a novel framework that optimizes text prompt\nembeddings through gradient-based refinement. Our approach uniquely decouples\ntraining from deployment:during optimization,labeled examples guide precise\nembedding adjustments while preserving semantic meaning; during inference, only\noptimized embeddings integrate with user queries. This enables fine-grained\ncalibration impossible in text space, such as enhancing the reasoning\ncapability of prompts like please reason step by step. Comprehensive\nevaluations across mathematical reasoning, sentiment analysis, and causal\njudgment tasks demonstrate EmbedGrad's effectiveness:optimizing this reasoning\nprompt for Qwen2.5-Math-1.5B increased accuracy from 14.74\\% to 58.96\\% on\nmathematical problems. Consistent improvements were observed across model\nscales (0.5B-14B) and all tasks, with particularly significant gains for\nsmaller models on complex problems like causal judgment. By bridging prompt\nengineering and parameter efficiency without architectural changes, our work\nestablishes embedding refinement as a powerful new paradigm for task\nadaptation.\n","authors":["Xiaoming Hou","Jiquan Zhang","Zibin Lin","DaCheng Tao","Shengli Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.03533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03529v1","updated":"2025-08-05T15:00:02Z","published":"2025-08-05T15:00:02Z","title":"Marito: Structuring and Building Open Multilingual Terminologies for\n  South African NLP","summary":"  The critical lack of structured terminological data for South Africa's\nofficial languages hampers progress in multilingual NLP, despite the existence\nof numerous government and academic terminology lists. These valuable assets\nremain fragmented and locked in non-machine-readable formats, rendering them\nunusable for computational research and development. \\emph{Marito} addresses\nthis challenge by systematically aggregating, cleaning, and standardising these\nscattered resources into open, interoperable datasets. We introduce the\nfoundational \\emph{Marito} dataset, released under the equitable,\nAfrica-centered NOODL framework. To demonstrate its immediate utility, we\nintegrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline.\nExperiments show substantial improvements in the accuracy and domain-specific\nconsistency of English-to-Tshivenda machine translation for large language\nmodels. \\emph{Marito} provides a scalable foundation for developing robust and\nequitable NLP technologies, ensuring South Africa's rich linguistic diversity\nis represented in the digital age.\n","authors":["Vukosi Marivate","Isheanesu Dzingirai","Fiskani Banda","Richard Lastrucci","Thapelo Sindane","Keabetswe Madumo","Kayode Olaleye","Abiodun Modupe","Unarine Netshifhefhe","Herkulaas Combrink","Mohlatlego Nakeng","Matome Ledwaba"],"pdf_url":"https://arxiv.org/pdf/2508.03529v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2508.03527v1","updated":"2025-08-05T14:58:14Z","published":"2025-08-05T14:58:14Z","title":"MoKA: Mixture of Kronecker Adapters","summary":"  Parameter-efficient fine-tuning (PEFT) is essential for reducing the\ncomputational overhead of large language models (LLMs). Low-rank family\nadapters are commonly used to control the parameter size efficiently while\nmaintaining the generative power of LLMs. However, their limited expressiveness\ndue to the rank constraint often restricts their performance on complex tasks.\nWe propose Mixture of Kronecker Adapters (MoKA), a new generation of Kronecker\nadapters that addresses this limitation by modeling weight updates as a mixture\nof Kronecker products. Our proposed adapter leverages a gating mechanism that\nmeasures the importance of each Kronecker factor, enabling more expressive\nadaptation. Moreover, MoKA enables a rank flexibility that provides a better\ntrade-off between parameter efficiency and accuracy. To ensure hardware\nefficiency, we reformulate Kronecker computations using standard matrix\noperations, allowing seamless deployment on GPU-optimized hardware. We conduct\nextensive experiments on instruction-tuning and commonsense reasoning tasks\nusing low-bit quantized versions of LLaMA2-7B and LLaMA3-8B models. MoKA not\nonly outperforms PEFT baselines, but also reduces the number of trainable\nparameters up to 27x, achieving state-of-the-art trade-offs between performance\nand parameter efficiency.\n","authors":["Mohammadreza Sadeghi","Mahsa Ghazvini Nejad","MirHamed Jafarzadeh Asl","Yu Gu","Yuanhao Yu","Masoud Asgharian","Vahid Partovi Nia"],"pdf_url":"https://arxiv.org/pdf/2508.03527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03523v1","updated":"2025-08-05T14:48:32Z","published":"2025-08-05T14:48:32Z","title":"FilBench: Can LLMs Understand and Generate Filipino?","summary":"  Despite the impressive performance of LLMs on English-based tasks, little is\nknown about their capabilities in specific languages such as Filipino. In this\nwork, we address this gap by introducing FilBench, a Filipino-centric benchmark\ndesigned to evaluate LLMs across a diverse set of tasks and capabilities in\nFilipino, Tagalog, and Cebuano. We carefully curate the tasks in FilBench to\nreflect the priorities and trends of NLP research in the Philippines such as\nCultural Knowledge, Classical NLP, Reading Comprehension, and Generation. By\nevaluating 27 state-of-the-art LLMs on FilBench, we find that several LLMs\nsuffer from reading comprehension and translation capabilities. Our results\nindicate that FilBench is challenging, with the best model, GPT-4o, achieving\nonly a score of 72.23%. Moreover, we also find that models trained specifically\nfor Southeast Asian languages tend to underperform on FilBench, with the\nhighest-performing model, SEA-LION v3 70B, achieving only a score of 61.07%.\nOur work demonstrates the value of curating language-specific LLM benchmarks to\naid in driving progress on Filipino NLP and increasing the inclusion of\nPhilippine languages in LLM development.\n","authors":["Lester James V. Miranda","Elyanah Aco","Conner Manuel","Jan Christian Blaise Cruz","Joseph Marvin Imperial"],"pdf_url":"https://arxiv.org/pdf/2508.03523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.10532v2","updated":"2025-08-05T14:47:50Z","published":"2025-07-14T17:55:15Z","title":"Reasoning or Memorization? Unreliable Results of Reinforcement Learning\n  Due to Data Contamination","summary":"  Reasoning in large language models has long been a central research focus,\nand recent studies employing reinforcement learning (RL) have introduced\ndiverse methods that yield substantial performance gains with minimal or even\nno external supervision. Surprisingly, some studies even suggest that random or\nincorrect reward signals can enhance performance. However, these breakthroughs\nare predominantly observed for the mathematically strong Qwen2.5 series on\nbenchmarks such as MATH-500, AMC, and AIME, and seldom transfer to models like\nLlama, which warrants a more in-depth investigation. In this work, our\nempirical analysis reveals that pre-training on massive web-scale corpora\nleaves Qwen2.5 susceptible to data contamination in widely used benchmarks.\nConsequently, conclusions derived from contaminated benchmarks on Qwen2.5\nseries may be unreliable. To obtain trustworthy evaluation results, we\nintroduce a generator that creates fully clean arithmetic problems of arbitrary\nlength and difficulty, dubbed RandomCalculation. Using this leakage-free\ndataset, we show that only accurate reward signals yield steady improvements\nthat surpass the base model's performance boundary in mathematical reasoning,\nwhereas random or incorrect rewards do not. Moreover, we conduct more\nfine-grained analyses to elucidate the factors underlying the different\nperformance observed on the MATH-500 and RandomCalculation benchmarks.\nConsequently, we recommend that future studies evaluate models on\nuncontaminated benchmarks and, when feasible, test various model series to\nensure trustworthy conclusions about RL and related methods.\n","authors":["Mingqi Wu","Zhihao Zhang","Qiaole Dong","Zhiheng Xi","Jun Zhao","Senjie Jin","Xiaoran Fan","Yuhao Zhou","Huijie Lv","Ming Zhang","Yanwei Fu","Qin Liu","Songyang Zhang","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2507.10532v2.pdf","comment":"33 pages"},{"id":"http://arxiv.org/abs/2508.03520v1","updated":"2025-08-05T14:46:28Z","published":"2025-08-05T14:46:28Z","title":"UPLME: Uncertainty-Aware Probabilistic Language Modelling for Robust\n  Empathy Regression","summary":"  Supervised learning for empathy regression is challenged by noisy\nself-reported empathy scores. While many algorithms have been proposed for\nlearning with noisy labels in textual classification problems, the regression\ncounterpart is relatively under-explored. We propose UPLME, an\nuncertainty-aware probabilistic language modelling framework to capture label\nnoise in the regression setting of empathy detection. UPLME includes a\nprobabilistic language model that predicts both empathy score and\nheteroscedastic uncertainty and is trained using Bayesian concepts with\nvariational model ensembling. We further introduce two novel loss components:\none penalises degenerate Uncertainty Quantification (UQ), and another enforces\nthe similarity between the input pairs on which we predict empathy. UPLME\nprovides state-of-the-art performance (Pearson Correlation Coefficient:\n$0.558\\rightarrow0.580$ and $0.629\\rightarrow0.634$) in terms of the\nperformance reported in the literature in two public benchmarks, having label\nnoise. Through synthetic label noise injection, we show that UPLME is effective\nin separating noisy and clean samples based on the predicted uncertainty. UPLME\nfurther outperform (Calibration error: $0.571\\rightarrow0.376$) a recent\nvariational model ensembling-based UQ method designed for regression problems.\n","authors":["Md Rakibul Hasan","Md Zakir Hossain","Aneesh Krishna","Shafin Rahman","Tom Gedeon"],"pdf_url":"https://arxiv.org/pdf/2508.03520v1.pdf","comment":"Code available at https://github.com/hasan-rakibul/UPLME"},{"id":"http://arxiv.org/abs/2508.03501v1","updated":"2025-08-05T14:30:47Z","published":"2025-08-05T14:30:47Z","title":"Training Long-Context, Multi-Turn Software Engineering Agents with\n  Reinforcement Learning","summary":"  Research on applications of Reinforcement Learning (RL) to Large Language\nModels (LLMs) has mostly been focused on single-turn problems, such as\nmathematical reasoning or single-shot code generation. While these problems can\nbe viewed as token-level multi-turn MDPs, this view corresponds to a degenerate\ncase of multi-turn interaction where the environment provides no feedback. This\ncontrasts with many real-world domains, such as software engineering (SWE),\nwhich require rich multi-turn interactions with a stateful environment that\nresponds to each action with a non-trivial observation.\n  To bridge this gap, we demonstrate the successful application of RL to this\ngeneral regime. Using a modified Decoupled Advantage Policy Optimization (DAPO)\nalgorithm, we train an agent based on Qwen2.5-72B-Instruct to solve real-world\nsoftware engineering tasks. Our approach increases the agent's success rate on\nthe SWE-bench Verified benchmark from a 20% rejection fine-tuned baseline to\n39%, without relying on any teacher models. On SWE-rebench, our agent matches\nor outperforms leading open-weight models such as DeepSeek-V3-0324 and\nQwen3-235B-A22B using an identical scaffolding, offering a viable path toward\nbuilding more capable autonomous agents for complex real-world problems based\non open models.\n","authors":["Alexander Golubev","Maria Trofimova","Sergei Polezhaev","Ibragim Badertdinov","Maksim Nekrashevich","Anton Shevtsov","Simon Karasik","Sergey Abramov","Andrei Andriushchenko","Filipp Fisin","Sergei Skvortsov","Boris Yangel"],"pdf_url":"https://arxiv.org/pdf/2508.03501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03489v1","updated":"2025-08-05T14:20:10Z","published":"2025-08-05T14:20:10Z","title":"CF-RAG: A Dataset and Method for Carbon Footprint QA Using\n  Retrieval-Augmented Generation","summary":"  Product sustainability reports provide valuable insights into the\nenvironmental impacts of a product and are often distributed in PDF format.\nThese reports often include a combination of tables and text, which complicates\ntheir analysis. The lack of standardization and the variability in reporting\nformats further exacerbate the difficulty of extracting and interpreting\nrelevant information from large volumes of documents. In this paper, we tackle\nthe challenge of answering questions related to carbon footprints within\nsustainability reports available in PDF format. Unlike previous approaches, our\nfocus is on addressing the difficulties posed by the unstructured and\ninconsistent nature of text extracted from PDF parsing. To facilitate this\nanalysis, we introduce CarbonPDF-QA, an open-source dataset containing\nquestion-answer pairs for 1735 product report documents, along with\nhuman-annotated answers. Our analysis shows that GPT-4o struggles to answer\nquestions with data inconsistencies. To address this limitation, we propose\nCarbonPDF, an LLM-based technique specifically designed to answer carbon\nfootprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama\n3 with our training data. Our results show that our technique outperforms\ncurrent state-of-the-art techniques, including question-answering (QA) systems\nfinetuned on table and text data.\n","authors":["Kaiwen Zhao","Bharathan Balaji","Stephen Lee"],"pdf_url":"https://arxiv.org/pdf/2508.03489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.07855v2","updated":"2025-08-05T14:18:32Z","published":"2025-07-10T15:38:17Z","title":"Principled Foundations for Preference Optimization","summary":"  In this paper, we show that direct preference optimization (DPO) is a very\nspecific form of a connection between two major theories in the ML context of\nlearning from preferences: loss functions (Savage) and stochastic choice\n(Doignon-Falmagne and Machina). The connection is established for all of\nSavage's losses and at this level of generality, (i) it includes support for\nabstention on the choice theory side, (ii) it includes support for non-convex\nobjectives on the ML side, and (iii) it allows to frame for free some notable\nextensions of the DPO setting, including margins and corrections for length.\nGetting to understand how DPO operates from a general principled perspective is\ncrucial because of the huge and diverse application landscape of models,\nbecause of the current momentum around DPO, but also -- and importantly --\nbecause many state of the art variations on DPO definitely occupy a small\nregion of the map that we cover. It also helps to understand the pitfalls of\ndeparting from this map, and figure out workarounds.\n","authors":["Wenxuan Zhou","Shujian Zhang","Brice Magdalou","John Lambert","Ehsan Amid","Richard Nock","Andrew Hard"],"pdf_url":"https://arxiv.org/pdf/2507.07855v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03481v1","updated":"2025-08-05T14:14:55Z","published":"2025-08-05T14:14:55Z","title":"Draw Your Mind: Personalized Generation via Condition-Level Modeling in\n  Text-to-Image Diffusion Models","summary":"  Personalized generation in T2I diffusion models aims to naturally incorporate\nindividual user preferences into the generation process with minimal user\nintervention. However, existing studies primarily rely on prompt-level modeling\nwith large-scale models, often leading to inaccurate personalization due to the\nlimited input token capacity of T2I diffusion models. To address these\nlimitations, we propose DrUM, a novel method that integrates user profiling\nwith a transformer-based adapter to enable personalized generation through\ncondition-level modeling in the latent space. DrUM demonstrates strong\nperformance on large-scale datasets and seamlessly integrates with open-source\ntext encoders, making it compatible with widely used foundation T2I models\nwithout requiring additional fine-tuning.\n","authors":["Hyungjin Kim","Seokho Ahn","Young-Duk Seo"],"pdf_url":"https://arxiv.org/pdf/2508.03481v1.pdf","comment":"Accepted at ICCV 2025"},{"id":"http://arxiv.org/abs/2508.03475v1","updated":"2025-08-05T14:10:09Z","published":"2025-08-05T14:10:09Z","title":"fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual\n  Fact-checked Claim Retrieval","summary":"  SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim\nRetrieval is approached as a Learning-to-Rank task using a bi-encoder model\nfine-tuned from a pre-trained transformer optimized for sentence similarity.\nTraining used both the source languages and their English translations for\nmultilingual retrieval and only English translations for cross-lingual\nretrieval. Using lightweight models with fewer than 500M parameters and\ntraining on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual\nand 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.\n","authors":["Pranshu Rastogi"],"pdf_url":"https://arxiv.org/pdf/2508.03475v1.pdf","comment":"7 pages, 6 tables. Code available at\n  https://github.com/pranshurastogi29/SemEval-2025-ACL-Multi-and-Crosslingual-Retrieval-using-Bi-encoders"},{"id":"http://arxiv.org/abs/2508.02208v2","updated":"2025-08-05T14:01:00Z","published":"2025-08-04T08:59:36Z","title":"Proof2Hybrid: Automatic Mathematical Benchmark Synthesis for\n  Proof-Centric Problems","summary":"  Evaluating the mathematical capability of Large Language Models (LLMs) is a\ncritical yet challenging frontier. Existing benchmarks fall short, particularly\nfor proof-centric problems, as manual creation is unscalable and costly,\nleaving the true mathematical abilities of LLMs largely unassessed. To overcome\nthese barriers, we propose Proof2Hybrid, the first fully automated framework\nthat synthesizes high-quality, proof-centric benchmarks from natural language\nmathematical corpora. The key novelty of our solution is Proof2X, a roadmap of\nconverting mathematical proofs into various kinds of questions that are easy to\nverify. Instructed by this roadmap, we propose a new type of hybrid-formatted\nquestions, named ``$m$-out-of-$n$ multiple judge questions'', specifically\ndesigned to enable robust, automatic evaluation while being resilient to\nguessing and superficial pattern matching inherent in traditional formats. As a\ndemonstration of our framework, we introduce AlgGeoTest, a benchmark for\nalgebraic geometry--a frontier domain of modern mathematics--comprising 456\nchallenging items. Our extensive evaluations on state-of-the-art LLMs using\nAlgGeoTest reveal profound deficits in their comprehension of algebraic\ngeometry, providing a more precise measure of their true mathematical\ncapabilities. Our framework and benchmark pave the way for a new wave of\nin-depth research into the mathematical intelligence of AI systems.\n","authors":["Yebo Peng","Zixiang Liu","Yaoming Li","Zhizhuo Yang","Xinye Xu","Bowen Ye","Weijun Yuan","Zihan Wang","Tong Yang"],"pdf_url":"https://arxiv.org/pdf/2508.02208v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06787v4","updated":"2025-08-05T13:56:40Z","published":"2024-08-13T10:15:55Z","title":"Bridging LLMs and KGs without Fine-Tuning: Intermediate Probing Meets\n  Subgraph-Aware Entity Descriptions","summary":"  Traditional knowledge graph completion (KGC) methods rely solely on\nstructural information, struggling with the inherent sparsity of knowledge\ngraphs (KGs). By contrast, Large Language Models (LLMs) encapsulate extensive\nworld knowledge and exhibit powerful context modeling capabilities, making them\npromising for mitigating the limitations of traditional methods. However,\ndirect fine-tuning of LLMs for KGC, though effective, imposes substantial\ncomputational and memory overheads, while utilizing non-fine-tuned LLMs is\nefficient but yields suboptimal performance. In this work, we propose a novel\nframework that synergizes the strengths of LLMs with robust knowledge\nrepresentation to enable effective and efficient KGC. We extract the\ncontext-aware hidden states of knowledge triples from the intermediate layers\nof LLMs, thereby capturing rich semantic and relational nuances. These\nrepresentations are then utilized to train a data-efficient classifier tailored\nspecifically for KGC tasks. To bridge the semantic gaps between LLMs and KGs,\nwe employ subgraph sampling on KGs to generate model-friendly entity\ndescriptions. We further adopt sliced mutual information (SMI) as a principled\nmetric to quantify the task-specific information encoded in these\nrepresentations. Extensive experiments on standard benchmarks validate the\nefficiency and effectiveness of our approach. We achieve a 47\\% relative\nimprovement over previous methods based on non-fine-tuned LLMs and, to our\nknowledge, are the first to achieve classification performance comparable to\nfine-tuned LLMs while enhancing GPU memory efficiency by $188\\times$ and\naccelerating training and inference by $26.11\\times$.\n","authors":["Bo Xue","Yi Xu","Yunchong Song","Jiaxin Ding","Luoyi Fu","Xinbing Wang"],"pdf_url":"https://arxiv.org/pdf/2408.06787v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03453v1","updated":"2025-08-05T13:54:01Z","published":"2025-08-05T13:54:01Z","title":"Cropping outperforms dropout as an augmentation strategy for training\n  self-supervised text embeddings","summary":"  Text embeddings, i.e. vector representations of entire texts, play an\nimportant role in many NLP applications, such as retrieval-augmented\ngeneration, sentiment analysis, clustering, or visualizing collections of texts\nfor data exploration. Currently, top-performing embedding models are derived\nfrom pre-trained language models via extensive supervised fine-tuning using\ncurated text pairs. This contrasts with computer vision, where self-supervised\ntraining based on data augmentations has demonstrated remarkable success. Here\nwe systematically compare the two most well-known augmentation strategies for\npositive pair generation in contrastive learning of text embeddings. We assess\nembedding quality on MTEB and additional in-domain evaluations and show that\ncropping augmentation strongly outperforms the dropout-based approach. We find\nthat on out-of-domain data, the quality of resulting embeddings is below the\nsupervised SOTA models, but for in-domain data, self-supervised fine-tuning\nproduces high-quality text embeddings after very short fine-tuning, sometimes\nonly marginally below the supervised SOTA. Finally, we show that representation\nquality increases towards the last transformer layers, which undergo the\nlargest change during fine-tuning; and that fine-tuning only those last layers\nis sufficient to reach similar embedding quality.\n","authors":["Rita González-Márquez","Philipp Berens","Dmitry Kobak"],"pdf_url":"https://arxiv.org/pdf/2508.03453v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03440v1","updated":"2025-08-05T13:38:33Z","published":"2025-08-05T13:38:33Z","title":"LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of\n  Large Reasoning Models","summary":"  Human cognition naturally engages with abstract and fluid concepts, whereas\nexisting reasoning models often rely on generating discrete tokens, potentially\nconstraining their expressive capabilities. Recent advancements aim to address\nthis limitation by enabling large language models (LLMs) to generate soft,\nabstract tokens, thus facilitating reasoning within a continuous concept space.\nThis paper explores the `Soft Thinking' capabilities of various LLMs by\nexamining the models' internal behavior using a suite of probing techniques.\nContrary to the common belief that Soft Thinking enables the simultaneous\nexploration of diverse reasoning paths, our findings reveal that LLMs\npredominantly rely on the most influential component of the soft inputs during\nsubsequent decoding steps. This reliance hinders the exploration of different\nreasoning paths and reduces vanilla Soft Thinking to a form of greedy decoding,\nobscuring the advantage of transmitting more information through Soft Tokens.\nTo tackle this issue, we explore sampling strategies to introduce\n\\emph{randomness}, employing methods such as Dirichlet resampling and the\nGumbel-Softmax trick. Our experiments demonstrate that incorporating randomness\ncan alleviate the limitations of vanilla approaches and unleash the potential\nof Soft Thinking. Notably, the Gumbel-Softmax trick provides adequate\nrandomness with controlled smoothness, resulting in superior performance across\neight reasoning benchmarks.\n","authors":["Junhong Wu","Jinliang Lu","Zixuan Ren","Ganqiang Hu","Zhi Wu","Dai Dai","Hua Wu"],"pdf_url":"https://arxiv.org/pdf/2508.03440v1.pdf","comment":"10 pages, 7 figures, working in progress"},{"id":"http://arxiv.org/abs/2508.03420v1","updated":"2025-08-05T13:01:13Z","published":"2025-08-05T13:01:13Z","title":"Variety Is the Spice of Life: Detecting Misinformation with Dynamic\n  Environmental Representations","summary":"  The proliferation of misinformation across diverse social media platforms has\ndrawn significant attention from both academic and industrial communities due\nto its detrimental effects. Accordingly, automatically distinguishing\nmisinformation, dubbed as Misinformation Detection (MD), has become an\nincreasingly active research topic. The mainstream methods formulate MD as a\nstatic learning paradigm, which learns the mapping between the content, links,\nand propagation of news articles and the corresponding manual veracity labels.\nHowever, the static assumption is often violated, since in real-world\nscenarios, the veracity of news articles may vacillate within the dynamically\nevolving social environment. To tackle this problem, we propose a novel\nframework, namely Misinformation detection with Dynamic Environmental\nRepresentations (MISDER). The basic idea of MISDER lies in learning a social\nenvironmental representation for each period and employing a temporal model to\npredict the representation for future periods. In this work, we specify the\ntemporal model as the LSTM model, continuous dynamics equation, and pre-trained\ndynamics system, suggesting three variants of MISDER, namely MISDER-LSTM,\nMISDER-ODE, and MISDER-PT, respectively. To evaluate the performance of MISDER,\nwe compare it to various MD baselines across 2 prevalent datasets, and the\nexperimental results can indicate the effectiveness of our proposed model.\n","authors":["Bing Wang","Ximing Li","Yiming Wang","Changchun Li","Jiaxu Cui","Renchu Guan","Bo Yang"],"pdf_url":"https://arxiv.org/pdf/2508.03420v1.pdf","comment":"Accepted by CIKM 2025. 11 pages, 4 figures. Code:\n  https://github.com/wangbing1416/MISDER"},{"id":"http://arxiv.org/abs/2508.02823v1","updated":"2025-08-05T12:54:13Z","published":"2025-08-05T12:54:13Z","title":"NeuroSync: Intent-Aware Code-Based Problem Solving via Direct LLM\n  Understanding Modification","summary":"  Conversational LLMs have been widely adopted by domain users with limited\nprogramming experience to solve domain problems. However, these users often\nface misalignment between their intent and generated code, resulting in\nfrustration and rounds of clarification. This work first investigates the cause\nof this misalignment, which dues to bidirectional ambiguity: both user intents\nand coding tasks are inherently nonlinear, yet must be expressed and\ninterpreted through linear prompts and code sequences. To address this, we\npropose direct intent-task matching, a new human-LLM interaction paradigm that\nexternalizes and enables direct manipulation of the LLM understanding, i.e.,\nthe coding tasks and their relationships inferred by the LLM prior to code\ngeneration. As a proof-of-concept, this paradigm is then implemented in\nNeuroSync, which employs a knowledge distillation pipeline to extract LLM\nunderstanding, user intents, and their mappings, and enhances the alignment by\nallowing users to intuitively inspect and edit them via visualizations. We\nevaluate the algorithmic components of NeuroSync via technical experiments, and\nassess its overall usability and effectiveness via a user study (N=12). The\nresults show that it enhances intent-task alignment, lowers cognitive effort,\nand improves coding efficiency.\n","authors":["Wenshuo Zhang","Leixian Shen","Shuchang Xu","Jindu Wang","Jian Zhao","Huamin Qu","Linping Yuan"],"pdf_url":"https://arxiv.org/pdf/2508.02823v1.pdf","comment":"Accepted in UIST 2025"},{"id":"http://arxiv.org/abs/2508.03399v1","updated":"2025-08-05T12:48:06Z","published":"2025-08-05T12:48:06Z","title":"ReDSM5: A Reddit Dataset for DSM-5 Depression Detection","summary":"  Depression is a pervasive mental health condition that affects hundreds of\nmillions of individuals worldwide, yet many cases remain undiagnosed due to\nbarriers in traditional clinical access and pervasive stigma. Social media\nplatforms, and Reddit in particular, offer rich, user-generated narratives that\ncan reveal early signs of depressive symptomatology. However, existing\ncomputational approaches often label entire posts simply as depressed or not\ndepressed, without linking language to specific criteria from the DSM-5, the\nstandard clinical framework for diagnosing depression. This limits both\nclinical relevance and interpretability. To address this gap, we introduce\nReDSM5, a novel Reddit corpus comprising 1484 long-form posts, each\nexhaustively annotated at the sentence level by a licensed psychologist for the\nnine DSM-5 depression symptoms. For each label, the annotator also provides a\nconcise clinical rationale grounded in DSM-5 methodology. We conduct an\nexploratory analysis of the collection, examining lexical, syntactic, and\nemotional patterns that characterize symptom expression in social media\nnarratives. Compared to prior resources, ReDSM5 uniquely combines\nsymptom-specific supervision with expert explanations, facilitating the\ndevelopment of models that not only detect depression but also generate\nhuman-interpretable reasoning. We establish baseline benchmarks for both\nmulti-label symptom classification and explanation generation, providing\nreference results for future research on detection and interpretability.\n","authors":["Eliseo Bao","Anxo Pérez","Javier Parapar"],"pdf_url":"https://arxiv.org/pdf/2508.03399v1.pdf","comment":"Accepted as a resource paper at CIKM 2025"},{"id":"http://arxiv.org/abs/2503.10408v2","updated":"2025-08-05T12:45:28Z","published":"2025-03-13T14:32:30Z","title":"Out-of-Context Relational Reasoning in Large Language Models","summary":"  Binary relations, such as equality, are basic mathematical concepts that\nappear, implicitly or explicitly, in most benchmarks for Large Language Models\n(LLM). A recent trend in the literature is benchmarking LLMs on out-of-context\nlearning, where the data is not presented in the prompt, but only during the\nmodel's training. However, existing works mostly focus on higher-order tasks,\nmaking it hard to interpret success or failure. In this work, we study how well\ncan LLMs reason out-of-context on binary relations by only learning the\nrepresentations of newly introduced tokens. Our experiments focus on equality\n($=$), inequality ($<$), and inclusion ($\\subset$) and the properties they\nsatisfy, such as reflexivity, symmetry, transitivity, and logical complexity\n(e.g., the number of reasoning \"hops\"). We show that LLMs achieve better than\nrandom accuracy, but are still far from perfect, even on relatively simple\nreasoning tasks involving binary relations. We analyse the learned\nrepresentations and show that LLMs encode useful information directly,\narranging the embeddings according to the task.\n","authors":["Jonathan Shaki","Emanuele La Malfa","Michael Wooldridge","Sarit Kraus"],"pdf_url":"https://arxiv.org/pdf/2503.10408v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.19331v2","updated":"2025-08-05T12:26:14Z","published":"2024-11-28T19:00:03Z","title":"Talking to DINO: Bridging Self-Supervised Vision Backbones with Language\n  for Open-Vocabulary Segmentation","summary":"  Open-Vocabulary Segmentation (OVS) aims at segmenting images from free-form\ntextual concepts without predefined training classes. While existing\nvision-language models such as CLIP can generate segmentation masks by\nleveraging coarse spatial information from Vision Transformers, they face\nchallenges in spatial localization due to their global alignment of image and\ntext features. Conversely, self-supervised visual models like DINO excel in\nfine-grained visual encoding but lack integration with language. To bridge this\ngap, we present Talk2DINO, a novel hybrid approach that combines the spatial\naccuracy of DINOv2 with the language understanding of CLIP. Our approach aligns\nthe textual embeddings of CLIP to the patch-level features of DINOv2 through a\nlearned mapping function without the need to fine-tune the underlying\nbackbones. At training time, we exploit the attention maps of DINOv2 to\nselectively align local visual patches with textual embeddings. We show that\nthe powerful semantic and localization abilities of Talk2DINO can enhance the\nsegmentation process, resulting in more natural and less noisy segmentations,\nand that our approach can also effectively distinguish foreground objects from\nthe background. Experimental results demonstrate that Talk2DINO achieves\nstate-of-the-art performance across several unsupervised OVS benchmarks. Source\ncode and models are publicly available at:\nhttps://lorebianchi98.github.io/Talk2DINO/.\n","authors":["Luca Barsellotti","Lorenzo Bianchi","Nicola Messina","Fabio Carrara","Marcella Cornia","Lorenzo Baraldi","Fabrizio Falchi","Rita Cucchiara"],"pdf_url":"https://arxiv.org/pdf/2411.19331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03366v1","updated":"2025-08-05T12:14:32Z","published":"2025-08-05T12:14:32Z","title":"A Comparative Study of Neurosymbolic AI Approaches to Interpretable\n  Logical Reasoning","summary":"  General logical reasoning, defined as the ability to reason deductively on\ndomain-agnostic tasks, continues to be a challenge for large language models\n(LLMs). Current LLMs fail to reason deterministically and are not\ninterpretable. As such, there has been a recent surge in interest in\nneurosymbolic AI, which attempts to incorporate logic into neural networks. We\nfirst identify two main neurosymbolic approaches to improving logical\nreasoning: (i) the integrative approach comprising models where symbolic\nreasoning is contained within the neural network, and (ii) the hybrid approach\ncomprising models where a symbolic solver, separate from the neural network,\nperforms symbolic reasoning. Both contain AI systems with promising results on\ndomain-specific logical reasoning benchmarks. However, their performance on\ndomain-agnostic benchmarks is understudied. To the best of our knowledge, there\nhas not been a comparison of the contrasting approaches that answers the\nfollowing question: Which approach is more promising for developing general\nlogical reasoning? To analyze their potential, the following best-in-class\ndomain-agnostic models are introduced: Logic Neural Network (LNN), which uses\nthe integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the\nhybrid approach. Using both models as case studies and representatives of each\napproach, our analysis demonstrates that the hybrid approach is more promising\nfor developing general logical reasoning because (i) its reasoning chain is\nmore interpretable, and (ii) it retains the capabilities and advantages of\nexisting LLMs. To support future works using the hybrid approach, we propose a\ngeneralizable framework based on LLM-SS that is modular by design,\nmodel-agnostic, domain-agnostic, and requires little to no human input.\n","authors":["Michael K. Chen"],"pdf_url":"https://arxiv.org/pdf/2508.03366v1.pdf","comment":"Accepted to NeSy 2025"},{"id":"http://arxiv.org/abs/2508.03363v1","updated":"2025-08-05T12:09:55Z","published":"2025-08-05T12:09:55Z","title":"Thinking with Nothinking Calibration: A New In-Context Learning Paradigm\n  in Reasoning Large Language Models","summary":"  Reasoning large language models (RLLMs) have recently demonstrated remarkable\ncapabilities through structured and multi-step reasoning. While prior research\nhas primarily focused on improving their training and inference strategies,\ntheir potential for in-context learning (ICL) remains largely underexplored. To\nfill this gap, we propose Thinking with Nothinking Calibration (JointThinking),\na new ICL paradigm that leverages the structured difference between two\nreasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy.\nSpecifically, our method prompts the model to generate two answers in parallel:\none in Thinking mode and the other in Nothinking mode. A second round of\nThinking is triggered only when the two initial responses are inconsistent,\nusing a single prompt that incorporates the original question and both\ncandidate answers. Since such disagreement occurs infrequently (e.g., only 6\\%\nin GSM8K), our method performs just one round of reasoning in most cases,\nresulting in minimal latency overhead. Extensive experiments across multiple\nreasoning benchmarks demonstrate that JointThinking significantly outperforms\nfew-shot chain-of-thought (CoT) and majority voting with improved answer\nrobustness. Moreover, It achieves comparable in-distribution performance to\ntraining-based SOTA method, while substantially outperforming on\nout-of-distribution tasks. We further conduct a systematic analysis of the\ncalibration mechanism, showing that leveraging different reasoning modes\nconsistently lowers the error rate and highlights the value of structural\nthinking diversity. Additionally, we observe that the performance gap between\nactual and ideal reasoning narrows as model size increases in the second round\nof thinking, indicating the strong scalability of our approach. Finally, we\ndiscuss current limitations and outline promising directions for future ICL\nresearch in RLLMs.\n","authors":["Haotian Wu","Bo Xu","Yao Shu","Menglin Yang","Chengwei Qin"],"pdf_url":"https://arxiv.org/pdf/2508.03363v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03358v1","updated":"2025-08-05T12:03:03Z","published":"2025-08-05T12:03:03Z","title":"Taggus: An Automated Pipeline for the Extraction of Characters' Social\n  Networks from Portuguese Fiction Literature","summary":"  Automatically identifying characters and their interactions from fiction\nbooks is, arguably, a complex task that requires pipelines that leverage\nmultiple Natural Language Processing (NLP) methods, such as Named Entity\nRecognition (NER) and Part-of-speech (POS) tagging. However, these methods are\nnot optimized for the task that leads to the construction of Social Networks of\nCharacters. Indeed, the currently available methods tend to underperform,\nespecially in less-represented languages, due to a lack of manually annotated\ndata for training. Here, we propose a pipeline, which we call Taggus, to\nextract social networks from literary fiction works in Portuguese. Our results\nshow that compared to readily available State-of-the-Art tools -- off-the-shelf\nNER tools and Large Language Models (ChatGPT) -- the resulting pipeline, which\nuses POS tagging and a combination of heuristics, achieves satisfying results\nwith an average F1-Score of $94.1\\%$ in the task of identifying characters and\nsolving for co-reference and $75.9\\%$ in interaction detection. These\nrepresent, respectively, an increase of $50.7\\%$ and $22.3\\%$ on results\nachieved by the readily available State-of-the-Art tools. Further steps to\nimprove results are outlined, such as solutions for detecting relationships\nbetween characters. Limitations on the size and scope of our testing samples\nare acknowledged. The Taggus pipeline is publicly available to encourage\ndevelopment in this field for the Portuguese language.2\n","authors":["Tiago G Canário","Catarina Duarte","Flávio L. Pinheiro","João L. M. Pereira"],"pdf_url":"https://arxiv.org/pdf/2508.03358v1.pdf","comment":"24 pages, 5 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2508.03351v1","updated":"2025-08-05T11:57:03Z","published":"2025-08-05T11:57:03Z","title":"VLMQ: Efficient Post-Training Quantization for Large Vision-Language\n  Models via Hessian Augmentation","summary":"  Post-training quantization (PTQ) has emerged as an effective approach for\ncompressing large models and accelerating their inference without retraining.\nWhile PTQ has been extensively studied in the context of large language models\n(LLMs), its applicability to vision-language models (VLMs) remains\nunderexplored. In this paper, we identify a modality discrepancy (\\emph{i.e.},\nlimited text tokens \\emph{vs.} excessive and redundant vision tokens) of VLMs.\nHowever, existing Hessian-based LLM PTQ methods treat all tokens equally during\nquantization, resulting in severe performance drops when applied to VLMs.\nMotivated by this observation, we propose a novel importance-aware PTQ\nframework tailored for VLMs, dubbed VLMQ. Specifically, to address vision token\nredundancy, VLMQ 1) optimizes an importance-aware objective that yields an\nenhanced Hessian with token-level importance factors, while retaining\ncompatibility with parallelized weight updates, and 2) ensures efficiency and\neffectiveness by computing these factors via a single lightweight block-wise\nbackward pass, guided by a theoretical connection to token-level perturbations.\nExtensive evaluations on 8 benchmarks across 0.5B$\\sim$32B VLMs demonstrate the\nstate-of-the-art (SOTA) performance of our VLMQ, particularly under low-bit\nsettings. For example, it achieves a substantial \\textbf{16.45\\%} improvement\non MME-RealWorld under 2-bit quantization.\n","authors":["Yufei Xue","Yushi Huang","Jiawei Shao","Jun Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.03351v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.02141v3","updated":"2025-08-05T11:25:03Z","published":"2024-12-03T03:57:24Z","title":"WSI-LLaVA: A Multimodal Large Language Model for Whole Slide Image","summary":"  Recent advancements in computational pathology have produced patch-level\nMulti-modal Large Language Models (MLLMs), but these models are limited by\ntheir inability to analyze whole slide images (WSIs) comprehensively and their\ntendency to bypass crucial morphological features that pathologists rely on for\ndiagnosis. To address these challenges, we first introduce WSI-Bench, a\nlarge-scale morphology-aware benchmark containing 180k VQA pairs from 9,850\nWSIs across 30 cancer types, designed to evaluate MLLMs' understanding of\nmorphological characteristics crucial for accurate diagnosis. Building upon\nthis benchmark, we present WSI-LLaVA, a novel framework for gigapixel WSI\nunderstanding that employs a three-stage training approach: WSI-text alignment,\nfeature space alignment, and task-specific instruction tuning. To better assess\nmodel performance in pathological contexts, we develop two specialized WSI\nmetrics: WSI-Precision and WSI-Relevance. Experimental results demonstrate that\nWSI-LLaVA outperforms existing models across all capability dimensions, with a\nsignificant improvement in morphological analysis, establishing a clear\ncorrelation between morphological understanding and diagnostic accuracy.\n","authors":["Yuci Liang","Xinheng Lyu","Meidan Ding","Wenting Chen","Jipeng Zhang","Yuexiang Ren","Xiangjian He","Song Wu","Sen Yang","Xiyue Wang","Xiaohan Xing","Linlin Shen"],"pdf_url":"https://arxiv.org/pdf/2412.02141v3.pdf","comment":"ICCV 2025, 38 pages, 22 figures, 35 tables"},{"id":"http://arxiv.org/abs/2503.11299v6","updated":"2025-08-05T11:19:51Z","published":"2025-03-14T11:08:30Z","title":"BriLLM: Brain-inspired Large Language Model","summary":"  We introduce BriLLM, a brain-inspired large language model that redefines the\nfoundations of generative language modeling. Departing from Transformer\narchitectures, GPT frameworks, and traditional input-output constrained\nparadigms, BriLLM is built on the Signal Fully-connected flowing (SiFu)\nmechanism - a directed graph-based neural network design that enables full\ninterpretability across all nodes, in contrast to conventional models limited\nto input-output interpretability. In this framework, tokens are represented as\ngraph nodes, with signal flows - either randomly initialized or user-defined -\npropagating along paths following a \"least resistance\" principle. The next\ntoken to be generated emerges as the target of this signal flow. Theoretically,\nBriLLM supports infinitely long n-gram modeling, with model size decoupled from\ninput and prediction length. Its signal propagation dynamics mimic human-like\ncognitive patterns, enabling recall activation and inherent multi-modal\ncompatibility. We release initial Chinese and English BriLLM versions (4000\ntokens, 32-dimensional nodes, 32-token sequence prediction capacity) with sizes\n~2B and ~1B parameters, respectively, achieving performance comparable to\nGPT-1.\n","authors":["Hai Zhao","Hongqiu Wu","Dongjie Yang","Anni Zou","Jiale Hong"],"pdf_url":"https://arxiv.org/pdf/2503.11299v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03333v1","updated":"2025-08-05T11:19:08Z","published":"2025-08-05T11:19:08Z","title":"CTTS: Collective Test-Time Scaling","summary":"  Test-time scaling (TTS) has emerged as a promising research field for\nenhancing the effectiveness of large language models (LLMs) without extra\ntraining. However, most existing approaches, e.g., Best-of-N and\nSelf-Consistency rely on a single agent interacting with a reward model\n(SA-SR), constrained by limited capabilities of a single test-time scaling\n(STTS) paradigm. On the other hand, recent works demonstrate that\ncollective-agent methods can break through the upper bound of single-agent\nsystems by orchestrating diverse models. Thus, in this paper, we take a first\nstep towards exploring Collective Test-Time Scaling (CTTS). Consider the\ndifferent interaction types of single and multiple models, we design three\nprimary paradigms to investigate the optimal paradigm of CTTS: (1) single agent\nto multiple reward models (SA-MR); (2) multiple agents to single reward model\n(MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive\nexperiments demonstrate that MA-MR consistently achieves the best performance.\nBased on this, we propose a novel framework named CTTS-MM that effectively\nleverages both multi-agent and multi-reward-model collaboration for enhanced\ninference. Specifically, for multi-agent collaboration, we propose an Agent\nCollaboration Search (ACS), which searches for the most effective combination\nof LLM agents from a large candidate pool; for multi-reward-model\ncollaboration, we propose Mixture of Reword Models (MoR), which consists of a\ncurated question pool and a Prior Reward model Ensemble Selection (PRES) to\nselect the optimal combinations of reward models via Pair-wise Reward Ranking\n(PRR) metric. Experiments across seven mainstream benchmarks demonstrate that\nthe proposed CTTS-MM consistently obtains superior performance. Code will be\nreleased at https://github.com/magent4aci/CTTS-MM.\n","authors":["Zhende Song","Shengji Tang","Peng Ye","Jiayuan Fan","Tao Chen"],"pdf_url":"https://arxiv.org/pdf/2508.03333v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2508.03670v1","updated":"2025-08-05T17:34:19Z","published":"2025-08-05T17:34:19Z","title":"Personalized Recommendation of Dish and Restaurant Collections on iFood","summary":"  Food delivery platforms face the challenge of helping users navigate vast\ncatalogs of restaurants and dishes to find meals they truly enjoy. This paper\npresents RED, an automated recommendation system designed for iFood, Latin\nAmerica's largest on-demand food delivery platform, to personalize the\nselection of curated food collections displayed to millions of users. Our\napproach employs a LightGBM classifier that scores collections based on three\nfeature groups: collection characteristics, user-collection similarity, and\ncontextual information. To address the cold-start problem of recommending newly\ncreated collections, we develop content-based representations using item\nembeddings and implement monotonicity constraints to improve generalization. We\ntackle data scarcity by bootstrapping from category carousel interactions and\naddress visibility bias through unbiased sampling of impressions and purchases\nin production. The system demonstrates significant real-world impact through\nextensive A/B testing with 5-10% of iFood's user base. Online results of our\nA/B tests add up to 97% improvement in Card Conversion Rate and 1.4% increase\nin overall App Conversion Rate compared to popularity-based baselines. Notably,\nour offline accuracy metrics strongly correlate with online performance,\nenabling reliable impact prediction before deployment. To our knowledge, this\nis the first work to detail large-scale recommendation of curated food\ncollections in a dynamic commercial environment.\n","authors":["Fernando F. Granado","Davi A. Bezerra","Iuri Queiroz","Nathan Oliveira","Pedro Fernandes","Bruno Schock"],"pdf_url":"https://arxiv.org/pdf/2508.03670v1.pdf","comment":"Workshop on Two-sided Marketplace Optimization: Search, Discovery,\n  Matching, Pricing & Growth in conjunction with KDD Conference (KDD 2025) in\n  Toronto, Canada"},{"id":"http://arxiv.org/abs/2505.18247v3","updated":"2025-08-05T17:28:07Z","published":"2025-05-23T17:18:45Z","title":"MetaGen Blended RAG: Unlocking Zero-Shot Precision for Specialized\n  Domain Question-Answering","summary":"  Retrieval-Augmented Generation (RAG) struggles with domain-specific\nenterprise datasets, often isolated behind firewalls and rich in complex,\nspecialized terminology unseen by LLMs during pre-training. Semantic\nvariability across domains like medicine, networking, or law hampers RAG's\ncontext precision, while fine-tuning solutions are costly, slow, and lack\ngeneralization as new data emerges. Achieving zero-shot precision with\nretrievers without fine-tuning still remains a key challenge. We introduce\n'MetaGen Blended RAG', a novel enterprise search approach that enhances\nsemantic retrievers through a metadata generation pipeline and hybrid query\nindexes using dense and sparse vectors. By leveraging key concepts, topics, and\nacronyms, our method creates metadata-enriched semantic indexes and boosted\nhybrid queries, delivering robust, scalable performance without fine-tuning. On\nthe biomedical PubMedQA dataset, MetaGen Blended RAG achieves 82% retrieval\naccuracy and 77% RAG accuracy, surpassing all prior zero-shot RAG benchmarks\nand even rivaling fine-tuned models on that dataset, while also excelling on\ndatasets like SQuAD and NQ. This approach redefines enterprise search using a\nnew approach to building semantic retrievers with unmatched generalization\nacross specialized domains.\n","authors":["Kunal Sawarkar","Shivam R. Solanki","Abhilasha Mangal"],"pdf_url":"https://arxiv.org/pdf/2505.18247v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03644v1","updated":"2025-08-05T16:55:02Z","published":"2025-08-05T16:55:02Z","title":"Are We on the Right Way for Assessing Document Retrieval-Augmented\n  Generation?","summary":"  Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language\nModels (MLLMs) show great promise for complex document understanding, yet their\ndevelopment is critically hampered by inadequate evaluation. Current benchmarks\noften focus on specific part of document RAG system and use synthetic data with\nincomplete ground truth and evidence labels, therefore failing to reflect\nreal-world bottlenecks and challenges. To overcome these limitations, we\nintroduce Double-Bench: a new large-scale, multilingual, and multimodal\nevaluation system that is able to produce fine-grained assessment to each\ncomponent within document RAG systems. It comprises 3,276 documents (72,880\npages) and 5,168 single- and multi-hop queries across 6 languages and 4\ndocument types with streamlined dynamic update support for potential data\ncontamination issues. Queries are grounded in exhaustively scanned evidence\npages and verified by human experts to ensure maximum quality and completeness.\nOur comprehensive experiments across 9 state-of-the-art embedding models, 4\nMLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text\nand visual embedding models is narrowing, highlighting the need in building\nstronger document retrieval models. Our findings also reveal the\nover-confidence dilemma within current document RAG frameworks that tend to\nprovide answer even without evidence support. We hope our fully open-source\nDouble-Bench provide a rigorous foundation for future research in advanced\ndocument RAG systems. We plan to retrieve timely corpus and release new\nbenchmarks on an annual basis.\n","authors":["Wenxuan Shen","Mingjia Wang","Yaochen Wang","Dongping Chen","Junjie Yang","Yao Wan","Weiwei Lin"],"pdf_url":"https://arxiv.org/pdf/2508.03644v1.pdf","comment":"In submission. Project website: https://double-bench.github.io/"},{"id":"http://arxiv.org/abs/2508.03628v1","updated":"2025-08-05T16:47:17Z","published":"2025-08-05T16:47:17Z","title":"LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for\n  Advertiser Keyphrase Recommendations at eBay","summary":"  Sellers at eBay are recommended keyphrases to bid on to enhance the\nperformance of their advertising campaigns. The relevance of these keyphrases\nis crucial in avoiding the overcrowding of search systems with irrelevant items\nand maintaining a positive seller perception. It is essential that keyphrase\nrecommendations align with both seller and Search judgments regarding auctions.\nDue to the difficulty in procuring negative human judgment at scale, employing\nLLM-as-a-judge to mimic seller judgment has been established as the norm in\nseveral studies. This study introduces a novel two-step LLM distillation\nprocess from a LLM-judge used to debias our Embedding Based Retrieval (EBR)\nmodel from the various biases that exist in click-data. We distill from an LLM\nteacher via a cross-encoder assistant into a bi-encoder student using a\nmulti-task training approach, ultimately employing the student bi-encoder to\nretrieve relevant advertiser keyphrases. We show that integrating a knowledge\ndistillation process from LLMs in a multi-task training setup enhances\nbi-encoder performance in retrieving relevant advertiser keyphrases at eBay.\n","authors":["Soumik Dey","Benjamin Braun","Naveen Ravipati","Hansi Wu","Binbin Li"],"pdf_url":"https://arxiv.org/pdf/2508.03628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03606v1","updated":"2025-08-05T16:22:45Z","published":"2025-08-05T16:22:45Z","title":"Demystifying Sequential Recommendations: Counterfactual Explanations via\n  Genetic Algorithms","summary":"  Sequential Recommender Systems (SRSs) have demonstrated remarkable\neffectiveness in capturing users' evolving preferences. However, their inherent\ncomplexity as \"black box\" models poses significant challenges for\nexplainability. This work presents the first counterfactual explanation\ntechnique specifically developed for SRSs, introducing a novel approach in this\nspace, addressing the key question: What minimal changes in a user's\ninteraction history would lead to different recommendations? To achieve this,\nwe introduce a specialized genetic algorithm tailored for discrete sequences\nand show that generating counterfactual explanations for sequential data is an\nNP-Complete problem. We evaluate these approaches across four experimental\nsettings, varying between targeted-untargeted and categorized-uncategorized\nscenarios, to comprehensively assess their capability in generating meaningful\nexplanations. Using three different datasets and three models, we are able to\ndemonstrate that our methods successfully generate interpretable counterfactual\nexplanation while maintaining model fidelity close to one. Our findings\ncontribute to the growing field of Explainable AI by providing a framework for\nunderstanding sequential recommendation decisions through the lens of \"what-if\"\nscenarios, ultimately enhancing user trust and system transparency.\n","authors":["Domiziano Scarcelli","Filippo Betello","Giuseppe Perelli","Fabrizio Silvestri","Gabriele Tolomei"],"pdf_url":"https://arxiv.org/pdf/2508.03606v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03583v1","updated":"2025-08-05T15:50:16Z","published":"2025-08-05T15:50:16Z","title":"OpenLifelogQA: An Open-Ended Multi-Modal Lifelog Question-Answering\n  Dataset","summary":"  Lifelogging refers to the process of passively collecting, storing, and\nanalysing personal daily life data using wearable devices. This data can\nsupport applications in memory preservation and enhancement. For example, using\nan ask-and-answer strategy, question-answering (QA) on lifelog data opens an\ninteractive and interesting way to explore memorable events and insights into\ndaily life. However, research resources for QA on lifelog data are limited to\nsmall-sized or synthetic QA datasets. In this paper, we present a novel lifelog\nQA dataset called OpenLifelogQA, building upon an 18-month lifelog dataset. Our\ndataset focuses on an open-ended and practical QA with real-world application\nin daily lifelog usage. We construct 14,187 pairs of Q&A with diverse types and\ndifficulty levels. A baseline experiment is reported for this dataset with\ncompetitive average performance of 89.7% BERT Score, 25.87% ROUGE-L and 3.9665\nLLM Score from LLaVA-NeXT-Interleave 7B model. We release this Q&A dataset to\nthe research community to support new research into lifelog technologies, such\nas enabling personal chat-based assistants for lifelog data to become a\nreality.\n","authors":["Quang-Linh Tran","Binh Nguyen","Gareth J. F. Jones","Cathal Gurrin"],"pdf_url":"https://arxiv.org/pdf/2508.03583v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03555v1","updated":"2025-08-05T15:23:40Z","published":"2025-08-05T15:23:40Z","title":"PyLate: Flexible Training and Retrieval for Late Interaction Models","summary":"  Neural ranking has become a cornerstone of modern information retrieval.\nWhile single vector search remains the dominant paradigm, it suffers from the\nshortcoming of compressing all the information into a single vector. This\ncompression leads to notable performance degradation in out-of-domain,\nlong-context, and reasoning-intensive retrieval tasks. Multi-vector approaches\npioneered by ColBERT aim to address these limitations by preserving individual\ntoken embeddings and computing similarity via the MaxSim operator. This\narchitecture has demonstrated superior empirical advantages, including enhanced\nout-of-domain generalization, long-context handling, and performance in complex\nretrieval scenarios. Despite these compelling empirical results and clear\ntheoretical advantages, the practical adoption and public availability of late\ninteraction models remain low compared to their single-vector counterparts,\nprimarily due to a lack of accessible and modular tools for training and\nexperimenting with such models. To bridge this gap, we introduce PyLate, a\nstreamlined library built on top of Sentence Transformers to support\nmulti-vector architectures natively, inheriting its efficient training,\nadvanced logging, and automated model card generation while requiring minimal\ncode changes to code templates users are already familiar with. By offering\nmulti-vector-specific features such as efficient indexes, PyLate aims to\naccelerate research and real-world application of late interaction models,\nthereby unlocking their full potential in modern IR systems. Finally, PyLate\nhas already enabled the development of state-of-the-art models, including\nGTE-ModernColBERT and Reason-ModernColBERT, demonstrating its practical utility\nfor both research and production environments.\n","authors":["Antoine Chaffin","Raphaël Sourty"],"pdf_url":"https://arxiv.org/pdf/2508.03555v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2508.03553v1","updated":"2025-08-05T15:20:52Z","published":"2025-08-05T15:20:52Z","title":"MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in\n  Multi-source Retrieval Augmented Generation","summary":"  Retrieval Augmented Generation (RAG) has emerged as a promising solution to\naddress hallucination issues in Large Language Models (LLMs). However, the\nintegration of multiple retrieval sources, while potentially more informative,\nintroduces new challenges that can paradoxically exacerbate hallucination\nproblems. These challenges manifest primarily in two aspects: the sparse\ndistribution of multi-source data that hinders the capture of logical\nrelationships and the inherent inconsistencies among different sources that\nlead to information conflicts. To address these challenges, we propose\nMultiRAG, a novel framework designed to mitigate hallucination in multi-source\nretrieval-augmented generation through knowledge-guided approaches. Our\nframework introduces two key innovations: (1) a knowledge construction module\nthat employs multi-source line graphs to efficiently aggregate logical\nrelationships across different knowledge sources, effectively addressing the\nsparse data distribution issue; and (2) a sophisticated retrieval module that\nimplements a multi-level confidence calculation mechanism, performing both\ngraph-level and node-level assessments to identify and eliminate unreliable\ninformation nodes, thereby reducing hallucinations caused by inter-source\ninconsistencies. Extensive experiments on four multi-domain query datasets and\ntwo multi-hop QA datasets demonstrate that MultiRAG significantly enhances the\nreliability and efficiency of knowledge retrieval in complex multi-source\nscenarios. \\textcolor{blue}{Our code is available in\nhttps://github.com/wuwenlong123/MultiRAG.\n","authors":["Wenlong Wu","Haofen Wang","Bohan Li","Peixuan Huang","Xinzhe Zhao","Lei Liang"],"pdf_url":"https://arxiv.org/pdf/2508.03553v1.pdf","comment":"Accepted by ICDE 2025 Research Paper"},{"id":"http://arxiv.org/abs/2508.03518v1","updated":"2025-08-05T14:46:06Z","published":"2025-08-05T14:46:06Z","title":"Parameter-Efficient Single Collaborative Branch for Recommendation","summary":"  Recommender Systems (RS) often rely on representations of users and items in\na joint embedding space and on a similarity metric to compute relevance scores.\nIn modern RS, the modules to obtain user and item representations consist of\ntwo distinct and separate neural networks (NN). In multimodal representation\nlearning, weight sharing has been proven effective in reducing the distance\nbetween multiple modalities of a same item. Inspired by these approaches, we\npropose a novel RS that leverages weight sharing between the user and item NN\nmodules used to obtain the latent representations in the shared embedding\nspace. The proposed framework consists of a single Collaborative Branch for\nRecommendation (CoBraR). We evaluate CoBraR by means of quantitative\nexperiments on e-commerce and movie recommendation. Our experiments show that\nby reducing the number of parameters and improving beyond-accuracy aspects\nwithout compromising accuracy, CoBraR has the potential to be applied and\nextended for real-world scenarios.\n","authors":["Marta Moscati","Shah Nawaz","Markus Schedl"],"pdf_url":"https://arxiv.org/pdf/2508.03518v1.pdf","comment":"5 pages"},{"id":"http://arxiv.org/abs/2508.03475v1","updated":"2025-08-05T14:10:09Z","published":"2025-08-05T14:10:09Z","title":"fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual\n  Fact-checked Claim Retrieval","summary":"  SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim\nRetrieval is approached as a Learning-to-Rank task using a bi-encoder model\nfine-tuned from a pre-trained transformer optimized for sentence similarity.\nTraining used both the source languages and their English translations for\nmultilingual retrieval and only English translations for cross-lingual\nretrieval. Using lightweight models with fewer than 500M parameters and\ntraining on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual\nand 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.\n","authors":["Pranshu Rastogi"],"pdf_url":"https://arxiv.org/pdf/2508.03475v1.pdf","comment":"7 pages, 6 tables. Code available at\n  https://github.com/pranshurastogi29/SemEval-2025-ACL-Multi-and-Crosslingual-Retrieval-using-Bi-encoders"},{"id":"http://arxiv.org/abs/2508.03358v1","updated":"2025-08-05T12:03:03Z","published":"2025-08-05T12:03:03Z","title":"Taggus: An Automated Pipeline for the Extraction of Characters' Social\n  Networks from Portuguese Fiction Literature","summary":"  Automatically identifying characters and their interactions from fiction\nbooks is, arguably, a complex task that requires pipelines that leverage\nmultiple Natural Language Processing (NLP) methods, such as Named Entity\nRecognition (NER) and Part-of-speech (POS) tagging. However, these methods are\nnot optimized for the task that leads to the construction of Social Networks of\nCharacters. Indeed, the currently available methods tend to underperform,\nespecially in less-represented languages, due to a lack of manually annotated\ndata for training. Here, we propose a pipeline, which we call Taggus, to\nextract social networks from literary fiction works in Portuguese. Our results\nshow that compared to readily available State-of-the-Art tools -- off-the-shelf\nNER tools and Large Language Models (ChatGPT) -- the resulting pipeline, which\nuses POS tagging and a combination of heuristics, achieves satisfying results\nwith an average F1-Score of $94.1\\%$ in the task of identifying characters and\nsolving for co-reference and $75.9\\%$ in interaction detection. These\nrepresent, respectively, an increase of $50.7\\%$ and $22.3\\%$ on results\nachieved by the readily available State-of-the-Art tools. Further steps to\nimprove results are outlined, such as solutions for detecting relationships\nbetween characters. Limitations on the size and scope of our testing samples\nare acknowledged. The Taggus pipeline is publicly available to encourage\ndevelopment in this field for the Portuguese language.2\n","authors":["Tiago G Canário","Catarina Duarte","Flávio L. Pinheiro","João L. M. Pereira"],"pdf_url":"https://arxiv.org/pdf/2508.03358v1.pdf","comment":"24 pages, 5 Figures, 4 Tables"},{"id":"http://arxiv.org/abs/2409.07276v3","updated":"2025-08-05T11:07:31Z","published":"2024-09-11T13:49:48Z","title":"Learning Multi-Aspect Item Palette: A Semantic Tokenization Framework\n  for Generative Recommendation","summary":"  Traditional recommendation models often rely on unique item identifiers (IDs)\nto distinguish between items, which can hinder their ability to effectively\nleverage item content information and generalize to long-tailed or cold-start\nitems. Recently, semantic tokenization has been proposed as a promising\nsolution that aims to tokenize each item's semantic representation into a\nsequence of discrete tokens. These semantic tokens have become fundamental in\ntraining generative recommendation models. However, existing methods typically\nrely on RQ-VAE, a residual vector quantizer, for semantic tokenization. This\nreliance introduces several key limitations, including challenges in embedding\nextraction, hierarchical coarse-to-fine quantization, and training stability.\nTo address these issues, we introduce LAMIA, a novel approach for multi-aspect\nsemantic tokenization. Unlike RQ-VAE, which uses a single embedding, LAMIA\nlearns an ``item palette''--a collection of independent and semantically\nparallel embeddings that capture multiple aspects of items. Additionally, LAMIA\nenhances the semantic encoders through domain-specific tuning using text-based\nreconstruction tasks, resulting in more representative item palette embeddings.\nWe have conducted extensive experiments to validate the effectiveness of the\nLAMIA framework across various recommendation tasks and datasets. Our results\ndemonstrate significant improvements in recommendation accuracy over existing\nmethods. To facilitate reproducible research, we will release the source code,\ndata, and configurations.\n","authors":["Qijiong Liu","Jieming Zhu","Zhaocheng Du","Lu Fan","Zhou Zhao","Xiao-Ming Wu"],"pdf_url":"https://arxiv.org/pdf/2409.07276v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00827v2","updated":"2025-08-05T10:39:24Z","published":"2025-05-12T15:11:11Z","title":"A Foundational Schema.org Mapping for a Legal Knowledge Graph:\n  Representing Brazilian Legal Norms as FRBR Works","summary":"  Structuring legal norms for machine readability is a critical prerequisite\nfor building advanced AI and information retrieval systems, such as Legal\nKnowledge Graphs (LKGs). Grounded in the Functional Requirements for\nBibliographic Records (FRBR) model, this paper proposes a foundational mapping\nfor the abstract legal Work - which is materialized as the Norm node in our\nlegal Graph RAG framework - to the interoperable schema.org/Legislation\nvocabulary. Using the Normas.leg.br portal as a practical case study, we\ndemonstrate how to describe this Work entity via JSON-LD, considering stable\nURN identifiers, inter-norm relationships, and lifecycle properties. This\nstructured, formal approach provides the essential first step toward creating a\ndeterministic and verifiable knowledge graph, which can serve as a formalized\n\"ground truth\" for Legal AI applications, overcoming the limitations of purely\nprobabilistic models.\n","authors":["Hudson de Martim"],"pdf_url":"https://arxiv.org/pdf/2508.00827v2.pdf","comment":"Substantial revision. Now grounded in the FRBR model, mapping the\n  legal norm as an abstract Work. Scope narrowed to the Work -> sdo:Legislation\n  mapping (LegislationObject section removed). Emphasizes creating a\n  deterministic 'ground truth' for Legal AI and Graph RAG"},{"id":"http://arxiv.org/abs/2402.03365v4","updated":"2025-08-05T10:31:51Z","published":"2024-01-31T11:03:58Z","title":"Heterophily-Aware Fair Recommendation using Graph Convolutional Networks","summary":"  In recent years, graph neural networks (GNNs) have become a popular tool to\nimprove the accuracy and performance of recommender systems. Modern recommender\nsystems are not only designed to serve end users, but also to benefit other\nparticipants, such as items and item providers. These participants may have\ndifferent or conflicting goals and interests, which raises the need for\nfairness and popularity bias considerations. GNN-based recommendation methods\nalso face the challenges of unfairness and popularity bias, and their\nnormalization and aggregation processes suffer from these challenges. In this\npaper, we propose a fair GNN-based recommender system, called HetroFair, to\nimprove item-side fairness. HetroFair uses two separate components to generate\nfairness-aware embeddings: i) Fairness-aware attention, which incorporates the\ndot product in the normalization process of GNNs to decrease the effect of\nnodes' degrees. ii) Heterophily feature weighting, to assign distinct weights\nto different features during the aggregation process. To evaluate the\neffectiveness of HetroFair, we conduct extensive experiments over six\nreal-world datasets. Our experimental results reveal that HetroFair not only\nalleviates unfairness and popularity bias on the item side but also achieves\nsuperior accuracy on the user side. Our implementation is publicly available at\nhttps://github.com/NematGH/HetroFair.\n","authors":["Nemat Gholinejad","Mostafa Haghir Chehreghani"],"pdf_url":"https://arxiv.org/pdf/2402.03365v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.19794v3","updated":"2025-08-05T10:29:19Z","published":"2025-06-24T17:04:23Z","title":"Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic\n  Empirical Study","summary":"  Large Language Models (LLMs) hold promise in automating data analysis tasks,\nyet open-source models face significant limitations in these kinds of\nreasoning-intensive scenarios. In this work, we investigate strategies to\nenhance the data analysis capabilities of open-source LLMs. By curating a seed\ndataset of diverse, realistic scenarios, we evaluate model behavior across\nthree core dimensions: data understanding, code generation, and strategic\nplanning. Our analysis reveals three key findings: (1) Strategic planning\nquality serves as the primary determinant of model performance; (2) Interaction\ndesign and task complexity significantly influence reasoning capabilities; (3)\nData quality demonstrates a greater impact than diversity in achieving optimal\nperformance. We leverage these insights to develop a data synthesis\nmethodology, demonstrating significant improvements in open-source LLMs'\nanalytical reasoning capabilities. Code is available at\nhttps://github.com/zjunlp/DataMind.\n","authors":["Yuqi Zhu","Yi Zhong","Jintian Zhang","Ziheng Zhang","Shuofei Qiao","Yujie Luo","Lun Du","Da Zheng","Ningyu Zhang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2506.19794v3.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2508.03306v1","updated":"2025-08-05T10:27:57Z","published":"2025-08-05T10:27:57Z","title":"Reliable Evaluation Protocol for Low-Precision Retrieval","summary":"  Lowering the numerical precision of model parameters and computations is\nwidely adopted to improve the efficiency of retrieval systems. However, when\ncomputing relevance scores between the query and documents in low-precision, we\nobserve spurious ties due to the reduced granularity. This introduces high\nvariability in the results based on tie resolution, making the evaluation less\nreliable. To address this, we propose a more robust retrieval evaluation\nprotocol designed to reduce score variation. It consists of: (1) High-Precision\nScoring (HPS), which upcasts the final scoring step to higher precision to\nresolve tied candidates with minimal computational cost; and (2) Tie-aware\nRetrieval Metrics (TRM), which report expected scores, range, and bias to\nquantify order uncertainty of tied candidates. Our experiments test multiple\nmodels with three scoring functions on two retrieval datasets to demonstrate\nthat HPS dramatically reduces tie-induced instability, and TRM accurately\nrecovers expected metric values. This combination enables a more consistent and\nreliable evaluation system for lower-precision retrievals.\n","authors":["Kisu Yang","Yoonna Jang","Hwanseok Jang","Kenneth Choi","Isabelle Augenstein","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2508.03306v1.pdf","comment":"11 pages, 5 figures, submitted to ARR"},{"id":"http://arxiv.org/abs/2508.03274v1","updated":"2025-08-05T09:52:53Z","published":"2025-08-05T09:52:53Z","title":"Investigating the Cognitive Response of Brake Lights in Initiating\n  Braking Action Using EEG","summary":"  Half of all road accidents result from either lack of driver attention or\nfrom maintaining insufficient separation between vehicles. Collision from the\nrear, in particular, has been identified as the most common class of accident\nin the UK, and its influencing factors have been widely studied for many years.\nRear-mounted stop lamps, illuminated when braking, are the primary mechanism to\nalert following drivers to the need to reduce speed or brake. This paper\ndevelops a novel brain response approach to measuring subject reaction to\ndifferent brake light designs. A variety of off-the-shelf brake light\nassemblies are tested in a physical simulated driving environment to assess the\ncognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs\nof incandescent bulb-based brake light assemblies are used and\nelectroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the\nP3 component evoked during the decision making process that occurs in the brain\nwhen a participant decides to lift their foot from the accelerator and depress\nthe brake. EEG analysis shows that both incandescent bulb-based lights are\nstatistically slower to evoke cognitive responses than all tested LED-based\nlights. Between the LED designs, differences are evident, but not statistically\nsignificant, attributed to the significant amount of movement artifact in the\nEEG signal.\n","authors":["Ramaswamy Palaniappan","Surej Mouli","Howard Bowman","Ian McLoughlin"],"pdf_url":"https://arxiv.org/pdf/2508.03274v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2010.10584"},{"id":"http://arxiv.org/abs/2506.10960v2","updated":"2025-08-05T08:58:05Z","published":"2025-06-12T17:57:05Z","title":"ChineseHarm-Bench: A Chinese Harmful Content Detection Benchmark","summary":"  Large language models (LLMs) have been increasingly applied to automated\nharmful content detection tasks, assisting moderators in identifying policy\nviolations and improving the overall efficiency and accuracy of content review.\nHowever, existing resources for harmful content detection are predominantly\nfocused on English, with Chinese datasets remaining scarce and often limited in\nscope. We present a comprehensive, professionally annotated benchmark for\nChinese content harm detection, which covers six representative categories and\nis constructed entirely from real-world data. Our annotation process further\nyields a knowledge rule base that provides explicit expert knowledge to assist\nLLMs in Chinese harmful content detection. In addition, we propose a\nknowledge-augmented baseline that integrates both human-annotated knowledge\nrules and implicit knowledge from large language models, enabling smaller\nmodels to achieve performance comparable to state-of-the-art LLMs. Code and\ndata are available at https://github.com/zjunlp/ChineseHarm-bench.\n","authors":["Kangwei Liu","Siyuan Cheng","Bozhong Tian","Xiaozhuan Liang","Yuyang Yin","Meng Han","Ningyu Zhang","Bryan Hooi","Xi Chen","Shumin Deng"],"pdf_url":"https://arxiv.org/pdf/2506.10960v2.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2505.12260v3","updated":"2025-08-05T08:01:24Z","published":"2025-05-18T06:51:21Z","title":"LightRetriever: A LLM-based Hybrid Retrieval Architecture with 1000x\n  Faster Query Inference","summary":"  Large Language Models (LLMs)-based text retrieval retrieves documents\nrelevant to search queries based on vector similarities. Documents are\npre-encoded offline, while queries arrive in real-time, necessitating an\nefficient online query encoder. Although LLMs significantly enhance retrieval\ncapabilities, serving deeply parameterized LLMs slows down query inference\nthroughput and increases demands for online deployment resources. In this\npaper, we propose LightRetriever, a novel LLM-based retriever with extremely\nlightweight query encoders. Our method retains a full-sized LLM for document\nencoding, but reduces the workload of query encoding to no more than an\nembedding lookup. Compared to serving a full LLM on an A800 GPU, our method\nachieves over 1000x speedup in query encoding and over 10x increase in\nend-to-end retrieval throughput. Extensive experiments on large-scale retrieval\nbenchmarks show that LightRetriever generalizes well across diverse tasks,\nmaintaining an average of 95% retrieval performance.\n","authors":["Guangyuan Ma","Yongliang Ma","Xuanrui Gou","Zhenpeng Su","Ming Zhou","Songlin Hu"],"pdf_url":"https://arxiv.org/pdf/2505.12260v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03172v1","updated":"2025-08-05T07:25:56Z","published":"2025-08-05T07:25:56Z","title":"Dual-disentangle Framework for Diversified Sequential Recommendation","summary":"  Sequential recommendation predicts user preferences over time and has\nachieved remarkable success. However, the growing length of user interaction\nsequences and the complex entanglement of evolving user interests and\nintentions introduce significant challenges to diversity. To address these, we\npropose a model-agnostic Dual-disentangle framework for Diversified Sequential\nRecommendation (DDSRec). The framework refines user interest and intention\nmodeling by adopting disentangling perspectives in interaction modeling and\nrepresentation learning, thereby balancing accuracy and diversity in sequential\nrecommendations. Extensive experiments on multiple public datasets demonstrate\nthe effectiveness and superiority of DDSRec in terms of accuracy and diversity\nfor sequential recommendations.\n","authors":["Haoran Zhang","Jingtong Liu","Jiangzhou Deng","Junpeng Guo"],"pdf_url":"https://arxiv.org/pdf/2508.03172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.04592v2","updated":"2025-08-05T06:00:01Z","published":"2025-02-07T00:55:25Z","title":"CAMEF: Causal-Augmented Multi-Modality Event-Driven Financial\n  Forecasting by Integrating Time Series Patterns and Salient Macroeconomic\n  Announcements","summary":"  Accurately forecasting the impact of macroeconomic events is critical for\ninvestors and policymakers. Salient events like monetary policy decisions and\nemployment reports often trigger market movements by shaping expectations of\neconomic growth and risk, thereby establishing causal relationships between\nevents and market behavior. Existing forecasting methods typically focus either\non textual analysis or time-series modeling, but fail to capture the\nmulti-modal nature of financial markets and the causal relationship between\nevents and price movements. To address these gaps, we propose CAMEF\n(Causal-Augmented Multi-Modality Event-Driven Financial Forecasting), a\nmulti-modality framework that effectively integrates textual and time-series\ndata with a causal learning mechanism and an LLM-based counterfactual event\naugmentation technique for causal-enhanced financial forecasting. Our\ncontributions include: (1) a multi-modal framework that captures causal\nrelationships between policy texts and historical price data; (2) a new\nfinancial dataset with six types of macroeconomic releases from 2008 to April\n2024, and high-frequency real trading data for five key U.S. financial assets;\nand (3) an LLM-based counterfactual event augmentation strategy. We compare\nCAMEF to state-of-the-art transformer-based time-series and multi-modal\nbaselines, and perform ablation studies to validate the effectiveness of the\ncausal learning mechanism and event types.\n","authors":["Yang Zhang","Wenbo Yang","Jun Wang","Qiang Ma","Jie Xiong"],"pdf_url":"https://arxiv.org/pdf/2502.04592v2.pdf","comment":"Accepted in SIGKDD 2025"},{"id":"http://arxiv.org/abs/2508.03088v1","updated":"2025-08-05T05:05:06Z","published":"2025-08-05T05:05:06Z","title":"ADSeeker: A Knowledge-Infused Framework for Anomaly Detection and\n  Reasoning","summary":"  Automatic vision inspection holds significant importance in industry\ninspection. While multimodal large language models (MLLMs) exhibit strong\nlanguage understanding capabilities and hold promise for this task, their\nperformance remains significantly inferior to that of human experts. In this\ncontext, we identify two key challenges: (i) insufficient integration of\nanomaly detection (AD) knowledge during pre-training, and (ii) the lack of\ntechnically precise and conte-aware language generation for anomaly reasoning.\nTo address these issues, we propose ADSeeker, an anomaly task assistant\ndesigned to enhance inspection performance through knowledge-grounded\nreasoning. ADSeeker leverages a curated visual document knowledge base,\nSEEK-MVTec&VisA (SEEK-M&V), which we construct to address the limitations of\nexisting resources that rely solely on unstructured text. SEEK-M&V includes\nsemantic-rich descriptions and image-document pairs, enabling more\ncomprehensive anomaly understanding. To effectively retrieve and utilize this\nknowledge, we introduce the Query Image-Knowledge Retrieval-Augmented\nGeneration (Q2K RAG) framework. To further enhance the performance in zero-shot\nanomaly detection (ZSAD), ADSeeker leverages the Hierarchical Sparse Prompt\nmechanism and type-level features to efficiently extract anomaly patterns.\nFurthermore, to tackle the challenge of limited in industry anomaly detection\n(IAD) data, we introduce the largest-scale AD dataset, Multi-type Anomaly\n(MulA), encompassing 72 multi-scale defect types across 26 Categories.\nExtensive experiments show that our plug-and-play framework, ADSeeker, achieves\nstate-of-the-art zero-shot performance on several benchmark datasets.\n","authors":["Kai Zhang","Zekai Zhang","Xihe Sun","Jingmeng Nie","Qinghui Chen","Han Hao","Jianyuan Guo","Jinglin Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.03088v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03016v1","updated":"2025-08-05T02:52:15Z","published":"2025-08-05T02:52:15Z","title":"KBest: Efficient Vector Search on Kunpeng CPU","summary":"  Vector search, which returns the vectors most similar to a given query vector\nfrom a large vector dataset, underlies many important applications such as\nsearch, recommendation, and LLMs. To be economic, vector search needs to be\nefficient to reduce the resources required by a given query workload. However,\nexisting vector search libraries (e.g., Faiss and DiskANN) are optimized for\nx86 CPU architectures (i.e., Intel and AMD CPUs) while Huawei Kunpeng CPUs are\nbased on the ARM architecture and competitive in compute power. In this paper,\nwe present KBest as a vector search library tailored for the latest Kunpeng 920\nCPUs. To be efficient, KBest incorporates extensive hardware-aware and\nalgorithmic optimizations, which include single-instruction-multiple-data\n(SIMD) accelerated distance computation, data prefetch, index refinement, early\ntermination, and vector quantization. Experiment results show that KBest\noutperforms SOTA vector search libraries running on x86 CPUs, and our\noptimizations can improve the query throughput by over 2x. Currently, KBest\nserves applications from both our internal business and external enterprise\nclients with tens of millions of queries on a daily basis.\n","authors":["Kaihao MA","Meiling Wang","Senkevich Oleg","Zijian LI","Daihao Xue","Dmitriy Malyshev","Yangming Lv","Shihai Xiao","Xiao Yan","Radionov Alexander","Weidi Zeng","Yuanzhan Gao","Zhiyu Zou","Yao xin","Liu Lin","Junhao Wu","Yiding Liu","Yaoyao Fu","Gongyi Wang","Gong Zhang","Fei Yi","Yingfan Liu"],"pdf_url":"https://arxiv.org/pdf/2508.03016v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03000v1","updated":"2025-08-05T02:03:59Z","published":"2025-08-05T02:03:59Z","title":"SustainableQA: A Comprehensive Question Answering Dataset for Corporate\n  Sustainability and EU Taxonomy Reporting","summary":"  The growing demand for corporate sustainability transparency, particularly\nunder new regulations like the EU Taxonomy, necessitates precise data\nextraction from large, unstructured corporate reports. Large Language Models\n(LLMs) and Retrieval-Augmented Generation (RAG) systems, requires high-quality,\ndomain-specific question-answering (QA) datasets to excel at particular\ndomains. To address this, we introduce SustainableQA, a novel dataset and a\nscalable pipeline for generating a comprehensive QA datasets from corporate\nsustainability reports and annual reports. Our approach integrates semantic\nchunk classification, a hybrid span extraction pipeline combining fine-tuned\nNamed Entity Recognition (NER), rule-based methods, and LLM-driven refinement,\nalongside a specialized table-to-paragraph transformation. With over 195,000\ndiverse factoid and non-factoid QA pairs, SustainableQA is an effective\nresource for developing and benchmarking advanced knowledge assistants capable\nof navigating complex sustainability compliance\n","authors":["Mohammed Ali","Abdelrahman Abdallah","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2508.03000v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03967v1","updated":"2025-08-05T23:10:56Z","published":"2025-08-05T23:10:56Z","title":"RAVID: Retrieval-Augmented Visual Detection: A Knowledge-Driven Approach\n  for AI-Generated Image Identification","summary":"  In this paper, we introduce RAVID, the first framework for AI-generated image\ndetection that leverages visual retrieval-augmented generation (RAG). While RAG\nmethods have shown promise in mitigating factual inaccuracies in foundation\nmodels, they have primarily focused on text, leaving visual knowledge\nunderexplored. Meanwhile, existing detection methods, which struggle with\ngeneralization and robustness, often rely on low-level artifacts and\nmodel-specific features, limiting their adaptability. To address this, RAVID\ndynamically retrieves relevant images to enhance detection. Our approach\nutilizes a fine-tuned CLIP image encoder, RAVID CLIP, enhanced with\ncategory-related prompts to improve representation learning. We further\nintegrate a vision-language model (VLM) to fuse retrieved images with the\nquery, enriching the input and improving accuracy. Given a query image, RAVID\ngenerates an embedding using RAVID CLIP, retrieves the most relevant images\nfrom a database, and combines these with the query image to form an enriched\ninput for a VLM (e.g., Qwen-VL or Openflamingo). Experiments on the\nUniversalFakeDetect benchmark, which covers 19 generative models, show that\nRAVID achieves state-of-the-art performance with an average accuracy of 93.85%.\nRAVID also outperforms traditional methods in terms of robustness, maintaining\nhigh accuracy even under image degradations such as Gaussian blur and JPEG\ncompression. Specifically, RAVID achieves an average accuracy of 80.27% under\ndegradation conditions, compared to 63.44% for the state-of-the-art model\nC2P-CLIP, demonstrating consistent improvements in both Gaussian blur and JPEG\ncompression scenarios. The code will be publicly available upon acceptance.\n","authors":["Mamadou Keita","Wassim Hamidouche","Hessen Bougueffa Eutamene","Abdelmalik Taleb-Ahmed","Abdenour Hadid"],"pdf_url":"https://arxiv.org/pdf/2508.03967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03941v1","updated":"2025-08-05T22:15:43Z","published":"2025-08-05T22:15:43Z","title":"Measuring the stability and plasticity of recommender systems","summary":"  The typical offline protocol to evaluate recommendation algorithms is to\ncollect a dataset of user-item interactions and then use a part of this dataset\nto train a model, and the remaining data to measure how closely the model\nrecommendations match the observed user interactions. This protocol is\nstraightforward, useful and practical, but it only captures performance of a\nparticular model trained at some point in the past. We know, however, that\nonline systems evolve over time. In general, it is a good idea that models\nreflect such changes, so models are frequently retrained with recent data. But\nif this is the case, to what extent can we trust previous evaluations? How will\na model perform when a different pattern (re)emerges? In this paper we propose\na methodology to study how recommendation models behave when they are\nretrained. The idea is to profile algorithms according to their ability to, on\nthe one hand, retain past patterns -- stability -- and, on the other hand,\n(quickly) adapt to changes -- plasticity. We devise an offline evaluation\nprotocol that provides detail on the long-term behavior of models, and that is\nagnostic to datasets, algorithms and metrics. To illustrate the potential of\nthis framework, we present preliminary results of three different types of\nalgorithms on the GoodReads dataset that suggest different stability and\nplasticity profiles depending on the algorithmic technique, and a possible\ntrade-off between stability and plasticity.Although additional experiments will\nbe necessary to confirm these observations, they already illustrate the\nusefulness of the proposed framework to gain insights on the long term dynamics\nof recommendation models.\n","authors":["Maria João Lavoura","Robert Jungnickel","João Vinagre"],"pdf_url":"https://arxiv.org/pdf/2508.03941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.09516v5","updated":"2025-08-05T19:08:38Z","published":"2025-03-12T16:26:39Z","title":"Search-R1: Training LLMs to Reason and Leverage Search Engines with\n  Reinforcement Learning","summary":"  Efficiently acquiring external knowledge and up-to-date information is\nessential for effective reasoning and text generation in large language models\n(LLMs). Prompting advanced LLMs with reasoning capabilities to use search\nengines during inference is often suboptimal, as the LLM might not fully\npossess the capability on how to interact optimally with the search engine.\nThis paper introduces Search-R1, an extension of reinforcement learning (RL)\nfor reasoning frameworks where the LLM learns to autonomously generate\n(multiple) search queries during step-by-step reasoning with real-time\nretrieval. Search-R1 optimizes LLM reasoning trajectories with multi-turn\nsearch interactions, leveraging retrieved token masking for stable RL training\nand a simple outcome-based reward function. Experiments on seven\nquestion-answering datasets show that Search-R1 improves performance by 41%\n(Qwen2.5-7B) and 20% (Qwen2.5-3B) over various RAG baselines under the same\nsetting. This paper further provides empirical insights into RL optimization\nmethods, LLM choices, and response length dynamics in retrieval-augmented\nreasoning. The code and model checkpoints are available at\nhttps://github.com/PeterGriffinJin/Search-R1.\n","authors":["Bowen Jin","Hansi Zeng","Zhenrui Yue","Jinsung Yoon","Sercan Arik","Dong Wang","Hamed Zamani","Jiawei Han"],"pdf_url":"https://arxiv.org/pdf/2503.09516v5.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2410.15576v2","updated":"2025-08-05T18:18:07Z","published":"2024-10-21T01:54:46Z","title":"A Survey of Conversational Search","summary":"  As a cornerstone of modern information access, search engines have become\nindispensable in everyday life. With the rapid advancements in AI and natural\nlanguage processing (NLP) technologies, particularly large language models\n(LLMs), search engines have evolved to support more intuitive and intelligent\ninteractions between users and systems. Conversational search, an emerging\nparadigm for next-generation search engines, leverages natural language\ndialogue to facilitate complex and precise information retrieval, thus\nattracting significant attention. Unlike traditional keyword-based search\nengines, conversational search systems enhance user experience by supporting\nintricate queries, maintaining context over multi-turn interactions, and\nproviding robust information integration and processing capabilities. Key\ncomponents such as query reformulation, search clarification, conversational\nretrieval, and response generation work in unison to enable these sophisticated\ninteractions. In this survey, we explore the recent advancements and potential\nfuture directions in conversational search, examining the critical modules that\nconstitute a conversational search system. We highlight the integration of LLMs\nin enhancing these systems and discuss the challenges and opportunities that\nlie ahead in this dynamic field. Additionally, we provide insights into\nreal-world applications and robust evaluations of current conversational search\nsystems, aiming to guide future research and development in conversational\nsearch.\n","authors":["Fengran Mo","Kelong Mao","Ziliang Zhao","Hongjin Qian","Haonan Chen","Yiruo Cheng","Xiaoxi Li","Yutao Zhu","Zhicheng Dou","Jian-Yun Nie"],"pdf_url":"https://arxiv.org/pdf/2410.15576v2.pdf","comment":"38 pages, 8 figures, corresponding Github repository:\n  https://github.com/fengranMark/ConvSearch-Survey"},{"id":"http://arxiv.org/abs/2508.03792v1","updated":"2025-08-05T17:50:39Z","published":"2025-08-05T17:50:39Z","title":"Recommending With, Not For: Co-Designing Recommender Systems for Social\n  Good","summary":"  Recommender systems are usually designed by engineers, researchers,\ndesigners, and other members of development teams. These systems are then\nevaluated based on goals set by the aforementioned teams and other business\nunits of the platforms operating the recommender systems. This design approach\nemphasizes the designers' vision for how the system can best serve the\ninterests of users, providers, businesses, and other stakeholders. Although\ndesigners may be well-informed about user needs through user experience and\nmarket research, they are still the arbiters of the system's design and\nevaluation, with other stakeholders' interests less emphasized in user-centered\ndesign and evaluation. When extended to recommender systems for social good,\nthis approach results in systems that reflect the social objectives as\nenvisioned by the designers and evaluated as the designers understand them.\nInstead, social goals and operationalizations should be developed through\nparticipatory and democratic processes that are accountable to their\nstakeholders. We argue that recommender systems aimed at improving social good\nshould be designed *by* and *with*, not just *for*, the people who will\nexperience their benefits and harms. That is, they should be designed in\ncollaboration with their users, creators, and other stakeholders as full\nco-designers, not only as user study participants.\n","authors":["Michael D. Ekstrand","Afsaneh Razi","Aleksandra Sarcevic","Maria Soledad Pera","Robin Burke","Katherine Landau Wright"],"pdf_url":"https://arxiv.org/pdf/2508.03792v1.pdf","comment":"Accepted to ACM TORS Special Issue on Recommender Systems for Social\n  Good"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2508.03693v1","updated":"2025-08-05T17:59:56Z","published":"2025-08-05T17:59:56Z","title":"PAC Apprenticeship Learning with Bayesian Active Inverse Reinforcement\n  Learning","summary":"  As AI systems become increasingly autonomous, reliably aligning their\ndecision-making to human preferences is essential. Inverse reinforcement\nlearning (IRL) offers a promising approach to infer preferences from\ndemonstrations. These preferences can then be used to produce an apprentice\npolicy that performs well on the demonstrated task. However, in domains like\nautonomous driving or robotics, where errors can have serious consequences, we\nneed not just good average performance but reliable policies with formal\nguarantees -- yet obtaining sufficient human demonstrations for reliability\nguarantees can be costly. Active IRL addresses this challenge by strategically\nselecting the most informative scenarios for human demonstration. We introduce\nPAC-EIG, an information-theoretic acquisition function that directly targets\nprobably-approximately-correct (PAC) guarantees for the learned policy --\nproviding the first such theoretical guarantee for active IRL with noisy expert\ndemonstrations. Our method maximises information gain about the regret of the\napprentice policy, efficiently identifying states requiring further\ndemonstration. We also present Reward-EIG as an alternative when learning the\nreward itself is the primary objective. Focusing on finite state-action spaces,\nwe prove convergence bounds, illustrate failure modes of prior heuristic\nmethods, and demonstrate our method's advantages experimentally.\n","authors":["Ondrej Bajgar","Dewi S. W. Gould","Jonathon Liu","Alessandro Abate","Konstantinos Gatsis","Michael A. Osborne"],"pdf_url":"https://arxiv.org/pdf/2508.03693v1.pdf","comment":"Published at RLC 2025"},{"id":"http://arxiv.org/abs/2508.03688v1","updated":"2025-08-05T17:57:56Z","published":"2025-08-05T17:57:56Z","title":"Learning quadratic neural networks in high dimensions: SGD dynamics and\n  scaling laws","summary":"  We study the optimization and sample complexity of gradient-based training of\na two-layer neural network with quadratic activation function in the\nhigh-dimensional regime, where the data is generated as $y \\propto\n\\sum_{j=1}^{r}\\lambda_j \\sigma\\left(\\langle \\boldsymbol{\\theta_j},\n\\boldsymbol{x}\\rangle\\right), \\boldsymbol{x} \\sim N(0,\\boldsymbol{I}_d)$,\n$\\sigma$ is the 2nd Hermite polynomial, and $\\lbrace\\boldsymbol{\\theta}_j\n\\rbrace_{j=1}^{r} \\subset \\mathbb{R}^d$ are orthonormal signal directions. We\nconsider the extensive-width regime $r \\asymp d^\\beta$ for $\\beta \\in [0, 1)$,\nand assume a power-law decay on the (non-negative) second-layer coefficients\n$\\lambda_j\\asymp j^{-\\alpha}$ for $\\alpha \\geq 0$. We present a sharp analysis\nof the SGD dynamics in the feature learning regime, for both the population\nlimit and the finite-sample (online) discretization, and derive scaling laws\nfor the prediction risk that highlight the power-law dependencies on the\noptimization time, sample size, and model width. Our analysis combines a\nprecise characterization of the associated matrix Riccati differential equation\nwith novel matrix monotonicity arguments to establish convergence guarantees\nfor the infinite-dimensional effective dynamics.\n","authors":["Gérard Ben Arous","Murat A. Erdogdu","N. Mert Vural","Denny Wu"],"pdf_url":"https://arxiv.org/pdf/2508.03688v1.pdf","comment":"84 pages"},{"id":"http://arxiv.org/abs/2506.05305v2","updated":"2025-08-05T17:56:29Z","published":"2025-06-05T17:52:30Z","title":"ProRefine: Inference-Time Prompt Refinement with Textual Feedback","summary":"  Agentic workflows, where multiple AI agents collaborate to accomplish complex\ntasks like reasoning or planning, play a substantial role in many cutting-edge\ncommercial applications, and continue to fascinate researchers across nearly\nall fields for their potential to accomplish expensive, complex tasks that,\nuntil recently, only humans have been trusted to do. These workflows depend\ncritically on the prompts used to provide the roles models play in such\nworkflows. Poorly designed prompts that fail even slightly to guide individual\nagents can lead to sub-optimal performance that may snowball within a system of\nagents, limiting their reliability and scalability. To address this important\nproblem of inference-time prompt optimization, we introduce ProRefine, an\ninnovative inference-time optimization method that uses an agentic loop of LLMs\nto generate and apply textual feedback. ProRefine dynamically refines prompts\nfor multi-step reasoning tasks without additional training or ground truth\nlabels. Evaluated on five benchmark mathematical reasoning datasets, ProRefine\nsignificantly surpasses zero-shot Chain-of-Thought baselines by 3 to 37\npercentage points. This approach not only boosts accuracy but also allows\nsmaller models to approach the performance of their larger counterparts. This\nhighlights its potential for building more cost-effective and powerful hybrid\nAI systems, thereby democratizing access to high-performing AI.\n","authors":["Deepak Pandita","Tharindu Cyril Weerasooriya","Ankit Parag Shah","Isabelle Diana May-Xin Ng","Christopher M. Homan","Wei Wei"],"pdf_url":"https://arxiv.org/pdf/2506.05305v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03685v1","updated":"2025-08-05T17:55:20Z","published":"2025-08-05T17:55:20Z","title":"No LLM Solved Yu Tsumura's 554th Problem","summary":"  We show, contrary to the optimism about LLM's problem-solving abilities,\nfueled by the recent gold medals that were attained, that a problem exists --\nYu Tsumura's 554th problem -- that a) is within the scope of an IMO problem in\nterms of proof sophistication, b) is not a combinatorics problem which has\ncaused issues for LLMs, c) requires fewer proof techniques than typical hard\nIMO problems, d) has a publicly available solution (likely in the training data\nof LLMs), and e) that cannot be readily solved by any existing off-the-shelf\nLLM (commercial or open-source).\n","authors":["Simon Frieder","William Hart"],"pdf_url":"https://arxiv.org/pdf/2508.03685v1.pdf","comment":"67 pages"},{"id":"http://arxiv.org/abs/2508.03682v1","updated":"2025-08-05T17:51:33Z","published":"2025-08-05T17:51:33Z","title":"Self-Questioning Language Models","summary":"  Can large language models improve without external data -- by generating\ntheir own questions and answers? We hypothesize that a pre-trained language\nmodel can improve its reasoning skills given only a single prompt specifying\nthe topic (e.g., algebra word problems) and asking the model to generate its\nown questions. To do this, we propose Self-Questioning Language Models (SQLM):\nan asymmetric self-play framework where a proposer is given the topic and\ngenerates a question for a solver, who tries to answer it. Both the proposer\nand solver are trained via reinforcement learning. The proposer receives a\nreward if the problem is not too easy or too difficult, and the solver receives\na reward based on majority voting, a proxy for correctness in the absence of\nground-truth answers. For coding, the proposer can instead generate unit tests\nwhich are used for verification. We study this asymmetric self-play framework\non three benchmarks: three-digit multiplication, algebra problems from the\nOMEGA benchmark, and programming problems from Codeforces. By continually\ngenerating more interesting problems and attempting to solve them, language\nmodels can improve on downstream benchmarks without access to any curated\ntraining datasets.\n","authors":["Lili Chen","Mihir Prabhudesai","Katerina Fragkiadaki","Hao Liu","Deepak Pathak"],"pdf_url":"https://arxiv.org/pdf/2508.03682v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03681v1","updated":"2025-08-05T17:51:01Z","published":"2025-08-05T17:51:01Z","title":"What If, But Privately: Private Counterfactual Retrieval","summary":"  Transparency and explainability are two important aspects to be considered\nwhen employing black-box machine learning models in high-stake applications.\nProviding counterfactual explanations is one way of catering this requirement.\nHowever, this also poses a threat to the privacy of the institution that is\nproviding the explanation, as well as the user who is requesting it. In this\nwork, we are primarily concerned with the user's privacy who wants to retrieve\na counterfactual instance, without revealing their feature vector to the\ninstitution. Our framework retrieves the exact nearest neighbor counterfactual\nexplanation from a database of accepted points while achieving perfect,\ninformation-theoretic, privacy for the user. First, we introduce the problem of\nprivate counterfactual retrieval (PCR) and propose a baseline PCR scheme that\nkeeps the user's feature vector information-theoretically private from the\ninstitution. Building on this, we propose two other schemes that reduce the\namount of information leaked about the institution database to the user,\ncompared to the baseline scheme. Second, we relax the assumption of mutability\nof all features, and consider the setting of immutable PCR (I-PCR). Here, the\nuser retrieves the nearest counterfactual without altering a private subset of\ntheir features, which constitutes the immutable set, while keeping their\nfeature vector and immutable set private from the institution. For this, we\npropose two schemes that preserve the user's privacy information-theoretically,\nbut ensure varying degrees of database privacy. Third, we extend our PCR and\nI-PCR schemes to incorporate user's preference on transforming their\nattributes, so that a more actionable explanation can be received. Finally, we\npresent numerical results to support our theoretical findings, and compare the\ndatabase leakage of the proposed schemes.\n","authors":["Shreya Meel","Mohamed Nomeir","Pasan Dissanayake","Sanghamitra Dutta","Sennur Ulukus"],"pdf_url":"https://arxiv.org/pdf/2508.03681v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2410.13812,\n  arXiv:2411.10429"},{"id":"http://arxiv.org/abs/2508.03680v1","updated":"2025-08-05T17:50:13Z","published":"2025-08-05T17:50:13Z","title":"Agent Lightning: Train ANY AI Agents with Reinforcement Learning","summary":"  We present Agent Lightning, a flexible and extensible framework that enables\nReinforcement Learning (RL)-based training of Large Language Models (LLMs) for\nany AI agent. Unlike existing methods that tightly couple RL training with\nagent or rely on sequence concatenation with masking, Agent Lightning achieves\ncomplete decoupling between agent execution and training, allowing seamless\nintegration with existing agents developed via diverse ways (e.g., using\nframeworks like LangChain, OpenAI Agents SDK, AutoGen, and building from\nscratch) with almost ZERO code modifications. By formulating agent execution as\nMarkov decision process, we define an unified data interface and propose a\nhierarchical RL algorithm, LightningRL, which contains a credit assignment\nmodule, allowing us to decompose trajectories generated by ANY agents into\ntraining transition. This enables RL to handle complex interaction logic, such\nas multi-agent scenarios and dynamic workflows. For the system design, we\nintroduce a Training-Agent Disaggregation architecture, and brings agent\nobservability frameworks into agent runtime, providing a standardized agent\nfinetuning interface. Experiments across text-to-SQL, retrieval-augmented\ngeneration, and math tool-use tasks demonstrate stable, continuous\nimprovements, showcasing the framework's potential for real-world agent\ntraining and deployment.\n","authors":["Xufang Luo","Yuge Zhang","Zhiyuan He","Zilong Wang","Siyun Zhao","Dongsheng Li","Luna K. Qiu","Yuqing Yang"],"pdf_url":"https://arxiv.org/pdf/2508.03680v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03679v1","updated":"2025-08-05T17:50:03Z","published":"2025-08-05T17:50:03Z","title":"Streaming Generated Gaussian Process Experts for Online Learning and\n  Control","summary":"  Gaussian Processes (GPs), as a nonparametric learning method, offer flexible\nmodeling capabilities and calibrated uncertainty quantification for function\napproximations. Additionally, GPs support online learning by efficiently\nincorporating new data with polynomial-time computation, making them\nwell-suited for safety-critical dynamical systems that require rapid\nadaptation. However, the inference and online updates of exact GPs, when\nprocessing streaming data, incur cubic computation time and quadratic storage\nmemory complexity, limiting their scalability to large datasets in real-time\nsettings. In this paper, we propose a \\underline{s}treaming\n\\underline{k}ernel-induced progressivel\\underline{y} generated expert framework\nof \\underline{G}aussian \\underline{p}rocesses (SkyGP) that addresses both\ncomputational and memory constraints by maintaining a bounded set of experts,\nwhile inheriting the learning performance guarantees from exact Gaussian\nprocesses. Furthermore, two SkyGP variants are introduced, each tailored to a\nspecific objective, either maximizing prediction accuracy (SkyGP-Dense) or\nimproving computational efficiency (SkyGP-Fast). The effectiveness of SkyGP is\nvalidated through extensive benchmarks and real-time control experiments\ndemonstrating its superior performance compared to state-of-the-art approaches.\n","authors":["Zewen Yang","Dongfa Zhang","Xiaobing Dai","Fengyi Yu","Chi Zhang","Bingkun Huang","Hamid Sadeghian","Sami Haddadin"],"pdf_url":"https://arxiv.org/pdf/2508.03679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03678v1","updated":"2025-08-05T17:49:48Z","published":"2025-08-05T17:49:48Z","title":"More Than a Score: Probing the Impact of Prompt Specificity on LLM Code\n  Generation","summary":"  State-of-the-art Large Language Models (LLMs) achieve high pass@1 on general\nbenchmarks like HumanEval but underperform on specialized suites such as\nParEval. Is this due to LLMs missing domain knowledge or insufficient prompt\ndetail is given? To answer this, we introduce PartialOrderEval, which augments\nany code generation benchmark with a partial order of prompts from minimal to\nmaximally detailed. Applying it to HumanEval and both serial and OpenMP subsets\nof ParEval, we measure how pass@1 scales with prompt specificity. Our\nexperiments with Llama-3.x and Qwen2.5-Coder demonstrate varying degrees of\nprompt sensitivity across different tasks, and a qualitative analysis\nhighlights explicit I/O specifications, edge-case handling, and stepwise\nbreakdowns as the key drivers of prompt detail improvement.\n","authors":["Yangtian Zi","Harshitha Menon","Arjun Guha"],"pdf_url":"https://arxiv.org/pdf/2508.03678v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03676v1","updated":"2025-08-05T17:46:40Z","published":"2025-08-05T17:46:40Z","title":"MaLV-OS: Rethinking the Operating System Architecture for Machine\n  Learning in Virtualized Clouds","summary":"  A large body of research has employed Machine Learning (ML) models to develop\nlearned operating systems (OSes) and kernels. The latter dynamically adapts to\nthe job load and dynamically adjusts resources (CPU, IO, memory, network\nbandwidth) allocation to respond to the actual user demand. What this work has\nin common is that it utilizes ML to improve kernel decisions. To this day, and\nto the best of our knowledge, no work has taken the opposite direction, i.e.,\nusing OS to improve ML. While some work proposes applying system-level\noptimizations to ML algorithms, they do not tailor the OS to adapt to the ML\ncontext. To address this limitation, we take an orthogonal approach in this\npaper by leveraging the OS to enhance the performance of ML models and\nalgorithms. We explore the path towards an ML-specialized OS, MaLV-OS. MaLV-OS\nrethinks the OS architecture to make it specifically tailored to ML workloads,\nespecially in virtualized clouds, which are now widely used to run ML\napplications. MaLV-OS envisioned architecture includes (1) a micro-kernel,\nMicro-LAKE, which allows kernel space applications to use the GPU, and (2) an\nMLaaS (ML as a Service) subsystem that gathers ML models to help Micro-LAKE\nwith memory management and CPU scheduling. MaLV-OS architecture also offloads\nsystem-sensitive parts of the models to the OS, to lighten the model complexity\nand programming, and speed up its execution. Finally, MaLV-OS integrates an\nopen-source GPU virtualization software, merged directly into the hypervisor.\nFor more flexibility, MaLV-OS vision is to enable the virtual machine to\ndynamically select MLaaS policies that can improve the performance of the model\nthe user is running. Because MLaaS is designed as loadable kernel modules, the\nMaLV-OS architecture enables the dynamic addition of new capabilities to the\nMLaaS subsystem.\n","authors":["Stella Bitchebe","Oana Balmau"],"pdf_url":"https://arxiv.org/pdf/2508.03676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.19361v2","updated":"2025-08-05T17:37:40Z","published":"2025-05-25T23:17:47Z","title":"Consistency-based Abductive Reasoning over Perceptual Errors of Multiple\n  Pre-trained Models in Novel Environments","summary":"  The deployment of pre-trained perception models in novel environments often\nleads to performance degradation due to distributional shifts. Although recent\nartificial intelligence approaches for metacognition use logical rules to\ncharacterize and filter model errors, improving precision often comes at the\ncost of reduced recall. This paper addresses the hypothesis that leveraging\nmultiple pre-trained models can mitigate this recall reduction. We formulate\nthe challenge of identifying and managing conflicting predictions from various\nmodels as a consistency-based abduction problem, building on the idea of\nabductive learning (ABL) but applying it to test-time instead of training. The\ninput predictions and the learned error detection rules derived from each model\nare encoded in a logic program. We then seek an abductive explanation--a subset\nof model predictions--that maximizes prediction coverage while ensuring the\nrate of logical inconsistencies (derived from domain constraints) remains below\na specified threshold. We propose two algorithms for this knowledge\nrepresentation task: an exact method based on Integer Programming (IP) and an\nefficient Heuristic Search (HS). Through extensive experiments on a simulated\naerial imagery dataset featuring controlled, complex distributional shifts, we\ndemonstrate that our abduction-based framework outperforms individual models\nand standard ensemble baselines, achieving, for instance, average relative\nimprovements of approximately 13.6\\% in F1-score and 16.6\\% in accuracy across\n15 diverse test datasets when compared to the best individual model. Our\nresults validate the use of consistency-based abduction as an effective\nmechanism to robustly integrate knowledge from multiple imperfect models in\nchallenging, novel scenarios.\n","authors":["Mario Leiva","Noel Ngu","Joshua Shay Kricheli","Aditya Taparia","Ransalu Senanayake","Paulo Shakarian","Nathaniel Bastian","John Corcoran","Gerardo Simari"],"pdf_url":"https://arxiv.org/pdf/2505.19361v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03670v1","updated":"2025-08-05T17:34:19Z","published":"2025-08-05T17:34:19Z","title":"Personalized Recommendation of Dish and Restaurant Collections on iFood","summary":"  Food delivery platforms face the challenge of helping users navigate vast\ncatalogs of restaurants and dishes to find meals they truly enjoy. This paper\npresents RED, an automated recommendation system designed for iFood, Latin\nAmerica's largest on-demand food delivery platform, to personalize the\nselection of curated food collections displayed to millions of users. Our\napproach employs a LightGBM classifier that scores collections based on three\nfeature groups: collection characteristics, user-collection similarity, and\ncontextual information. To address the cold-start problem of recommending newly\ncreated collections, we develop content-based representations using item\nembeddings and implement monotonicity constraints to improve generalization. We\ntackle data scarcity by bootstrapping from category carousel interactions and\naddress visibility bias through unbiased sampling of impressions and purchases\nin production. The system demonstrates significant real-world impact through\nextensive A/B testing with 5-10% of iFood's user base. Online results of our\nA/B tests add up to 97% improvement in Card Conversion Rate and 1.4% increase\nin overall App Conversion Rate compared to popularity-based baselines. Notably,\nour offline accuracy metrics strongly correlate with online performance,\nenabling reliable impact prediction before deployment. To our knowledge, this\nis the first work to detail large-scale recommendation of curated food\ncollections in a dynamic commercial environment.\n","authors":["Fernando F. Granado","Davi A. Bezerra","Iuri Queiroz","Nathan Oliveira","Pedro Fernandes","Bruno Schock"],"pdf_url":"https://arxiv.org/pdf/2508.03670v1.pdf","comment":"Workshop on Two-sided Marketplace Optimization: Search, Discovery,\n  Matching, Pricing & Growth in conjunction with KDD Conference (KDD 2025) in\n  Toronto, Canada"},{"id":"http://arxiv.org/abs/2505.18247v3","updated":"2025-08-05T17:28:07Z","published":"2025-05-23T17:18:45Z","title":"MetaGen Blended RAG: Unlocking Zero-Shot Precision for Specialized\n  Domain Question-Answering","summary":"  Retrieval-Augmented Generation (RAG) struggles with domain-specific\nenterprise datasets, often isolated behind firewalls and rich in complex,\nspecialized terminology unseen by LLMs during pre-training. Semantic\nvariability across domains like medicine, networking, or law hampers RAG's\ncontext precision, while fine-tuning solutions are costly, slow, and lack\ngeneralization as new data emerges. Achieving zero-shot precision with\nretrievers without fine-tuning still remains a key challenge. We introduce\n'MetaGen Blended RAG', a novel enterprise search approach that enhances\nsemantic retrievers through a metadata generation pipeline and hybrid query\nindexes using dense and sparse vectors. By leveraging key concepts, topics, and\nacronyms, our method creates metadata-enriched semantic indexes and boosted\nhybrid queries, delivering robust, scalable performance without fine-tuning. On\nthe biomedical PubMedQA dataset, MetaGen Blended RAG achieves 82% retrieval\naccuracy and 77% RAG accuracy, surpassing all prior zero-shot RAG benchmarks\nand even rivaling fine-tuned models on that dataset, while also excelling on\ndatasets like SQuAD and NQ. This approach redefines enterprise search using a\nnew approach to building semantic retrievers with unmatched generalization\nacross specialized domains.\n","authors":["Kunal Sawarkar","Shivam R. Solanki","Abhilasha Mangal"],"pdf_url":"https://arxiv.org/pdf/2505.18247v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03665v1","updated":"2025-08-05T17:24:50Z","published":"2025-08-05T17:24:50Z","title":"A DbC Inspired Neurosymbolic Layer for Trustworthy Agent Design","summary":"  Generative models, particularly Large Language Models (LLMs), produce fluent\noutputs yet lack verifiable guarantees. We adapt Design by Contract (DbC) and\ntype-theoretic principles to introduce a contract layer that mediates every LLM\ncall. Contracts stipulate semantic and type requirements on inputs and outputs,\ncoupled with probabilistic remediation to steer generation toward compliance.\nThe layer exposes the dual view of LLMs as semantic parsers and probabilistic\nblack-box components. Contract satisfaction is probabilistic and semantic\nvalidation is operationally defined through programmer-specified conditions on\nwell-typed data structures. More broadly, this work postulates that any two\nagents satisfying the same contracts are \\emph{functionally equivalent} with\nrespect to those contracts.\n","authors":["Claudiu Leoveanu-Condrei"],"pdf_url":"https://arxiv.org/pdf/2508.03665v1.pdf","comment":"3 pages, 1 figure"},{"id":"http://arxiv.org/abs/2508.03663v1","updated":"2025-08-05T17:18:34Z","published":"2025-08-05T17:18:34Z","title":"Forest vs Tree: The $(N, K)$ Trade-off in Reproducible ML Evaluation","summary":"  Reproducibility is a cornerstone of scientific validation and of the\nauthority it confers on its results. Reproducibility in machine learning\nevaluations leads to greater trust, confidence, and value. However, the ground\ntruth responses used in machine learning often necessarily come from humans,\namong whom disagreement is prevalent, and surprisingly little research has\nstudied the impact of effectively ignoring disagreement in these responses, as\nis typically the case. One reason for the lack of research is that budgets for\ncollecting human-annotated evaluation data are limited, and obtaining more\nsamples from multiple annotators for each example greatly increases the\nper-item annotation costs. We investigate the trade-off between the number of\nitems ($N$) and the number of responses per item ($K$) needed for reliable\nmachine learning evaluation. We analyze a diverse collection of categorical\ndatasets for which multiple annotations per item exist, and simulated\ndistributions fit to these datasets, to determine the optimal $(N, K)$\nconfiguration, given a fixed budget ($N \\times K$), for collecting evaluation\ndata and reliably comparing the performance of machine learning models. Our\nfindings show, first, that accounting for human disagreement may come with $N\n\\times K$ at no more than 1000 (and often much lower) for every dataset tested\non at least one metric. Moreover, this minimal $N \\times K$ almost always\noccurred for $K > 10$. Furthermore, the nature of the tradeoff between $K$ and\n$N$ -- or if one even existed -- depends on the evaluation metric, with metrics\nthat are more sensitive to the full distribution of responses performing better\nat higher levels of $K$. Our methods can be used to help ML practitioners get\nmore effective test data by finding the optimal metrics and number of items and\nannotations per item to collect to get the most reliability for their budget.\n","authors":["Deepak Pandita","Flip Korn","Chris Welty","Christopher M. Homan"],"pdf_url":"https://arxiv.org/pdf/2508.03663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03660v1","updated":"2025-08-05T17:15:35Z","published":"2025-08-05T17:15:35Z","title":"Efficient Morphology-Aware Policy Transfer to New Embodiments","summary":"  Morphology-aware policy learning is a means of enhancing policy sample\nefficiency by aggregating data from multiple agents. These types of policies\nhave previously been shown to help generalize over dynamic, kinematic, and limb\nconfiguration variations between agent morphologies. Unfortunately, these\npolicies still have sub-optimal zero-shot performance compared to end-to-end\nfinetuning on morphologies at deployment. This limitation has ramifications in\npractical applications such as robotics because further data collection to\nperform end-to-end finetuning can be computationally expensive. In this work,\nwe investigate combining morphology-aware pretraining with parameter efficient\nfinetuning (PEFT) techniques to help reduce the learnable parameters necessary\nto specialize a morphology-aware policy to a target embodiment. We compare\ndirectly tuning sub-sets of model weights, input learnable adapters, and prefix\ntuning techniques for online finetuning. Our analysis reveals that PEFT\ntechniques in conjunction with policy pre-training generally help reduce the\nnumber of samples to necessary to improve a policy compared to training models\nend-to-end from scratch. We further find that tuning as few as less than 1% of\ntotal parameters will improve policy performance compared the zero-shot\nperformance of the base pretrained a policy.\n","authors":["Michael Przystupa","Hongyao Tang","Martin Jagersand","Santiago Miret","Mariano Phielipp","Matthew E. Taylor","Glen Berseth"],"pdf_url":"https://arxiv.org/pdf/2508.03660v1.pdf","comment":"19 pages, 10 Figures, Published at the 2025 Reinforcement Learning\n  Conference"},{"id":"http://arxiv.org/abs/2508.00222v2","updated":"2025-08-05T17:06:11Z","published":"2025-07-31T23:55:29Z","title":"RL-PLUS: Countering Capability Boundary Collapse of LLMs in\n  Reinforcement Learning with Hybrid-policy Optimization","summary":"  Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its essentially on-policy strategy coupled with LLM's\nimmense action space and sparse reward. Critically, RLVR can lead to the\ncapability boundary collapse, narrowing the LLM's problem-solving scope. To\naddress this problem, we propose RL-PLUS, a novel hybrid-policy optimization\napproach for LLMs that synergizes internal exploitation with external data to\nachieve stronger reasoning capabilities and surpass the boundaries of base\nmodels. RL-PLUS integrates two core components, i.e., Multiple Importance\nSampling to address for distributional mismatch from external data, and\nExploration-Based Advantage Function to guide the model towards high-value,\nunexplored reasoning paths. We provide both theoretical analysis and extensive\nexperiments to demonstrate the superiority and generalizability of our\napproach. Compared with existing RLVR methods, RL-PLUS achieves 1)\nstate-of-the-art performance on six math reasoning benchmarks; 2) superior\nperformance on six out-of-distribution reasoning tasks; 3) consistent and\nsignificant gains across diverse model families, with average relative\nimprovements up to 69.2\\%. Moreover, the analysis of Pass@k curves indicates\nthat RL-PLUS effectively resolves the capability boundary collapse problem.\n","authors":["Yihong Dong","Xue Jiang","Yongding Tao","Huanyu Liu","Kechi Zhang","Lili Mou","Rongyu Cao","Yingwei Ma","Jue Chen","Binhua Li","Zhi Jin","Fei Huang","Yongbin Li","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2508.00222v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03649v1","updated":"2025-08-05T16:57:24Z","published":"2025-08-05T16:57:24Z","title":"Cross-Model Semantics in Representation Learning","summary":"  The internal representations learned by deep networks are often sensitive to\narchitecture-specific choices, raising questions about the stability,\nalignment, and transferability of learned structure across models. In this\npaper, we investigate how structural constraints--such as linear shaping\noperators and corrective paths--affect the compatibility of internal\nrepresentations across different architectures. Building on the insights from\nprior studies on structured transformations and convergence, we develop a\nframework for measuring and analyzing representational alignment across\nnetworks with distinct but related architectural priors. Through a combination\nof theoretical insights, empirical probes, and controlled transfer experiments,\nwe demonstrate that structural regularities induce representational geometry\nthat is more stable under architectural variation. This suggests that certain\nforms of inductive bias not only support generalization within a model, but\nalso improve the interoperability of learned features across models. We\nconclude with a discussion on the implications of representational\ntransferability for model distillation, modular learning, and the principled\ndesign of robust learning systems.\n","authors":["Saleh Nikooroo","Thomas Engel"],"pdf_url":"https://arxiv.org/pdf/2508.03649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03645v1","updated":"2025-08-05T16:55:50Z","published":"2025-08-05T16:55:50Z","title":"DiWA: Diffusion Policy Adaptation with World Models","summary":"  Fine-tuning diffusion policies with reinforcement learning (RL) presents\nsignificant challenges. The long denoising sequence for each action prediction\nimpedes effective reward propagation. Moreover, standard RL methods require\nmillions of real-world interactions, posing a major bottleneck for practical\nfine-tuning. Although prior work frames the denoising process in diffusion\npolicies as a Markov Decision Process to enable RL-based updates, its strong\ndependence on environment interaction remains highly inefficient. To bridge\nthis gap, we introduce DiWA, a novel framework that leverages a world model for\nfine-tuning diffusion-based robotic skills entirely offline with reinforcement\nlearning. Unlike model-free approaches that require millions of environment\ninteractions to fine-tune a repertoire of robot skills, DiWA achieves effective\nadaptation using a world model trained once on a few hundred thousand offline\nplay interactions. This results in dramatically improved sample efficiency,\nmaking the approach significantly more practical and safer for real-world robot\nlearning. On the challenging CALVIN benchmark, DiWA improves performance across\neight tasks using only offline adaptation, while requiring orders of magnitude\nfewer physical interactions than model-free baselines. To our knowledge, this\nis the first demonstration of fine-tuning diffusion policies for real-world\nrobotic skills using an offline world model. We make the code publicly\navailable at https://diwa.cs.uni-freiburg.de.\n","authors":["Akshay L Chandra","Iman Nematollahi","Chenguang Huang","Tim Welschehold","Wolfram Burgard","Abhinav Valada"],"pdf_url":"https://arxiv.org/pdf/2508.03645v1.pdf","comment":"Accepted at the 2025 Conference on Robot Learning (CoRL)"},{"id":"http://arxiv.org/abs/2508.03636v1","updated":"2025-08-05T16:51:29Z","published":"2025-08-05T16:51:29Z","title":"Likelihood Matching for Diffusion Models","summary":"  We propose a Likelihood Matching approach for training diffusion models by\nfirst establishing an equivalence between the likelihood of the target data\ndistribution and a likelihood along the sample path of the reverse diffusion.\nTo efficiently compute the reverse sample likelihood, a quasi-likelihood is\nconsidered to approximate each reverse transition density by a Gaussian\ndistribution with matched conditional mean and covariance, respectively. The\nscore and Hessian functions for the diffusion generation are estimated by\nmaximizing the quasi-likelihood, ensuring a consistent matching of both the\nfirst two transitional moments between every two time points. A stochastic\nsampler is introduced to facilitate computation that leverages on both the\nestimated score and Hessian information. We establish consistency of the\nquasi-maximum likelihood estimation, and provide non-asymptotic convergence\nguarantees for the proposed sampler, quantifying the rates of the approximation\nerrors due to the score and Hessian estimation, dimensionality, and the number\nof diffusion steps. Empirical and simulation evaluations demonstrate the\neffectiveness of the proposed Likelihood Matching and validate the theoretical\nresults.\n","authors":["Lei Qian","Wu Su","Yanqi Huang","Song Xi Chen"],"pdf_url":"https://arxiv.org/pdf/2508.03636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03635v1","updated":"2025-08-05T16:50:50Z","published":"2025-08-05T16:50:50Z","title":"Cross-patient Seizure Onset Zone Classification by Patient-Dependent\n  Weight","summary":"  Identifying the seizure onset zone (SOZ) in patients with focal epilepsy is\nessential for surgical treatment and remains challenging due to its dependence\non visual judgment by clinical experts. The development of machine learning can\nassist in diagnosis and has made promising progress. However, unlike data in\nother fields, medical data is usually collected from individual patients, and\neach patient has different illnesses, physical conditions, and medical\nhistories, which leads to differences in the distribution of each patient's\ndata. This makes it difficult for a machine learning model to achieve\nconsistently reliable performance in every new patient dataset, which we refer\nto as the \"cross-patient problem.\" In this paper, we propose a method to\nfine-tune a pretrained model using patient-specific weights for every new test\npatient to improve diagnostic performance. First, the supervised learning\nmethod is used to train a machine learning model. Next, using the intermediate\nfeatures of the trained model obtained through the test patient data, the\nsimilarity between the test patient data and each training patient's data is\ndefined to determine the weight of each training patient to be used in the\nfollowing fine-tuning. Finally, we fine-tune all parameters in the pretrained\nmodel with training data and patient weights. In the experiment, the\nleave-one-patient-out method is used to evaluate the proposed method, and the\nresults show improved classification accuracy for every test patient, with an\naverage improvement of more than 10%.\n","authors":["Xuyang Zhao","Hidenori Sugano","Toshihisa Tanaka"],"pdf_url":"https://arxiv.org/pdf/2508.03635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03633v1","updated":"2025-08-05T16:50:33Z","published":"2025-08-05T16:50:33Z","title":"Pair Correlation Factor and the Sample Complexity of Gaussian Mixtures","summary":"  We study the problem of learning Gaussian Mixture Models (GMMs) and ask:\nwhich structural properties govern their sample complexity? Prior work has\nlargely tied this complexity to the minimum pairwise separation between\ncomponents, but we demonstrate this view is incomplete.\n  We introduce the \\emph{Pair Correlation Factor} (PCF), a geometric quantity\ncapturing the clustering of component means. Unlike the minimum gap, the PCF\nmore accurately dictates the difficulty of parameter recovery.\n  In the uniform spherical case, we give an algorithm with improved sample\ncomplexity bounds, showing when more than the usual $\\epsilon^{-2}$ samples are\nnecessary.\n","authors":["Farzad Aryan"],"pdf_url":"https://arxiv.org/pdf/2508.03633v1.pdf","comment":"21 pages, no figures"},{"id":"http://arxiv.org/abs/2508.03628v1","updated":"2025-08-05T16:47:17Z","published":"2025-08-05T16:47:17Z","title":"LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for\n  Advertiser Keyphrase Recommendations at eBay","summary":"  Sellers at eBay are recommended keyphrases to bid on to enhance the\nperformance of their advertising campaigns. The relevance of these keyphrases\nis crucial in avoiding the overcrowding of search systems with irrelevant items\nand maintaining a positive seller perception. It is essential that keyphrase\nrecommendations align with both seller and Search judgments regarding auctions.\nDue to the difficulty in procuring negative human judgment at scale, employing\nLLM-as-a-judge to mimic seller judgment has been established as the norm in\nseveral studies. This study introduces a novel two-step LLM distillation\nprocess from a LLM-judge used to debias our Embedding Based Retrieval (EBR)\nmodel from the various biases that exist in click-data. We distill from an LLM\nteacher via a cross-encoder assistant into a bi-encoder student using a\nmulti-task training approach, ultimately employing the student bi-encoder to\nretrieve relevant advertiser keyphrases. We show that integrating a knowledge\ndistillation process from LLMs in a multi-task training setup enhances\nbi-encoder performance in retrieving relevant advertiser keyphrases at eBay.\n","authors":["Soumik Dey","Benjamin Braun","Naveen Ravipati","Hansi Wu","Binbin Li"],"pdf_url":"https://arxiv.org/pdf/2508.03628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.02480v2","updated":"2025-08-05T16:46:20Z","published":"2025-04-03T10:57:26Z","title":"Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak\n  Single-Photon Lidar Imaging","summary":"  Single-photon Lidar imaging offers a significant advantage in 3D imaging due\nto its high resolution and long-range capabilities, however it is challenging\nto apply in noisy environments with multiple targets per pixel. To tackle these\nchallenges, several methods have been proposed. Statistical methods demonstrate\ninterpretability on the inferred parameters, but they are often limited in\ntheir ability to handle complex scenes. Deep learning-based methods have shown\nsuperior performance in terms of accuracy and robustness, but they lack\ninterpretability or they are limited to a single-peak per pixel. In this paper,\nwe propose a deep unrolling algorithm for dual-peak single-photon Lidar\nimaging. We introduce a hierarchical Bayesian model for multiple targets and\npropose a neural network that unrolls the underlying statistical method. To\nsupport multiple targets, we adopt a dual depth maps representation and exploit\ngeometric deep learning to extract features from the point cloud. The proposed\nmethod takes advantages of statistical methods and learning-based methods in\nterms of accuracy and quantifying uncertainty. The experimental results on\nsynthetic and real data demonstrate the competitive performance when compared\nto existing methods, while also providing uncertainty information.\n","authors":["Kyungmin Choi","JaKeoung Koo","Stephen McLaughlin","Abderrahim Halimi"],"pdf_url":"https://arxiv.org/pdf/2504.02480v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03614v1","updated":"2025-08-05T16:28:43Z","published":"2025-08-05T16:28:43Z","title":"Minimal Convolutional RNNs Accelerate Spatiotemporal Learning","summary":"  We introduce MinConvLSTM and MinConvGRU, two novel spatiotemporal models that\ncombine the spatial inductive biases of convolutional recurrent networks with\nthe training efficiency of minimal, parallelizable RNNs. Our approach extends\nthe log-domain prefix-sum formulation of MinLSTM and MinGRU to convolutional\narchitectures, enabling fully parallel training while retaining localized\nspatial modeling. This eliminates the need for sequential hidden state updates\nduring teacher forcing - a major bottleneck in conventional ConvRNN models. In\naddition, we incorporate an exponential gating mechanism inspired by the xLSTM\narchitecture into the MinConvLSTM, which further simplifies the log-domain\ncomputation. Our models are structurally minimal and computationally efficient,\nwith reduced parameter count and improved scalability. We evaluate our models\non two spatiotemporal forecasting tasks: Navier-Stokes dynamics and real-world\ngeopotential data. In terms of training speed, our architectures significantly\noutperform standard ConvLSTMs and ConvGRUs. Moreover, our models also achieve\nlower prediction errors in both domains, even in closed-loop autoregressive\nmode. These findings demonstrate that minimal recurrent structures, when\ncombined with convolutional input aggregation, offer a compelling and efficient\nalternative for spatiotemporal sequence modeling, bridging the gap between\nrecurrent simplicity and spatial complexity.\n","authors":["Coşku Can Horuz","Sebastian Otte","Martin V. Butz","Matthias Karlbauer"],"pdf_url":"https://arxiv.org/pdf/2508.03614v1.pdf","comment":"Accepted at ICANN 2025"},{"id":"http://arxiv.org/abs/2508.03613v1","updated":"2025-08-05T16:28:22Z","published":"2025-08-05T16:28:22Z","title":"Goedel-Prover-V2: Scaling Formal Theorem Proving with Scaffolded Data\n  Synthesis and Self-Correction","summary":"  We introduce Goedel-Prover-V2, a series of open-source language models that\nset a new state-of-the-art in automated theorem proving. Built on the standard\nexpert iteration and reinforcement learning pipeline, our approach incorporates\nthree key innovations: (1) Scaffolded data synthesis: We generate synthetic\ntasks of increasing difficulty to train the model to master increasingly\ncomplex theorems; (2) Verifier-guided self-correction: We enable the model to\niteratively revise its proofs by leveraging feedback from the Lean compiler;\n(3) Model averaging: We merge model checkpoints to mitigate the decrease in\nmodel output diversity in later stages of training. Our small model,\nGoedel-Prover-V2-8B, reaches 84.6% pass@32 on MiniF2F and outperforms\nDeepSeek-Prover-V2-671B under the same metric, despite being 80X smaller. Our\nflagship model, Goedel-Prover-V2-32B, achieves 88.1% on MiniF2F at pass@32 in\nstandard mode and 90.4% in self-correction mode, outperforming prior SOTA by a\nlarge margin. Additionally, our flagship model solves 86 problems on\nPutnamBench at pass@184, securing the first place among open-source models on\nthe leaderboard, surpassing DeepSeek-Prover-V2-671B's record of solving 47\nproblems by pass@1024 with a significantly smaller model size and compute\nbudget. At the time of its release (July-August 2025), Goedel-Prover-V2\nachieves the strongest overall performance among all open-source theorem\nprovers. It also ranks among the top-performing models--including closed-source\nsystems with publicly reported performance--under a constrained test-time\ncompute budget. Our models, code, and data are released at\nhttps://github.com/Goedel-LM/Goedel-Prover-V2.\n","authors":["Yong Lin","Shange Tang","Bohan Lyu","Ziran Yang","Jui-Hui Chung","Haoyu Zhao","Lai Jiang","Yihan Geng","Jiawei Ge","Jingruo Sun","Jiayun Wu","Jiri Gesi","Ximing Lu","David Acuna","Kaiyu Yang","Hongzhou Lin","Yejin Choi","Danqi Chen","Sanjeev Arora","Chi Jin"],"pdf_url":"https://arxiv.org/pdf/2508.03613v1.pdf","comment":"24 pages, 10 figures, 4 tables"},{"id":"http://arxiv.org/abs/2502.08808v2","updated":"2025-08-05T16:27:52Z","published":"2025-02-12T21:44:06Z","title":"A First-order Generative Bilevel Optimization Framework for Diffusion\n  Models","summary":"  Diffusion models, which iteratively denoise data samples to synthesize\nhigh-quality outputs, have achieved empirical success across domains. However,\noptimizing these models for downstream tasks often involves nested bilevel\nstructures, such as tuning hyperparameters for fine-tuning tasks or noise\nschedules in training dynamics, where traditional bilevel methods fail due to\nthe infinite-dimensional probability space and prohibitive sampling costs. We\nformalize this challenge as a generative bilevel optimization problem and\naddress two key scenarios: (1) fine-tuning pre-trained models via an\ninference-only lower-level solver paired with a sample-efficient gradient\nestimator for the upper level, and (2) training diffusion model from scratch\nwith noise schedule optimization by reparameterizing the lower-level problem\nand designing a computationally tractable gradient estimator. Our first-order\nbilevel framework overcomes the incompatibility of conventional bilevel methods\nwith diffusion processes, offering theoretical grounding and computational\npracticality. Experiments demonstrate that our method outperforms existing\nfine-tuning and hyperparameter search baselines.\n","authors":["Quan Xiao","Hui Yuan","A F M Saif","Gaowen Liu","Ramana Kompella","Mengdi Wang","Tianyi Chen"],"pdf_url":"https://arxiv.org/pdf/2502.08808v2.pdf","comment":"Cameral-ready version: added experiments using the HPSv2 reward,\n  improved notation consistency for the diffusion model, and added related\n  works"},{"id":"http://arxiv.org/abs/2503.07120v2","updated":"2025-08-05T16:17:01Z","published":"2025-03-10T09:49:18Z","title":"FEB-Cache: Frequency-Guided Exposure Bias Reduction for Enhancing\n  Diffusion Transformer Caching","summary":"  Diffusion Transformer (DiT) has exhibited impressive generation capabilities\nbut faces great challenges due to its high computational complexity. To address\nthis issue, various methods, notably feature caching, have been introduced.\nHowever, these approaches focus on aligning non-cache diffusion without\nanalyzing why caching damage the generation processes. In this paper, we first\nconfirm that the cache greatly amplifies the exposure bias, resulting in a\ndecline in the generation quality. However, directly applying noise scaling is\nchallenging for this issue due to the non-smoothness of exposure bias. We found\nthat this phenomenon stems from the mismatch between its frequency response\ncharacteristics and the simple cache of Attention and MLP. Since these two\ncomponents exhibit unique preferences for frequency signals, which provides us\nwith a caching strategy to separate Attention and MLP to achieve an enhanced\nfit of exposure bias and reduce it. Based on this, we introduced FEB-Cache, a\njoint caching strategy that aligns with the non-exposed bias diffusion process\n(which gives us a higher performance cap) of caching Attention and MLP based on\nthe frequency-guided cache table. Our approach combines a comprehensive\nunderstanding of the caching mechanism and offers a new perspective on\nleveraging caching to accelerate the diffusion process. Empirical results\nindicate that FEB-Cache optimizes model performance while concurrently\nfacilitating acceleration.\n","authors":["Zhen Zou","Feng Zhao"],"pdf_url":"https://arxiv.org/pdf/2503.07120v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03598v1","updated":"2025-08-05T16:06:26Z","published":"2025-08-05T16:06:26Z","title":"DyCAF-Net: Dynamic Class-Aware Fusion Network","summary":"  Recent advancements in object detection rely on modular architectures with\nmulti-scale fusion and attention mechanisms. However, static fusion heuristics\nand class-agnostic attention limit performance in dynamic scenes with\nocclusions, clutter, and class imbalance. We introduce Dynamic Class-Aware\nFusion Network (DyCAF-Net) that addresses these challenges through three\ninnovations: (1) an input-conditioned equilibrium-based neck that iteratively\nrefines multi-scale features via implicit fixed-point modeling, (2) a dual\ndynamic attention mechanism that adaptively recalibrates channel and spatial\nresponses using input- and class-dependent cues, and (3) class-aware feature\nadaptation that modulates features to prioritize discriminative regions for\nrare classes. Through comprehensive ablation studies with YOLOv8 and related\narchitectures, alongside benchmarking against nine state-of-the-art baselines,\nDyCAF-Net achieves significant improvements in precision, mAP@50, and mAP@50-95\nacross 13 diverse benchmarks, including occlusion-heavy and long-tailed\ndatasets. The framework maintains computational efficiency ($\\sim$11.1M\nparameters) and competitive inference speeds, while its adaptability to scale\nvariance, semantic overlaps, and class imbalance positions it as a robust\nsolution for real-world detection tasks in medical imaging, surveillance, and\nautonomous systems.\n","authors":["Md Abrar Jahin","Shahriar Soudeep","M. F. Mridha","Nafiz Fahad","Md. Jakir Hossen"],"pdf_url":"https://arxiv.org/pdf/2508.03598v1.pdf","comment":"Accepted to IEEE DSAA 2025 (10 pages, 5 figures)"},{"id":"http://arxiv.org/abs/2507.10643v3","updated":"2025-08-05T16:03:04Z","published":"2025-07-14T16:38:30Z","title":"TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc\n  Attributions for Opaque Models","summary":"  Existing post-hoc model-agnostic methods generate external explanations for\nopaque models, primarily by locally attributing the model output to its input\nfeatures. However, they often lack an explicit and systematic framework for\nquantifying the contribution of individual features. Building on the Taylor\nexpansion framework introduced by Deng et al. (2024) to unify existing local\nattribution methods, we propose a rigorous set of postulates -- \"precision\",\n\"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific\nattribution. Guided by these postulates, we introduce TaylorPODA (Taylor\nexpansion-derived imPortance-Order aDapted Attribution), which incorporates an\nadditional \"adaptation\" property. This property enables alignment with\ntask-specific goals, especially in post-hoc settings lacking ground-truth\nexplanations. Empirical evaluations demonstrate that TaylorPODA achieves\ncompetitive results against baseline methods, providing principled and\nvisualization-friendly explanations. This work enhances the trustworthy\ndeployment of opaque models by offering explanations with stronger theoretical\ngrounding.\n","authors":["Yuchi Tang","Iñaki Esnaola","George Panoutsos"],"pdf_url":"https://arxiv.org/pdf/2507.10643v3.pdf","comment":"18 pages, 4 figures. Submitted to AAAI 2026. Re-upload with amended\n  manuscript"},{"id":"http://arxiv.org/abs/2508.03593v1","updated":"2025-08-05T15:58:31Z","published":"2025-08-05T15:58:31Z","title":"On the (In)Significance of Feature Selection in High-Dimensional\n  Datasets","summary":"  Extensive research has been done on feature selection (FS) algorithms for\nhigh-dimensional datasets aiming to improve model performance, reduce\ncomputational cost and identify features of interest. We test the null\nhypothesis of using randomly selected features to compare against features\nselected by FS algorithms to validate the performance of the latter. Our\nresults show that FS on high-dimensional datasets (in particular gene\nexpression) in classification tasks is not useful. We find that (1) models\ntrained on small subsets (0.02%-1% of all features) of randomly selected\nfeatures almost always perform comparably to those trained on all features, and\n(2) a \"typical\"- sized random subset provides comparable or superior\nperformance to that of top-k features selected in various published studies.\nThus, our work challenges many feature selection results on high dimensional\ndatasets, particularly in computational genomics. It raises serious concerns\nabout studies that propose drug design or targeted interventions based on\ncomputationally selected genes, without further validation in a wet lab.\n","authors":["Bhavesh Neekhra","Debayan Gupta","Partha Pratim Chakravarti"],"pdf_url":"https://arxiv.org/pdf/2508.03593v1.pdf","comment":"submitted to Nature Computational Science (double-blind review in\n  progress). supplementary material included in pdf; anonymized code at:\n  https://anonymous.4open.science/r/Feature_Selection_HD-D853/README.md"},{"id":"http://arxiv.org/abs/2508.03590v1","updated":"2025-08-05T15:57:22Z","published":"2025-08-05T15:57:22Z","title":"SolarSeer: Ultrafast and accurate 24-hour solar irradiance forecasts\n  outperforming numerical weather prediction across the USA","summary":"  Accurate 24-hour solar irradiance forecasting is essential for the safe and\neconomic operation of solar photovoltaic systems. Traditional numerical weather\nprediction (NWP) models represent the state-of-the-art in forecasting\nperformance but rely on computationally costly data assimilation and solving\ncomplicated partial differential equations (PDEs) that simulate atmospheric\nphysics. Here, we introduce SolarSeer, an end-to-end large artificial\nintelligence (AI) model for solar irradiance forecasting across the Contiguous\nUnited States (CONUS). SolarSeer is designed to directly map the historical\nsatellite observations to future forecasts, eliminating the computational\noverhead of data assimilation and PDEs solving. This efficiency allows\nSolarSeer to operate over 1,500 times faster than traditional NWP, generating\n24-hour cloud cover and solar irradiance forecasts for the CONUS at 5-kilometer\nresolution in under 3 seconds. Compared with the state-of-the-art NWP in the\nCONUS, i.e., High-Resolution Rapid Refresh (HRRR), SolarSeer significantly\nreduces the root mean squared error of solar irradiance forecasting by 27.28%\nin reanalysis data and 15.35% across 1,800 stations. SolarSeer also effectively\ncaptures solar irradiance fluctuations and significantly enhances the\nfirst-order irradiance difference forecasting accuracy. SolarSeer's ultrafast,\naccurate 24-hour solar irradiance forecasts provide strong support for the\ntransition to sustainable, net-zero energy systems.\n","authors":["Mingliang Bai","Zuliang Fang","Shengyu Tao","Siqi Xiang","Jiang Bian","Yanfei Xiang","Pengcheng Zhao","Weixin Jin","Jonathan A. Weyn","Haiyu Dong","Bin Zhang","Hongyu Sun","Kit Thambiratnam","Qi Zhang","Hongbin Sun","Xuan Zhang","Qiuwei Wu"],"pdf_url":"https://arxiv.org/pdf/2508.03590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03589v1","updated":"2025-08-05T15:56:36Z","published":"2025-08-05T15:56:36Z","title":"VITA: Variational Pretraining of Transformers for Climate-Robust Crop\n  Yield Forecasting","summary":"  Accurate crop yield forecasting is essential for global food security.\nHowever, current AI models systematically underperform when yields deviate from\nhistorical trends. This issue arises from key data challenges, including a\nmajor asymmetry between rich pretraining weather datasets and the limited data\navailable for fine-tuning. We introduce VITA (Variational Inference Transformer\nfor Asymmetric data), a variational pretraining framework that addresses this\nasymmetry. Instead of relying on input reconstruction, VITA uses detailed\nweather variables as proxy targets during pretraining and learns to predict\nrich atmospheric states through self-supervised feature masking. This allows\nthe model to be fine-tuned using only basic weather statistics during\ndeployment. Applied to 763 counties in the U.S. Corn Belt, VITA achieves\nstate-of-the-art performance in predicting corn and soybean yields across all\nevaluation scenarios. While it consistently delivers superior performance under\nnormal conditions, its advantages are particularly pronounced during extreme\nweather years, with statistically significant improvements (paired t-test, $p\n\\approx 0.01$). Importantly, VITA outperforms prior frameworks like GNN-RNN\nusing less data, making it more practical for real-world use--particularly in\ndata-scarce regions. This work highlights how domain-aware AI design can\novercome data limitations and support resilient agricultural forecasting in a\nchanging climate.\n","authors":["Adib Hasan","Mardavij Roozbehani","Munther Dahleh"],"pdf_url":"https://arxiv.org/pdf/2508.03589v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.06219v2","updated":"2025-08-05T15:55:24Z","published":"2025-04-08T17:08:06Z","title":"Can Performant LLMs Be Ethical? Quantifying the Impact of Web Crawling\n  Opt-Outs","summary":"  The increasing adoption of web crawling opt-outs by copyright holders of\nonline content raises critical questions about the impact of data compliance on\nlarge language model (LLM) performance. However, little is known about how\nthese restrictions (and the resultant filtering of pretraining datasets) affect\nthe capabilities of models trained using these corpora. In this work, we\nconceptualize this effect as the $\\textit{data compliance gap}$ (DCG), which\nquantifies the performance difference between models trained on datasets that\ncomply with web crawling opt-outs, and those that do not. We measure the data\ncompliance gap in two settings: pretraining models from scratch and continual\npretraining from existing compliant models (simulating a setting where\ncopyrighted data could be integrated later in pretraining). Our experiments\nwith 1.5B models show that, as of January 2025, compliance with web data\nopt-outs does not degrade general knowledge acquisition (close to 0\\% DCG).\nHowever, in specialized domains such as biomedical research, excluding major\npublishers leads to performance declines. These findings suggest that while\ngeneral-purpose LLMs can be trained to perform equally well using fully open\ndata, performance in specialized domains may benefit from access to\nhigh-quality copyrighted sources later in training. Our study provides\nempirical insights into the long-debated trade-off between data compliance and\ndownstream model performance, informing future discussions on AI training\npractices and policy decisions. Our website is available at\nhttps://data-compliance.github.io/.\n","authors":["Dongyang Fan","Vinko Sabolčec","Matin Ansaripour","Ayush Kumar Tarun","Martin Jaggi","Antoine Bosselut","Imanol Schlag"],"pdf_url":"https://arxiv.org/pdf/2504.06219v2.pdf","comment":"COLM 2025 Camera Ready version"},{"id":"http://arxiv.org/abs/2508.03587v1","updated":"2025-08-05T15:54:21Z","published":"2025-08-05T15:54:21Z","title":"Zero-Variance Gradients for Variational Autoencoders","summary":"  Training deep generative models like Variational Autoencoders (VAEs) is often\nhindered by the need to backpropagate gradients through the stochastic sampling\nof their latent variables, a process that inherently introduces estimation\nvariance, which can slow convergence and degrade performance. In this paper, we\npropose a new perspective that sidesteps this problem, which we call Silent\nGradients. Instead of improving stochastic estimators, we leverage specific\ndecoder architectures to analytically compute the expected ELBO, yielding a\ngradient with zero variance. We first provide a theoretical foundation for this\nmethod and demonstrate its superiority over existing estimators in a controlled\nsetting with a linear decoder. To generalize our approach for practical use\nwith complex, expressive decoders, we introduce a novel training dynamic that\nuses the exact, zero-variance gradient to guide the early stages of encoder\ntraining before annealing to a standard stochastic estimator. Our experiments\nshow that this technique consistently improves the performance of established\nbaselines, including reparameterization, Gumbel-Softmax, and REINFORCE, across\nmultiple datasets. This work opens a new direction for training generative\nmodels by combining the stability of analytical computation with the\nexpressiveness of deep, nonlinear architecture.\n","authors":["Zilei Shao","Anji Liu","Guy Van den Broeck"],"pdf_url":"https://arxiv.org/pdf/2508.03587v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03586v1","updated":"2025-08-05T15:53:05Z","published":"2025-08-05T15:53:05Z","title":"DeepFaith: A Domain-Free and Model-Agnostic Unified Framework for Highly\n  Faithful Explanations","summary":"  Explainable AI (XAI) builds trust in complex systems through model\nattribution methods that reveal the decision rationale. However, due to the\nabsence of a unified optimal explanation, existing XAI methods lack a ground\ntruth for objective evaluation and optimization. To address this issue, we\npropose Deep architecture-based Faith explainer (DeepFaith), a domain-free and\nmodel-agnostic unified explanation framework under the lens of faithfulness. By\nestablishing a unified formulation for multiple widely used and well-validated\nfaithfulness metrics, we derive an optimal explanation objective whose solution\nsimultaneously achieves optimal faithfulness across these metrics, thereby\nproviding a ground truth from a theoretical perspective. We design an explainer\nlearning framework that leverages multiple existing explanation methods,\napplies deduplicating and filtering to construct high-quality supervised\nexplanation signals, and optimizes both pattern consistency loss and local\ncorrelation to train a faithful explainer. Once trained, DeepFaith can generate\nhighly faithful explanations through a single forward pass without accessing\nthe model being explained. On 12 diverse explanation tasks spanning 6 models\nand 6 datasets, DeepFaith achieves the highest overall faithfulness across 10\nmetrics compared to all baseline methods, highlighting its effectiveness and\ncross-domain generalizability.\n","authors":["Yuhan Guo","Lizhong Ding","Shihan Jia","Yanyu Ren","Pengqi Li","Jiarun Fu","Changsheng Li","Ye yuan","Guoren Wang"],"pdf_url":"https://arxiv.org/pdf/2508.03586v1.pdf","comment":"22 pages"},{"id":"http://arxiv.org/abs/2508.03579v1","updated":"2025-08-05T15:47:16Z","published":"2025-08-05T15:47:16Z","title":"Heterogeneity-Oblivious Robust Federated Learning","summary":"  Federated Learning (FL) remains highly vulnerable to poisoning attacks,\nespecially under real-world hyper-heterogeneity, where clients differ\nsignificantly in data distributions, communication capabilities, and model\narchitectures. Such heterogeneity not only undermines the effectiveness of\naggregation strategies but also makes attacks more difficult to detect.\nFurthermore, high-dimensional models expand the attack surface. To address\nthese challenges, we propose Horus, a heterogeneity-oblivious robust FL\nframework centered on low-rank adaptations (LoRAs). Rather than aggregating\nfull model parameters, Horus inserts LoRAs into empirically stable layers and\naggregates only LoRAs to reduce the attack surface.We uncover a key empirical\nobservation that the input projection (LoRA-A) is markedly more stable than the\noutput projection (LoRA-B) under heterogeneity and poisoning. Leveraging this,\nwe design a Heterogeneity-Oblivious Poisoning Score using the features from\nLoRA-A to filter poisoned clients. For the remaining benign clients, we propose\nprojection-aware aggregation mechanism to preserve collaborative signals while\nsuppressing drifts, which reweights client updates by consistency with the\nglobal directions. Extensive experiments across diverse datasets, model\narchitectures, and attacks demonstrate that Horus consistently outperforms\nstate-of-the-art baselines in both robustness and accuracy.\n","authors":["Weiyao Zhang","Jinyang Li","Qi Song","Miao Wang","Chungang Lin","Haitong Luo","Xuying Meng","Yujun Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.03579v1.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2507.02409v3","updated":"2025-08-05T15:46:50Z","published":"2025-07-03T08:04:49Z","title":"S2FGL: Spatial Spectral Federated Graph Learning","summary":"  Federated Graph Learning (FGL) combines the privacy-preserving capabilities\nof federated learning (FL) with the strong graph modeling capability of Graph\nNeural Networks (GNNs). Current research addresses subgraph-FL from the\nstructural perspective, neglecting the propagation of graph signals on spatial\nand spectral domains of the structure. From a spatial perspective, subgraph-FL\nintroduces edge disconnections between clients, leading to disruptions in label\nsignals and a degradation in the semantic knowledge of the global GNN. From a\nspectral perspective, spectral heterogeneity causes inconsistencies in signal\nfrequencies across subgraphs, which makes local GNNs overfit the local signal\npropagation schemes. As a result, spectral client drift occurs, undermining\nglobal generalizability. To tackle the challenges, we propose a global\nknowledge repository to mitigate the challenge of poor semantic knowledge\ncaused by label signal disruption. Furthermore, we design a frequency alignment\nto address spectral client drift. The combination of Spatial and Spectral\nstrategies forms our framework S2FGL. Extensive experiments on multiple\ndatasets demonstrate the superiority of S2FGL. The code is available at\nhttps://github.com/Wonder7racer/S2FGL.git.\n","authors":["Zihan Tan","Suyuan Huang","Guancheng Wan","Wenke Huang","He Li","Mang Ye"],"pdf_url":"https://arxiv.org/pdf/2507.02409v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.17748v2","updated":"2025-08-05T15:46:33Z","published":"2025-07-23T17:59:02Z","title":"Large Learning Rates Simultaneously Achieve Robustness to Spurious\n  Correlations and Compressibility","summary":"  Robustness and resource-efficiency are two highly desirable properties for\nmodern machine learning models. However, achieving them jointly remains a\nchallenge. In this paper, we identify high learning rates as a facilitator for\nsimultaneously achieving robustness to spurious correlations and network\ncompressibility. We demonstrate that large learning rates also produce\ndesirable representation properties such as invariant feature utilization,\nclass separation, and activation sparsity. Our findings indicate that large\nlearning rates compare favorably to other hyperparameters and regularization\nmethods, in consistently satisfying these properties in tandem. In addition to\ndemonstrating the positive effect of large learning rates across diverse\nspurious correlation datasets, models, and optimizers, we also present strong\nevidence that the previously documented success of large learning rates in\nstandard classification tasks is related to addressing hidden/rare spurious\ncorrelations in the training dataset. Our investigation of the mechanisms\nunderlying this phenomenon reveals the importance of confident mispredictions\nof bias-conflicting samples under large learning rates.\n","authors":["Melih Barsbey","Lucas Prieto","Stefanos Zafeiriou","Tolga Birdal"],"pdf_url":"https://arxiv.org/pdf/2507.17748v2.pdf","comment":"Accepted at ICCV 2025, 25 pages"},{"id":"http://arxiv.org/abs/2508.03571v1","updated":"2025-08-05T15:39:37Z","published":"2025-08-05T15:39:37Z","title":"Tackling Distribution Shift in LLM via KILO: Knowledge-Instructed\n  Learning for Continual Adaptation","summary":"  Large Language Models (LLMs) often suffer from performance degradation when\nfaced with domain shifts, primarily due to catastrophic forgetting. In this\nwork, we propose KILO (Knowledge-Instructed Learning for Continual Adaptation),\na novel continual learning framework that integrates dynamic knowledge graphs\nwith instruction tuning. By leveraging retrieved domain-specific knowledge as\nguidance during training, KILO enhances both adaptability to new domains and\nretention of previously acquired knowledge. We pretrain our model on\nWikiText-103 and evaluate sequential adaptation across four diverse target\ndomains: BioASQ, SciQ, TweetEval, and MIND. Our experiments demonstrate that\nKILO consistently outperforms strong baselines, including continual\nfine-tuning, ERNIE 2.0, and CPT, in terms of backward transfer, forward\ntransfer, F1 score, retention rate, and training efficiency. These results\nhighlight the effectiveness of combining structured knowledge retrieval and\ninstruction prompting to overcome domain shift challenges in continual learning\nscenarios.\n","authors":["Iing Muttakhiroh","Thomas Fevens"],"pdf_url":"https://arxiv.org/pdf/2508.03571v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03556v1","updated":"2025-08-05T15:25:24Z","published":"2025-08-05T15:25:24Z","title":"VRPRM: Process Reward Modeling via Visual Reasoning","summary":"  Process Reward Model (PRM) is widely used in the post-training of Large\nLanguage Model (LLM) because it can perform fine-grained evaluation of the\nreasoning steps of generated content. However, most PRMs lack long-term\nreasoning and deep thinking capabilities. On the other hand, although a few\nworks have tried to introduce Chain-of-Thought capability into PRMs, the\nannotation cost of CoT-PRM data is too expensive to play a stable role in\nvarious tasks. To address the above challenges, we propose VRPRM, a process\nreward model via visual reasoning, and design an efficient two-stage training\nstrategy. Experimental results show that using only 3.6K CoT-PRM SFT data and\n50K non-CoT PRM RL training data, VRPRM can surpass the non-thinking PRM with a\ntotal data volume of 400K and achieved a relative performance improvement of up\nto 118\\% over the base model in the BoN experiment. This result confirms that\nthe proposed combined training strategy can achieve higher quality reasoning\ncapabilities at a lower data annotation cost, thus providing a new paradigm for\nPRM training with more efficient data utilization.\n","authors":["Xinquan Chen","Bangwei Liu","Xuhong Wang"],"pdf_url":"https://arxiv.org/pdf/2508.03556v1.pdf","comment":"13 pages, 5 figures"},{"id":"http://arxiv.org/abs/2508.03546v1","updated":"2025-08-05T15:15:30Z","published":"2025-08-05T15:15:30Z","title":"Supervised Dynamic Dimension Reduction with Deep Neural Network","summary":"  This paper studies the problem of dimension reduction, tailored to improving\ntime series forecasting with high-dimensional predictors. We propose a novel\nSupervised Deep Dynamic Principal component analysis (SDDP) framework that\nincorporates the target variable and lagged observations into the factor\nextraction process. Assisted by a temporal neural network, we construct\ntarget-aware predictors by scaling the original predictors in a supervised\nmanner, with larger weights assigned to predictors with stronger forecasting\npower. A principal component analysis is then performed on the target-aware\npredictors to extract the estimated SDDP factors. This supervised factor\nextraction not only improves predictive accuracy in the downstream forecasting\ntask but also yields more interpretable and target-specific latent factors.\nBuilding upon SDDP, we propose a factor-augmented nonlinear dynamic forecasting\nmodel that unifies a broad family of factor-model-based forecasting approaches.\nTo further demonstrate the broader applicability of SDDP, we extend our studies\nto a more challenging scenario when the predictors are only partially\nobservable. We validate the empirical performance of the proposed method on\nseveral real-world public datasets. The results show that our algorithm\nachieves notable improvements in forecasting accuracy compared to\nstate-of-the-art methods.\n","authors":["Zhanye Luo","Yuefeng Han","Xiufan Yu"],"pdf_url":"https://arxiv.org/pdf/2508.03546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.14961v4","updated":"2025-08-05T15:13:16Z","published":"2024-01-26T15:52:41Z","title":"Set-Based Training for Neural Network Verification","summary":"  Neural networks are vulnerable to adversarial attacks, i.e., small input\nperturbations can significantly affect the outputs of a neural network.\nTherefore, to ensure safety of neural networks in safety-critical environments,\nthe robustness of a neural network must be formally verified against input\nperturbations, e.g., from noisy sensors. To improve the robustness of neural\nnetworks and thus simplify the formal verification, we present a novel\nset-based training procedure in which we compute the set of possible outputs\ngiven the set of possible inputs and compute for the first time a gradient set,\ni.e., each possible output has a different gradient. Therefore, we can directly\nreduce the size of the output enclosure by choosing gradients toward its\ncenter. Small output enclosures increase the robustness of a neural network\nand, at the same time, simplify its formal verification. The latter benefit is\ndue to the fact that a larger size of propagated sets increases the\nconservatism of most verification methods. Our extensive evaluation\ndemonstrates that set-based training produces robust neural networks with\ncompetitive performance, which can be verified using fast (polynomial-time)\nverification algorithms due to the reduced output set.\n","authors":["Lukas Koller","Tobias Ladner","Matthias Althoff"],"pdf_url":"https://arxiv.org/pdf/2401.14961v4.pdf","comment":"published at Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2401.14973v3","updated":"2025-08-05T15:10:13Z","published":"2024-01-26T16:06:01Z","title":"Discovering group dynamics in coordinated time series via hierarchical\n  recurrent switching-state models","summary":"  We seek a computationally efficient model for a collection of time series\narising from multiple interacting entities (a.k.a. \"agents\"). Recent models of\ntemporal patterns across individuals fail to incorporate explicit system-level\ncollective behavior that can influence the trajectories of individual entities.\nTo address this gap in the literature, we present a new hierarchical\nswitching-state model that can be trained in an unsupervised fashion to\nsimultaneously learn both system-level and individual-level dynamics. We employ\na latent system-level discrete state Markov chain that provides top-down\ninfluence on latent entity-level chains which in turn govern the emission of\neach observed time series. Recurrent feedback from the observations to the\nlatent chains at both entity and system levels allows recent situational\ncontext to inform how dynamics unfold at all levels in bottom-up fashion. We\nhypothesize that including both top-down and bottom-up influences on group\ndynamics will improve interpretability of the learned dynamics and reduce error\nwhen forecasting. Our hierarchical switching recurrent dynamical model can be\nlearned via closed-form variational coordinate ascent updates to all latent\nchains that scale linearly in the number of entities. This is asymptotically no\nmore costly than fitting a separate model for each entity. Analysis of both\nsynthetic data and real basketball team movements suggests our lean parametric\nmodel can achieve competitive forecasts compared to larger neural network\nmodels that require far more computational resources. Further experiments on\nsoldier data as well as a synthetic task with 64 cooperating entities show how\nour approach can yield interpretable insights about team dynamics over time.\n","authors":["Michael T. Wojnowicz","Kaitlin Gili","Preetish Rath","Eric Miller","Jeffrey Miller","Clifford Hancock","Meghan O'Donovan","Seth Elkin-Frankston","Tad T. Brunyé","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2401.14973v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03541v1","updated":"2025-08-05T15:10:09Z","published":"2025-08-05T15:10:09Z","title":"Vision-based Perception System for Automated Delivery Robot-Pedestrians\n  Interactions","summary":"  The integration of Automated Delivery Robots (ADRs) into pedestrian-heavy\nurban spaces introduces unique challenges in terms of safe, efficient, and\nsocially acceptable navigation. We develop the complete pipeline for a single\nvision sensor based multi-pedestrian detection and tracking, pose estimation,\nand monocular depth perception. Leveraging the real-world MOT17 dataset\nsequences, this study demonstrates how integrating human-pose estimation and\ndepth cues enhances pedestrian trajectory prediction and identity maintenance,\neven under occlusions and dense crowds. Results show measurable improvements,\nincluding up to a 10% increase in identity preservation (IDF1), a 7%\nimprovement in multiobject tracking accuracy (MOTA), and consistently high\ndetection precision exceeding 85%, even in challenging scenarios. Notably, the\nsystem identifies vulnerable pedestrian groups supporting more socially aware\nand inclusive robot behaviour.\n","authors":["Ergi Tushe","Bilal Farooq"],"pdf_url":"https://arxiv.org/pdf/2508.03541v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03527v1","updated":"2025-08-05T14:58:14Z","published":"2025-08-05T14:58:14Z","title":"MoKA: Mixture of Kronecker Adapters","summary":"  Parameter-efficient fine-tuning (PEFT) is essential for reducing the\ncomputational overhead of large language models (LLMs). Low-rank family\nadapters are commonly used to control the parameter size efficiently while\nmaintaining the generative power of LLMs. However, their limited expressiveness\ndue to the rank constraint often restricts their performance on complex tasks.\nWe propose Mixture of Kronecker Adapters (MoKA), a new generation of Kronecker\nadapters that addresses this limitation by modeling weight updates as a mixture\nof Kronecker products. Our proposed adapter leverages a gating mechanism that\nmeasures the importance of each Kronecker factor, enabling more expressive\nadaptation. Moreover, MoKA enables a rank flexibility that provides a better\ntrade-off between parameter efficiency and accuracy. To ensure hardware\nefficiency, we reformulate Kronecker computations using standard matrix\noperations, allowing seamless deployment on GPU-optimized hardware. We conduct\nextensive experiments on instruction-tuning and commonsense reasoning tasks\nusing low-bit quantized versions of LLaMA2-7B and LLaMA3-8B models. MoKA not\nonly outperforms PEFT baselines, but also reduces the number of trainable\nparameters up to 27x, achieving state-of-the-art trade-offs between performance\nand parameter efficiency.\n","authors":["Mohammadreza Sadeghi","Mahsa Ghazvini Nejad","MirHamed Jafarzadeh Asl","Yu Gu","Yuanhao Yu","Masoud Asgharian","Vahid Partovi Nia"],"pdf_url":"https://arxiv.org/pdf/2508.03527v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.18219v2","updated":"2025-08-05T14:52:53Z","published":"2025-07-24T09:15:07Z","title":"FedSA-GCL: A Semi-Asynchronous Federated Graph Learning Framework with\n  Personalized Aggregation and Cluster-Aware Broadcasting","summary":"  Federated Graph Learning (FGL) is a distributed learning paradigm that\nenables collaborative training over large-scale subgraphs located on multiple\nlocal systems. However, most existing FGL approaches rely on synchronous\ncommunication, which leads to inefficiencies and is often impractical in\nreal-world deployments. Meanwhile, current asynchronous federated learning\n(AFL) methods are primarily designed for conventional tasks such as image\nclassification and natural language processing, without accounting for the\nunique topological properties of graph data. Directly applying these methods to\ngraph learning can possibly result in semantic drift and representational\ninconsistency in the global model. To address these challenges, we propose\nFedSA-GCL, a semi-asynchronous federated framework that leverages both\ninter-client label distribution divergence and graph topological\ncharacteristics through a novel ClusterCast mechanism for efficient training.\nWe evaluate FedSA-GCL on multiple real-world graph datasets using the Louvain\nand Metis split algorithms, and compare it against 9 baselines. Extensive\nexperiments demonstrate that our method achieves strong robustness and\noutstanding efficiency, outperforming the baselines by an average of 2.92% with\nthe Louvain and by 3.4% with the Metis.\n","authors":["Zhongzheng Yuan","Lianshuai Guo","Xunkai Li","Yinlin Zhu","Wenyu Wang","Meixia Qu"],"pdf_url":"https://arxiv.org/pdf/2507.18219v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03524v1","updated":"2025-08-05T14:51:44Z","published":"2025-08-05T14:51:44Z","title":"Semantic Mosaicing of Histo-Pathology Image Fragments using Visual\n  Foundation Models","summary":"  In histopathology, tissue samples are often larger than a standard microscope\nslide, making stitching of multiple fragments necessary to process entire\nstructures such as tumors. Automated stitching is a prerequisite for scaling\nanalysis, but is challenging due to possible tissue loss during preparation,\ninhomogeneous morphological distortion, staining inconsistencies, missing\nregions due to misalignment on the slide, or frayed tissue edges. This limits\nstate-of-the-art stitching methods using boundary shape matching algorithms to\nreconstruct artificial whole mount slides (WMS). Here, we introduce\nSemanticStitcher using latent feature representations derived from a visual\nhistopathology foundation model to identify neighboring areas in different\nfragments. Robust pose estimation based on a large number of semantic matching\ncandidates derives a mosaic of multiple fragments to form the WMS. Experiments\non three different histopathology datasets demonstrate that SemanticStitcher\nyields robust WMS mosaicing and consistently outperforms the state of the art\nin correct boundary matches.\n","authors":["Stefan Brandstätter","Maximilian Köller","Philipp Seeböck","Alissa Blessing","Felicitas Oberndorfer","Svitlana Pochepnia","Helmut Prosch","Georg Langs"],"pdf_url":"https://arxiv.org/pdf/2508.03524v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.19895v2","updated":"2025-08-05T14:48:55Z","published":"2025-07-26T09:50:21Z","title":"Nonconvex Optimization Framework for Group-Sparse Feedback\n  Linear-Quadratic Optimal Control: Non-Penalty Approach","summary":"  This work is a companion paper of [8], where the distributed linear-quadratic\nproblem with fixed communication topology (DFT-LQ) and the sparse feedback LQ\nproblem (SF-LQ) are formulated into a nonsmooth and nonconvex optimization\nproblem with affine constraints. Moreover, a penalty approach is considered in\n\\cite{feng-part1}, and the PALM (proximal alternating linearized minimization)\nalgorithm is studied with convergence and complexity analysis. In this paper,\nwe aim to address the inherent drawbacks of the penalty approach, such as the\nchallenge of tuning the penalty parameter and the risk of introducing spurious\nstationary points. Specifically, we first reformulate the SF-LQ problem and the\nDFT-LQ problem from an epi-composition function perspective, aiming to solve\nthe constrained problem directly. Then, from a theoretical viewpoint, we\nrevisit the alternating direction method of multipliers (ADMM) and establish\nits convergence to the set of cluster points under certain assumptions. When\nthese assumptions do not hold, we can effectively utilize alternative\napproaches combining subgradient descent with Difference-of-Convex relaxation\nmethods. In summary, our results enable the direct design of group-sparse\nfeedback gains with theoretical guarantees, without resorting to convex\nsurrogates, restrictive structural assumptions, or penalty formulations that\nincorporate constraints into the cost function.\n","authors":["Lechen Feng","Xun Li","Yuan-Hua Ni"],"pdf_url":"https://arxiv.org/pdf/2507.19895v2.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2507.18114"},{"id":"http://arxiv.org/abs/2508.03522v1","updated":"2025-08-05T14:47:59Z","published":"2025-08-05T14:47:59Z","title":"Machine Learning Algorithms for Transplanting Accelerometer Observations\n  in Future Satellite Gravimetry Missions","summary":"  Accurate and continuous monitoring of Earth's gravity field is essential for\ntracking mass redistribution processes linked to climate variability,\nhydrological cycles, and geodynamic phenomena. While the GRACE and GRACE\nFollow-On (GRACE-FO) missions have set the benchmark for satellite gravimetry\nusing low-low satellite to satellite tracking (LL-SST), the precision of\ngravity field recovery still strongly depends on the quality of accelerometer\n(ACC) performance and the continuity of ACC data. Traditional electrostatic\naccelerometers (EA) face limitations that can hinder mission outcomes,\nprompting exploration of advanced sensor technologies and data recovery\ntechniques. This study presents a systematic evaluation of accelerometer data\ntransplantation using novel accelerometer configurations, including Cold Atom\nInterferometry (CAI) accelerometers and hybrid EA-CAI setups, and applying both\nanalytical and machine learning-based methods. Using comprehensive closed-loop\nLL-SST simulations, we compare four scenarios ranging from the conventional\nEA-only setup to ideal dual hybrid configurations, with a particular focus on\nthe performance of transplant-based approaches using different neural network\napproaches. Our results show that the dual hybrid configuration provides the\nmost accurate gravity field retrieval. However, the transplant-based hybrid\nsetup, especially when supported by machine learning, emerges as a robust and\ncost-effective alternative, achieving comparable performance with minimal extra\nhardware. These findings highlight the promise of combining quantum sensor\ntechnology and data-driven transplantation for future satellite gravimetry\nmissions, paving the way for improved global monitoring of Earth's dynamic\ngravity field.\n","authors":["Mohsen Romeshkani","Jürgen Müller","Sahar Ebadi","Alexey Kupriyanov","Annike Knabe","Nina Fletling","Manuel Schilling"],"pdf_url":"https://arxiv.org/pdf/2508.03522v1.pdf","comment":null}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2508.03688v1","updated":"2025-08-05T17:57:56Z","published":"2025-08-05T17:57:56Z","title":"Learning quadratic neural networks in high dimensions: SGD dynamics and\n  scaling laws","summary":"  We study the optimization and sample complexity of gradient-based training of\na two-layer neural network with quadratic activation function in the\nhigh-dimensional regime, where the data is generated as $y \\propto\n\\sum_{j=1}^{r}\\lambda_j \\sigma\\left(\\langle \\boldsymbol{\\theta_j},\n\\boldsymbol{x}\\rangle\\right), \\boldsymbol{x} \\sim N(0,\\boldsymbol{I}_d)$,\n$\\sigma$ is the 2nd Hermite polynomial, and $\\lbrace\\boldsymbol{\\theta}_j\n\\rbrace_{j=1}^{r} \\subset \\mathbb{R}^d$ are orthonormal signal directions. We\nconsider the extensive-width regime $r \\asymp d^\\beta$ for $\\beta \\in [0, 1)$,\nand assume a power-law decay on the (non-negative) second-layer coefficients\n$\\lambda_j\\asymp j^{-\\alpha}$ for $\\alpha \\geq 0$. We present a sharp analysis\nof the SGD dynamics in the feature learning regime, for both the population\nlimit and the finite-sample (online) discretization, and derive scaling laws\nfor the prediction risk that highlight the power-law dependencies on the\noptimization time, sample size, and model width. Our analysis combines a\nprecise characterization of the associated matrix Riccati differential equation\nwith novel matrix monotonicity arguments to establish convergence guarantees\nfor the infinite-dimensional effective dynamics.\n","authors":["Gérard Ben Arous","Murat A. Erdogdu","N. Mert Vural","Denny Wu"],"pdf_url":"https://arxiv.org/pdf/2508.03688v1.pdf","comment":"84 pages"},{"id":"http://arxiv.org/abs/2508.03679v1","updated":"2025-08-05T17:50:03Z","published":"2025-08-05T17:50:03Z","title":"Streaming Generated Gaussian Process Experts for Online Learning and\n  Control","summary":"  Gaussian Processes (GPs), as a nonparametric learning method, offer flexible\nmodeling capabilities and calibrated uncertainty quantification for function\napproximations. Additionally, GPs support online learning by efficiently\nincorporating new data with polynomial-time computation, making them\nwell-suited for safety-critical dynamical systems that require rapid\nadaptation. However, the inference and online updates of exact GPs, when\nprocessing streaming data, incur cubic computation time and quadratic storage\nmemory complexity, limiting their scalability to large datasets in real-time\nsettings. In this paper, we propose a \\underline{s}treaming\n\\underline{k}ernel-induced progressivel\\underline{y} generated expert framework\nof \\underline{G}aussian \\underline{p}rocesses (SkyGP) that addresses both\ncomputational and memory constraints by maintaining a bounded set of experts,\nwhile inheriting the learning performance guarantees from exact Gaussian\nprocesses. Furthermore, two SkyGP variants are introduced, each tailored to a\nspecific objective, either maximizing prediction accuracy (SkyGP-Dense) or\nimproving computational efficiency (SkyGP-Fast). The effectiveness of SkyGP is\nvalidated through extensive benchmarks and real-time control experiments\ndemonstrating its superior performance compared to state-of-the-art approaches.\n","authors":["Zewen Yang","Dongfa Zhang","Xiaobing Dai","Fengyi Yu","Chi Zhang","Bingkun Huang","Hamid Sadeghian","Sami Haddadin"],"pdf_url":"https://arxiv.org/pdf/2508.03679v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03677v1","updated":"2025-08-05T17:47:53Z","published":"2025-08-05T17:47:53Z","title":"FairLangProc: A Python package for fairness in NLP","summary":"  The rise in usage of Large Language Models to near ubiquitousness in recent\nyears has risen societal concern about their applications in decision-making\ncontexts, such as organizational justice or healthcare. This, in turn, poses\nquestions about the fairness of these models in critical settings, which leads\nto the developement of different procedures to address bias in Natural Language\nProcessing. Although many datasets, metrics and algorithms have been proposed\nto measure and mitigate harmful prejudice in Natural Language Processing, their\nimplementation is diverse and far from centralized. As a response, this paper\npresents FairLangProc, a comprehensive Python package providing a common\nimplementation of some of the more recent advances in fairness in Natural\nLanguage Processing providing an interface compatible with the famous Hugging\nFace transformers library, aiming to encourage the widespread use and\ndemocratization of bias mitigation techniques. The implementation can be found\non https://github.com/arturo-perez-peralta/FairLangProc.\n","authors":["Arturo Pérez-Peralta","Sandra Benítez-Peña","Rosa E. Lillo"],"pdf_url":"https://arxiv.org/pdf/2508.03677v1.pdf","comment":"40 pages, 4 figures, 3 tables"},{"id":"http://arxiv.org/abs/2508.03636v1","updated":"2025-08-05T16:51:29Z","published":"2025-08-05T16:51:29Z","title":"Likelihood Matching for Diffusion Models","summary":"  We propose a Likelihood Matching approach for training diffusion models by\nfirst establishing an equivalence between the likelihood of the target data\ndistribution and a likelihood along the sample path of the reverse diffusion.\nTo efficiently compute the reverse sample likelihood, a quasi-likelihood is\nconsidered to approximate each reverse transition density by a Gaussian\ndistribution with matched conditional mean and covariance, respectively. The\nscore and Hessian functions for the diffusion generation are estimated by\nmaximizing the quasi-likelihood, ensuring a consistent matching of both the\nfirst two transitional moments between every two time points. A stochastic\nsampler is introduced to facilitate computation that leverages on both the\nestimated score and Hessian information. We establish consistency of the\nquasi-maximum likelihood estimation, and provide non-asymptotic convergence\nguarantees for the proposed sampler, quantifying the rates of the approximation\nerrors due to the score and Hessian estimation, dimensionality, and the number\nof diffusion steps. Empirical and simulation evaluations demonstrate the\neffectiveness of the proposed Likelihood Matching and validate the theoretical\nresults.\n","authors":["Lei Qian","Wu Su","Yanqi Huang","Song Xi Chen"],"pdf_url":"https://arxiv.org/pdf/2508.03636v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03633v1","updated":"2025-08-05T16:50:33Z","published":"2025-08-05T16:50:33Z","title":"Pair Correlation Factor and the Sample Complexity of Gaussian Mixtures","summary":"  We study the problem of learning Gaussian Mixture Models (GMMs) and ask:\nwhich structural properties govern their sample complexity? Prior work has\nlargely tied this complexity to the minimum pairwise separation between\ncomponents, but we demonstrate this view is incomplete.\n  We introduce the \\emph{Pair Correlation Factor} (PCF), a geometric quantity\ncapturing the clustering of component means. Unlike the minimum gap, the PCF\nmore accurately dictates the difficulty of parameter recovery.\n  In the uniform spherical case, we give an algorithm with improved sample\ncomplexity bounds, showing when more than the usual $\\epsilon^{-2}$ samples are\nnecessary.\n","authors":["Farzad Aryan"],"pdf_url":"https://arxiv.org/pdf/2508.03633v1.pdf","comment":"21 pages, no figures"},{"id":"http://arxiv.org/abs/2502.08808v2","updated":"2025-08-05T16:27:52Z","published":"2025-02-12T21:44:06Z","title":"A First-order Generative Bilevel Optimization Framework for Diffusion\n  Models","summary":"  Diffusion models, which iteratively denoise data samples to synthesize\nhigh-quality outputs, have achieved empirical success across domains. However,\noptimizing these models for downstream tasks often involves nested bilevel\nstructures, such as tuning hyperparameters for fine-tuning tasks or noise\nschedules in training dynamics, where traditional bilevel methods fail due to\nthe infinite-dimensional probability space and prohibitive sampling costs. We\nformalize this challenge as a generative bilevel optimization problem and\naddress two key scenarios: (1) fine-tuning pre-trained models via an\ninference-only lower-level solver paired with a sample-efficient gradient\nestimator for the upper level, and (2) training diffusion model from scratch\nwith noise schedule optimization by reparameterizing the lower-level problem\nand designing a computationally tractable gradient estimator. Our first-order\nbilevel framework overcomes the incompatibility of conventional bilevel methods\nwith diffusion processes, offering theoretical grounding and computational\npracticality. Experiments demonstrate that our method outperforms existing\nfine-tuning and hyperparameter search baselines.\n","authors":["Quan Xiao","Hui Yuan","A F M Saif","Gaowen Liu","Ramana Kompella","Mengdi Wang","Tianyi Chen"],"pdf_url":"https://arxiv.org/pdf/2502.08808v2.pdf","comment":"Cameral-ready version: added experiments using the HPSv2 reward,\n  improved notation consistency for the diffusion model, and added related\n  works"},{"id":"http://arxiv.org/abs/2507.10643v3","updated":"2025-08-05T16:03:04Z","published":"2025-07-14T16:38:30Z","title":"TaylorPODA: A Taylor Expansion-Based Method to Improve Post-Hoc\n  Attributions for Opaque Models","summary":"  Existing post-hoc model-agnostic methods generate external explanations for\nopaque models, primarily by locally attributing the model output to its input\nfeatures. However, they often lack an explicit and systematic framework for\nquantifying the contribution of individual features. Building on the Taylor\nexpansion framework introduced by Deng et al. (2024) to unify existing local\nattribution methods, we propose a rigorous set of postulates -- \"precision\",\n\"federation\", and \"zero-discrepancy\" -- to govern Taylor term-specific\nattribution. Guided by these postulates, we introduce TaylorPODA (Taylor\nexpansion-derived imPortance-Order aDapted Attribution), which incorporates an\nadditional \"adaptation\" property. This property enables alignment with\ntask-specific goals, especially in post-hoc settings lacking ground-truth\nexplanations. Empirical evaluations demonstrate that TaylorPODA achieves\ncompetitive results against baseline methods, providing principled and\nvisualization-friendly explanations. This work enhances the trustworthy\ndeployment of opaque models by offering explanations with stronger theoretical\ngrounding.\n","authors":["Yuchi Tang","Iñaki Esnaola","George Panoutsos"],"pdf_url":"https://arxiv.org/pdf/2507.10643v3.pdf","comment":"18 pages, 4 figures. Submitted to AAAI 2026. Re-upload with amended\n  manuscript"},{"id":"http://arxiv.org/abs/2508.03593v1","updated":"2025-08-05T15:58:31Z","published":"2025-08-05T15:58:31Z","title":"On the (In)Significance of Feature Selection in High-Dimensional\n  Datasets","summary":"  Extensive research has been done on feature selection (FS) algorithms for\nhigh-dimensional datasets aiming to improve model performance, reduce\ncomputational cost and identify features of interest. We test the null\nhypothesis of using randomly selected features to compare against features\nselected by FS algorithms to validate the performance of the latter. Our\nresults show that FS on high-dimensional datasets (in particular gene\nexpression) in classification tasks is not useful. We find that (1) models\ntrained on small subsets (0.02%-1% of all features) of randomly selected\nfeatures almost always perform comparably to those trained on all features, and\n(2) a \"typical\"- sized random subset provides comparable or superior\nperformance to that of top-k features selected in various published studies.\nThus, our work challenges many feature selection results on high dimensional\ndatasets, particularly in computational genomics. It raises serious concerns\nabout studies that propose drug design or targeted interventions based on\ncomputationally selected genes, without further validation in a wet lab.\n","authors":["Bhavesh Neekhra","Debayan Gupta","Partha Pratim Chakravarti"],"pdf_url":"https://arxiv.org/pdf/2508.03593v1.pdf","comment":"submitted to Nature Computational Science (double-blind review in\n  progress). supplementary material included in pdf; anonymized code at:\n  https://anonymous.4open.science/r/Feature_Selection_HD-D853/README.md"},{"id":"http://arxiv.org/abs/2507.17748v2","updated":"2025-08-05T15:46:33Z","published":"2025-07-23T17:59:02Z","title":"Large Learning Rates Simultaneously Achieve Robustness to Spurious\n  Correlations and Compressibility","summary":"  Robustness and resource-efficiency are two highly desirable properties for\nmodern machine learning models. However, achieving them jointly remains a\nchallenge. In this paper, we identify high learning rates as a facilitator for\nsimultaneously achieving robustness to spurious correlations and network\ncompressibility. We demonstrate that large learning rates also produce\ndesirable representation properties such as invariant feature utilization,\nclass separation, and activation sparsity. Our findings indicate that large\nlearning rates compare favorably to other hyperparameters and regularization\nmethods, in consistently satisfying these properties in tandem. In addition to\ndemonstrating the positive effect of large learning rates across diverse\nspurious correlation datasets, models, and optimizers, we also present strong\nevidence that the previously documented success of large learning rates in\nstandard classification tasks is related to addressing hidden/rare spurious\ncorrelations in the training dataset. Our investigation of the mechanisms\nunderlying this phenomenon reveals the importance of confident mispredictions\nof bias-conflicting samples under large learning rates.\n","authors":["Melih Barsbey","Lucas Prieto","Stefanos Zafeiriou","Tolga Birdal"],"pdf_url":"https://arxiv.org/pdf/2507.17748v2.pdf","comment":"Accepted at ICCV 2025, 25 pages"},{"id":"http://arxiv.org/abs/2508.03546v1","updated":"2025-08-05T15:15:30Z","published":"2025-08-05T15:15:30Z","title":"Supervised Dynamic Dimension Reduction with Deep Neural Network","summary":"  This paper studies the problem of dimension reduction, tailored to improving\ntime series forecasting with high-dimensional predictors. We propose a novel\nSupervised Deep Dynamic Principal component analysis (SDDP) framework that\nincorporates the target variable and lagged observations into the factor\nextraction process. Assisted by a temporal neural network, we construct\ntarget-aware predictors by scaling the original predictors in a supervised\nmanner, with larger weights assigned to predictors with stronger forecasting\npower. A principal component analysis is then performed on the target-aware\npredictors to extract the estimated SDDP factors. This supervised factor\nextraction not only improves predictive accuracy in the downstream forecasting\ntask but also yields more interpretable and target-specific latent factors.\nBuilding upon SDDP, we propose a factor-augmented nonlinear dynamic forecasting\nmodel that unifies a broad family of factor-model-based forecasting approaches.\nTo further demonstrate the broader applicability of SDDP, we extend our studies\nto a more challenging scenario when the predictors are only partially\nobservable. We validate the empirical performance of the proposed method on\nseveral real-world public datasets. The results show that our algorithm\nachieves notable improvements in forecasting accuracy compared to\nstate-of-the-art methods.\n","authors":["Zhanye Luo","Yuefeng Han","Xiufan Yu"],"pdf_url":"https://arxiv.org/pdf/2508.03546v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.14973v3","updated":"2025-08-05T15:10:13Z","published":"2024-01-26T16:06:01Z","title":"Discovering group dynamics in coordinated time series via hierarchical\n  recurrent switching-state models","summary":"  We seek a computationally efficient model for a collection of time series\narising from multiple interacting entities (a.k.a. \"agents\"). Recent models of\ntemporal patterns across individuals fail to incorporate explicit system-level\ncollective behavior that can influence the trajectories of individual entities.\nTo address this gap in the literature, we present a new hierarchical\nswitching-state model that can be trained in an unsupervised fashion to\nsimultaneously learn both system-level and individual-level dynamics. We employ\na latent system-level discrete state Markov chain that provides top-down\ninfluence on latent entity-level chains which in turn govern the emission of\neach observed time series. Recurrent feedback from the observations to the\nlatent chains at both entity and system levels allows recent situational\ncontext to inform how dynamics unfold at all levels in bottom-up fashion. We\nhypothesize that including both top-down and bottom-up influences on group\ndynamics will improve interpretability of the learned dynamics and reduce error\nwhen forecasting. Our hierarchical switching recurrent dynamical model can be\nlearned via closed-form variational coordinate ascent updates to all latent\nchains that scale linearly in the number of entities. This is asymptotically no\nmore costly than fitting a separate model for each entity. Analysis of both\nsynthetic data and real basketball team movements suggests our lean parametric\nmodel can achieve competitive forecasts compared to larger neural network\nmodels that require far more computational resources. Further experiments on\nsoldier data as well as a synthetic task with 64 cooperating entities show how\nour approach can yield interpretable insights about team dynamics over time.\n","authors":["Michael T. Wojnowicz","Kaitlin Gili","Preetish Rath","Eric Miller","Jeffrey Miller","Clifford Hancock","Meghan O'Donovan","Seth Elkin-Frankston","Tad T. Brunyé","Michael C. Hughes"],"pdf_url":"https://arxiv.org/pdf/2401.14973v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13527v3","updated":"2025-08-05T13:33:06Z","published":"2024-12-18T06:09:00Z","title":"Lyapunov Analysis For Monotonically Forward-Backward Accelerated\n  Algorithms","summary":"  Nesterov's accelerated gradient method (NAG) achieves faster convergence than\ngradient descent for convex optimization but lacks monotonicity in function\nvalues. To address this, Beck and Teboulle [2009b] proposed a monotonic\nvariant, M-NAG, and extended it to the proximal setting as M-FISTA for\ncomposite problems such as Lasso. However, establishing the linear convergence\nof M-NAG and M-FISTA under strong convexity remains an open problem. In this\npaper, we analyze M-NAG via the implicit-velocity phase representation and show\nthat an additional assumption, either the position update or the phase-coupling\nrelation, is necessary to fully recover the NAG iterates. The essence of M-NAG\nlies in controlling an auxiliary sequence to enforce non-increase. We further\ndemonstrate that the M-NAG update alone is sufficient to construct a Lyapunov\nfunction guaranteeing linear convergence, without relying on full NAG iterates.\nBy modifying the mixed sequence to incorporate forward-indexed gradients, we\ndevelop a new Lyapunov function that removes the kinetic energy term, enabling\na direct extension to M-NAG. The required starting index depends only on the\nmomentum parameter and not on problem constants. Finally, leveraging newly\ndeveloped proximal inequalities, we extend our results to M-FISTA, establishing\nits linear convergence and deepening the theoretical understanding of monotonic\naccelerated methods.\n","authors":["Mingwei Fu","Bin Shi"],"pdf_url":"https://arxiv.org/pdf/2412.13527v3.pdf","comment":"20 pages, 4 figures, and 1 table"},{"id":"http://arxiv.org/abs/2501.02298v4","updated":"2025-08-05T13:15:21Z","published":"2025-01-04T14:33:27Z","title":"Beyond Log-Concavity and Score Regularity: Improved Convergence Bounds\n  for Score-Based Generative Models in W2-distance","summary":"  Score-based Generative Models (SGMs) aim to sample from a target distribution\nby learning score functions using samples perturbed by Gaussian noise. Existing\nconvergence bounds for SGMs in the $\\mathcal{W}_2$-distance rely on stringent\nassumptions about the data distribution. In this work, we present a novel\nframework for analyzing $\\mathcal{W}_2$-convergence in SGMs, significantly\nrelaxing traditional assumptions such as log-concavity and score regularity.\nLeveraging the regularization properties of the Ornstein--Uhlenbeck (OU)\nprocess, we show that weak log-concavity of the data distribution evolves into\nlog-concavity over time. This transition is rigorously quantified through a\nPDE-based analysis of the Hamilton--Jacobi--Bellman equation governing the\nlog-density of the forward process. Moreover, we establish that the drift of\nthe time-reversed OU process alternates between contractive and non-contractive\nregimes, reflecting the dynamics of concavity. Our approach circumvents the\nneed for stringent regularity conditions on the score function and its\nestimators, relying instead on milder, more practical assumptions. We\ndemonstrate the wide applicability of this framework through explicit\ncomputations on Gaussian mixture models, illustrating its versatility and\npotential for broader classes of data distributions.\n","authors":["Marta Gentiloni-Silveri","Antonio Ocello"],"pdf_url":"https://arxiv.org/pdf/2501.02298v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01957v2","updated":"2025-08-05T11:07:50Z","published":"2025-08-03T23:48:46Z","title":"Stochastic Encodings for Active Feature Acquisition","summary":"  Active Feature Acquisition is an instance-wise, sequential decision making\nproblem. The aim is to dynamically select which feature to measure based on\ncurrent observations, independently for each test instance. Common approaches\neither use Reinforcement Learning, which experiences training difficulties, or\ngreedily maximize the conditional mutual information of the label and\nunobserved features, which makes myopic acquisitions. To address these\nshortcomings, we introduce a latent variable model, trained in a supervised\nmanner. Acquisitions are made by reasoning about the features across many\npossible unobserved realizations in a stochastic latent space. Extensive\nevaluation on a large range of synthetic and real datasets demonstrates that\nour approach reliably outperforms a diverse set of baselines.\n","authors":["Alexander Norcliffe","Changhee Lee","Fergus Imrie","Mihaela van der Schaar","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2508.01957v2.pdf","comment":"31 pages, 15 figures, 17 tables, published at ICML 2025"},{"id":"http://arxiv.org/abs/2508.03314v1","updated":"2025-08-05T10:48:40Z","published":"2025-08-05T10:48:40Z","title":"A Dual Optimization View to Empirical Risk Minimization with\n  f-Divergence Regularization","summary":"  The dual formulation of empirical risk minimization with f-divergence\nregularization (ERM-fDR) is introduced. The solution of the dual optimization\nproblem to the ERM-fDR is connected to the notion of normalization function\nintroduced as an implicit function. This dual approach leverages the\nLegendre-Fenchel transform and the implicit function theorem to provide a\nnonlinear ODE expression to the normalization function. Furthermore, the\nnonlinear ODE expression and its properties provide a computationally efficient\nmethod to calculate the normalization function of the ERM-fDR solution under a\nmild condition.\n","authors":["Francisco Daunas","Iñaki Esnaola","Samir M. Perlaza"],"pdf_url":"https://arxiv.org/pdf/2508.03314v1.pdf","comment":"Conference paper to appear in ITW 2025. arXiv admin note: substantial\n  text overlap with arXiv:2502.14544; text overlap with arXiv:2402.00501"},{"id":"http://arxiv.org/abs/2508.03272v1","updated":"2025-08-05T09:51:55Z","published":"2025-08-05T09:51:55Z","title":"The alpha-beta divergence for real and complex data","summary":"  Divergences are fundamental to the information criteria that underpin most\nsignal processing algorithms. The alpha-beta family of divergences, designed\nfor non-negative data, offers a versatile framework that parameterizes and\ncontinuously interpolates several separable divergences found in existing\nliterature. This work extends the definition of alpha-beta divergences to\naccommodate complex data, specifically when the arguments of the divergence are\ncomplex vectors. This novel formulation is designed in such a way that, by\nsetting the divergence hyperparameters to unity, it particularizes to the\nwell-known Euclidean and Mahalanobis squared distances. Other choices of\nhyperparameters yield practical separable and non-separable extensions of\nseveral classical divergences. In the context of the problem of approximating a\ncomplex random vector, the centroid obtained by optimizing the alpha-beta mean\ndistortion has a closed-form expression, which interpretation sheds light on\nthe distinct roles of the divergence hyperparameters. These contributions may\nhave wide potential applicability, as there are many signal processing domains\nin which the underlying data are inherently complex.\n","authors":["Sergio Cruces"],"pdf_url":"https://arxiv.org/pdf/2508.03272v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.12487v2","updated":"2025-08-05T09:40:04Z","published":"2025-05-18T16:21:23Z","title":"Stereographic Multi-Try Metropolis Algorithms for Heavy-tailed Sampling","summary":"  Markov chain Monte Carlo (MCMC) methods for sampling from heavy-tailed\ndistributions present unique challenges, particularly in high dimensions.\nMulti-proposal MCMC algorithms have recently gained attention for their\npotential to improve performance, especially through parallel implementation on\nmodern hardware. This paper introduces a novel family of gradient-free MCMC\nalgorithms that combine the multi-try Metropolis (MTM) with stereographic MCMC\nframework, specifically designed for efficient sampling from heavy-tailed\ntargets. The proposed stereographic multi-try Metropolis (SMTM) algorithm not\nonly outperforms traditional Euclidean MTM and existing stereographic\nrandom-walk Metropolis methods, but also avoids the pathological convergence\nbehavior often observed in MTM and demonstrates strong robustness to tuning.\nThese properties are supported by scaling analysis and extensive simulation\nstudies.\n","authors":["Zhihao Wang","Jun Yang"],"pdf_url":"https://arxiv.org/pdf/2505.12487v2.pdf","comment":"43 pages, 8 figures"},{"id":"http://arxiv.org/abs/2501.11638v2","updated":"2025-08-05T09:33:59Z","published":"2025-01-20T18:12:59Z","title":"Class Imbalance in Anomaly Detection: Learning from an Exactly Solvable\n  Model","summary":"  Class imbalance (CI) is a longstanding problem in machine learning, slowing\ndown training and reducing performances. Although empirical remedies exist, it\nis often unclear which ones work best and when, due to the lack of an\noverarching theory. We address a common case of imbalance, that of anomaly (or\noutlier) detection. We provide a theoretical framework to analyze, interpret\nand address CI. It is based on an exact solution of the teacher-student\nperceptron model, through replica theory. Within this framework, one can\ndistinguish several sources of CI: either intrinsic, train or test imbalance.\nOur analysis reveals that the optimal train imbalance is generally different\nfrom 50%, with a non trivial dependence on the intrinsic imbalance, the\nabundance of data and on the noise in the learning. Moreover, there is a\ncrossover between a small noise training regime where results are independent\nof the noise level to a high noise regime where performances quickly degrade\nwith noise. Our results challenge some of the conventional wisdom on CI and\noffer practical guidelines to address it.\n","authors":["F. S. Pezzicoli","V. Ros","F. P. Landes","M. Baity-Jesi"],"pdf_url":"https://arxiv.org/pdf/2501.11638v2.pdf","comment":"version accepted at AISTATS 2025"},{"id":"http://arxiv.org/abs/2508.03245v1","updated":"2025-08-05T09:24:09Z","published":"2025-08-05T09:24:09Z","title":"On Conformal Machine Unlearning","summary":"  The increasing demand for data privacy, driven by regulations such as GDPR\nand CCPA, has made Machine Unlearning (MU) essential for removing the influence\nof specific training samples from machine learning models while preserving\nperformance on retained data. However, most existing MU methods lack rigorous\nstatistical guarantees, rely on heuristic metrics, and often require\ncomputationally expensive retraining baselines. To overcome these limitations,\nwe introduce a new definition for MU based on Conformal Prediction (CP),\nproviding statistically sound, uncertainty-aware guarantees without the need\nfor the concept of naive retraining. We formalize conformal criteria that\nquantify how often forgotten samples are excluded from CP sets, and propose\nempirical metrics,the Efficiently Covered Frequency (ECF at c) and its\ncomplement, the Efficiently Uncovered Frequency (EuCF at d), to measure the\neffectiveness of unlearning. We further present a practical unlearning method\ndesigned to optimize these conformal metrics. Extensive experiments across\ndiverse forgetting scenarios, datasets and models demonstrate the efficacy of\nour approach in removing targeted data.\n","authors":["Yahya Alkhatib","Wee Peng Tay"],"pdf_url":"https://arxiv.org/pdf/2508.03245v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03210v1","updated":"2025-08-05T08:37:58Z","published":"2025-08-05T08:37:58Z","title":"Convergence of Deterministic and Stochastic Diffusion-Model Samplers: A\n  Simple Analysis in Wasserstein Distance","summary":"  We provide new convergence guarantees in Wasserstein distance for\ndiffusion-based generative models, covering both stochastic (DDPM-like) and\ndeterministic (DDIM-like) sampling methods. We introduce a simple framework to\nanalyze discretization, initialization, and score estimation errors. Notably,\nwe derive the first Wasserstein convergence bound for the Heun sampler and\nimprove existing results for the Euler sampler of the probability flow ODE. Our\nanalysis emphasizes the importance of spatial regularity of the learned score\nfunction and argues for controlling the score error with respect to the true\nreverse process, in line with denoising score matching. We also incorporate\nrecent results on smoothed Wasserstein distances to sharpen initialization\nerror bounds.\n","authors":["Eliot Beyler","Francis Bach"],"pdf_url":"https://arxiv.org/pdf/2508.03210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03072v1","updated":"2025-08-05T04:43:01Z","published":"2025-08-05T04:43:01Z","title":"Achieving Limited Adaptivity for Multinomial Logistic Bandits","summary":"  Multinomial Logistic Bandits have recently attracted much attention due to\ntheir ability to model problems with multiple outcomes. In this setting, each\ndecision is associated with many possible outcomes, modeled using a multinomial\nlogit function. Several recent works on multinomial logistic bandits have\nsimultaneously achieved optimal regret and computational efficiency. However,\nmotivated by real-world challenges and practicality, there is a need to develop\nalgorithms with limited adaptivity, wherein we are allowed only $M$ policy\nupdates. To address these challenges, we present two algorithms, B-MNL-CB and\nRS-MNL, that operate in the batched and rarely-switching paradigms,\nrespectively. The batched setting involves choosing the $M$ policy update\nrounds at the start of the algorithm, while the rarely-switching setting can\nchoose these $M$ policy update rounds in an adaptive fashion. Our first\nalgorithm, B-MNL-CB extends the notion of distributional optimal designs to the\nmultinomial setting and achieves $\\tilde{O}(\\sqrt{T})$ regret assuming the\ncontexts are generated stochastically when presented with $\\Omega(\\log \\log T)$\nupdate rounds. Our second algorithm, RS-MNL works with adversarially generated\ncontexts and can achieve $\\tilde{O}(\\sqrt{T})$ regret with $\\tilde{O}(\\log T)$\npolicy updates. Further, we conducted experiments that demonstrate that our\nalgorithms (with a fixed number of policy updates) are extremely competitive\n(and often better) than several state-of-the-art baselines (which update their\npolicy every round), showcasing the applicability of our algorithms in various\npractical scenarios.\n","authors":["Sukruta Prakash Midigeshi","Tanmay Goyal","Gaurav Sinha"],"pdf_url":"https://arxiv.org/pdf/2508.03072v1.pdf","comment":"Accepted to RLC 2025"},{"id":"http://arxiv.org/abs/2507.03885v2","updated":"2025-08-05T04:09:21Z","published":"2025-07-05T03:54:37Z","title":"Unraveling the Black-box Magic: An Analysis of Neural Networks' Dynamic\n  Extrema","summary":"  We point out that neural networks are not black boxes, and their\ngeneralization stems from the ability to dynamically map a dataset to the\nextrema of the model function. We further prove that the number of extrema in a\nneural network is positively correlated with the number of its parameters. We\nthen propose a new algorithm that is significantly different from\nback-propagation algorithm, which mainly obtains the values of parameters by\nsolving a system of linear equations. Some difficult situations, such as\ngradient vanishing and overfitting, can be reasonably explained and dealt with\nin this framework.\n","authors":["Shengjian Chen"],"pdf_url":"https://arxiv.org/pdf/2507.03885v2.pdf","comment":"19 pages, 8 figures, for understanding the principles of large\n  language models"},{"id":"http://arxiv.org/abs/2504.13134v2","updated":"2025-08-05T02:01:15Z","published":"2025-04-17T17:47:15Z","title":"Energy-Based Reward Models for Robust Language Model Alignment","summary":"  Reward models (RMs) are essential for aligning Large Language Models (LLMs)\nwith human preferences. However, they often struggle with capturing complex\nhuman preferences and generalizing to unseen data. To address these challenges,\nwe introduce Energy-Based Reward Model (EBRM), a lightweight post-hoc\nrefinement framework that enhances RM robustness and generalization. EBRM\nmodels the reward distribution explicitly, capturing uncertainty in human\npreferences and mitigating the impact of noisy or misaligned annotations. It\nachieves this through conflict-aware data filtering, label-noise-aware\ncontrastive training, and hybrid initialization. Notably, EBRM enhances RMs\nwithout retraining, making it computationally efficient and adaptable across\ndifferent models and tasks. Empirical evaluations on RM benchmarks demonstrate\nsignificant improvements in both robustness and generalization, achieving up to\na 5.97% improvement in safety-critical alignment tasks compared to standard\nRMs. Furthermore, reinforcement learning experiments confirm that our refined\nrewards enhance alignment quality, effectively delaying reward hacking. These\nresults demonstrate our approach as a scalable and effective enhancement for\nexisting RMs and alignment pipelines. The code is available at EBRM.\n","authors":["Anamika Lochab","Ruqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2504.13134v2.pdf","comment":"Accepted by COLM 2025"},{"id":"http://arxiv.org/abs/2508.03940v1","updated":"2025-08-05T22:13:08Z","published":"2025-08-05T22:13:08Z","title":"FairPOT: Balancing AUC Performance and Fairness with Proportional\n  Optimal Transport","summary":"  Fairness metrics utilizing the area under the receiver operator\ncharacteristic curve (AUC) have gained increasing attention in high-stakes\ndomains such as healthcare, finance, and criminal justice. In these domains,\nfairness is often evaluated over risk scores rather than binary outcomes, and a\ncommon challenge is that enforcing strict fairness can significantly degrade\nAUC performance. To address this challenge, we propose Fair Proportional\nOptimal Transport (FairPOT), a novel, model-agnostic post-processing framework\nthat strategically aligns risk score distributions across different groups\nusing optimal transport, but does so selectively by transforming a controllable\nproportion, i.e., the top-lambda quantile, of scores within the disadvantaged\ngroup. By varying lambda, our method allows for a tunable trade-off between\nreducing AUC disparities and maintaining overall AUC performance. Furthermore,\nwe extend FairPOT to the partial AUC setting, enabling fairness interventions\nto concentrate on the highest-risk regions. Extensive experiments on synthetic,\npublic, and clinical datasets show that FairPOT consistently outperforms\nexisting post-processing techniques in both global and partial AUC scenarios,\noften achieving improved fairness with slight AUC degradation or even positive\ngains in utility. The computational efficiency and practical adaptability of\nFairPOT make it a promising solution for real-world deployment.\n","authors":["Pengxi Liu","Yi Shen","Matthew M. Engelhard","Benjamin A. Goldstein","Michael J. Pencina","Nicoleta J. Economou-Zavlanos","Michael M. Zavlanos"],"pdf_url":"https://arxiv.org/pdf/2508.03940v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03913v1","updated":"2025-08-05T21:01:58Z","published":"2025-08-05T21:01:58Z","title":"Fast and Accurate Explanations of Distance-Based Classifiers by\n  Uncovering Latent Explanatory Structures","summary":"  Distance-based classifiers, such as k-nearest neighbors and support vector\nmachines, continue to be a workhorse of machine learning, widely used in\nscience and industry. In practice, to derive insights from these models, it is\nalso important to ensure that their predictions are explainable. While the\nfield of Explainable AI has supplied methods that are in principle applicable\nto any model, it has also emphasized the usefulness of latent structures (e.g.\nthe sequence of layers in a neural network) to produce explanations. In this\npaper, we contribute by uncovering a hidden neural network structure in\ndistance-based classifiers (consisting of linear detection units combined with\nnonlinear pooling layers) upon which Explainable AI techniques such as\nlayer-wise relevance propagation (LRP) become applicable. Through quantitative\nevaluations, we demonstrate the advantage of our novel explanation approach\nover several baselines. We also show the overall usefulness of explaining\ndistance-based models through two practical use cases.\n","authors":["Florian Bley","Jacob Kauffmann","Simon León Krug","Klaus-Robert Müller","Grégoire Montavon"],"pdf_url":"https://arxiv.org/pdf/2508.03913v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17333v2","updated":"2025-08-05T20:45:08Z","published":"2024-05-27T16:34:18Z","title":"Generating Accurate Synthetic Survival Data by Conditioning on Outcomes","summary":"  Synthetically generated data can improve privacy, fairness, and data\naccessibility; however, it can be challenging in specialized scenarios such as\nsurvival analysis. One key challenge in this setting is censoring, i.e., the\ntiming of an event is unknown in some cases. Existing methods struggle to\naccurately reproduce the distributions of both observed and censored event\ntimes when generating synthetic data. We propose a conceptually simple approach\nthat generates covariates conditioned on event times and censoring indicators\nby leveraging existing tabular data generation models without making\nassumptions about the mechanism underlying censoring. Experiments on real-world\ndatasets demonstrate that our method consistently outperforms baselines and\nimproves downstream survival model performance.\n","authors":["Mohd Ashhad","Ricardo Henao"],"pdf_url":"https://arxiv.org/pdf/2405.17333v2.pdf","comment":"Accepted to Machine Learning for Healthcare (MLHC) 2025"},{"id":"http://arxiv.org/abs/2508.03904v1","updated":"2025-08-05T20:43:23Z","published":"2025-08-05T20:43:23Z","title":"Reinforcement Learning in MDPs with Information-Ordered Policies","summary":"  We propose an epoch-based reinforcement learning algorithm for\ninfinite-horizon average-cost Markov decision processes (MDPs) that leverages a\npartial order over a policy class. In this structure, $\\pi' \\leq \\pi$ if data\ncollected under $\\pi$ can be used to estimate the performance of $\\pi'$,\nenabling counterfactual inference without additional environment interaction.\nLeveraging this partial order, we show that our algorithm achieves a regret\nbound of $O(\\sqrt{w \\log(|\\Theta|) T})$, where $w$ is the width of the partial\norder. Notably, the bound is independent of the state and action space sizes.\nWe illustrate the applicability of these partial orders in many domains in\noperations research, including inventory control and queuing systems. For each,\nwe apply our framework to that problem, yielding new theoretical guarantees and\nstrong empirical results without imposing extra assumptions such as convexity\nin the inventory model or specialized arrival-rate structure in the queuing\nmodel.\n","authors":["Zhongjun Zhang","Shipra Agrawal","Ilan Lobel","Sean R. Sinclair","Christina Lee Yu"],"pdf_url":"https://arxiv.org/pdf/2508.03904v1.pdf","comment":"57 pages, 2 figures"},{"id":"http://arxiv.org/abs/2508.03896v1","updated":"2025-08-05T20:34:04Z","published":"2025-08-05T20:34:04Z","title":"Reliable Programmatic Weak Supervision with Confidence Intervals for\n  Label Probabilities","summary":"  The accurate labeling of datasets is often both costly and time-consuming.\nGiven an unlabeled dataset, programmatic weak supervision obtains probabilistic\npredictions for the labels by leveraging multiple weak labeling functions (LFs)\nthat provide rough guesses for labels. Weak LFs commonly provide guesses with\nassorted types and unknown interdependences that can result in unreliable\npredictions. Furthermore, existing techniques for programmatic weak supervision\ncannot provide assessments for the reliability of the probabilistic predictions\nfor labels. This paper presents a methodology for programmatic weak supervision\nthat can provide confidence intervals for label probabilities and obtain more\nreliable predictions. In particular, the methods proposed use uncertainty sets\nof distributions that encapsulate the information provided by LFs with\nunrestricted behavior and typology. Experiments on multiple benchmark datasets\nshow the improvement of the presented methods over the state-of-the-art and the\npracticality of the confidence intervals presented.\n","authors":["Verónica Álvarez","Santiago Mazuelas","Steven An","Sanjoy Dasgupta"],"pdf_url":"https://arxiv.org/pdf/2508.03896v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03867v1","updated":"2025-08-05T19:30:11Z","published":"2025-08-05T19:30:11Z","title":"Constraining the outputs of ReLU neural networks","summary":"  We introduce a class of algebraic varieties naturally associated with ReLU\nneural networks, arising from the piecewise linear structure of their outputs\nacross activation regions in input space, and the piecewise multilinear\nstructure in parameter space. By analyzing the rank constraints on the network\noutputs within each activation region, we derive polynomial equations that\ncharacterize the functions representable by the network. We further investigate\nconditions under which these varieties attain their expected dimension,\nproviding insight into the expressive and structural properties of ReLU\nnetworks.\n","authors":["Yulia Alexandr","Guido Montúfar"],"pdf_url":"https://arxiv.org/pdf/2508.03867v1.pdf","comment":"32 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.03836v1","updated":"2025-08-05T18:34:00Z","published":"2025-08-05T18:34:00Z","title":"DP-NCB: Privacy Preserving Fair Bandits","summary":"  Multi-armed bandit algorithms are fundamental tools for sequential\ndecision-making under uncertainty, with widespread applications across domains\nsuch as clinical trials and personalized decision-making. As bandit algorithms\nare increasingly deployed in these socially sensitive settings, it becomes\ncritical to protect user data privacy and ensure fair treatment across decision\nrounds. While prior work has independently addressed privacy and fairness in\nbandit settings, the question of whether both objectives can be achieved\nsimultaneously has remained largely open. Existing privacy-preserving bandit\nalgorithms typically optimize average regret, a utilitarian measure, whereas\nfairness-aware approaches focus on minimizing Nash regret, which penalizes\ninequitable reward distributions, but often disregard privacy concerns.\n  To bridge this gap, we introduce Differentially Private Nash Confidence Bound\n(DP-NCB)-a novel and unified algorithmic framework that simultaneously ensures\n$\\epsilon$-differential privacy and achieves order-optimal Nash regret,\nmatching known lower bounds up to logarithmic factors. The framework is\nsufficiently general to operate under both global and local differential\nprivacy models, and is anytime, requiring no prior knowledge of the time\nhorizon. We support our theoretical guarantees with simulations on synthetic\nbandit instances, showing that DP-NCB incurs substantially lower Nash regret\nthan state-of-the-art baselines. Our results offer a principled foundation for\ndesigning bandit algorithms that are both privacy-preserving and fair, making\nthem suitable for high-stakes, socially impactful applications.\n","authors":["Dhruv Sarkar","Nishant Pandey","Sayak Ray Chowdhury"],"pdf_url":"https://arxiv.org/pdf/2508.03836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03827v1","updated":"2025-08-05T18:15:27Z","published":"2025-08-05T18:15:27Z","title":"Scalable Neural Network-based Blackbox Optimization","summary":"  Bayesian Optimization (BO) is a widely used approach for blackbox\noptimization that leverages a Gaussian process (GP) model and an acquisition\nfunction to guide future sampling. While effective in low-dimensional settings,\nBO faces scalability challenges in high-dimensional spaces and with large\nnumber of function evaluations due to the computational complexity of GP\nmodels. In contrast, neural networks (NNs) offer better scalability and can\nmodel complex functions, which led to the development of NN-based BO\napproaches. However, these methods typically rely on estimating model\nuncertainty in NN prediction -- a process that is often computationally\nintensive and complex, particularly in high dimensions. To address these\nlimitations, a novel method, called scalable neural network-based blackbox\noptimization (SNBO), is proposed that does not rely on model uncertainty\nestimation. Specifically, SNBO adds new samples using separate criteria for\nexploration and exploitation, while adaptively controlling the sampling region\nto ensure efficient optimization. SNBO is evaluated on a range of optimization\nproblems spanning from 10 to 102 dimensions and compared against four\nstate-of-the-art baseline algorithms. Across the majority of test problems,\nSNBO attains function values better than the best-performing baseline\nalgorithm, while requiring 40-60% fewer function evaluations and reducing the\nruntime by at least an order of magnitude.\n","authors":["Pavankumar Koratikere","Leifur Leifsson"],"pdf_url":"https://arxiv.org/pdf/2508.03827v1.pdf","comment":"This preprint has been submitted to Structural and Multidisciplinary\n  Optimization for peer review. An open-source implementation of SNBO is\n  available at: https://github.com/ComputationalDesignLab/snbo"},{"id":"http://arxiv.org/abs/2508.03059v1","updated":"2025-08-05T04:08:49Z","published":"2025-08-05T04:08:49Z","title":"Two-sample comparison through additive tree models for density ratios","summary":"  The ratio of two densities characterizes their differences. We consider\nlearning the density ratio given i.i.d. observations from each of the two\ndistributions. We propose additive tree models for the density ratio along with\nefficient algorithms for training these models using a new loss function called\nthe balancing loss. With this loss, additive tree models for the density ratio\ncan be trained using algorithms original designed for supervised learning.\nSpecifically, they can be trained from both an optimization perspective that\nparallels tree boosting and from a (generalized) Bayesian perspective that\nparallels Bayesian additive regression trees (BART). For the former, we present\ntwo boosting algorithms -- one based on forward-stagewise fitting and the other\nbased on gradient boosting, both of which produce a point estimate for the\ndensity ratio function. For the latter, we show that due to the loss function's\nresemblance to an exponential family kernel, the new loss can serve as a\npseudo-likelihood for which conjugate priors exist, thereby enabling effective\ngeneralized Bayesian inference on the density ratio using backfitting samplers\ndesigned for BART. The resulting uncertainty quantification on the inferred\ndensity ratio is critical for applications involving high-dimensional and\ncomplex distributions in which uncertainty given limited data can often be\nsubstantial. We provide insights on the balancing loss through its close\nconnection to the exponential loss in binary classification and to the\nvariational form of f-divergence, in particular that of the squared Hellinger\ndistance. Our numerical experiments demonstrate the accuracy of the proposed\napproach while providing unique capabilities in uncertainty quantification. We\ndemonstrate the application of our method in a case study involving assessing\nthe quality of generative models for microbiome compositional data.\n","authors":["Naoki Awaya","Yuliang Xu","Li Ma"],"pdf_url":"https://arxiv.org/pdf/2508.03059v1.pdf","comment":null}],"Computation":[{"id":"http://arxiv.org/abs/2506.11369v3","updated":"2025-08-05T13:39:59Z","published":"2025-06-13T00:08:41Z","title":"Filtrated Kinematic Connectivity Analysis for Lower-limb Joint Effective\n  Age Evaluation","summary":"  To understand and communicate the risk of chronic lower-limb joint diseases\nassociated with aging, it is crucial to investigate the relationship between\nage and gait dynamics, particularly through angular kinematics. One key\nchallenge is that angular kinematic trajectories are highly interconnected, and\nthe structures of the interconnections vary across different components.\nNeglecting the interconnections and the variability in the connectivity\nstructures impairs the understanding of age-associated gait coordination. To\nthis end, we develop a novel kinematic connectivity analysis framework,\ngrounded in multiple functional regression, to evaluate lower-limb joint\neffective age and uncover age-related kinematic features. The proposed approach\nis built upon the concept of filtration, a widely used tool in network analysis\nand topological data analysis for multi-resolution exploration. Specifically,\nwe develop a forest-structured covariate grouping framework in which different\nkinematic trajectories are aggregated hierarchically to capture both\n(partially) shared and idiosyncratic motion signatures which are strongly\nassociated with aging. We also develop a novel filtrated functional partial\nleast squares approach for model estimation and feature extraction. Compared to\nexisting approaches, our proposed approach demonstrates superior predictive\npower while providing novel insights into the coordinated evolution of angular\nkinematics during aging. In addition, the proposed framework is broadly\napplicable and can be readily extended in other scientific domains.\n","authors":["Shuhao Jiao","Hernando Ombao","Ian W. McKeague"],"pdf_url":"https://arxiv.org/pdf/2506.11369v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.12487v2","updated":"2025-08-05T09:40:04Z","published":"2025-05-18T16:21:23Z","title":"Stereographic Multi-Try Metropolis Algorithms for Heavy-tailed Sampling","summary":"  Markov chain Monte Carlo (MCMC) methods for sampling from heavy-tailed\ndistributions present unique challenges, particularly in high dimensions.\nMulti-proposal MCMC algorithms have recently gained attention for their\npotential to improve performance, especially through parallel implementation on\nmodern hardware. This paper introduces a novel family of gradient-free MCMC\nalgorithms that combine the multi-try Metropolis (MTM) with stereographic MCMC\nframework, specifically designed for efficient sampling from heavy-tailed\ntargets. The proposed stereographic multi-try Metropolis (SMTM) algorithm not\nonly outperforms traditional Euclidean MTM and existing stereographic\nrandom-walk Metropolis methods, but also avoids the pathological convergence\nbehavior often observed in MTM and demonstrates strong robustness to tuning.\nThese properties are supported by scaling analysis and extensive simulation\nstudies.\n","authors":["Zhihao Wang","Jun Yang"],"pdf_url":"https://arxiv.org/pdf/2505.12487v2.pdf","comment":"43 pages, 8 figures"},{"id":"http://arxiv.org/abs/2508.02964v1","updated":"2025-08-05T00:01:41Z","published":"2025-08-05T00:01:41Z","title":"Injecting Measurement Information Yields a Fast and Noise-Robust\n  Diffusion-Based Inverse Problem Solver","summary":"  Diffusion models have been firmly established as principled zero-shot solvers\nfor linear and nonlinear inverse problems, owing to their powerful image prior\nand iterative sampling algorithm. These approaches often rely on Tweedie's\nformula, which relates the diffusion variate $\\mathbf{x}_t$ to the posterior\nmean $\\mathbb{E} [\\mathbf{x}_0 | \\mathbf{x}_t]$, in order to guide the\ndiffusion trajectory with an estimate of the final denoised sample\n$\\mathbf{x}_0$. However, this does not consider information from the\nmeasurement $\\mathbf{y}$, which must then be integrated downstream. In this\nwork, we propose to estimate the conditional posterior mean $\\mathbb{E}\n[\\mathbf{x}_0 | \\mathbf{x}_t, \\mathbf{y}]$, which can be formulated as the\nsolution to a lightweight, single-parameter maximum likelihood estimation\nproblem. The resulting prediction can be integrated into any standard sampler,\nresulting in a fast and memory-efficient inverse solver. Our optimizer is\namenable to a noise-aware likelihood-based stopping criteria that is robust to\nmeasurement noise in $\\mathbf{y}$. We demonstrate comparable or improved\nperformance against a wide selection of contemporary inverse solvers across\nmultiple datasets and tasks.\n","authors":["Jonathan Patsenker","Henry Li","Myeongseob Ko","Ruoxi Jia","Yuval Kluger"],"pdf_url":"https://arxiv.org/pdf/2508.02964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03059v1","updated":"2025-08-05T04:08:49Z","published":"2025-08-05T04:08:49Z","title":"Two-sample comparison through additive tree models for density ratios","summary":"  The ratio of two densities characterizes their differences. We consider\nlearning the density ratio given i.i.d. observations from each of the two\ndistributions. We propose additive tree models for the density ratio along with\nefficient algorithms for training these models using a new loss function called\nthe balancing loss. With this loss, additive tree models for the density ratio\ncan be trained using algorithms original designed for supervised learning.\nSpecifically, they can be trained from both an optimization perspective that\nparallels tree boosting and from a (generalized) Bayesian perspective that\nparallels Bayesian additive regression trees (BART). For the former, we present\ntwo boosting algorithms -- one based on forward-stagewise fitting and the other\nbased on gradient boosting, both of which produce a point estimate for the\ndensity ratio function. For the latter, we show that due to the loss function's\nresemblance to an exponential family kernel, the new loss can serve as a\npseudo-likelihood for which conjugate priors exist, thereby enabling effective\ngeneralized Bayesian inference on the density ratio using backfitting samplers\ndesigned for BART. The resulting uncertainty quantification on the inferred\ndensity ratio is critical for applications involving high-dimensional and\ncomplex distributions in which uncertainty given limited data can often be\nsubstantial. We provide insights on the balancing loss through its close\nconnection to the exponential loss in binary classification and to the\nvariational form of f-divergence, in particular that of the squared Hellinger\ndistance. Our numerical experiments demonstrate the accuracy of the proposed\napproach while providing unique capabilities in uncertainty quantification. We\ndemonstrate the application of our method in a case study involving assessing\nthe quality of generative models for microbiome compositional data.\n","authors":["Naoki Awaya","Yuliang Xu","Li Ma"],"pdf_url":"https://arxiv.org/pdf/2508.03059v1.pdf","comment":null}]},"2025-08-06T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2508.04700v1","updated":"2025-08-06T17:58:46Z","published":"2025-08-06T17:58:46Z","title":"SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from\n  Experience","summary":"  Repurposing large vision-language models (LVLMs) as computer use agents\n(CUAs) has led to substantial breakthroughs, primarily driven by human-labeled\ndata. However, these models often struggle with novel and specialized software,\nparticularly in scenarios lacking human annotations. To address this challenge,\nwe propose SEAgent, an agentic self-evolving framework enabling CUAs to\nautonomously evolve through interactions with unfamiliar software.\nSpecifically, SEAgent empowers computer-use agents to autonomously master novel\nsoftware environments via experiential learning, where agents explore new\nsoftware, learn through iterative trial-and-error, and progressively tackle\nauto-generated tasks organized from simple to complex. To achieve this goal, we\ndesign a World State Model for step-wise trajectory assessment, along with a\nCurriculum Generator that generates increasingly diverse and challenging tasks.\nThe agent's policy is updated through experiential learning, comprised of\nadversarial imitation of failure actions and Group Relative Policy Optimization\n(GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist\ntraining strategy that integrates individual experiential insights from\nspecialist agents, facilitating the development of a stronger generalist CUA\ncapable of continuous autonomous evolution. This unified agent ultimately\nachieves performance surpassing ensembles of individual specialist agents on\ntheir specialized software. We validate the effectiveness of SEAgent across\nfive novel software environments within OS-World. Our approach achieves a\nsignificant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a\ncompetitive open-source CUA, i.e., UI-TARS.\n","authors":["Zeyi Sun","Ziyu Liu","Yuhang Zang","Yuhang Cao","Xiaoyi Dong","Tong Wu","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2508.04700v1.pdf","comment":"Code at https://github.com/SunzeY/SEAgent"},{"id":"http://arxiv.org/abs/2508.04699v1","updated":"2025-08-06T17:58:36Z","published":"2025-08-06T17:58:36Z","title":"Hop, Skip, and Overthink: Diagnosing Why Reasoning Models Fumble during\n  Multi-Hop Analysis","summary":"  The emergence of reasoning models and their integration into practical AI\nchat bots has led to breakthroughs in solving advanced math, deep search, and\nextractive question answering problems that requires a complex and multi-step\nthought process. Yet, a complete understanding of why these models hallucinate\nmore than general purpose language models is missing. In this investigative\nstudy, we systematicallyexplore reasoning failures of contemporary language\nmodels on multi-hop question answering tasks. We introduce a novel, nuanced\nerror categorization framework that examines failures across three critical\ndimensions: the diversity and uniqueness of source documents involved (\"hops\"),\ncompleteness in capturing relevant information (\"coverage\"), and cognitive\ninefficiency (\"overthinking\"). Through rigorous hu-man annotation, supported by\ncomplementary automated metrics, our exploration uncovers intricate error\npatterns often hidden by accuracy-centric evaluations. This investigative\napproach provides deeper insights into the cognitive limitations of current\nmodels and offers actionable guidance toward enhancing reasoning fidelity,\ntransparency, and robustness in future language modeling efforts.\n","authors":["Anushka Yadav","Isha Nalawade","Srujana Pillarichety","Yashwanth Babu","Reshmi Ghosh","Samyadeep Basu","Wenlong Zhao","Ali Nasaeh","Sriram Balasubramanian","Soundararajan Srinivasan"],"pdf_url":"https://arxiv.org/pdf/2508.04699v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04698v1","updated":"2025-08-06T17:58:26Z","published":"2025-08-06T17:58:26Z","title":"FaST: Feature-aware Sampling and Tuning for Personalized Preference\n  Alignment with Limited Data","summary":"  LLM-powered conversational assistants are often deployed in a\none-size-fits-all manner, which fails to accommodate individual user\npreferences. Recently, LLM personalization -- tailoring models to align with\nspecific user preferences -- has gained increasing attention as a way to bridge\nthis gap. In this work, we specifically focus on a practical yet challenging\nsetting where only a small set of preference annotations can be collected per\nuser -- a problem we define as Personalized Preference Alignment with Limited\nData (PPALLI). To support research in this area, we introduce two datasets --\nDnD and ELIP -- and benchmark a variety of alignment techniques on them. We\nfurther propose FaST, a highly parameter-efficient approach that leverages\nhigh-level features automatically discovered from the data, achieving the best\noverall performance.\n","authors":["Thibaut Thonet","Germán Kruszewski","Jos Rozen","Pierre Erbacher","Marc Dymetman"],"pdf_url":"https://arxiv.org/pdf/2508.04698v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04683v1","updated":"2025-08-06T17:47:00Z","published":"2025-08-06T17:47:00Z","title":"Query Attribute Modeling: Improving search relevance with Semantic\n  Search and Meta Data Filtering","summary":"  This study introduces Query Attribute Modeling (QAM), a hybrid framework that\nenhances search precision and relevance by decomposing open text queries into\nstructured metadata tags and semantic elements. QAM addresses traditional\nsearch limitations by automatically extracting metadata filters from free-form\ntext queries, reducing noise and enabling focused retrieval of relevant items.\n  Experimental evaluation using the Amazon Toys Reviews dataset (10,000 unique\nitems with 40,000+ reviews and detailed product attributes) demonstrated QAM's\nsuperior performance, achieving a mean average precision at 5 (mAP@5) of\n52.99\\%. This represents significant improvement over conventional methods,\nincluding BM25 keyword search, encoder-based semantic similarity search,\ncross-encoder re-ranking, and hybrid search combining BM25 and semantic results\nvia Reciprocal Rank Fusion (RRF). The results establish QAM as a robust\nsolution for Enterprise Search applications, particularly in e-commerce\nsystems.\n","authors":["Karthik Menon","Batool Arhamna Haider","Muhammad Arham","Kanwal Mehreen","Ram Mohan Rao Kadiyala","Hamza Farooq"],"pdf_url":"https://arxiv.org/pdf/2508.04683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04676v1","updated":"2025-08-06T17:42:22Z","published":"2025-08-06T17:42:22Z","title":"GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via\n  General Samples Replay","summary":"  The continual learning capability of large language models (LLMs) is crucial\nfor advancing artificial general intelligence. However, continual fine-tuning\nLLMs across various domains often suffers from catastrophic forgetting,\ncharacterized by: 1) significant forgetting of their general capabilities, and\n2) sharp performance declines in previously learned tasks. To simultaneously\naddress both issues in a simple yet stable manner, we propose General Sample\nReplay (GeRe), a framework that use usual pretraining texts for efficient\nanti-forgetting. Beyond revisiting the most prevalent replay-based practices\nunder GeRe, we further leverage neural states to introduce a enhanced\nactivation states constrained optimization method using threshold-based margin\n(TM) loss, which maintains activation state consistency during replay learning.\nWe are the first to validate that a small, fixed set of pre-collected general\nreplay samples is sufficient to resolve both concerns--retaining general\ncapabilities while promoting overall performance across sequential tasks.\nIndeed, the former can inherently facilitate the latter. Through controlled\nexperiments, we systematically compare TM with different replay strategies\nunder the GeRe framework, including vanilla label fitting, logit imitation via\nKL divergence and feature imitation via L1/L2 losses. Results demonstrate that\nTM consistently improves performance and exhibits better robustness. Our work\npaves the way for efficient replay of LLMs for the future. Our code and data\nare available at https://github.com/Qznan/GeRe.\n","authors":["Yunan Zhang","Shuoran Jiang","Mengchen Zhao","Yuefeng Li","Yang Fan","Xiangping Wu","Qingcai Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09908v2","updated":"2025-08-06T17:36:57Z","published":"2024-10-13T16:28:38Z","title":"Beyond Adapter Retrieval: Latent Geometry-Preserving Composition via\n  Sparse Task Projection","summary":"  Recent advances in parameter-efficient transfer learning have demonstrated\nthe utility of composing LoRA adapters from libraries of pretrained modules.\nHowever, most existing approaches rely on simple retrieval heuristics or\nuniform averaging, which overlook the latent structure of task relationships in\nrepresentation space. We propose a new framework for adapter reuse that moves\nbeyond retrieval, formulating adapter composition as a geometry-aware sparse\nreconstruction problem. Specifically, we represent each task by a latent\nprototype vector derived from the base model's encoder and aim to approximate\nthe target task prototype as a sparse linear combination of retrieved reference\nprototypes, under an $\\ell_1$-regularized optimization objective. The resulting\ncombination weights are then used to blend the corresponding LoRA adapters,\nyielding a composite adapter tailored to the target task. This formulation not\nonly preserves the local geometric structure of the task representation\nmanifold, but also promotes interpretability and efficient reuse by selecting a\nminimal set of relevant adapters. We demonstrate the effectiveness of our\napproach across multiple domains-including medical image segmentation, medical\nreport generation and image synthesis. Our results highlight the benefit of\ncoupling retrieval with latent geometry-aware optimization for improved\nzero-shot generalization.\n","authors":["Pengfei Jin","Peng Shu","Sifan Song","Sekeun Kim","Qing Xiao","Cheng Chen","Tianming Liu","Xiang Li","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2410.09908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06663v2","updated":"2025-08-06T17:33:10Z","published":"2025-01-11T23:29:51Z","title":"Ultra Memory-Efficient On-FPGA Training of Transformers via\n  Tensor-Compressed Optimization","summary":"  Transformer models have achieved state-of-the-art performance across a wide\nrange of machine learning tasks. There is growing interest in training\ntransformers on resource-constrained edge devices due to considerations such as\nprivacy, domain adaptation, and on-device scientific machine learning. However,\nthe significant computational and memory demands required for transformer\ntraining often exceed the capabilities of an edge device. Leveraging low-rank\ntensor compression, this paper presents the first on-FPGA accelerator for\nend-to-end transformer training. On the algorithm side, we present a\nbi-directional contraction flow for tensorized transformer training,\nsignificantly reducing the computational FLOPS and intra-layer memory costs\ncompared to existing tensor operations. On the hardware side, we store all\nhighly compressed model parameters and gradient information on chip, creating\nan on-chip-memory-only framework for each stage in training. This reduces\noff-chip communication and minimizes latency and energy costs. Additionally, we\nimplement custom computing kernels for each training stage and employ\nintra-layer parallelism and pipe-lining to further enhance run-time and memory\nefficiency. Through experiments on transformer models within $36.7$ to $93.5$\nMB using FP-32 data formats on the ATIS dataset, our tensorized FPGA\naccelerator could conduct single-batch end-to-end training on the AMD Alevo U50\nFPGA, with a memory budget of less than $6$-MB BRAM and $22.5$-MB URAM.\nCompared to uncompressed training on the NVIDIA RTX 3090 GPU, our on-FPGA\ntraining achieves a memory reduction of $30\\times$ to $51\\times$. Our FPGA\naccelerator also achieves up to $3.6\\times$ less energy cost per epoch compared\nwith tensor Transformer training on an NVIDIA RTX 3090 GPU.\n","authors":["Jiayi Tian","Jinming Lu","Hai Li","Xiangwei Wang","Cong Hao","Ian Young","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.06663v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04664v1","updated":"2025-08-06T17:32:58Z","published":"2025-08-06T17:32:58Z","title":"Sculptor: Empowering LLMs with Cognitive Agency via Active Context\n  Management","summary":"  Large Language Models (LLMs) suffer from significant performance degradation\nwhen processing long contexts due to proactive interference, where irrelevant\ninformation in earlier parts of the context disrupts reasoning and memory\nrecall. While most research focuses on external memory systems to augment LLMs'\ncapabilities, we propose a complementary approach: empowering LLMs with Active\nContext Management (ACM) tools to actively sculpt their internal working\nmemory. We introduce Sculptor, a framework that equips LLMs with three\ncategories of tools: (1) context fragmentation, (2) summary, hide, and restore,\nand (3) intelligent search. Our approach enables LLMs to proactively manage\ntheir attention and working memory, analogous to how humans selectively focus\non relevant information while filtering out distractions. Experimental\nevaluation on information-sparse benchmarks-PI-LLM (proactive interference) and\nNeedleBench Multi-Needle Reasoning-demonstrates that Sculptor significantly\nimproves performance even without specific training, leveraging LLMs' inherent\ntool calling generalization capabilities. By enabling Active Context\nManagement, Sculptor not only mitigates proactive interference but also\nprovides a cognitive foundation for more reliable reasoning across diverse\nlong-context tasks-highlighting that explicit context-control strategies,\nrather than merely larger token windows, are key to robustness at scale.\n","authors":["Mo Li","L. H. Xu","Qitai Tan","Ting Cao","Yunxin Liu"],"pdf_url":"https://arxiv.org/pdf/2508.04664v1.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2507.04642v2","updated":"2025-08-06T17:29:40Z","published":"2025-07-07T03:50:59Z","title":"R1-RE: Cross-Domain Relation Extraction with RLVR","summary":"  Relation extraction (RE) is a core task in natural language processing.\nTraditional approaches typically frame RE as a supervised learning problem,\ndirectly mapping context to labels-an approach that often suffers from poor\nout-of-domain (OOD) generalization. Inspired by the workflow of human\nannotators, we reframe RE as a reasoning task guided by annotation guidelines\nand introduce R1-RE, the first reinforcement learning with verifiable reward\n(RLVR) framework for RE tasks. Our method elicits the reasoning abilities of\nsmall language models for annotation tasks, resulting in significantly improved\nOOD robustness. We evaluate our approach on the public Sem-2010 dataset and a\nprivate MDKG dataset. The R1-RE-7B model attains an average OOD accuracy of\napproximately 70%, on par with leading proprietary models such as GPT-4o.\nAdditionally, our comprehensive analysis provides novel insights into the\ntraining dynamics and emergent reasoning behaviors of the RLVR paradigm for RE.\n","authors":["Runpeng Dai","Tong Zheng","Run Yang","Kaixian Yu","Hongtu Zhu"],"pdf_url":"https://arxiv.org/pdf/2507.04642v2.pdf","comment":"14 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.04660v1","updated":"2025-08-06T17:28:31Z","published":"2025-08-06T17:28:31Z","title":"Multi-module GRPO: Composing Policy Gradients and Prompt Optimization\n  for Language Model Programs","summary":"  Group Relative Policy Optimization (GRPO) has proven to be an effective tool\nfor post-training language models (LMs). However, AI systems are increasingly\nexpressed as modular programs that mix together multiple LM calls with distinct\nprompt templates and other tools, and it is not clear how best to leverage GRPO\nto improve these systems. We begin to address this challenge by defining\nmmGRPO, a simple multi-module generalization of GRPO that groups LM calls by\nmodule across rollouts and handles variable-length and interrupted\ntrajectories. We find that mmGRPO, composed with automatic prompt optimization,\nimproves accuracy by 11% on average across classification, many-hop search, and\nprivacy-preserving delegation tasks against the post-trained LM, and by 5%\nagainst prompt optimization on its own. We open-source mmGRPO in DSPy as the\ndspy.GRPO optimizer.\n","authors":["Noah Ziems","Dilara Soylu","Lakshya A Agrawal","Isaac Miller","Liheng Lai","Chen Qian","Kaiqiang Song","Meng Jiang","Dan Klein","Matei Zaharia","Karel D'Oosterlinck","Christopher Potts","Omar Khattab"],"pdf_url":"https://arxiv.org/pdf/2508.04660v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.05828v2","updated":"2025-08-06T17:19:50Z","published":"2025-06-06T07:53:58Z","title":"FinanceReasoning: Benchmarking Financial Numerical Reasoning More\n  Credible, Comprehensive and Challenging","summary":"  We introduce FinanceReasoning, a novel benchmark designed to evaluate the\nreasoning capabilities of large reasoning models (LRMs) in financial numerical\nreasoning problems. Compared to existing benchmarks, our work provides three\nkey advancements. (1) Credibility: We update 15.6% of the questions from four\npublic datasets, annotating 908 new questions with detailed Python solutions\nand rigorously refining evaluation standards. This enables an accurate\nassessment of the reasoning improvements of LRMs. (2) Comprehensiveness:\nFinanceReasoning covers 67.8% of financial concepts and formulas, significantly\nsurpassing existing datasets. Additionally, we construct 3,133 Python-formatted\nfunctions, which enhances LRMs' financial reasoning capabilities through\nrefined knowledge (e.g., 83.2% $\\rightarrow$ 91.6% for GPT-4o). (3) Challenge:\nModels are required to apply multiple financial formulas for precise numerical\nreasoning on 238 Hard problems. The best-performing model (i.e., OpenAI o1 with\nPoT) achieves 89.1% accuracy, yet LRMs still face challenges in numerical\nprecision. We demonstrate that combining Reasoner and Programmer models can\neffectively enhance LRMs' performance (e.g., 83.2% $\\rightarrow$ 87.8% for\nDeepSeek-R1). Our work paves the way for future research on evaluating and\nimproving LRMs in domain-specific complex reasoning tasks.\n","authors":["Zichen Tang","Haihong E","Ziyan Ma","Haoyang He","Jiacheng Liu","Zhongjun Yang","Zihua Rong","Rongjin Li","Kun Ji","Qing Huang","Xinyang Hu","Yang Liu","Qianhe Zheng"],"pdf_url":"https://arxiv.org/pdf/2506.05828v2.pdf","comment":"Accepted by ACL 2025 Main Conference"},{"id":"http://arxiv.org/abs/2508.04638v1","updated":"2025-08-06T17:04:58Z","published":"2025-08-06T17:04:58Z","title":"Can NLP Tackle Hate Speech in the Real World? Stakeholder-Informed\n  Feedback and Survey on Counterspeech","summary":"  Counterspeech, i.e. the practice of responding to online hate speech, has\ngained traction in NLP as a promising intervention. While early work emphasised\ncollaboration with non-governmental organisation stakeholders, recent research\ntrends have shifted toward automated pipelines that reuse a small set of legacy\ndatasets, often without input from affected communities. This paper presents a\nsystematic review of 74 NLP studies on counterspeech, analysing the extent to\nwhich stakeholder participation influences dataset creation, model development,\nand evaluation. To complement this analysis, we conducted a participatory case\nstudy with five NGOs specialising in online Gender-Based Violence (oGBV),\nidentifying stakeholder-informed practices for counterspeech generation. Our\nfindings reveal a growing disconnect between current NLP research and the needs\nof communities most impacted by toxic online content. We conclude with concrete\nrecommendations for re-centring stakeholder expertise in counterspeech\nresearch.\n","authors":["Tanvi Dinkar","Aiqi Jiang","Simona Frenda","Poppy Gerrard-Abbott","Nancie Gunson","Gavin Abercrombie","Ioannis Konstas"],"pdf_url":"https://arxiv.org/pdf/2508.04638v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04632v1","updated":"2025-08-06T17:00:54Z","published":"2025-08-06T17:00:54Z","title":"IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with\n  Verifiable Rewards","summary":"  Reinforcement Learning with Verifiable Rewards (RLVR) improves instruction\nfollowing capabilities of large language models (LLMs), but suffers from\ntraining inefficiency due to inadequate difficulty assessment. Moreover, RLVR\nis prone to over-optimization, where LLMs exploit verification shortcuts\nwithout aligning to the actual intent of user instructions. We introduce\nInstruction Following Decorator (IFDecorator}, a framework that wraps RLVR\ntraining into a robust and sample-efficient pipeline. It consists of three\ncomponents: (1) a cooperative-adversarial data flywheel that co-evolves\ninstructions and hybrid verifications, generating progressively more\nchallenging instruction-verification pairs; (2) IntentCheck, a bypass module\nenforcing intent alignment; and (3) trip wires, a diagnostic mechanism that\ndetects reward hacking via trap instructions, which trigger and capture\nshortcut exploitation behaviors. Our Qwen2.5-32B-Instruct-IFDecorator achieves\n87.43% accuracy on IFEval, outperforming larger proprietary models such as\nGPT-4o. Additionally, we demonstrate substantial improvements on FollowBench\nwhile preserving general capabilities. Our trip wires show significant\nreductions in reward hacking rates. We will release models, code, and data for\nfuture research.\n","authors":["Xu Guo","Tianyi Liang","Tong Jian","Xiaogui Yang","Ling-I Wu","Chenhui Li","Zhihui Lu","Qipeng Guo","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04632v1.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2412.04449v2","updated":"2025-08-06T16:57:39Z","published":"2024-12-05T18:58:03Z","title":"p-MoD: Building Mixture-of-Depths MLLMs via Progressive Ratio Decay","summary":"  Despite the remarkable performance of multimodal large language models\n(MLLMs) across diverse tasks, the substantial training and inference costs\nimpede their advancement. In this paper, we propose p-MoD, an efficient MLLM\narchitecture that significantly reduces training and inference costs while\nmaintaining model performance. The majority of computation in MLLMs stems from\nthe overwhelming volume of vision tokens processed by the transformer-based\nLLM. Accordingly, we leverage the Mixture-of-Depths (MoD) mechanism, where each\nLLM layer selects essential vision tokens to process while skipping redundant\nones. However, integrating MoD into MLLMs is non-trivial. To address the\nchallenges of training and inference stability as well as limited training\ndata, we adapt the MoD module with two novel designs: tanh-gated weight\nnormalization (TanhNorm) and symmetric token reweighting (STRing). Moreover, we\nobserve that vision tokens exhibit higher redundancy in deeper layers and thus\ndesign a progressive ratio decay (PRD) strategy, which gradually reduces the\ntoken retention ratio layer by layer, employing a shifted cosine schedule. This\ncrucial design fully unleashes the potential of MoD, significantly boosting the\nefficiency and performance of our models. Extensive experiments on two baseline\nmodels across 15 benchmarks show that our model matches or even surpasses the\nperformance of corresponding baselines, while requiring only 55.6% TFLOPs and\n53.7% KV cache storage during inference, and 77.7% GPU hours during training.\n","authors":["Jun Zhang","Desen Meng","Zhengming Zhang","Zhenpeng Huang","Tao Wu","Limin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.04449v2.pdf","comment":"Accepted by ICCV 2025; Code released at\n  https://github.com/MCG-NJU/p-MoD"},{"id":"http://arxiv.org/abs/2508.04626v1","updated":"2025-08-06T16:51:38Z","published":"2025-08-06T16:51:38Z","title":"P-Aligner: Enabling Pre-Alignment of Language Models via Principled\n  Instruction Synthesis","summary":"  Large Language Models (LLMs) are expected to produce safe, helpful, and\nhonest content during interaction with human users, but they frequently fail to\nalign with such values when given flawed instructions, e.g., missing context,\nambiguous directives, or inappropriate tone, leaving substantial room for\nimprovement along multiple dimensions. A cost-effective yet high-impact way is\nto pre-align instructions before the model begins decoding. Existing approaches\neither rely on prohibitive test-time search costs or end-to-end model rewrite,\nwhich is powered by a customized training corpus with unclear objectives. In\nthis work, we demonstrate that the goal of efficient and effective preference\nalignment can be achieved by P-Aligner, a lightweight module generating\ninstructions that preserve the original intents while being expressed in a more\nhuman-preferred form. P-Aligner is trained on UltraPrompt, a new dataset\nsynthesized via a proposed principle-guided pipeline using Monte-Carlo Tree\nSearch, which systematically explores the space of candidate instructions that\nare closely tied to human preference. Experiments across different methods show\nthat P-Aligner generally outperforms strong baselines across various models and\nbenchmarks, including average win-rate gains of 28.35% and 8.69% on GPT-4-turbo\nand Gemma-2-SimPO, respectively. Further analyses validate its effectiveness\nand efficiency through multiple perspectives, including data quality, search\nstrategies, iterative deployment, and time overhead.\n","authors":["Feifan Song","Bofei Gao","Yifan Song","Yi Liu","Weimin Xiong","Yuyang Song","Tianyu Liu","Guoyin Wang","Houfeng Wang"],"pdf_url":"https://arxiv.org/pdf/2508.04626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04623v1","updated":"2025-08-06T16:49:13Z","published":"2025-08-06T16:49:13Z","title":"Lightweight Transformers for Zero-Shot and Fine-Tuned Text-to-SQL\n  Generation Using Spider","summary":"  Text-to-SQL translation enables non-expert users to query relational\ndatabases using natural language, with applications in education and business\nintelligence. This study evaluates three lightweight transformer models -\nT5-Small, BART-Small, and GPT-2 - on the Spider dataset, focusing on\nlow-resource settings. We developed a reusable, model-agnostic pipeline that\ntailors schema formatting to each model's architecture, training them across\n1000 to 5000 iterations and evaluating on 1000 test samples using Logical Form\nAccuracy (LFAcc), BLEU, and Exact Match (EM) metrics. Fine-tuned T5-Small\nachieves the highest LFAcc (27.8%), outperforming BART-Small (23.98%) and GPT-2\n(20.1%), highlighting encoder-decoder models' superiority in schema-aware SQL\ngeneration. Despite resource constraints limiting performance, our pipeline's\nmodularity supports future enhancements, such as advanced schema linking or\nalternative base models. This work underscores the potential of compact\ntransformers for accessible text-to-SQL solutions in resource-scarce\nenvironments.\n","authors":["Chirag Seth","Utkarsh Singh"],"pdf_url":"https://arxiv.org/pdf/2508.04623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00222v3","updated":"2025-08-06T16:36:42Z","published":"2025-07-31T23:55:29Z","title":"RL-PLUS: Countering Capability Boundary Collapse of LLMs in\n  Reinforcement Learning with Hybrid-policy Optimization","summary":"  Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its essentially on-policy strategy coupled with LLM's\nimmense action space and sparse reward. Critically, RLVR can lead to the\ncapability boundary collapse, narrowing the LLM's problem-solving scope. To\naddress this problem, we propose RL-PLUS, a novel hybrid-policy optimization\napproach for LLMs that synergizes internal exploitation with external data to\nachieve stronger reasoning capabilities and surpass the boundaries of base\nmodels. RL-PLUS integrates two core components, i.e., Multiple Importance\nSampling to address distributional mismatch from external data, and\nExploration-Based Advantage Function to guide the model towards high-value,\nunexplored reasoning paths. We provide both theoretical analysis and extensive\nexperiments to demonstrate the superiority and generalizability of our\napproach. Compared with existing RLVR methods, RL-PLUS achieves 1)\nstate-of-the-art performance on six math reasoning benchmarks; 2) superior\nperformance on six out-of-distribution reasoning tasks; 3) consistent and\nsignificant gains across diverse model families, with average relative\nimprovements up to 69.2\\%. Moreover, the analysis of Pass@k curves indicates\nthat RL-PLUS effectively resolves the capability boundary collapse problem.\n","authors":["Yihong Dong","Xue Jiang","Yongding Tao","Huanyu Liu","Kechi Zhang","Lili Mou","Rongyu Cao","Yingwei Ma","Jue Chen","Binhua Li","Zhi Jin","Fei Huang","Yongbin Li","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2508.00222v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.04618v4","updated":"2025-08-06T16:33:12Z","published":"2024-03-07T16:02:31Z","title":"Strong Priority and Determinacy in Timed CCS","summary":"  Building on the standard theory of process algebra with priorities, we\nidentify a new scheduling mechanism, called \"constructive reduction\" which is\ndesigned to capture the essence of synchronous programming. The distinctive\nproperty of this evaluation strategy is to achieve determinacy-by-construction\nfor multi-cast concurrent communication with shared memory. In the technical\nsetting of CCS extended by clocks and priorities, we prove for a large class of\n\"coherent\" processes a confluence property for constructive reductions. We show\nthat under some restrictions, called \"pivotability\", coherence is preserved by\nthe operators of prefix, summation, parallel composition, restriction and\nhiding. Since this permits memory and sharing, we are able to cover a strictly\nlarger class of processes compared to those in Milner's classical confluence\ntheory for CCS without priorities.\n","authors":["Luigi Liquori","Michael Mendler"],"pdf_url":"https://arxiv.org/pdf/2403.04618v4.pdf","comment":"Change Notes (06.08.25): Streamlined the definition of coherence and\n  non-interference; Corrections in Def.~14 for coherence, adding condition on\n  residual transitions; Adjusted coding of Esterel signals (Ex.~11) to match\n  adjusted Def.~14; To reflect changed Def.~14, use the term \"c-coherence'';\n  Minor rewrite of Sec.~2.3 and Sec.~4; Further corrections and revisions in\n  Appendices"},{"id":"http://arxiv.org/abs/2508.04604v1","updated":"2025-08-06T16:24:17Z","published":"2025-08-06T16:24:17Z","title":"TURA: Tool-Augmented Unified Retrieval Agent for AI Search","summary":"  The advent of Large Language Models (LLMs) is transforming search engines\ninto conversational AI search products, primarily using Retrieval-Augmented\nGeneration (RAG) on web corpora. However, this paradigm has significant\nindustrial limitations. Traditional RAG approaches struggle with real-time\nneeds and structured queries that require accessing dynamically generated\ncontent like ticket availability or inventory. Limited to indexing static\npages, search engines cannot perform the interactive queries needed for such\ntime-sensitive data. Academic research has focused on optimizing RAG for static\ncontent, overlooking complex intents and the need for dynamic sources like\ndatabases and real-time APIs. To bridge this gap, we introduce TURA\n(Tool-Augmented Unified Retrieval Agent for AI Search), a novel three-stage\nframework that combines RAG with agentic tool-use to access both static content\nand dynamic, real-time information. TURA has three key components: an\nIntent-Aware Retrieval module to decompose queries and retrieve information\nsources encapsulated as Model Context Protocol (MCP) Servers, a DAG-based Task\nPlanner that models task dependencies as a Directed Acyclic Graph (DAG) for\noptimal parallel execution, and a lightweight Distilled Agent Executor for\nefficient tool calling. TURA is the first architecture to systematically bridge\nthe gap between static RAG and dynamic information sources for a world-class AI\nsearch product. Serving tens of millions of users, it leverages an agentic\nframework to deliver robust, real-time answers while meeting the low-latency\ndemands of a large-scale industrial system.\n","authors":["Zhejun Zhao","Yuehu Dong","Alley Liu","Lixue Zheng","Pingsheng Liu","Dongdong Shen","Long Xia","Jiashu Zhao","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2508.04604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15877v2","updated":"2025-08-06T16:19:30Z","published":"2024-05-24T18:40:20Z","title":"Basis Selection: Low-Rank Decomposition of Pretrained Large Language\n  Models for Target Applications","summary":"  Large language models (LLMs) significantly enhance the performance of various\napplications, but they are computationally intensive and energy-demanding. This\nmakes it challenging to deploy them on devices with limited resources, such as\npersonal computers and mobile/wearable devices, and results in substantial\ninference costs in resource-rich environments like cloud servers. To extend the\nuse of LLMs, we introduce a low-rank decomposition approach to effectively\ncompress these models, tailored to the requirements of specific applications.\nWe observe that LLMs pretrained on general datasets contain many redundant\ncomponents not needed for particular applications. Our method focuses on\nidentifying and removing these redundant parts, retaining only the necessary\nelements for the target applications. Specifically, we represent the weight\nmatrices of LLMs as a linear combination of base components. We then prune the\nirrelevant bases and enhance the model with new bases beneficial for specific\napplications. Deep compression results on the Llama 2-7b and -13B models,\nconducted on target applications including mathematical reasoning and code\ngeneration, show that our method significantly reduces model size while\nmaintaining comparable accuracy to state-of-the-art low-rank compression\ntechniques.\n","authors":["Yang Li","Daniel Agyei Asante","Changsheng Zhao","Ernie Chang","Yangyang Shi","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2405.15877v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04586v1","updated":"2025-08-06T16:08:27Z","published":"2025-08-06T16:08:27Z","title":"Position: The Current AI Conference Model is Unsustainable! Diagnosing\n  the Crisis of Centralized AI Conference","summary":"  Artificial Intelligence (AI) conferences are essential for advancing\nresearch, sharing knowledge, and fostering academic community. However, their\nrapid expansion has rendered the centralized conference model increasingly\nunsustainable. This paper offers a data-driven diagnosis of a structural crisis\nthat threatens the foundational goals of scientific dissemination, equity, and\ncommunity well-being. We identify four key areas of strain: (1) scientifically,\nwith per-author publication rates more than doubling over the past decade to\nover 4.5 papers annually; (2) environmentally, with the carbon footprint of a\nsingle conference exceeding the daily emissions of its host city; (3)\npsychologically, with 71% of online community discourse reflecting negative\nsentiment and 35% referencing mental health concerns; and (4) logistically,\nwith attendance at top conferences such as NeurIPS 2024 beginning to outpace\nvenue capacity. These pressures point to a system that is misaligned with its\ncore mission. In response, we propose the Community-Federated Conference (CFC)\nmodel, which separates peer review, presentation, and networking into globally\ncoordinated but locally organized components, offering a more sustainable,\ninclusive, and resilient path forward for AI research.\n","authors":["Nuo Chen","Moming Duan","Andre Huikai Lin","Qian Wang","Jiaying Wu","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2508.04586v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2502.16781v2","updated":"2025-08-06T16:07:06Z","published":"2025-02-24T02:16:37Z","title":"Evaluating Robustness of LLMs in Question Answering on Multilingual\n  Noisy OCR Data","summary":"  Optical Character Recognition (OCR) plays a crucial role in digitizing\nhistorical and multilingual documents, yet OCR errors - imperfect extraction of\ntext, including character insertion, deletion, and substitution can\nsignificantly impact downstream tasks like question-answering (QA). In this\nwork, we conduct a comprehensive analysis of how OCR-induced noise affects the\nperformance of Multilingual QA Systems. To support this analysis, we introduce\na multilingual QA dataset MultiOCR-QA, comprising 50K question-answer pairs\nacross three languages, English, French, and German. The dataset is curated\nfrom OCR-ed historical documents, which include different levels and types of\nOCR noise. We then evaluate how different state-of-the-art Large Language\nmodels (LLMs) perform under different error conditions, focusing on three major\nOCR error types. Our findings show that QA systems are highly prone to\nOCR-induced errors and perform poorly on noisy OCR text. By comparing model\nperformance on clean versus noisy texts, we provide insights into the\nlimitations of current approaches and emphasize the need for more\nnoise-resilient QA systems in historical digitization contexts.\n","authors":["Bhawna Piryani","Jamshid Mozafari","Abdelrahman Abdallah","Antoine Doucet","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2502.16781v2.pdf","comment":"Accepted at CIKM 2025"},{"id":"http://arxiv.org/abs/2507.17937v2","updated":"2025-08-06T16:06:47Z","published":"2025-07-23T21:11:47Z","title":"Bob's Confetti: Phonetic Memorization Attacks in Music and Video\n  Generation","summary":"  Memorization in generative models extends far beyond verbatim text\nreproduction--it manifests through non-literal patterns, semantic associations,\nand surprisingly, across modalities in transcript-conditioned generation tasks\nsuch as Lyrics-to-Song (L2S) and Text-to-Video (T2V) models. We reveal a new\nclass of cross-modality memorization where models trained on these tasks leak\ncopyrighted content through indirect, phonetic pathways invisible to\ntraditional text-based analysis. In this work, we introduce Adversarial\nPhoneTic Prompting (APT), an attack that replaces iconic phrases with\nhomophonic alternatives--e.g., \"mom's spaghetti\" becomes \"Bob's\nconfetti\"--preserving the acoustic form while largely changing semantic\ncontent. We demonstrate that models can be prompted to regurgitate memorized\nsongs using phonetically similar but semantically unrelated lyrics. Despite the\nsemantic drift, black-box models like SUNO and open-source models like YuE\ngenerate outputs that are strikingly similar to the original\nsongs--melodically, rhythmically, and vocally--achieving high scores on\nAudioJudge, CLAP, and CoverID. These effects persist across genres and\nlanguages. More surprisingly, we find that phonetic prompts alone can trigger\nvisual memorization in text-to-video models: when given altered lyrics from\nLose Yourself, Veo 3 generates scenes that mirror the original music\nvideo--complete with a hooded rapper and dim urban settings--despite no\nexplicit visual cues in the prompt. This cross-modality leakage represents an\nunprecedented threat: models memorize deep, structural patterns that transcend\ntheir training modality, making traditional safety measures like copyright\nfilters ineffective. Our findings reveal a fundamental vulnerability in\ntranscript-conditioned generative models and raise urgent concerns around\ncopyright, provenance, and secure deployment of multimodal generation systems.\n","authors":["Jaechul Roh","Zachary Novack","Yuefeng Peng","Niloofar Mireshghallah","Taylor Berg-Kirkpatrick","Amir Houmansadr"],"pdf_url":"https://arxiv.org/pdf/2507.17937v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04581v1","updated":"2025-08-06T16:06:43Z","published":"2025-08-06T16:06:43Z","title":"Share Your Attention: Transformer Weight Sharing via Matrix-based\n  Dictionary Learning","summary":"  Large language models (LLMs) have revolutionized AI applications, yet their\nhigh computational and memory demands hinder their widespread deployment.\nExisting compression techniques focus on intra-block optimizations (e.g.\nlow-rank approximation, attention head pruning), while the repetitive layered\nstructure of transformers implies significant inter-block redundancy - a\ndimension largely unexplored beyond key-value (KV) caching. Inspired by\ndictionary learning in CNNs, we propose a framework for structured weight\nsharing across transformer layers. Our approach decomposes attention projection\nmatrices into shared dictionary atoms, reducing the attention module's\nparameters by 66.7% while achieving on-par performance. Unlike complex methods\nrequiring distillation or architectural changes, MASA (Matrix Atom Sharing in\nAttention) operates as a drop-in replacement - trained with standard optimizers\n- and represents each layer's weights as linear combinations of shared matrix\natoms. Experiments across scales (100M-700M parameters) show that MASA achieves\nbetter benchmark accuracy and perplexity than grouped-query attention (GQA),\nlow-rank baselines and recently proposed Repeat-all-over/Sequential sharing at\ncomparable parameter budgets. Ablation studies confirm robustness to the\ndictionary size and the efficacy of shared representations in capturing\ncross-layer statistical regularities. Extending to Vision Transformers (ViT),\nMASA matches performance metrics on image classification and detection tasks\nwith 66.7% fewer attention parameters. By combining dictionary learning\nstrategies with transformer efficiency, MASA offers a scalable blueprint for\nparameter-efficient models without sacrificing performance. Finally, we\ninvestigate the possibility of employing MASA on pretrained LLMs to reduce\ntheir number of parameters without experiencing any significant drop in their\nperformance.\n","authors":["Magauiya Zhussip","Dmitriy Shopkhoev","Ammar Ali","Stamatios Lefkimmiatis"],"pdf_url":"https://arxiv.org/pdf/2508.04581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04575v1","updated":"2025-08-06T15:59:18Z","published":"2025-08-06T15:59:18Z","title":"Beyond Brainstorming: What Drives High-Quality Scientific Ideas? Lessons\n  from Multi-Agent Collaboration","summary":"  While AI agents show potential in scientific ideation, most existing\nframeworks rely on single-agent refinement, limiting creativity due to bounded\nknowledge and perspective. Inspired by real-world research dynamics, this paper\ninvestigates whether structured multi-agent discussions can surpass solitary\nideation. We propose a cooperative multi-agent framework for generating\nresearch proposals and systematically compare configurations including group\nsize, leaderled versus leaderless structures, and team compositions varying in\ninterdisciplinarity and seniority. To assess idea quality, we employ a\ncomprehensive protocol with agent-based scoring and human review across\ndimensions such as novelty, strategic vision, and integration depth. Our\nresults show that multi-agent discussions substantially outperform solitary\nbaselines. A designated leader acts as a catalyst, transforming discussion into\nmore integrated and visionary proposals. Notably, we find that cognitive\ndiversity is a primary driver of quality, yet expertise is a non-negotiable\nprerequisite, as teams lacking a foundation of senior knowledge fail to surpass\neven a single competent agent. These findings offer actionable insights for\ndesigning collaborative AI ideation systems and shed light on how team\nstructure influences creative outcomes.\n","authors":["Nuo Chen","Yicheng Tong","Jiaying Wu","Minh Duc Duong","Qian Wang","Qingyun Zou","Bryan Hooi","Bingsheng He"],"pdf_url":"https://arxiv.org/pdf/2508.04575v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2508.04571v1","updated":"2025-08-06T15:53:58Z","published":"2025-08-06T15:53:58Z","title":"Do Recommender Systems Really Leverage Multimodal Content? A\n  Comprehensive Analysis on Multimodal Representations for Recommendation","summary":"  Multimodal Recommender Systems aim to improve recommendation accuracy by\nintegrating heterogeneous content, such as images and textual metadata. While\neffective, it remains unclear whether their gains stem from true multimodal\nunderstanding or increased model complexity. This work investigates the role of\nmultimodal item embeddings, emphasizing the semantic informativeness of the\nrepresentations. Initial experiments reveal that embeddings from standard\nextractors (e.g., ResNet50, Sentence-Bert) enhance performance, but rely on\nmodality-specific encoders and ad hoc fusion strategies that lack control over\ncross-modal alignment. To overcome these limitations, we leverage Large\nVision-Language Models (LVLMs) to generate multimodal-by-design embeddings via\nstructured prompts. This approach yields semantically aligned representations\nwithout requiring any fusion. Experiments across multiple settings show notable\nperformance improvements. Furthermore, LVLMs embeddings offer a distinctive\nadvantage: they can be decoded into structured textual descriptions, enabling\ndirect assessment of their multimodal comprehension. When such descriptions are\nincorporated as side content into recommender systems, they improve\nrecommendation performance, empirically validating the semantic depth and\nalignment encoded within LVLMs outputs. Our study highlights the importance of\nsemantically rich representations and positions LVLMs as a compelling\nfoundation for building robust and meaningful multimodal representations in\nrecommendation tasks.\n","authors":["Claudio Pomo","Matteo Attimonelli","Danilo Danese","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2508.04571v1.pdf","comment":"Accepted as Full Research Papers at CIKM 2025"},{"id":"http://arxiv.org/abs/2508.04567v1","updated":"2025-08-06T15:51:02Z","published":"2025-08-06T15:51:02Z","title":"Analyzing and Mitigating Object Hallucination: A Training Bias\n  Perspective","summary":"  As scaling up training data has significantly improved the general multimodal\ncapabilities of Large Vision-Language Models (LVLMs), they still suffer from\nthe hallucination issue, generating text that is inconsistent with the visual\ninput. This phenomenon motivates us to systematically investigate the role of\ntraining data in hallucination. We introduce a new benchmark, POPEv2, which\nconsists of counterfactual images collected from the training data of LVLMs\nwith certain objects masked. Through comprehensive evaluation on POPEv2, we\nfind that current LVLMs suffer from training bias: they fail to fully leverage\ntheir training data and hallucinate more frequently on images seen during\ntraining. Specifically, they perform poorly on counterfactual images, often\nincorrectly answering ``Yes'' to questions about masked objects. To understand\nthis issue, we conduct probing experiments on the models' internal components,\nrevealing that this training bias is primarily located in the language modeling\n(LM) head. Based on these findings, we propose Obliviate, an efficient and\nlightweight unlearning method designed to mitigate object hallucination via\ntraining bias unlearning. Obliviate identifies the discrepancy between\nground-truth labels and model outputs on the training data as a proxy for bias\nand adopts a parameter- and data-efficient fine-tuning strategy that only\nupdates the LM head. Extensive experiments demonstrate the effectiveness of our\napproach. While only reusing the training data and updating approximately 2\\%\nof the parameters, Obliviate significantly reduces hallucination across both\ndiscriminative and generative tasks. Furthermore, it demonstrates strong\nscalability with respect to both model size (2B to 72B) and training data\nvolume, and exhibits promising generalization to hallucination types beyond\nobject-level hallucination. Our code and data will be publicly released.\n","authors":["Yifan Li","Kun Zhou","Wayne Xin Zhao","Lei Fang","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2508.04567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2502.15434v3","updated":"2025-08-06T15:35:58Z","published":"2025-02-21T13:01:26Z","title":"Mixup Model Merge: Enhancing Model Merging Performance through\n  Randomized Linear Interpolation","summary":"  Model merging aims to integrate multiple task-specific models into a unified\nmodel that inherits the capabilities of the task-specific models, without\nadditional training. Existing model merging methods often lack consideration of\nthe varying contribution ratios of different task-specific models to the final\nmerged model. In this paper, we propose Mixup Model Merge (M3), a simple yet\neffective method inspired by the randomized linear interpolation strategy from\nthe Mixup data augmentation technique. M3 performs randomized linear\ninterpolation in parameter space between two task-specific LLMs, where\ninterpolation coefficients are sampled from a Beta distribution to explore\ndiverse contribution ratios. This controllable randomness allows M3 to\noutperform standard equal-ratio merging by discovering better contribution\nratio combinations. Extensive experiments show that M3 significantly (1)\nimproves merged LLM performance across tasks, (2) enhances out-of-distribution\nand adversarial robustness, (3) outperforms the positive effects of the\nsparsification method DARE on model merging and can be further combined with\nDARE to achieve superior results, and (4) balances exploration efficiency and\ndiversity in contribution ratios by tuning the Beta distribution's shape\nparameters. The code is provided in the supplementary materials.\n","authors":["Yue Zhou","Yi Chang","Yuan Wu"],"pdf_url":"https://arxiv.org/pdf/2502.15434v3.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2504.14194v4","updated":"2025-08-06T15:34:10Z","published":"2025-04-19T06:12:33Z","title":"Meta-rater: A Multi-dimensional Data Selection Method for Pre-training\n  Language Models","summary":"  The composition of pre-training datasets for large language models (LLMs)\nremains largely undisclosed, hindering transparency and efforts to optimize\ndata quality, a critical driver of model performance. Current data selection\nmethods, such as natural language quality assessments, diversity-based filters,\nand classifier-based approaches, are limited by single-dimensional evaluation\nor redundancy-focused strategies. To address these gaps, we propose four\ndimensions to evaluate data quality: professionalism, readability, reasoning,\nand cleanliness. We further introduce Meta-rater,a multi-dimensional data\nselection method that integrates these dimensions with existing quality metrics\nthrough learned optimal weightings. Meta-rater employs proxy models to train a\nregression model that predicts validation loss, enabling the identification of\noptimal combinations of quality scores. Experiments demonstrate that Meta-rater\ndoubles convergence speed for 1.3B parameter models and improves downstream\ntask performance by 3.23, with advantages that scale to models as large as 7.2B\nparameters. Our work establishes that holistic, multi-dimensional quality\nintegration significantly outperforms conventional single-dimension approaches,\noffering a scalable paradigm for enhancing pre-training efficiency and model\ncapability. To advance future research, we release scripts, data, and models at\nhttps://github.com/opendatalab/Meta-rater.\n","authors":["Xinlin Zhuang","Jiahui Peng","Ren Ma","Yinfan Wang","Tianyi Bai","Xingjian Wei","Jiantao Qiu","Chi Zhang","Ying Qian","Conghui He"],"pdf_url":"https://arxiv.org/pdf/2504.14194v4.pdf","comment":"ACL 2025 Best Theme Paper Award"},{"id":"http://arxiv.org/abs/2508.03440v2","updated":"2025-08-06T15:16:05Z","published":"2025-08-05T13:38:33Z","title":"LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of\n  Large Reasoning Models","summary":"  Human cognition naturally engages with abstract and fluid concepts, whereas\nexisting reasoning models often rely on generating discrete tokens, potentially\nconstraining their expressive capabilities. Recent advancements aim to address\nthis limitation by enabling large language models (LLMs) to generate soft,\nabstract tokens, thus facilitating reasoning within a continuous concept space.\nThis paper explores the `Soft Thinking' capabilities of various LLMs by\nexamining the models' internal behavior using a suite of probing techniques.\nContrary to the common belief that Soft Thinking enables the simultaneous\nexploration of diverse reasoning paths, our findings reveal that LLMs\npredominantly rely on the most influential component of the soft inputs during\nsubsequent decoding steps. This reliance hinders the exploration of different\nreasoning paths and reduces vanilla Soft Thinking to a form of greedy decoding,\nobscuring the advantage of transmitting more information through Soft Tokens.\nTo tackle this issue, we explore sampling strategies to introduce\n\\emph{randomness}, employing methods such as Dirichlet resampling and the\nGumbel-Softmax trick. Our experiments demonstrate that incorporating randomness\ncan alleviate the limitations of vanilla approaches and unleash the potential\nof Soft Thinking. Notably, the Gumbel-Softmax trick provides adequate\nrandomness with controlled smoothness, resulting in superior performance across\neight reasoning benchmarks.\n","authors":["Chünhung Wu","Jinliang Lu","Zixuan Ren","Gangqiang Hu","Zhi Wu","Dai Dai","Hua Wu"],"pdf_url":"https://arxiv.org/pdf/2508.03440v2.pdf","comment":"10 pages, 7 figures, working in progress"},{"id":"http://arxiv.org/abs/2508.04531v1","updated":"2025-08-06T15:13:24Z","published":"2025-08-06T15:13:24Z","title":"Unveiling the Landscape of Clinical Depression Assessment: From\n  Behavioral Signatures to Psychiatric Reasoning","summary":"  Depression is a widespread mental disorder that affects millions worldwide.\nWhile automated depression assessment shows promise, most studies rely on\nlimited or non-clinically validated data, and often prioritize complex model\ndesign over real-world effectiveness. In this paper, we aim to unveil the\nlandscape of clinical depression assessment. We introduce C-MIND, a clinical\nneuropsychiatric multimodal diagnosis dataset collected over two years from\nreal hospital visits. Each participant completes three structured psychiatric\ntasks and receives a final diagnosis from expert clinicians, with informative\naudio, video, transcript, and functional near-infrared spectroscopy (fNIRS)\nsignals recorded. Using C-MIND, we first analyze behavioral signatures relevant\nto diagnosis. We train a range of classical models to quantify how different\ntasks and modalities contribute to diagnostic performance, and dissect the\neffectiveness of their combinations. We then explore whether LLMs can perform\npsychiatric reasoning like clinicians and identify their clear limitations in\nrealistic clinical settings. In response, we propose to guide the reasoning\nprocess with clinical expertise and consistently improves LLM diagnostic\nperformance by up to 10% in Macro-F1 score. We aim to build an infrastructure\nfor clinical depression assessment from both data and algorithmic perspectives,\nenabling C-MIND to facilitate grounded and reliable research for mental\nhealthcare.\n","authors":["Zhuang Chen","Guanqun Bi","Wen Zhang","Jiawei Hu","Aoyun Wang","Xiyao Xiao","Kun Feng","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2508.04531v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04530v1","updated":"2025-08-06T15:12:05Z","published":"2025-08-06T15:12:05Z","title":"StyliTruth : Unlocking Stylized yet Truthful LLM Generation via\n  Disentangled Steering","summary":"  Generating stylized large language model (LLM) responses via representation\nediting is a promising way for fine-grained output control. However, there\nexists an inherent trade-off: imposing a distinctive style often degrades\ntruthfulness. Existing representation editing methods, by naively injecting\nstyle signals, overlook this collateral impact and frequently contaminate the\nmodel's core truthfulness representations, resulting in reduced answer\ncorrectness. We term this phenomenon stylization-induced truthfulness collapse.\nWe attribute this issue to latent coupling between style and truth directions\nin certain key attention heads, and propose StyliTruth, a mechanism that\npreserves stylization while keeping truthfulness intact. StyliTruth separates\nthe style-relevant and truth-relevant subspaces in the model's representation\nspace via an orthogonal deflation process. This decomposition enables\nindependent control of style and truth in their own subspaces, minimizing\ninterference. By designing adaptive, token-level steering vectors within each\nsubspace, we dynamically and precisely control the generation process to\nmaintain both stylistic fidelity and truthfulness. We validate our method on\nmultiple styles and languages. Extensive experiments and analyses show that\nStyliTruth significantly reduces stylization-induced truthfulness collapse and\noutperforms existing inference-time intervention methods in balancing style\nadherence with truthfulness.\n","authors":["Chenglei Shen","Zhongxiang Sun","Teng Shi","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2508.04530v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15787v4","updated":"2025-08-06T15:09:52Z","published":"2025-06-18T18:10:30Z","title":"SLR: Automated Synthesis for Scalable Logical Reasoning","summary":"  We introduce SLR, an end-to-end framework for systematic evaluation and\ntraining of Large Language Models (LLMs) via Scalable Logical Reasoning. Given\na user's task specification, SLR automatically synthesizes (i) an instruction\nprompt for an inductive reasoning task, (ii) a validation program, executable\non model outputs to provide verifiable rewards, and (iii) the latent\nground-truth rule. This process is fully automated, scalable, requires no human\nannotations, and offers precise control over task difficulty. Using SLR, we\ncreate SLR-Bench, a benchmark comprising 19k prompts organized into 20\ncurriculum levels that progressively increase in relational, arithmetic, and\nrecursive complexity. Large-scale evaluation reveals that contemporary LLMs\nreadily produce syntactically valid rules, yet often fail at correct logical\ninference. Recent reasoning LLMs demonstrate improved performance but incur\nvery high test-time computation, with costs exceeding $300 for just 1,000\nprompts. Finally, curriculum learning via SLR doubles Llama-3-8B accuracy on\nSLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of\ncomputational cost. Moreover, these reasoning capabilities generalize to a wide\nrange of established benchmarks, underscoring the effectiveness of SLR for\ndownstream reasoning.\n","authors":["Lukas Helff","Ahmad Omar","Felix Friedrich","Antonia Wüst","Hikaru Shindo","Rupert Mitchell","Tim Woydt","Patrick Schramowski","Wolfgang Stammer","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2506.15787v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.22716v2","updated":"2025-08-06T14:53:31Z","published":"2025-07-30T14:29:44Z","title":"From Sufficiency to Reflection: Reinforcement-Guided Thinking Quality in\n  Retrieval-Augmented Reasoning for LLMs","summary":"  Reinforcement learning-based retrieval-augmented generation (RAG) methods\nenhance the reasoning abilities of large language models (LLMs). However, most\nrely only on final-answer rewards, overlooking intermediate reasoning quality.\nThis paper analyzes existing RAG reasoning models and identifies three main\nfailure patterns: (1) information insufficiency, meaning the model fails to\nretrieve adequate support; (2) faulty reasoning, where logical or content-level\nflaws appear despite sufficient information; and (3) answer-reasoning\ninconsistency, where a valid reasoning chain leads to a mismatched final\nanswer. We propose TIRESRAG-R1, a novel framework using a\nthink-retrieve-reflect process and a multi-dimensional reward system to improve\nreasoning and stability. TIRESRAG-R1 introduces: (1) a sufficiency reward to\nencourage thorough retrieval; (2) a reasoning quality reward to assess the\nrationality and accuracy of the reasoning chain; and (3) a reflection reward to\ndetect and revise errors. It also employs a difficulty-aware reweighting\nstrategy and training sample filtering to boost performance on complex tasks.\nExperiments on four multi-hop QA datasets show that TIRESRAG-R1 outperforms\nprior RAG methods and generalizes well to single-hop tasks. The code and data\nare available at: https://github.com/probe2/TIRESRAG-R1.\n","authors":["Jie He","Victor Gutiérrez-Basulto","Jeff Z. Pan"],"pdf_url":"https://arxiv.org/pdf/2507.22716v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04495v1","updated":"2025-08-06T14:44:23Z","published":"2025-08-06T14:44:23Z","title":"Causal Reflection with Language Models","summary":"  While LLMs exhibit impressive fluency and factual recall, they struggle with\nrobust causal reasoning, often relying on spurious correlations and brittle\npatterns. Similarly, traditional Reinforcement Learning agents also lack causal\nunderstanding, optimizing for rewards without modeling why actions lead to\noutcomes. We introduce Causal Reflection, a framework that explicitly models\ncausality as a dynamic function over state, action, time, and perturbation,\nenabling agents to reason about delayed and nonlinear effects. Additionally, we\ndefine a formal Reflect mechanism that identifies mismatches between predicted\nand observed outcomes and generates causal hypotheses to revise the agent's\ninternal model. In this architecture, LLMs serve not as black-box reasoners,\nbut as structured inference engines translating formal causal outputs into\nnatural language explanations and counterfactuals. Our framework lays the\ntheoretical groundwork for Causal Reflective agents that can adapt,\nself-correct, and communicate causal understanding in evolving environments.\n","authors":["Abi Aryan","Zac Liu"],"pdf_url":"https://arxiv.org/pdf/2508.04495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04494v1","updated":"2025-08-06T14:43:22Z","published":"2025-08-06T14:43:22Z","title":"CALE : Concept-Aligned Embeddings for Both Within-Lemma and Inter-Lemma\n  Sense Differentiation","summary":"  Lexical semantics is concerned with both the multiple senses a word can adopt\nin different contexts, and the semantic relations that exist between meanings\nof different words. To investigate them, Contextualized Language Models are a\nvaluable tool that provides context-sensitive representations that can be used\nto investigate lexical meaning. Recent works like XL-LEXEME have leveraged the\ntask of Word-in-Context to fine-tune them to get more semantically accurate\nrepresentations, but Word-in-Context only compares occurrences of the same\nlemma, limiting the range of captured information. In this paper, we propose an\nextension, Concept Differentiation, to include inter-words scenarios. We\nprovide a dataset for this task, derived from SemCor data. Then we fine-tune\nseveral representation models on this dataset. We call these models\nConcept-Aligned Embeddings (CALE). By challenging our models and other models\non various lexical semantic tasks, we demonstrate that the proposed models\nprovide efficient multi-purpose representations of lexical meaning that reach\nbest performances in our experiments. We also show that CALE's fine-tuning\nbrings valuable changes to the spatial organization of embeddings.\n","authors":["Bastien Liétard","Gabriel Loiseau"],"pdf_url":"https://arxiv.org/pdf/2508.04494v1.pdf","comment":"Under review in ARR July 2025"},{"id":"http://arxiv.org/abs/2508.04482v1","updated":"2025-08-06T14:33:45Z","published":"2025-08-06T14:33:45Z","title":"OS Agents: A Survey on MLLM-based Agents for General Computing Devices\n  Use","summary":"  The dream to create AI assistants as capable and versatile as the fictional\nJ.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution\nof (multi-modal) large language models ((M)LLMs), this dream is closer to\nreality, as (M)LLM-based Agents using computing devices (e.g., computers and\nmobile phones) by operating within the environments and interfaces (e.g.,\nGraphical User Interface (GUI)) provided by operating systems (OS) to automate\ntasks have significantly advanced. This paper presents a comprehensive survey\nof these advanced agents, designated as OS Agents. We begin by elucidating the\nfundamentals of OS Agents, exploring their key components including the\nenvironment, observation space, and action space, and outlining essential\ncapabilities such as understanding, planning, and grounding. We then examine\nmethodologies for constructing OS Agents, focusing on domain-specific\nfoundation models and agent frameworks. A detailed review of evaluation\nprotocols and benchmarks highlights how OS Agents are assessed across diverse\ntasks. Finally, we discuss current challenges and identify promising directions\nfor future research, including safety and privacy, personalization and\nself-evolution. This survey aims to consolidate the state of OS Agents\nresearch, providing insights to guide both academic inquiry and industrial\ndevelopment. An open-source GitHub repository is maintained as a dynamic\nresource to foster further innovation in this field. We present a 9-page\nversion of our work, accepted by ACL 2025, to provide a concise overview to the\ndomain.\n","authors":["Xueyu Hu","Tao Xiong","Biao Yi","Zishu Wei","Ruixuan Xiao","Yurun Chen","Jiasheng Ye","Meiling Tao","Xiangxin Zhou","Ziyu Zhao","Yuhuai Li","Shengze Xu","Shenzhi Wang","Xinchen Xu","Shuofei Qiao","Zhaokai Wang","Kun Kuang","Tieyong Zeng","Liang Wang","Jiwei Li","Yuchen Eleanor Jiang","Wangchunshu Zhou","Guoyin Wang","Keting Yin","Zhou Zhao","Hongxia Yang","Fan Wu","Shengyu Zhang","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2508.04482v1.pdf","comment":"ACL 2025 (Oral)"},{"id":"http://arxiv.org/abs/2508.04469v1","updated":"2025-08-06T14:12:05Z","published":"2025-08-06T14:12:05Z","title":"FrEVL: Leveraging Frozen Pretrained Embeddings for Efficient\n  Vision-Language Understanding","summary":"  The deployment of vision-language models remains constrained by substantial\ncomputational requirements. We present \\textbf{FrEVL}, a framework exploring\nwhether frozen pretrained embeddings can support effective vision-language\nunderstanding. Our analysis reveals that frozen embeddings contain rich\ninformation for discriminative tasks, achieving 85\\% to 95\\% of\nstate-of-the-art performance on standard benchmarks with only 68.4M trainable\nparameters. This performance dichotomy reveals a critical insight: frozen\nembedding effectiveness depends on alignment between pretraining objectives and\ndownstream task requirements. When accounting for end-to-end computation\nincluding embedding extraction, FrEVL provides $2.3\\times$ speedup with 52\\%\nlower energy consumption, making it suitable for scenarios with pre-computable\ninputs or when deployment constraints outweigh marginal performance gains. Our\nevaluation provides practitioners with guidance on when frozen embedding\napproaches represent viable alternatives to full model deployment. We will\nrelease our complete implementation and evaluation framework to facilitate\nfurther research into efficient multi-modal understanding.\n","authors":["Emmanuelle Bourigault","Pauline Bourigault"],"pdf_url":"https://arxiv.org/pdf/2508.04469v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2410.13928v3","updated":"2025-08-06T13:47:10Z","published":"2024-10-17T17:56:01Z","title":"Automatically Interpreting Millions of Features in Large Language Models","summary":"  While the activations of neurons in deep neural networks usually do not have\na simple human-understandable interpretation, sparse autoencoders (SAEs) can be\nused to transform these activations into a higher-dimensional latent space\nwhich may be more easily interpretable. However, these SAEs can have millions\nof distinct latent features, making it infeasible for humans to manually\ninterpret each one. In this work, we build an open-source automated pipeline to\ngenerate and evaluate natural language explanations for SAE features using\nLLMs. We test our framework on SAEs of varying sizes, activation functions, and\nlosses, trained on two different open-weight LLMs. We introduce five new\ntechniques to score the quality of explanations that are cheaper to run than\nthe previous state of the art. One of these techniques, intervention scoring,\nevaluates the interpretability of the effects of intervening on a feature,\nwhich we find explains features that are not recalled by existing methods. We\npropose guidelines for generating better explanations that remain valid for a\nbroader set of activating contexts, and discuss pitfalls with existing scoring\ntechniques. We use our explanations to measure the semantic similarity of\nindependently trained SAEs, and find that SAEs trained on nearby layers of the\nresidual stream are highly similar. Our large-scale analysis confirms that SAE\nlatents are indeed much more interpretable than neurons, even when neurons are\nsparsified using top-$k$ postprocessing. Our code is available at\nhttps://github.com/EleutherAI/sae-auto-interp, and our explanations are\navailable at\nhttps://huggingface.co/datasets/EleutherAI/auto_interp_explanations.\n","authors":["Gonçalo Paulo","Alex Mallen","Caden Juang","Nora Belrose"],"pdf_url":"https://arxiv.org/pdf/2410.13928v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.15299v4","updated":"2025-08-06T13:42:41Z","published":"2025-03-19T15:21:48Z","title":"Inside-Out: Hidden Factual Knowledge in LLMs","summary":"  This work presents a framework for assessing whether large language models\n(LLMs) encode more factual knowledge in their parameters than what they express\nin their outputs. While a few studies hint at this possibility, none has\nclearly defined or demonstrated this phenomenon. We first propose a formal\ndefinition of knowledge, quantifying it for a given question as the fraction of\ncorrect-incorrect answer pairs where the correct one is ranked higher. This\ngives rise to external and internal knowledge, depending on the information\nused to score individual answer candidates: either the model's observable\ntoken-level probabilities or its intermediate computations. Hidden knowledge\narises when internal knowledge exceeds external knowledge. We then present a\ncase study, applying this framework to three popular open-weights LLMs in a\nclosed-book QA setup. Our results indicate that: (1) LLMs consistently encode\nmore factual knowledge internally than what they express externally, with an\naverage relative gap of 40%. (2) Surprisingly, some knowledge is so deeply\nhidden that a model can internally know an answer perfectly, yet fail to\ngenerate it even once, despite large-scale repeated sampling of 1,000 answers.\nThis reveals fundamental limitations in the generation capabilities of LLMs,\nwhich (3) put a practical constraint on scaling test-time compute via repeated\nanswer sampling in closed-book QA: significant performance improvements remain\ninaccessible because some answers are practically never sampled, yet if they\nwere, we would be guaranteed to rank them first.\n","authors":["Zorik Gekhman","Eyal Ben David","Hadas Orgad","Eran Ofek","Yonatan Belinkov","Idan Szpektor","Jonathan Herzig","Roi Reichart"],"pdf_url":"https://arxiv.org/pdf/2503.15299v4.pdf","comment":"Accepted to COLM 2025"},{"id":"http://arxiv.org/abs/2508.04442v1","updated":"2025-08-06T13:30:51Z","published":"2025-08-06T13:30:51Z","title":"Automated Generation of Curriculum-Aligned Multiple-Choice Questions for\n  Malaysian Secondary Mathematics Using Generative AI","summary":"  This paper addresses the critical need for scalable and high-quality\neducational assessment tools within the Malaysian education system. It\nhighlights the potential of Generative AI (GenAI) while acknowledging the\nsignificant challenges of ensuring factual accuracy and curriculum alignment,\nespecially for low-resource languages like Bahasa Melayu. This research\nintroduces and compares four incremental pipelines for generating Form 1\nMathematics multiple-choice questions (MCQs) in Bahasa Melayu using OpenAI's\nGPT-4o. The methods range from non-grounded prompting (structured and basic) to\nRetrieval-Augmented Generation (RAG) approaches (one using the LangChain\nframework, one implemented manually). The system is grounded in official\ncurriculum documents, including teacher-prepared notes and the yearly teaching\nplan (RPT). A dual-pronged automated evaluation framework is employed to assess\nthe generated questions. Curriculum alignment is measured using Semantic\nTextual Similarity (STS) against the RPT, while contextual validity is verified\nthrough a novel RAG-based Question-Answering (RAG-QA) method. The results\ndemonstrate that RAG-based pipelines significantly outperform non-grounded\nprompting methods, producing questions with higher curriculum alignment and\nfactual validity. The study further analyzes the trade-offs between the ease of\nimplementation of framework-based RAG and the fine-grained control offered by a\nmanual pipeline. This work presents a validated methodology for generating\ncurriculum-specific educational content in a low-resource language, introduces\na symbiotic RAG-QA evaluation technique, and provides actionable insights for\nthe development and deployment of practical EdTech solutions in Malaysia and\nsimilar regions.\n","authors":["Rohaizah Abdul Wahid","Muhamad Said Nizamuddin Nadim","Suliana Sulaiman","Syahmi Akmal Shaharudin","Muhammad Danial Jupikil","Iqqwan Jasman Su Azlan Su"],"pdf_url":"https://arxiv.org/pdf/2508.04442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04440v1","updated":"2025-08-06T13:28:22Z","published":"2025-08-06T13:28:22Z","title":"StepFun-Formalizer: Unlocking the Autoformalization Potential of LLMs\n  through Knowledge-Reasoning Fusion","summary":"  Autoformalization aims to translate natural-language mathematical statements\ninto a formal language. While LLMs have accelerated progress in this area,\nexisting methods still suffer from low accuracy. We identify two key abilities\nfor effective autoformalization: comprehensive mastery of formal-language\ndomain knowledge, and reasoning capability of natural language problem\nunderstanding and informal-formal alignment. Without the former, a model cannot\nidentify the correct formal objects; without the latter, it struggles to\ninterpret real-world contexts and map them precisely into formal expressions.\nTo address these gaps, we introduce ThinkingF, a data synthesis and training\npipeline that improves both abilities. First, we construct two datasets: one by\ndistilling and selecting large-scale examples rich in formal knowledge, and\nanother by generating informal-to-formal reasoning trajectories guided by\nexpert-designed templates. We then apply SFT and RLVR with these datasets to\nfurther fuse and refine the two abilities. The resulting 7B and 32B models\nexhibit both comprehensive formal knowledge and strong informal-to-formal\nreasoning. Notably, StepFun-Formalizer-32B achieves SOTA BEq@1 scores of 40.5%\non FormalMATH-Lite and 26.7% on ProverBench, surpassing all prior\ngeneral-purpose and specialized models.\n","authors":["Yutong Wu","Di Huang","Ruosi Wan","Yue Peng","Shijie Shang","Chenrui Cao","Lei Qi","Rui Zhang","Zidong Du","Jie Yan","Xing Hu"],"pdf_url":"https://arxiv.org/pdf/2508.04440v1.pdf","comment":"24 pages, 17 figures, under review"},{"id":"http://arxiv.org/abs/2508.04423v1","updated":"2025-08-06T13:11:17Z","published":"2025-08-06T13:11:17Z","title":"Evaluating, Synthesizing, and Enhancing for Customer Support\n  Conversation","summary":"  Effective customer support requires not only accurate problem solving but\nalso structured and empathetic communication aligned with professional\nstandards. However, existing dialogue datasets often lack strategic guidance,\nand real-world service data is difficult to access and annotate. To address\nthis, we introduce the task of Customer Support Conversation (CSC), aimed at\ntraining customer service agents to respond using well-defined support\nstrategies. We propose a structured CSC framework grounded in COPC guidelines,\ndefining five conversational stages and twelve strategies to guide high-quality\ninteractions. Based on this, we construct CSConv, an evaluation dataset of\n1,855 real-world customer-agent conversations rewritten using LLMs to reflect\ndeliberate strategy use, and annotated accordingly. Additionally, we develop a\nrole-playing approach that simulates strategy-rich conversations using\nLLM-powered roles aligned with the CSC framework, resulting in the training\ndataset RoleCS. Experiments show that fine-tuning strong LLMs on RoleCS\nsignificantly improves their ability to generate high-quality, strategy-aligned\nresponses on CSConv. Human evaluations further confirm gains in problem\nresolution. All code and data will be made publicly available at\nhttps://github.com/aliyun/qwen-dianjin.\n","authors":["Jie Zhu","Huaixia Dou","Junhui Li","Lifan Guo","Feng Chen","Chi Zhang","Fang Kong"],"pdf_url":"https://arxiv.org/pdf/2508.04423v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2508.04412v1","updated":"2025-08-06T12:56:54Z","published":"2025-08-06T12:56:54Z","title":"Beyond Pixels: Exploring DOM Downsampling for LLM-Based Web Agents","summary":"  Frontier LLMs only recently enabled serviceable, autonomous web agents. At\nthat, a model poses as an instantaneous domain model backend. Ought to suggest\ninteraction, it is consulted with a web-based task and respective application\nstate. The key problem lies in application state serialisation\n$\\unicode{x2013}$ referred to as snapshot. State-of-the-art web agents are\npremised on grounded GUI snapshots, i.e., screenshots enhanced with visual\ncues. Not least to resemble human perception, but for images representing\nrelatively cheap means of model input. LLM vision still lag behind code\ninterpretation capabilities. DOM snapshots, which structurally resemble HTML,\nimpose a desired alternative. Vast model input token size, however, disables\nreliable implementation with web agents to date.\n  We propose D2Snap, a first-of-its-kind DOM downsampling algorithm. Based on a\nGPT-4o backend, we evaluate D2Snap on tasks sampled from the Online-Mind2Web\ndataset. The success rate of D2Snap-downsampled DOM snapshots (67%) matches a\ngrounded GUI snapshot baseline (65%) $\\unicode{x2013}$ within the same input\ntoken order of magnitude (1e3). Our best evaluated configurations\n$\\unicode{x2013}$ one token order above, but within the model's context window\n$\\unicode{x2013}$ outperform this baseline by 8%. Our evaluation, moreover,\nyields that DOM-inherent hierarchy embodies a strong UI feature for LLMs.\n","authors":["Thassilo M. Schiepanski","Nicholas Piël"],"pdf_url":"https://arxiv.org/pdf/2508.04412v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16520v4","updated":"2025-08-06T12:55:44Z","published":"2024-10-21T21:21:29Z","title":"AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context","summary":"  As our understanding of autism and ableism continues to increase, so does our\nunderstanding of ableist language towards autistic people. Such language poses\na significant challenge in NLP research due to its subtle and context-dependent\nnature. Yet, detecting anti-autistic ableist language remains underexplored,\nwith existing NLP tools often failing to capture its nuanced expressions. We\npresent AUTALIC, the first benchmark dataset dedicated to the detection of\nanti-autistic ableist language in context, addressing a significant gap in the\nfield. The dataset comprises 2,400 autism-related sentences collected from\nReddit, accompanied by surrounding context, and is annotated by trained experts\nwith backgrounds in neurodiversity. Our comprehensive evaluation reveals that\ncurrent language models, including state-of-the-art LLMs, struggle to reliably\nidentify anti-autistic ableism and align with human judgments, underscoring\ntheir limitations in this domain. We publicly release AUTALIC along with the\nindividual annotations which serve as a valuable resource to researchers\nworking on ableism, neurodiversity, and also studying disagreements in\nannotation tasks. This dataset serves as a crucial step towards developing more\ninclusive and context-aware NLP systems that better reflect diverse\nperspectives.\n","authors":["Naba Rizvi","Harper Strickland","Daniel Gitelman","Tristan Cooper","Alexis Morales-Flores","Michael Golden","Aekta Kallepalli","Akshat Alurkar","Haaset Owens","Saleha Ahmedi","Isha Khirwadkar","Imani Munyaka","Nedjma Ousidhoum"],"pdf_url":"https://arxiv.org/pdf/2410.16520v4.pdf","comment":"accepted to ACL main 2025, 9 pages, 5 figures, 7 tables"},{"id":"http://arxiv.org/abs/2508.04403v1","updated":"2025-08-06T12:45:09Z","published":"2025-08-06T12:45:09Z","title":"Dialogue Response Prefetching Based on Semantic Similarity and\n  Prediction Confidence of Language Model","summary":"  Prefetching of dialogue responses has been investigated to reduce\nuser-perceived latency (UPL), which refers to the user's waiting time before\nreceiving the system's response, in spoken dialogue systems. To reduce the UPL,\nit is necessary to predict complete user utterances before the end of the\nuser's speech, typically by language models, to prepare prefetched dialogue\nresponses. In this study, we proposed a prediction confidence model (PCM) that\ndetermines whether prefetching is possible or not by estimating the semantic\nsimilarity between the predicted complete user utterance and the complete user\nutterance. We evaluated our PCM based on the differences between the predicted\ncomplete user utterance and the complete user utterance.\n","authors":["Kiyotada Mori","Seiya Kawano","Angel Fernando Garcia Contreras","Koichiro Yoshino"],"pdf_url":"https://arxiv.org/pdf/2508.04403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04402v1","updated":"2025-08-06T12:44:57Z","published":"2025-08-06T12:44:57Z","title":"What Do Humans Hear When Interacting? Experiments on Selective Listening\n  for Evaluating ASR of Spoken Dialogue Systems","summary":"  Spoken dialogue systems (SDSs) utilize automatic speech recognition (ASR) at\nthe front end of their pipeline. The role of ASR in SDSs is to recognize\ninformation in user speech related to response generation appropriately.\nExamining selective listening of humans, which refers to the ability to focus\non and listen to important parts of a conversation during the speech, will\nenable us to identify the ASR capabilities required for SDSs and evaluate them.\nIn this study, we experimentally confirmed selective listening when humans\ngenerate dialogue responses by comparing human transcriptions for generating\ndialogue responses and reference transcriptions. Based on our experimental\nresults, we discuss the possibility of a new ASR evaluation method that\nleverages human selective listening, which can identify the gap between\ntranscription ability between ASR systems and humans.\n","authors":["Kiyotada Mori","Seiya Kawano","Chaoran Liu","Carlos Toshinori Ishi","Angel Fernando Garcia Contreras","Koichiro Yoshino"],"pdf_url":"https://arxiv.org/pdf/2508.04402v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04401v1","updated":"2025-08-06T12:43:04Z","published":"2025-08-06T12:43:04Z","title":"Why are LLMs' abilities emergent?","summary":"  The remarkable success of Large Language Models (LLMs) in generative tasks\nhas raised fundamental questions about the nature of their acquired\ncapabilities, which often appear to emerge unexpectedly without explicit\ntraining. This paper examines the emergent properties of Deep Neural Networks\n(DNNs) through both theoretical analysis and empirical observation, addressing\nthe epistemological challenge of \"creation without understanding\" that\ncharacterises contemporary AI development. We explore how the neural approach's\nreliance on nonlinear, stochastic processes fundamentally differs from symbolic\ncomputational paradigms, creating systems whose macro-level behaviours cannot\nbe analytically derived from micro-level neuron activities. Through analysis of\nscaling laws, grokking phenomena, and phase transitions in model capabilities,\nI demonstrate that emergent abilities arise from the complex dynamics of highly\nsensitive nonlinear systems rather than simply from parameter scaling alone. My\ninvestigation reveals that current debates over metrics, pre-training loss\nthresholds, and in-context learning miss the fundamental ontological nature of\nemergence in DNNs. I argue that these systems exhibit genuine emergent\nproperties analogous to those found in other complex natural phenomena, where\nsystemic capabilities emerge from cooperative interactions among simple\ncomponents without being reducible to their individual behaviours. The paper\nconcludes that understanding LLM capabilities requires recognising DNNs as a\nnew domain of complex dynamical systems governed by universal principles of\nemergence, similar to those operating in physics, chemistry, and biology. This\nperspective shifts the focus from purely phenomenological definitions of\nemergence to understanding the internal dynamic transformations that enable\nthese systems to acquire capabilities that transcend their individual\ncomponents.\n","authors":["Vladimír Havlík"],"pdf_url":"https://arxiv.org/pdf/2508.04401v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2508.04399v1","updated":"2025-08-06T12:41:18Z","published":"2025-08-06T12:41:18Z","title":"Improving Crash Data Quality with Large Language Models: Evidence from\n  Secondary Crash Narratives in Kentucky","summary":"  This study evaluates advanced natural language processing (NLP) techniques to\nenhance crash data quality by mining crash narratives, using secondary crash\nidentification in Kentucky as a case study. Drawing from 16,656 manually\nreviewed narratives from 2015-2022, with 3,803 confirmed secondary crashes, we\ncompare three model classes: zero-shot open-source large language models (LLMs)\n(LLaMA3:70B, DeepSeek-R1:70B, Qwen3:32B, Gemma3:27B); fine-tuned transformers\n(BERT, DistilBERT, RoBERTa, XLNet, Longformer); and traditional logistic\nregression as baseline. Models were calibrated on 2015-2021 data and tested on\n1,771 narratives from 2022. Fine-tuned transformers achieved superior\nperformance, with RoBERTa yielding the highest F1-score (0.90) and accuracy\n(95%). Zero-shot LLaMA3:70B reached a comparable F1 of 0.86 but required 139\nminutes of inference; the logistic baseline lagged well behind (F1:0.66). LLMs\nexcelled in recall for some variants (e.g., GEMMA3:27B at 0.94) but incurred\nhigh computational costs (up to 723 minutes for DeepSeek-R1:70B), while\nfine-tuned models processed the test set in seconds after brief training.\nFurther analysis indicated that mid-sized LLMs (e.g., DeepSeek-R1:32B) can\nrival larger counterparts in performance while reducing runtime, suggesting\nopportunities for optimized deployments. Results highlight trade-offs between\naccuracy, efficiency, and data requirements, with fine-tuned transformer models\nbalancing precision and recall effectively on Kentucky data. Practical\ndeployment considerations emphasize privacy-preserving local deployment,\nensemble approaches for improved accuracy, and incremental processing for\nscalability, providing a replicable scheme for enhancing crash-data quality\nwith advanced NLP.\n","authors":["Xu Zhang","Mei Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04399v1.pdf","comment":"19 pages, 2 figures"},{"id":"http://arxiv.org/abs/2508.04350v1","updated":"2025-08-06T11:42:54Z","published":"2025-08-06T11:42:54Z","title":"Chain of Questions: Guiding Multimodal Curiosity in Language Models","summary":"  Reasoning capabilities in large language models (LLMs) have substantially\nadvanced through methods such as chain-of-thought and explicit step-by-step\nexplanations. However, these improvements have not yet fully transitioned to\nmultimodal contexts, where models must proactively decide which sensory\nmodalities such as vision, audio, or spatial perception to engage when\ninteracting with complex real-world environments. In this paper, we introduce\nthe Chain of Questions (CoQ) framework, a curiosity-driven reasoning approach\nthat encourages multimodal language models to dynamically generate targeted\nquestions regarding their surroundings. These generated questions guide the\nmodel to selectively activate relevant modalities, thereby gathering critical\ninformation necessary for accurate reasoning and response generation. We\nevaluate our framework on a novel multimodal benchmark dataset, assembled by\nintegrating WebGPT, ScienceQA, AVSD, and ScanQA datasets. Experimental results\ndemonstrate that our CoQ method improves a foundation model's ability to\neffectively identify and integrate pertinent sensory information. This leads to\nimproved accuracy, interpretability, and alignment of the reasoning process\nwith diverse multimodal tasks.\n","authors":["Nima Iji","Kia Dashtipour"],"pdf_url":"https://arxiv.org/pdf/2508.04350v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2508.04683v1","updated":"2025-08-06T17:47:00Z","published":"2025-08-06T17:47:00Z","title":"Query Attribute Modeling: Improving search relevance with Semantic\n  Search and Meta Data Filtering","summary":"  This study introduces Query Attribute Modeling (QAM), a hybrid framework that\nenhances search precision and relevance by decomposing open text queries into\nstructured metadata tags and semantic elements. QAM addresses traditional\nsearch limitations by automatically extracting metadata filters from free-form\ntext queries, reducing noise and enabling focused retrieval of relevant items.\n  Experimental evaluation using the Amazon Toys Reviews dataset (10,000 unique\nitems with 40,000+ reviews and detailed product attributes) demonstrated QAM's\nsuperior performance, achieving a mean average precision at 5 (mAP@5) of\n52.99\\%. This represents significant improvement over conventional methods,\nincluding BM25 keyword search, encoder-based semantic similarity search,\ncross-encoder re-ranking, and hybrid search combining BM25 and semantic results\nvia Reciprocal Rank Fusion (RRF). The results establish QAM as a robust\nsolution for Enterprise Search applications, particularly in e-commerce\nsystems.\n","authors":["Karthik Menon","Batool Arhamna Haider","Muhammad Arham","Kanwal Mehreen","Ram Mohan Rao Kadiyala","Hamza Farooq"],"pdf_url":"https://arxiv.org/pdf/2508.04683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.13415v2","updated":"2025-08-06T17:45:47Z","published":"2024-11-20T16:02:14Z","title":"Harnessing Large Language Models for Group POI Recommendations","summary":"  The rapid proliferation of Location-Based Social Networks (LBSNs) has\nunderscored the importance of Point-of-Interest (POI) recommendation systems in\nenhancing user experiences. While individual POI recommendation methods\nleverage users' check-in histories to provide personalized suggestions, they\nstruggle to address scenarios requiring group decision-making. Group POI\nrecommendation systems aim to satisfy the collective preferences of multiple\nusers, but existing approaches face two major challenges: diverse group\npreferences and extreme data sparsity in group check-in data. To overcome these\nchallenges, we propose LLMGPR, a novel framework that leverages large language\nmodels (LLMs) for group POI recommendations. LLMGPR introduces\nsemantic-enhanced POI tokens and incorporates rich contextual information to\nmodel the diverse and complex dynamics of group decision-making. To further\nenhance its capabilities, we developed a sequencing adapter using Quantized\nLow-Rank Adaptation (QLoRA), which aligns LLMs with group POI recommendation\ntasks. To address the issue of sparse group check-in data, LLMGPR employs an\naggregation adapter that integrates individual representations into meaningful\ngroup representations. Additionally, a self-supervised learning (SSL) task is\ndesigned to predict the purposes of check-in sequences (e.g., business trips\nand family vacations), thereby enriching group representations with deeper\nsemantic insights. Extensive experiments demonstrate the effectiveness of\nLLMGPR, showcasing its ability to significantly enhance the accuracy and\nrobustness of group POI recommendations.\n","authors":["Jing Long","Liang Qu","Junliang Yu","Tong Chen","Quoc Viet Hung Nguyen","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2411.13415v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04623v1","updated":"2025-08-06T16:49:13Z","published":"2025-08-06T16:49:13Z","title":"Lightweight Transformers for Zero-Shot and Fine-Tuned Text-to-SQL\n  Generation Using Spider","summary":"  Text-to-SQL translation enables non-expert users to query relational\ndatabases using natural language, with applications in education and business\nintelligence. This study evaluates three lightweight transformer models -\nT5-Small, BART-Small, and GPT-2 - on the Spider dataset, focusing on\nlow-resource settings. We developed a reusable, model-agnostic pipeline that\ntailors schema formatting to each model's architecture, training them across\n1000 to 5000 iterations and evaluating on 1000 test samples using Logical Form\nAccuracy (LFAcc), BLEU, and Exact Match (EM) metrics. Fine-tuned T5-Small\nachieves the highest LFAcc (27.8%), outperforming BART-Small (23.98%) and GPT-2\n(20.1%), highlighting encoder-decoder models' superiority in schema-aware SQL\ngeneration. Despite resource constraints limiting performance, our pipeline's\nmodularity supports future enhancements, such as advanced schema linking or\nalternative base models. This work underscores the potential of compact\ntransformers for accessible text-to-SQL solutions in resource-scarce\nenvironments.\n","authors":["Chirag Seth","Utkarsh Singh"],"pdf_url":"https://arxiv.org/pdf/2508.04623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04618v1","updated":"2025-08-06T16:45:05Z","published":"2025-08-06T16:45:05Z","title":"HiD-VAE: Interpretable Generative Recommendation via Hierarchical and\n  Disentangled Semantic IDs","summary":"  Recommender systems are indispensable for helping users navigate the immense\nitem catalogs of modern online platforms. Recently, generative recommendation\nhas emerged as a promising paradigm, unifying the conventional\nretrieve-and-rank pipeline into an end-to-end model capable of dynamic\ngeneration. However, existing generative methods are fundamentally constrained\nby their unsupervised tokenization, which generates semantic IDs suffering from\ntwo critical flaws: (1) they are semantically flat and uninterpretable, lacking\na coherent hierarchy, and (2) they are prone to representation entanglement\n(i.e., ``ID collisions''), which harms recommendation accuracy and diversity.\nTo overcome these limitations, we propose HiD-VAE, a novel framework that\nlearns hierarchically disentangled item representations through two core\ninnovations. First, HiD-VAE pioneers a hierarchically-supervised quantization\nprocess that aligns discrete codes with multi-level item tags, yielding more\nuniform and disentangled IDs. Crucially, the trained codebooks can predict\nhierarchical tags, providing a traceable and interpretable semantic path for\neach recommendation. Second, to combat representation entanglement, HiD-VAE\nincorporates a novel uniqueness loss that directly penalizes latent space\noverlap. This mechanism not only resolves the critical ID collision problem but\nalso promotes recommendation diversity by ensuring a more comprehensive\nutilization of the item representation space. These high-quality, disentangled\nIDs provide a powerful foundation for downstream generative models. Extensive\nexperiments on three public benchmarks validate HiD-VAE's superior performance\nagainst state-of-the-art methods. The code is available at\nhttps://anonymous.4open.science/r/HiD-VAE-84B2.\n","authors":["Dengzhao Fang","Jingtong Gao","Chengcheng Zhu","Yu Li","Xiangyu Zhao","Yi Chang"],"pdf_url":"https://arxiv.org/pdf/2508.04618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04612v1","updated":"2025-08-06T16:33:20Z","published":"2025-08-06T16:33:20Z","title":"A Reproducible, Scalable Pipeline for Synthesizing Autoregressive Model\n  Literature","summary":"  The accelerating pace of research on autoregressive generative models has\nproduced thousands of papers, making manual literature surveys and reproduction\nstudies increasingly impractical. We present a fully open-source, reproducible\npipeline that automatically retrieves candidate documents from public\nrepositories, filters them for relevance, extracts metadata, hyper-parameters\nand reported results, clusters topics, produces retrieval-augmented summaries\nand generates containerised scripts for re-running selected experiments.\nQuantitative evaluation on 50 manually-annotated papers shows F1 scores above\n0.85 for relevance classification, hyper-parameter extraction and citation\nidentification. Experiments on corpora of up to 1000 papers demonstrate\nnear-linear scalability with eight CPU workers. Three case studies -- AWD-LSTM\non WikiText-2, Transformer-XL on WikiText-103 and an autoregressive music model\non the Lakh MIDI dataset -- confirm that the extracted settings support\nfaithful reproduction, achieving test perplexities within 1--3% of the original\nreports.\n","authors":["Faruk Alpay","Bugra Kilictas","Hamdi Alakkad"],"pdf_url":"https://arxiv.org/pdf/2508.04612v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2508.04604v1","updated":"2025-08-06T16:24:17Z","published":"2025-08-06T16:24:17Z","title":"TURA: Tool-Augmented Unified Retrieval Agent for AI Search","summary":"  The advent of Large Language Models (LLMs) is transforming search engines\ninto conversational AI search products, primarily using Retrieval-Augmented\nGeneration (RAG) on web corpora. However, this paradigm has significant\nindustrial limitations. Traditional RAG approaches struggle with real-time\nneeds and structured queries that require accessing dynamically generated\ncontent like ticket availability or inventory. Limited to indexing static\npages, search engines cannot perform the interactive queries needed for such\ntime-sensitive data. Academic research has focused on optimizing RAG for static\ncontent, overlooking complex intents and the need for dynamic sources like\ndatabases and real-time APIs. To bridge this gap, we introduce TURA\n(Tool-Augmented Unified Retrieval Agent for AI Search), a novel three-stage\nframework that combines RAG with agentic tool-use to access both static content\nand dynamic, real-time information. TURA has three key components: an\nIntent-Aware Retrieval module to decompose queries and retrieve information\nsources encapsulated as Model Context Protocol (MCP) Servers, a DAG-based Task\nPlanner that models task dependencies as a Directed Acyclic Graph (DAG) for\noptimal parallel execution, and a lightweight Distilled Agent Executor for\nefficient tool calling. TURA is the first architecture to systematically bridge\nthe gap between static RAG and dynamic information sources for a world-class AI\nsearch product. Serving tens of millions of users, it leverages an agentic\nframework to deliver robust, real-time answers while meeting the low-latency\ndemands of a large-scale industrial system.\n","authors":["Zhejun Zhao","Yuehu Dong","Alley Liu","Lixue Zheng","Pingsheng Liu","Dongdong Shen","Long Xia","Jiashu Zhao","Dawei Yin"],"pdf_url":"https://arxiv.org/pdf/2508.04604v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04571v1","updated":"2025-08-06T15:53:58Z","published":"2025-08-06T15:53:58Z","title":"Do Recommender Systems Really Leverage Multimodal Content? A\n  Comprehensive Analysis on Multimodal Representations for Recommendation","summary":"  Multimodal Recommender Systems aim to improve recommendation accuracy by\nintegrating heterogeneous content, such as images and textual metadata. While\neffective, it remains unclear whether their gains stem from true multimodal\nunderstanding or increased model complexity. This work investigates the role of\nmultimodal item embeddings, emphasizing the semantic informativeness of the\nrepresentations. Initial experiments reveal that embeddings from standard\nextractors (e.g., ResNet50, Sentence-Bert) enhance performance, but rely on\nmodality-specific encoders and ad hoc fusion strategies that lack control over\ncross-modal alignment. To overcome these limitations, we leverage Large\nVision-Language Models (LVLMs) to generate multimodal-by-design embeddings via\nstructured prompts. This approach yields semantically aligned representations\nwithout requiring any fusion. Experiments across multiple settings show notable\nperformance improvements. Furthermore, LVLMs embeddings offer a distinctive\nadvantage: they can be decoded into structured textual descriptions, enabling\ndirect assessment of their multimodal comprehension. When such descriptions are\nincorporated as side content into recommender systems, they improve\nrecommendation performance, empirically validating the semantic depth and\nalignment encoded within LVLMs outputs. Our study highlights the importance of\nsemantically rich representations and positions LVLMs as a compelling\nfoundation for building robust and meaningful multimodal representations in\nrecommendation tasks.\n","authors":["Claudio Pomo","Matteo Attimonelli","Danilo Danese","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2508.04571v1.pdf","comment":"Accepted as Full Research Papers at CIKM 2025"},{"id":"http://arxiv.org/abs/2410.10639v2","updated":"2025-08-06T15:46:37Z","published":"2024-10-14T15:50:35Z","title":"Paragon: Parameter Generation for Controllable Multi-Task Recommendation","summary":"  Commercial recommender systems face the challenge that task requirements from\nplatforms or users often change dynamically (e.g., varying preferences for\naccuracy or diversity). Ideally, the model should be re-trained after resetting\na new objective function, adapting to these changes in task requirements.\nHowever, in practice, the high computational costs associated with retraining\nmake this process impractical for models already deployed to online\nenvironments. This raises a new challenging problem: how to efficiently adapt\nthe learned model to different task requirements by controlling the model\nparameters after deployment, without the need for retraining. To address this\nissue, we propose a novel controllable learning approach via \\textbf{para}meter\n\\textbf{g}eneration for c\\textbf{on}trollable multi-task recommendation\n(\\textbf{Paragon}), which allows the customization and adaptation of\nrecommendation model parameters to new task requirements without retraining.\nSpecifically, we first obtain the optimized model parameters through adapter\ntunning based on the feasible task requirements. Then, we utilize the\ngenerative model as a parameter generator, employing classifier-free guidance\nin conditional training to learn the distribution of optimized model parameters\nunder various task requirements. Finally, the parameter generator is applied to\neffectively generate model parameters in a test-time adaptation manner given\ntask requirements. Moreover, Paragon seamlessly integrates with various\nexisting recommendation models to enhance their controllability. Extensive\nexperiments on two public datasets and one commercial dataset demonstrate that\nParagon can efficiently generate model parameters instead of retraining,\nreducing computational time by at least 94.6\\%. The code is released at\n\\href{https://github.com/bubble65/Paragon}{https://github.com/bubble65/Paragon}.\n","authors":["Chenglei Shen","Jiahao Zhao","Xiao Zhang","Weijie Yu","Ming He","Jianping Fan"],"pdf_url":"https://arxiv.org/pdf/2410.10639v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06083v3","updated":"2025-08-06T15:22:29Z","published":"2024-07-04T09:50:50Z","title":"A Survey of Controllable Learning: Methods and Applications in\n  Information Retrieval","summary":"  Controllability has become a crucial aspect of trustworthy machine learning,\nenabling learners to meet predefined targets and adapt dynamically at test time\nwithout requiring retraining as the targets shift. We provide a formal\ndefinition of controllable learning (CL), and discuss its applications in\ninformation retrieval (IR) where information needs are often complex and\ndynamic. The survey categorizes CL according to what is controllable (e.g.,\nmultiple objectives, user portrait, scenario adaptation), who controls (users\nor platforms), how control is implemented (e.g., rule-based method, Pareto\noptimization, hypernetwork and others), and where to implement control (e.g.,\npre-processing, in-processing, post-processing methods). Then, we identify\nchallenges faced by CL across training, evaluation, task setting, and\ndeployment in online environments. Additionally, we outline promising\ndirections for CL in theoretical analysis, efficient computation, empowering\nlarge language models, application scenarios and evaluation frameworks.\n","authors":["Chenglei Shen","Xiao Zhang","Teng Shi","Changshuo Zhang","Guofu Xie","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2407.06083v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04474v1","updated":"2025-08-06T14:25:05Z","published":"2025-08-06T14:25:05Z","title":"TRAIL: Joint Inference and Refinement of Knowledge Graphs with Large\n  Language Models","summary":"  Recent advances in large language models (LLMs) have unlocked powerful\nreasoning and decision-making capabilities. However, their inherent dependence\non static parametric memory fundamentally limits their adaptability, factual\naccuracy, and interpretability in knowledge-intensive scenarios. Knowledge\ngraphs (KGs), as structured repositories of explicit relational knowledge,\noffer a promising approach for augmenting LLMs with external, interpretable\nmemory. Nevertheless, most existing methods that combine LLMs with KGs treat\nreasoning and knowledge updating as separate processes, resulting in suboptimal\nutilization of new information and hindering real-time updates. In this work,\nwe propose TRAIL: a novel, unified framework for Thinking, Reasoning, And\nIncremental Learning that couples joint inference and dynamic KG refinement\nwith large language models. TRAIL enables LLM agents to iteratively explore,\nupdate, and refine knowledge graphs during the reasoning process, employing a\nconfidence-driven mechanism for the generation, validation, and pruning of new\nfacts. This plug-and-play architecture facilitates seamless integration with\nvarious LLMs, supporting continual adaptation without the need for retraining.\nExtensive experiments on multiple benchmarks demonstrate that TRAIL outperforms\nexisting KG-augmented and retrieval-augmented LLM baselines by 3% to 13%. More\nimportantly, these results represent a significant step toward developing\nadaptive, memory-augmented language models capable of continual learning and\nreliable, transparent reasoning.\n","authors":["Xinkui Zhao","Haode Li","Yifan Zhang","Guanjie Cheng","Yueshen Xu"],"pdf_url":"https://arxiv.org/pdf/2508.04474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04419v1","updated":"2025-08-06T13:06:24Z","published":"2025-08-06T13:06:24Z","title":"Algorithm Selection for Recommender Systems via Meta-Learning on\n  Algorithm Characteristics","summary":"  The Algorithm Selection Problem for recommender systems-choosing the best\nalgorithm for a given user or context-remains a significant challenge.\nTraditional meta-learning approaches often treat algorithms as categorical\nchoices, ignoring their intrinsic properties. Recent work has shown that\nexplicitly characterizing algorithms with features can improve model\nperformance in other domains. Building on this, we propose a per-user\nmeta-learning approach for recommender system selection that leverages both\nuser meta-features and automatically extracted algorithm features from source\ncode. Our preliminary results, averaged over six diverse datasets, show that\naugmenting a meta-learner with algorithm features improves its average NDCG@10\nperformance by 8.83% from 0.135 (user features only) to 0.147. This enhanced\nmodel outperforms the Single Best Algorithm baseline (0.131) and successfully\ncloses 10.5% of the performance gap to a theoretical oracle selector. These\nfindings show that even static source code metrics provide a valuable\npredictive signal, presenting a promising direction for building more robust\nand intelligent recommender systems.\n","authors":["Jarne Mathi Decker","Joeran Beel"],"pdf_url":"https://arxiv.org/pdf/2508.04419v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04399v1","updated":"2025-08-06T12:41:18Z","published":"2025-08-06T12:41:18Z","title":"Improving Crash Data Quality with Large Language Models: Evidence from\n  Secondary Crash Narratives in Kentucky","summary":"  This study evaluates advanced natural language processing (NLP) techniques to\nenhance crash data quality by mining crash narratives, using secondary crash\nidentification in Kentucky as a case study. Drawing from 16,656 manually\nreviewed narratives from 2015-2022, with 3,803 confirmed secondary crashes, we\ncompare three model classes: zero-shot open-source large language models (LLMs)\n(LLaMA3:70B, DeepSeek-R1:70B, Qwen3:32B, Gemma3:27B); fine-tuned transformers\n(BERT, DistilBERT, RoBERTa, XLNet, Longformer); and traditional logistic\nregression as baseline. Models were calibrated on 2015-2021 data and tested on\n1,771 narratives from 2022. Fine-tuned transformers achieved superior\nperformance, with RoBERTa yielding the highest F1-score (0.90) and accuracy\n(95%). Zero-shot LLaMA3:70B reached a comparable F1 of 0.86 but required 139\nminutes of inference; the logistic baseline lagged well behind (F1:0.66). LLMs\nexcelled in recall for some variants (e.g., GEMMA3:27B at 0.94) but incurred\nhigh computational costs (up to 723 minutes for DeepSeek-R1:70B), while\nfine-tuned models processed the test set in seconds after brief training.\nFurther analysis indicated that mid-sized LLMs (e.g., DeepSeek-R1:32B) can\nrival larger counterparts in performance while reducing runtime, suggesting\nopportunities for optimized deployments. Results highlight trade-offs between\naccuracy, efficiency, and data requirements, with fine-tuned transformer models\nbalancing precision and recall effectively on Kentucky data. Practical\ndeployment considerations emphasize privacy-preserving local deployment,\nensemble approaches for improved accuracy, and incremental processing for\nscalability, providing a replicable scheme for enhancing crash-data quality\nwith advanced NLP.\n","authors":["Xu Zhang","Mei Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04399v1.pdf","comment":"19 pages, 2 figures"},{"id":"http://arxiv.org/abs/2508.04337v1","updated":"2025-08-06T11:30:07Z","published":"2025-08-06T11:30:07Z","title":"Modelling and Classifying the Components of a Literature Review","summary":"  Previous work has demonstrated that AI methods for analysing scientific\nliterature benefit significantly from annotating sentences in papers according\nto their rhetorical roles, such as research gaps, results, limitations,\nextensions of existing methodologies, and others. Such representations also\nhave the potential to support the development of a new generation of systems\ncapable of producing high-quality literature reviews. However, achieving this\ngoal requires the definition of a relevant annotation schema and effective\nstrategies for large-scale annotation of the literature. This paper addresses\nthese challenges by 1) introducing a novel annotation schema specifically\ndesigned to support literature review generation and 2) conducting a\ncomprehensive evaluation of a wide range of state-of-the-art large language\nmodels (LLMs) in classifying rhetorical roles according to this schema. To this\nend, we also present Sci-Sentence, a novel multidisciplinary benchmark\ncomprising 700 sentences manually annotated by domain experts and 2,240\nsentences automatically labelled using LLMs. We evaluate 37 LLMs on this\nbenchmark, spanning diverse model families and sizes, using both zero-shot\nlearning and fine-tuning approaches. The experiments yield several novel\ninsights that advance the state of the art in this challenging domain. First,\nthe current generation of LLMs performs remarkably well on this task when\nfine-tuned on high-quality data, achieving performance levels above 96\\% F1.\nSecond, while large proprietary models like GPT-4o achieve the best results,\nsome lightweight open-source alternatives also demonstrate excellent\nperformance. Finally, enriching the training data with semi-synthetic examples\ngenerated by LLMs proves beneficial, enabling small encoders to achieve robust\nresults and significantly enhancing the performance of several open decoder\nmodels.\n","authors":["Francisco Bolaños","Angelo Salatino","Francesco Osborne","Enrico Motta"],"pdf_url":"https://arxiv.org/pdf/2508.04337v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04293v1","updated":"2025-08-06T10:30:22Z","published":"2025-08-06T10:30:22Z","title":"Comparative Analysis of Novel NIRMAL Optimizer Against Adam and SGD with\n  Momentum","summary":"  This study proposes NIRMAL (Novel Integrated Robust Multi-Adaptation\nLearning), a novel optimization algorithm that combines multiple strategies\ninspired by the movements of the chess piece. These strategies include gradient\ndescent, momentum, stochastic perturbations, adaptive learning rates, and\nnon-linear transformations. We carefully evaluated NIRMAL against two widely\nused and successful optimizers, Adam and SGD with Momentum, on four benchmark\nimage classification datasets: MNIST, FashionMNIST, CIFAR-10, and CIFAR-100.\nThe custom convolutional neural network (CNN) architecture is applied on each\ndataset. The experimental results show that NIRMAL achieves competitive\nperformance, particularly on the more challenging CIFAR-100 dataset, where it\nachieved a test accuracy of 45.32\\%and a weighted F1-score of 0.4328. This\nperformance surpasses Adam (41.79\\% accuracy, 0.3964 F1-score) and closely\nmatches SGD with Momentum (46.97\\% accuracy, 0.4531 F1-score). Also, NIRMAL\nexhibits robust convergence and strong generalization capabilities, especially\non complex datasets, as evidenced by stable training results in loss and\naccuracy curves. These findings underscore NIRMAL's significant ability as a\nversatile and effective optimizer for various deep learning tasks.\n","authors":["Nirmal Gaud","Surej Mouli","Preeti Katiyar","Vaduguru Venkata Ramya"],"pdf_url":"https://arxiv.org/pdf/2508.04293v1.pdf","comment":"9 pages, 12 figures"},{"id":"http://arxiv.org/abs/2508.04247v1","updated":"2025-08-06T09:29:50Z","published":"2025-08-06T09:29:50Z","title":"I$^3$-MRec: Invariant Learning with Information Bottleneck for\n  Incomplete Modality Recommendation","summary":"  Multimodal recommender systems (MRS) improve recommendation performance by\nintegrating diverse semantic information from multiple modalities. However, the\nassumption of the availability of all modalities rarely holds in practice due\nto missing images, incomplete descriptions, or inconsistent user content. These\nchallenges significantly degrade the robustness and generalization capabilities\nof current models. To address these challenges, we introduce a novel method\ncalled \\textbf{I$^3$-MRec}, which uses \\textbf{I}nvariant learning with\n\\textbf{I}nformation bottleneck principle for \\textbf{I}ncomplete\n\\textbf{M}odality \\textbf{Rec}ommendation. To achieve robust performance in\nmissing modality scenarios, I$^3$-MRec enforces two pivotal properties: (i)\ncross-modal preference invariance, which ensures consistent user preference\nmodeling across varying modality environments, and (ii) compact yet effective\nmodality representation, which filters out task-irrelevant modality information\nwhile maximally preserving essential features relevant to recommendation. By\ntreating each modality as a distinct semantic environment, I$^3$-MRec employs\ninvariant risk minimization (IRM) to learn modality-specific item\nrepresentations. In parallel, a missing-aware fusion module grounded in the\nInformation Bottleneck (IB) principle extracts compact and effective item\nembeddings by suppressing modality noise and preserving core user preference\nsignals. Extensive experiments conducted on three real-world datasets\ndemonstrate that I$^3$-MRec consistently outperforms existing state-of-the-art\nMRS methods across various modality-missing scenarios, highlighting its\neffectiveness and robustness in practical applications. The code and processed\ndatasets are released at https://github.com/HuilinChenJN/I3-MRec.\n","authors":["Huilin Chen","Miaomiao Cai","Fan Liu","Zhiyong Cheng","Richang Hong","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2508.04247v1.pdf","comment":"ACM Multimedia 2025 Accepted"},{"id":"http://arxiv.org/abs/2506.22303v2","updated":"2025-08-06T09:12:14Z","published":"2025-06-27T15:15:42Z","title":"GraphRAG-Induced Dual Knowledge Structure Graphs for Personalized\n  Learning Path Recommendation","summary":"  Learning path recommendation seeks to provide learners with a structured\nsequence of learning items (\\eg, knowledge concepts or exercises) to optimize\ntheir learning efficiency. Despite significant efforts in this area, most\nexisting methods primarily rely on prerequisite relationships, which present\ntwo major limitations: 1) Requiring prerequisite relationships between\nknowledge concepts, which are difficult to obtain due to the cost of expert\nannotation, hindering the application of current learning path recommendation\nmethods. 2) Relying on a single, sequentially dependent knowledge structure\nbased on prerequisite relationships implies that difficulties at any stage can\ncause learning blockages, which in turn disrupt subsequent learning processes.\nTo address these challenges, we propose a novel approach, GraphRAG-Induced Dual\nKnowledge Structure Graphs for Personalized Learning Path Recommendation\n(KnowLP), which enhances learning path recommendations by incorporating both\nprerequisite and similarity relationships between knowledge concepts.\nSpecifically, we introduce a knowledge concept structure graph generation\nmodule EDU-GraphRAG that adaptively constructs knowledge concept structure\ngraphs for different educational datasets, significantly improving the\ngeneralizability of learning path recommendation methods. We then propose a\nDiscrimination Learning-driven Reinforcement Learning (DLRL) module, which\nmitigates the issue of blocked learning paths, further enhancing the efficacy\nof learning path recommendations. Finally, we conduct extensive experiments on\nthree benchmark datasets, demonstrating that our method not only achieves\nstate-of-the-art performance but also provides interpretable reasoning for the\nrecommended learning paths.\n","authors":["Xinghe Cheng","Zihan Zhang","Jiapu Wang","Liangda Fang","Chaobo He","Quanlong Guan","Shirui Pan","Weiqi Luo"],"pdf_url":"https://arxiv.org/pdf/2506.22303v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04221v1","updated":"2025-08-06T08:54:57Z","published":"2025-08-06T08:54:57Z","title":"Discrete-event Tensor Factorization: Learning a Smooth Embedding for\n  Continuous Domains","summary":"  Recommender systems learn from past user behavior to predict future user\npreferences. Intuitively, it has been established that the most recent\ninteractions are more indicative of future preferences than older interactions.\nMany recommendation algorithms use this notion to either drop older\ninteractions or to assign them a lower weight, so the model can focus on the\nmore informative, recent information. However, very few approaches model the\nflow of time explicitly.\n  This paper analyzes how time can be encoded in factorization-style\nrecommendation models. By including absolute time as a feature, our models can\nlearn varying user preferences and changing item perception over time. In\naddition to simple binning approaches, we also propose a novel, fully\ncontinuous time encoding mechanism. Through the use of a polynomial fit inside\nthe loss function, our models completely avoid the need for discretization, and\nthey are able to capture the time dimension in arbitrary resolution.\n  We perform a comparative study on three real-world datasets that span\nmultiple years, where long user histories are present, and items stay relevant\nfor a longer time. Empirical results show that, by explicitly modeling time,\nour models are very effective at capturing temporal signals, such as varying\nitem popularities over time. Despite this however, our experiments also\nindicate that a simple post-hoc popularity adjustment is often sufficient to\nachieve the best performance on the unseen test set. This teaches us that, for\nthe recommendation task, predicting the future is more important than capturing\npast trends. As such, we argue that specialized mechanisms are needed for\nextrapolation to future data.\n","authors":["Joey De Pauw","Bart Goethals"],"pdf_url":"https://arxiv.org/pdf/2508.04221v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04213v1","updated":"2025-08-06T08:48:14Z","published":"2025-08-06T08:48:14Z","title":"A Hybrid AI Methodology for Generating Ontologies of Research Topics\n  from Scientific Paper Corpora","summary":"  Taxonomies and ontologies of research topics (e.g., MeSH, UMLS, CSO, NLM)\nplay a central role in providing the primary framework through which\nintelligent systems can explore and interpret the literature. However, these\nresources have traditionally been manually curated, a process that is\ntime-consuming, prone to obsolescence, and limited in granularity. This paper\npresents Sci-OG, a semi-auto\\-mated methodology for generating research topic\nontologies, employing a multi-step approach: 1) Topic Discovery, extracting\npotential topics from research papers; 2) Relationship Classification,\ndetermining semantic relationships between topic pairs; and 3) Ontology\nConstruction, refining and organizing topics into a structured ontology. The\nrelationship classification component, which constitutes the core of the\nsystem, integrates an encoder-based language model with features describing\ntopic occurrence in the scientific literature. We evaluate this approach\nagainst a range of alternative solutions using a dataset of 21,649 manually\nannotated semantic triples. Our method achieves the highest F1 score (0.951),\nsurpassing various competing approaches, including a fine-tuned SciBERT model\nand several LLM baselines, such as the fine-tuned GPT4-mini. Our work is\ncorroborated by a use case which illustrates the practical application of our\nsystem to extend the CSO ontology in the area of cybersecurity. The presented\nsolution is designed to improve the accessibility, organization, and analysis\nof scientific knowledge, thereby supporting advancements in AI-enabled\nliterature management and research exploration.\n","authors":["Alessia Pisu","Livio Pompianu","Francesco Osborne","Diego Reforgiato Recupero","Daniele Riboni","Angelo Salatino"],"pdf_url":"https://arxiv.org/pdf/2508.04213v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04206v1","updated":"2025-08-06T08:39:07Z","published":"2025-08-06T08:39:07Z","title":"ViLLA-MMBench: A Unified Benchmark Suite for LLM-Augmented Multimodal\n  Movie Recommendation","summary":"  Recommending long-form video content demands joint modeling of visual, audio,\nand textual modalities, yet most benchmarks address only raw features or narrow\nfusion. We present ViLLA-MMBench, a reproducible, extensible benchmark for\nLLM-augmented multimodal movie recommendation. Built on MovieLens and MMTF-14K,\nit aligns dense item embeddings from three modalities: audio (block-level,\ni-vector), visual (CNN, AVF), and text. Missing or sparse metadata is\nautomatically enriched using state-of-the-art LLMs (e.g., OpenAI Ada),\ngenerating high-quality synopses for thousands of movies. All text (raw or\naugmented) is embedded with configurable encoders (Ada, LLaMA-2, Sentence-T5),\nproducing multiple ready-to-use sets. The pipeline supports interchangeable\nearly-, mid-, and late-fusion (concatenation, PCA, CCA, rank-aggregation) and\nmultiple backbones (MF, VAECF, VBPR, AMR, VMF) for ablation. Experiments are\nfully declarative via a single YAML file. Evaluation spans accuracy (Recall,\nnDCG) and beyond-accuracy metrics: cold-start rate, coverage, novelty,\ndiversity, fairness. Results show LLM-based augmentation and strong text\nembeddings boost cold-start and coverage, especially when fused with\naudio-visual features. Systematic benchmarking reveals universal versus\nbackbone- or metric-specific combinations. Open-source code, embeddings, and\nconfigs enable reproducible, fair multimodal RS research and advance principled\ngenerative AI integration in large-scale recommendation. Code:\nhttps://recsys-lab.github.io/ViLLA-MMBench\n","authors":["Fatemeh Nazary","Ali Tourani","Yashar Deldjoo","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2508.04206v1.pdf","comment":"17 pages, 3 figures, 5 tables"},{"id":"http://arxiv.org/abs/2507.03958v2","updated":"2025-08-06T08:11:23Z","published":"2025-07-05T08:50:29Z","title":"A Comparative Study of Specialized LLMs as Dense Retrievers","summary":"  While large language models (LLMs) are increasingly deployed as dense\nretrievers, the impact of their domain-specific specialization on retrieval\neffectiveness remains underexplored. This investigation systematically examines\nhow task-specific adaptations in LLMs influence their retrieval capabilities,\nan essential step toward developing unified retrievers capable of handling\ntext, code, images, and multimodal content. We conduct extensive experiments\nwith eight Qwen2.5 7B LLMs, including base, instruction-tuned,\ncode/math-specialized, long reasoning, and vision-language models across\nzero-shot retrieval settings and the supervised setting. For the zero-shot\nretrieval settings, we consider text retrieval from the BEIR benchmark and code\nretrieval from the CoIR benchmark. Further, to evaluate supervised performance,\nall LLMs are fine-tuned on the MS MARCO dataset. We find that mathematical\nspecialization and the long reasoning capability cause consistent degradation\nin three settings, indicating conflicts between mathematical reasoning and\nsemantic matching. The vision-language model and code-specialized LLMs\ndemonstrate superior zero-shot performance compared to other LLMs, even\nsurpassing BM25 on the code retrieval task, and maintain comparable performance\nto base LLMs in supervised settings. These findings suggest promising\ndirections for the unified retrieval task leveraging cross-domain and\ncross-modal fusion.\n","authors":["Hengran Zhang","Keping Bi","Jiafeng Guo"],"pdf_url":"https://arxiv.org/pdf/2507.03958v2.pdf","comment":"Accepted by CCIR25 and published by Springer LNCS or LNAI"},{"id":"http://arxiv.org/abs/2410.23736v2","updated":"2025-08-06T07:58:08Z","published":"2024-10-31T08:49:05Z","title":"Modality and Task Adaptation for Enhanced Zero-shot Composed Image\n  Retrieval","summary":"  As a challenging vision-language task, Zero-Shot Composed Image Retrieval\n(ZS-CIR) is designed to retrieve target images using bi-modal (image+text)\nqueries. Typical ZS-CIR methods employ an inversion network to generate\npseudo-word tokens that effectively represent the input semantics. However, the\ninversion-based methods suffer from two inherent issues: First, the task\ndiscrepancy exists because inversion training and CIR inference involve\ndifferent objectives. Second, the modality discrepancy arises from the input\nfeature distribution mismatch between training and inference. To this end, we\npropose a lightweight post-hoc framework, consisting of two components: (1) A\nnew text-anchored triplet construction pipeline leverages a large language\nmodel (LLM) to transform a standard image-text dataset into a triplet dataset,\nwhere a textual description serves as the target of each triplet. (2) The\nMoTa-Adapter, a novel parameter-efficient fine-tuning method, adapts the dual\nencoder to the CIR task using our constructed triplet data. Specifically, on\nthe text side, multiple sets of learnable task prompts are integrated via a\nMixture-of-Experts (MoE) layer to capture task-specific priors and handle\ndifferent types of modifications. On the image side, MoTa-Adapter modulates the\ninversion network's input to better match the downstream text encoder. In\naddition, an entropy-based optimization strategy is proposed to assign greater\nweight to challenging samples, thus ensuring efficient adaptation. Experiments\nshow that, with the incorporation of our proposed components, inversion-based\nmethods achieve significant improvements, reaching state-of-the-art performance\nacross four widely-used benchmarks. All data and code will be made publicly\navailable.\n","authors":["Haiwen Li","Fei Su","Zhicheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.23736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02096v2","updated":"2025-08-06T07:55:11Z","published":"2025-08-04T06:07:33Z","title":"Evaluating User Experience in Conversational Recommender Systems: A\n  Systematic Review Across Classical and LLM-Powered Approaches","summary":"  Conversational Recommender Systems (CRSs) are receiving growing research\nattention across domains, yet their user experience (UX) evaluation remains\nlimited. Existing reviews largely overlook empirical UX studies, particularly\nin adaptive and large language model (LLM)-based CRSs. To address this gap, we\nconducted a systematic review following PRISMA guidelines, synthesising 23\nempirical studies published between 2017 and 2025. We analysed how UX has been\nconceptualised, measured, and shaped by domain, adaptivity, and LLM. Our\nfindings reveal persistent limitations: post hoc surveys dominate, turn-level\naffective UX constructs are rarely assessed, and adaptive behaviours are seldom\nlinked to UX outcomes. LLM-based CRSs introduce further challenges, including\nepistemic opacity and verbosity, yet evaluations infrequently address these\nissues. We contribute a structured synthesis of UX metrics, a comparative\nanalysis of adaptive and nonadaptive systems, and a forward-looking agenda for\nLLM-aware UX evaluation. These findings support the development of more\ntransparent, engaging, and user-centred CRS evaluation practices.\n","authors":["Raj Mahmud","Yufeng Wu","Abdullah Bin Sawad","Shlomo Berkovsky","Mukesh Prasad","A. Baki Kocaballi"],"pdf_url":"https://arxiv.org/pdf/2508.02096v2.pdf","comment":"Accepted at OzCHI 2025. 23 pages, 1 figure, 5 tables"},{"id":"http://arxiv.org/abs/2508.04162v1","updated":"2025-08-06T07:39:17Z","published":"2025-08-06T07:39:17Z","title":"SSEmb: A Joint Structural and Semantic Embedding Framework for\n  Mathematical Formula Retrieval","summary":"  Formula retrieval is an important topic in Mathematical Information\nRetrieval. We propose SSEmb, a novel embedding framework capable of capturing\nboth structural and semantic features of mathematical formulas. Structurally,\nwe employ Graph Contrastive Learning to encode formulas represented as Operator\nGraphs. To enhance structural diversity while preserving mathematical validity\nof these formula graphs, we introduce a novel graph data augmentation approach\nthrough a substitution strategy. Semantically, we utilize Sentence-BERT to\nencode the surrounding text of formulas. Finally, for each query and its\ncandidates, structural and semantic similarities are calculated separately and\nthen fused through a weighted scheme. In the ARQMath-3 formula retrieval task,\nSSEmb outperforms existing embedding-based methods by over 5 percentage points\non P'@10 and nDCG'@10. Furthermore, SSEmb enhances the performance of all runs\nof other methods and achieves state-of-the-art results when combined with\nApproach0.\n","authors":["Ruyin Li","Xiaoyu Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04162v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04152v1","updated":"2025-08-06T07:28:11Z","published":"2025-08-06T07:28:11Z","title":"Bridging Search and Recommendation through Latent Cross Reasoning","summary":"  Search and recommendation (S&R) are fundamental components of modern online\nplatforms, yet effectively leveraging search behaviors to improve\nrecommendation remains a challenging problem. User search histories often\ncontain noisy or irrelevant signals that can even degrade recommendation\nperformance, while existing approaches typically encode S&R histories either\njointly or separately without explicitly identifying which search behaviors are\ntruly useful. Inspired by the human decision-making process, where one first\nidentifies recommendation intent and then reasons about relevant evidence, we\ndesign a latent cross reasoning framework that first encodes user S&R histories\nto capture global interests and then iteratively reasons over search behaviors\nto extract signals beneficial for recommendation. Contrastive learning is\nemployed to align latent reasoning states with target items, and reinforcement\nlearning is further introduced to directly optimize ranking performance.\nExtensive experiments on public benchmarks demonstrate consistent improvements\nover strong baselines, validating the importance of reasoning in enhancing\nsearch-aware recommendation.\n","authors":["Teng Shi","Weicong Qin","Weijie Yu","Xiao Zhang","Ming He","Jianping Fan","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2508.04152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04145v1","updated":"2025-08-06T07:16:40Z","published":"2025-08-06T07:16:40Z","title":"Benefit from Rich: Tackling Search Interaction Sparsity in Search\n  Enhanced Recommendation","summary":"  In modern online platforms, search and recommendation (S&R) often coexist,\noffering opportunities for performance improvement through search-enhanced\napproaches. Existing studies show that incorporating search signals boosts\nrecommendation performance. However, the effectiveness of these methods relies\nheavily on rich search interactions. They primarily benefit a small subset of\nusers with abundant search behavior, while offering limited improvements for\nthe majority of users who exhibit only sparse search activity. To address the\nproblem of sparse search data in search-enhanced recommendation, we face two\nkey challenges: (1) how to learn useful search features for users with sparse\nsearch interactions, and (2) how to design effective training objectives under\nsparse conditions. Our idea is to leverage the features of users with rich\nsearch interactions to enhance those of users with sparse search interactions.\nBased on this idea, we propose GSERec, a method that utilizes message passing\non the User-Code Graphs to alleviate data sparsity in Search-Enhanced\nRecommendation. Specifically, we utilize Large Language Models (LLMs) with\nvector quantization to generate discrete codes, which connect similar users and\nthereby construct the graph. Through message passing on this graph, embeddings\nof users with rich search data are propagated to enhance the embeddings of\nusers with sparse interactions. To further ensure that the message passing\ncaptures meaningful information from truly similar users, we introduce a\ncontrastive loss to better model user similarities. The enhanced user\nrepresentations are then integrated into downstream search-enhanced\nrecommendation models. Experiments on three real-world datasets show that\nGSERec consistently outperforms baselines, especially for users with sparse\nsearch behaviors.\n","authors":["Teng Shi","Weijie Yu","Xiao Zhang","Ming He","Jianping Fan","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2508.04145v1.pdf","comment":"Accepted by CIKM 2025"},{"id":"http://arxiv.org/abs/2401.11441v3","updated":"2025-08-06T03:23:30Z","published":"2024-01-21T09:42:24Z","title":"On-Device Recommender Systems: A Comprehensive Survey","summary":"  Recommender systems have been widely deployed in various real-world\napplications to help users identify content of interest from massive amounts of\ninformation. Traditional recommender systems work by collecting user-item\ninteraction data in a cloud-based data center and training a centralized model\nto perform the recommendation service. However, such cloud-based recommender\nsystems (CloudRSs) inevitably suffer from excessive resource consumption,\nresponse latency, as well as privacy and security risks concerning both data\nand models. Recently, driven by the advances in storage, communication, and\ncomputation capabilities of edge devices, there has been a shift of focus from\nCloudRSs to on-device recommender systems (DeviceRSs), which leverage the\ncapabilities of edge devices to minimize centralized data storage requirements,\nreduce the response latency caused by communication overheads, and enhance user\nprivacy and security by localizing data processing and model training. Despite\nthe rapid rise of DeviceRSs, there is a clear absence of timely literature\nreviews that systematically introduce, categorize and contrast these methods.\nTo bridge this gap, we aim to provide a comprehensive survey of DeviceRSs,\ncovering three main aspects: (1) the deployment and inference of DeviceRSs (2)\nthe training and update of DeviceRSs (3) the security and privacy of DeviceRSs.\nFurthermore, we provide a fine-grained and systematic taxonomy of the methods\ninvolved in each aspect, followed by a discussion regarding challenges and\nfuture research directions. This is the first comprehensive survey on DeviceRSs\nthat covers a spectrum of tasks to fit various needs. We believe this survey\nwill help readers effectively grasp the current research status in this field,\nequip them with relevant technical foundations, and stimulate new research\nideas for developing DeviceRSs.\n","authors":["Hongzhi Yin","Liang Qu","Tong Chen","Wei Yuan","Ruiqi Zheng","Jing Long","Xin Xia","Yuhui Shi","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2401.11441v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04032v1","updated":"2025-08-06T02:52:09Z","published":"2025-08-06T02:52:09Z","title":"Enhancing Serendipity Recommendation System by Constructing Dynamic User\n  Knowledge Graphs with Large Language Models","summary":"  The feedback loop in industrial recommendation systems reinforces homogeneous\ncontent, creates filter bubble effects, and diminishes user satisfaction.\nRecently, large language models(LLMs) have demonstrated potential in\nserendipity recommendation, thanks to their extensive world knowledge and\nsuperior reasoning capabilities. However, these models still face challenges in\nensuring the rationality of the reasoning process, the usefulness of the\nreasoning results, and meeting the latency requirements of industrial\nrecommendation systems (RSs). To address these challenges, we propose a method\nthat leverages llm to dynamically construct user knowledge graphs, thereby\nenhancing the serendipity of recommendation systems. This method comprises a\ntwo stage framework:(1) two-hop interest reasoning, where user static profiles\nand historical behaviors are utilized to dynamically construct user knowledge\ngraphs via llm. Two-hop reasoning, which can enhance the quality and accuracy\nof LLM reasoning results, is then performed on the constructed graphs to\nidentify users' potential interests; and(2) Near-line adaptation, a\ncost-effective approach to deploying the aforementioned models in industrial\nrecommendation systems. We propose a u2i (user-to-item) retrieval model that\nalso incorporates i2i (item-to-item) retrieval capabilities, the retrieved\nitems not only exhibit strong relevance to users' newly emerged interests but\nalso retain the high conversion rate of traditional u2i retrieval. Our online\nexperiments on the Dewu app, which has tens of millions of users, indicate that\nthe method increased the exposure novelty rate by 4.62%, the click novelty rate\nby 4.85%, the average view duration per person by 0.15%, unique visitor click\nthrough rate by 0.07%, and unique visitor interaction penetration by 0.30%,\nenhancing user experience.\n","authors":["Qian Yong","Yanhui Li","Jialiang Shi","Yaguang Dou","Tian Qi"],"pdf_url":"https://arxiv.org/pdf/2508.04032v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2508.03306v2","updated":"2025-08-06T02:48:59Z","published":"2025-08-05T10:27:57Z","title":"Reliable Evaluation Protocol for Low-Precision Retrieval","summary":"  Lowering the numerical precision of model parameters and computations is\nwidely adopted to improve the efficiency of retrieval systems. However, when\ncomputing relevance scores between the query and documents in low-precision, we\nobserve spurious ties due to the reduced granularity. This introduces high\nvariability in the results based on tie resolution, making the evaluation less\nreliable. To address this, we propose a more robust retrieval evaluation\nprotocol designed to reduce score variation. It consists of: (1) High-Precision\nScoring (HPS), which upcasts the final scoring step to higher precision to\nresolve tied candidates with minimal computational cost; and (2) Tie-aware\nRetrieval Metrics (TRM), which report expected scores, range, and bias to\nquantify order uncertainty of tied candidates. Our experiments test multiple\nmodels with three scoring functions on two retrieval datasets to demonstrate\nthat HPS dramatically reduces tie-induced instability, and TRM accurately\nrecovers expected metric values. This combination enables a more consistent and\nreliable evaluation system for lower-precision retrievals.\n","authors":["Kisu Yang","Yoonna Jang","Hwanseok Jang","Kenneth Choi","Isabelle Augenstein","Heuiseok Lim"],"pdf_url":"https://arxiv.org/pdf/2508.03306v2.pdf","comment":"11 pages, 5 figures, submitted to ARR"},{"id":"http://arxiv.org/abs/2508.04028v1","updated":"2025-08-06T02:44:08Z","published":"2025-08-06T02:44:08Z","title":"Dual Prompt Learning for Adapting Vision-Language Models to Downstream\n  Image-Text Retrieval","summary":"  Recently, prompt learning has demonstrated remarkable success in adapting\npre-trained Vision-Language Models (VLMs) to various downstream tasks such as\nimage classification. However, its application to the downstream Image-Text\nRetrieval (ITR) task is more challenging. We find that the challenge lies in\ndiscriminating both fine-grained attributes and similar subcategories of the\ndownstream data. To address this challenge, we propose Dual prompt Learning\nwith Joint Category-Attribute Reweighting (DCAR), a novel dual-prompt learning\nframework to achieve precise image-text matching. The framework dynamically\nadjusts prompt vectors from both semantic and visual dimensions to improve the\nperformance of CLIP on the downstream ITR task. Based on the prompt paradigm,\nDCAR jointly optimizes attribute and class features to enhance fine-grained\nrepresentation learning. Specifically, (1) at the attribute level, it\ndynamically updates the weights of attribute descriptions based on text-image\nmutual information correlation; (2) at the category level, it introduces\nnegative samples from multiple perspectives with category-matching weighting to\nlearn subcategory distinctions. To validate our method, we construct the\nFine-class Described Retrieval Dataset (FDRD), which serves as a challenging\nbenchmark for ITR in downstream data domains. It covers over 1,500 downstream\nfine categories and 230,000 image-caption pairs with detailed attribute\nannotations. Extensive experiments on FDRD demonstrate that DCAR achieves\nstate-of-the-art performance over existing baselines.\n","authors":["Yifan Wang","Tao Wang","Chenwei Tang","Caiyang Yu","Zhengqing Zang","Mengmi Zhang","Shudong Huang","Jiancheng Lv"],"pdf_url":"https://arxiv.org/pdf/2508.04028v1.pdf","comment":"10 pages, 7figures"},{"id":"http://arxiv.org/abs/2508.04022v1","updated":"2025-08-06T02:29:40Z","published":"2025-08-06T02:29:40Z","title":"Prototype-Driven Structure Synergy Network for Remote Sensing Images\n  Segmentation","summary":"  In the semantic segmentation of remote sensing images, acquiring complete\nground objects is critical for achieving precise analysis. However, this task\nis severely hindered by two major challenges: high intra-class variance and\nhigh inter-class similarity. Traditional methods often yield incomplete\nsegmentation results due to their inability to effectively unify class\nrepresentations and distinguish between similar features. Even emerging\nclass-guided approaches are limited by coarse class prototype representations\nand a neglect of target structural information.\n  Therefore, this paper proposes a Prototype-Driven Structure Synergy Network\n(PDSSNet). The design of this network is based on a core concept, a complete\nground object is jointly defined by its invariant class semantics and its\nvariant spatial structure. To implement this, we have designed three key\nmodules. First, the Adaptive Prototype Extraction Module (APEM) ensures\nsemantic accuracy from the source by encoding the ground truth to extract\nunbiased class prototypes. Subsequently, the designed Semantic-Structure\nCoordination Module (SSCM) follows a hierarchical semantics-first,\nstructure-second principle. This involves first establishing a global semantic\ncognition, then leveraging structural information to constrain and refine the\nsemantic representation, thereby ensuring the integrity of class information.\nFinally, the Channel Similarity Adjustment Module (CSAM) employs a dynamic\nstep-size adjustment mechanism to focus on discriminative features between\nclasses.\n  Extensive experiments demonstrate that PDSSNet outperforms state-of-the-art\nmethods. The source code is available at\nhttps://github.com/wangjunyi-1/PDSSNet.\n","authors":["Junyi Wang","Jinjiang Li","Guodong Fan","Yakun Ju","Xiang Fang","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2508.04022v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21563v2","updated":"2025-08-06T01:55:06Z","published":"2025-07-29T07:51:56Z","title":"Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank\n  Augmentation","summary":"  Recommendation systems often suffer from data sparsity caused by limited\nuser-item interactions, which degrade their performance and amplify popularity\nbias in real-world scenarios. This paper proposes a novel data augmentation\nframework that leverages Large Language Models (LLMs) and item textual\ndescriptions to enrich interaction data. By few-shot prompting LLMs multiple\ntimes to rerank items and aggregating the results via majority voting, we\ngenerate high-confidence synthetic user-item interactions, supported by\ntheoretical guarantees based on the concentration of measure. To effectively\nleverage the augmented data in the context of a graph recommendation system, we\nintegrate it into a graph contrastive learning framework to mitigate\ndistributional shift and alleviate popularity bias. Extensive experiments show\nthat our method improves accuracy and reduces popularity bias, outperforming\nstrong baselines.\n","authors":["Minh-Anh Nguyen","Bao Nguyen","Ha Lan N. T.","Tuan Anh Hoang","Duc-Trong Le","Dung D. Le"],"pdf_url":"https://arxiv.org/pdf/2507.21563v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04001v1","updated":"2025-08-06T01:28:49Z","published":"2025-08-06T01:28:49Z","title":"ConvMix: A Mixed-Criteria Data Augmentation Framework for Conversational\n  Dense Retrieval","summary":"  Conversational search aims to satisfy users' complex information needs via\nmultiple-turn interactions. The key challenge lies in revealing real users'\nsearch intent from the context-dependent queries. Previous studies achieve\nconversational search by fine-tuning a conversational dense retriever with\nrelevance judgments between pairs of context-dependent queries and documents.\nHowever, this training paradigm encounters data scarcity issues. To this end,\nwe propose ConvMix, a mixed-criteria framework to augment conversational dense\nretrieval, which covers more aspects than existing data augmentation\nframeworks. We design a two-sided relevance judgment augmentation schema in a\nscalable manner via the aid of large language models. Besides, we integrate the\nframework with quality control mechanisms to obtain semantically diverse\nsamples and near-distribution supervisions to combine various annotated data.\nExperimental results on five widely used benchmarks show that the\nconversational dense retriever trained by our ConvMix framework outperforms\nprevious baseline methods, which demonstrates our superior effectiveness.\n","authors":["Fengran Mo","Jinghan Zhang","Yuchen Hui","Jia Ao Sun","Zhichao Xu","Zhan Su","Jian-Yun Nie"],"pdf_url":"https://arxiv.org/pdf/2508.04001v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10507v3","updated":"2025-08-06T20:36:12Z","published":"2025-04-09T17:46:12Z","title":"PinRec: Outcome-Conditioned, Multi-Token Generative Retrieval for\n  Industry-Scale Recommendation Systems","summary":"  Generative retrieval methods utilize generative sequential modeling\ntechniques, such as transformers, to generate candidate items for recommender\nsystems. These methods have demonstrated promising results in academic\nbenchmarks, surpassing traditional retrieval models like two-tower\narchitectures. However, current generative retrieval methods lack the\nscalability required for industrial recommender systems, and they are\ninsufficiently flexible to satisfy the multiple metric requirements of modern\nsystems. This paper introduces PinRec, a novel generative retrieval model\ndeveloped for applications at Pinterest. PinRec utilizes outcome-conditioned\ngeneration, enabling modelers to specify how to balance various outcome\nmetrics, such as the number of saves and clicks, to effectively align with\nbusiness goals and user exploration. Additionally, PinRec incorporates\nmulti-token generation to enhance output diversity while optimizing generation.\nOur experiments demonstrate that PinRec can successfully balance performance,\ndiversity, and efficiency, delivering a significant positive impact to users\nusing generative models. This paper marks a significant milestone in generative\nretrieval, as it presents, to our knowledge, the first rigorous study on\nimplementing generative retrieval at the scale of Pinterest.\n","authors":["Anirudhan Badrinath","Prabhat Agarwal","Laksh Bhasin","Jaewon Yang","Jiajing Xu","Charles Rosenberg"],"pdf_url":"https://arxiv.org/pdf/2504.10507v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02929v2","updated":"2025-08-06T18:44:24Z","published":"2025-08-04T22:03:13Z","title":"Realizing Scaling Laws in Recommender Systems: A Foundation-Expert\n  Paradigm for Hyperscale Model Deployment","summary":"  While scaling laws promise significant performance gains for recommender\nsystems, efficiently deploying hyperscale models remains a major unsolved\nchallenge. In contrast to fields where FMs are already widely adopted such as\nnatural language processing and computer vision, progress in recommender\nsystems is hindered by unique challenges including the need to learn from\nonline streaming data under shifting data distributions, the need to adapt to\ndifferent recommendation surfaces with a wide diversity in their downstream\ntasks and their input distributions, and stringent latency and computational\nconstraints. To bridge this gap, we propose to leverage the Foundation-Expert\nParadigm: a framework designed for the development and deployment of hyperscale\nrecommendation FMs. In our approach, a central FM is trained on lifelong,\ncross-surface, multi-modal user data to learn generalizable knowledge. This\nknowledge is then efficiently transferred to various lightweight,\nsurface-specific \"expert\" models via target-aware embeddings, allowing them to\nadapt to local data distributions and optimization goals with minimal overhead.\nTo meet our training, inference and development needs, we built HyperCast, a\nproduction-grade infrastructure system that re-engineers training, serving,\nlogging and iteration to power this decoupled paradigm. Our approach is now\ndeployed at Meta serving tens of billions of user requests daily, demonstrating\nonline metric improvements over our previous one-stage production system while\nimproving developer velocity and maintaining infrastructure efficiency. To the\nbest of our knowledge, this work represents the first successful deployment of\na Foundation-Expert paradigm at this scale, offering a proven,\ncompute-efficient, and developer-friendly blueprint to realize the promise of\nscaling laws in recommender systems.\n","authors":["Dai Li","Kevin Course","Wei Li","Hongwei Li","Jie Hua","Yiqi Chen","Zhao Zhu","Rui Jian","Xuan Cao","Bi Xue","Yu Shi","Jing Qian","Kai Ren","Matt Ma","Qunshu Zhang","Rui Li"],"pdf_url":"https://arxiv.org/pdf/2508.02929v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04792v1","updated":"2025-08-06T18:06:36Z","published":"2025-08-06T18:06:36Z","title":"Federated Continual Recommendation","summary":"  The increasing emphasis on privacy in recommendation systems has led to the\nadoption of Federated Learning (FL) as a privacy-preserving solution, enabling\ncollaborative training without sharing user data. While Federated\nRecommendation (FedRec) effectively protects privacy, existing methods struggle\nwith non-stationary data streams, failing to maintain consistent recommendation\nquality over time. On the other hand, Continual Learning Recommendation (CLRec)\nmethods address evolving user preferences but typically assume centralized data\naccess, making them incompatible with FL constraints. To bridge this gap, we\nintroduce Federated Continual Recommendation (FCRec), a novel task that\nintegrates FedRec and CLRec, requiring models to learn from streaming data\nwhile preserving privacy. As a solution, we propose F3CRec, a framework\ndesigned to balance knowledge retention and adaptation under the strict\nconstraints of FCRec. F3CRec introduces two key components: Adaptive Replay\nMemory on the client side, which selectively retains past preferences based on\nuser-specific shifts, and Item-wise Temporal Mean on the server side, which\nintegrates new knowledge while preserving prior information. Extensive\nexperiments demonstrate that F3CRec outperforms existing approaches in\nmaintaining recommendation quality over time in a federated environment.\n","authors":["Jaehyung Lim","Wonbin Kweon","Woojoo Kim","Junyoung Kim","Seongjin Choi","Dongha Kim","Hwanjo Yu"],"pdf_url":"https://arxiv.org/pdf/2508.04792v1.pdf","comment":"Accepted to CIKM 2025"},{"id":"http://arxiv.org/abs/2508.04273v1","updated":"2025-08-06T09:58:43Z","published":"2025-08-06T09:58:43Z","title":"Audio Does Matter: Importance-Aware Multi-Granularity Fusion for Video\n  Moment Retrieval","summary":"  Video Moment Retrieval (VMR) aims to retrieve a specific moment semantically\nrelated to the given query. To tackle this task, most existing VMR methods\nsolely focus on the visual and textual modalities while neglecting the\ncomplementary but important audio modality. Although a few recent works try to\ntackle the joint audio-vision-text reasoning, they treat all modalities equally\nand simply embed them without fine-grained interaction for moment retrieval.\nThese designs are counter-practical as: Not all audios are helpful for video\nmoment retrieval, and the audio of some videos may be complete noise or\nbackground sound that is meaningless to the moment determination. To this end,\nwe propose a novel Importance-aware Multi-Granularity fusion model (IMG), which\nlearns to dynamically and selectively aggregate the audio-vision-text contexts\nfor VMR. Specifically, after integrating the textual guidance with vision and\naudio separately, we first design a pseudo-label-supervised audio importance\npredictor that predicts the importance score of the audio, and accordingly\nassigns weights to mitigate the interference caused by noisy audio. Then, we\ndesign a multi-granularity audio fusion module that adaptively fuses audio and\nvisual modalities at local-, event-, and global-level, fully capturing their\ncomplementary contexts. We further propose a cross-modal knowledge distillation\nstrategy to address the challenge of missing audio modality during inference.\nTo evaluate our method, we further construct a new VMR dataset, i.e.,\nCharades-AudioMatter, where audio-related samples are manually selected and\nre-organized from the original Charades-STA to validate the model's capability\nin utilizing audio modality. Extensive experiments validate the effectiveness\nof our method, achieving state-of-the-art with audio-video fusion in VMR\nmethods. Our code is available at https://github.com/HuiGuanLab/IMG.\n","authors":["Junan Lin","Daizong Liu","Xianke Chen","Xiaoye Qu","Xun Yang","Jixiang Zhu","Sanyuan Zhang","Jianfeng Dong"],"pdf_url":"https://arxiv.org/pdf/2508.04273v1.pdf","comment":"Accepted to ACM MM 2025"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2508.04700v1","updated":"2025-08-06T17:58:46Z","published":"2025-08-06T17:58:46Z","title":"SEAgent: Self-Evolving Computer Use Agent with Autonomous Learning from\n  Experience","summary":"  Repurposing large vision-language models (LVLMs) as computer use agents\n(CUAs) has led to substantial breakthroughs, primarily driven by human-labeled\ndata. However, these models often struggle with novel and specialized software,\nparticularly in scenarios lacking human annotations. To address this challenge,\nwe propose SEAgent, an agentic self-evolving framework enabling CUAs to\nautonomously evolve through interactions with unfamiliar software.\nSpecifically, SEAgent empowers computer-use agents to autonomously master novel\nsoftware environments via experiential learning, where agents explore new\nsoftware, learn through iterative trial-and-error, and progressively tackle\nauto-generated tasks organized from simple to complex. To achieve this goal, we\ndesign a World State Model for step-wise trajectory assessment, along with a\nCurriculum Generator that generates increasingly diverse and challenging tasks.\nThe agent's policy is updated through experiential learning, comprised of\nadversarial imitation of failure actions and Group Relative Policy Optimization\n(GRPO) on successful ones. Furthermore, we introduce a specialist-to-generalist\ntraining strategy that integrates individual experiential insights from\nspecialist agents, facilitating the development of a stronger generalist CUA\ncapable of continuous autonomous evolution. This unified agent ultimately\nachieves performance surpassing ensembles of individual specialist agents on\ntheir specialized software. We validate the effectiveness of SEAgent across\nfive novel software environments within OS-World. Our approach achieves a\nsignificant improvement of 23.2% in success rate, from 11.3% to 34.5%, over a\ncompetitive open-source CUA, i.e., UI-TARS.\n","authors":["Zeyi Sun","Ziyu Liu","Yuhang Zang","Yuhang Cao","Xiaoyi Dong","Tong Wu","Dahua Lin","Jiaqi Wang"],"pdf_url":"https://arxiv.org/pdf/2508.04700v1.pdf","comment":"Code at https://github.com/SunzeY/SEAgent"},{"id":"http://arxiv.org/abs/2508.04683v1","updated":"2025-08-06T17:47:00Z","published":"2025-08-06T17:47:00Z","title":"Query Attribute Modeling: Improving search relevance with Semantic\n  Search and Meta Data Filtering","summary":"  This study introduces Query Attribute Modeling (QAM), a hybrid framework that\nenhances search precision and relevance by decomposing open text queries into\nstructured metadata tags and semantic elements. QAM addresses traditional\nsearch limitations by automatically extracting metadata filters from free-form\ntext queries, reducing noise and enabling focused retrieval of relevant items.\n  Experimental evaluation using the Amazon Toys Reviews dataset (10,000 unique\nitems with 40,000+ reviews and detailed product attributes) demonstrated QAM's\nsuperior performance, achieving a mean average precision at 5 (mAP@5) of\n52.99\\%. This represents significant improvement over conventional methods,\nincluding BM25 keyword search, encoder-based semantic similarity search,\ncross-encoder re-ranking, and hybrid search combining BM25 and semantic results\nvia Reciprocal Rank Fusion (RRF). The results establish QAM as a robust\nsolution for Enterprise Search applications, particularly in e-commerce\nsystems.\n","authors":["Karthik Menon","Batool Arhamna Haider","Muhammad Arham","Kanwal Mehreen","Ram Mohan Rao Kadiyala","Hamza Farooq"],"pdf_url":"https://arxiv.org/pdf/2508.04683v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04676v1","updated":"2025-08-06T17:42:22Z","published":"2025-08-06T17:42:22Z","title":"GeRe: Towards Efficient Anti-Forgetting in Continual Learning of LLM via\n  General Samples Replay","summary":"  The continual learning capability of large language models (LLMs) is crucial\nfor advancing artificial general intelligence. However, continual fine-tuning\nLLMs across various domains often suffers from catastrophic forgetting,\ncharacterized by: 1) significant forgetting of their general capabilities, and\n2) sharp performance declines in previously learned tasks. To simultaneously\naddress both issues in a simple yet stable manner, we propose General Sample\nReplay (GeRe), a framework that use usual pretraining texts for efficient\nanti-forgetting. Beyond revisiting the most prevalent replay-based practices\nunder GeRe, we further leverage neural states to introduce a enhanced\nactivation states constrained optimization method using threshold-based margin\n(TM) loss, which maintains activation state consistency during replay learning.\nWe are the first to validate that a small, fixed set of pre-collected general\nreplay samples is sufficient to resolve both concerns--retaining general\ncapabilities while promoting overall performance across sequential tasks.\nIndeed, the former can inherently facilitate the latter. Through controlled\nexperiments, we systematically compare TM with different replay strategies\nunder the GeRe framework, including vanilla label fitting, logit imitation via\nKL divergence and feature imitation via L1/L2 losses. Results demonstrate that\nTM consistently improves performance and exhibits better robustness. Our work\npaves the way for efficient replay of LLMs for the future. Our code and data\nare available at https://github.com/Qznan/GeRe.\n","authors":["Yunan Zhang","Shuoran Jiang","Mengchen Zhao","Yuefeng Li","Yang Fan","Xiangping Wu","Qingcai Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04676v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04670v1","updated":"2025-08-06T17:37:06Z","published":"2025-08-06T17:37:06Z","title":"Robustly Learning Monotone Single-Index Models","summary":"  We consider the basic problem of learning Single-Index Models with respect to\nthe square loss under the Gaussian distribution in the presence of adversarial\nlabel noise. Our main contribution is the first computationally efficient\nalgorithm for this learning task, achieving a constant factor approximation,\nthat succeeds for the class of {\\em all} monotone activations with bounded\nmoment of order $2 + \\zeta,$ for $\\zeta > 0.$ This class in particular includes\nall monotone Lipschitz functions and even discontinuous functions like\n(possibly biased) halfspaces. Prior work for the case of unknown activation\neither does not attain constant factor approximation or succeeds for a\nsubstantially smaller family of activations. The main conceptual novelty of our\napproach lies in developing an optimization framework that steps outside the\nboundaries of usual gradient methods and instead identifies a useful vector\nfield to guide the algorithm updates by directly leveraging the problem\nstructure, properties of Gaussian spaces, and regularity of monotone functions.\n","authors":["Puqian Wang","Nikos Zarifis","Ilias Diakonikolas","Jelena Diakonikolas"],"pdf_url":"https://arxiv.org/pdf/2508.04670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09908v2","updated":"2025-08-06T17:36:57Z","published":"2024-10-13T16:28:38Z","title":"Beyond Adapter Retrieval: Latent Geometry-Preserving Composition via\n  Sparse Task Projection","summary":"  Recent advances in parameter-efficient transfer learning have demonstrated\nthe utility of composing LoRA adapters from libraries of pretrained modules.\nHowever, most existing approaches rely on simple retrieval heuristics or\nuniform averaging, which overlook the latent structure of task relationships in\nrepresentation space. We propose a new framework for adapter reuse that moves\nbeyond retrieval, formulating adapter composition as a geometry-aware sparse\nreconstruction problem. Specifically, we represent each task by a latent\nprototype vector derived from the base model's encoder and aim to approximate\nthe target task prototype as a sparse linear combination of retrieved reference\nprototypes, under an $\\ell_1$-regularized optimization objective. The resulting\ncombination weights are then used to blend the corresponding LoRA adapters,\nyielding a composite adapter tailored to the target task. This formulation not\nonly preserves the local geometric structure of the task representation\nmanifold, but also promotes interpretability and efficient reuse by selecting a\nminimal set of relevant adapters. We demonstrate the effectiveness of our\napproach across multiple domains-including medical image segmentation, medical\nreport generation and image synthesis. Our results highlight the benefit of\ncoupling retrieval with latent geometry-aware optimization for improved\nzero-shot generalization.\n","authors":["Pengfei Jin","Peng Shu","Sifan Song","Sekeun Kim","Qing Xiao","Cheng Chen","Tianming Liu","Xiang Li","Quanzheng Li"],"pdf_url":"https://arxiv.org/pdf/2410.09908v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04665v1","updated":"2025-08-06T17:34:43Z","published":"2025-08-06T17:34:43Z","title":"Perch 2.0: The Bittern Lesson for Bioacoustics","summary":"  Perch is a performant pre-trained model for bioacoustics. It was trained in\nsupervised fashion, providing both off-the-shelf classification scores for\nthousands of vocalizing species as well as strong embeddings for transfer\nlearning. In this new release, Perch 2.0, we expand from training exclusively\non avian species to a large multi-taxa dataset. The model is trained with\nself-distillation using a prototype-learning classifier as well as a new\nsource-prediction training criterion. Perch 2.0 obtains state-of-the-art\nperformance on the BirdSet and BEANS benchmarks. It also outperforms\nspecialized marine models on marine transfer learning tasks, despite having\nalmost no marine training data. We present hypotheses as to why fine-grained\nspecies classification is a particularly robust pre-training task for\nbioacoustics.\n","authors":["Bart van Merriënboer","Vincent Dumoulin","Jenny Hamer","Lauren Harrell","Andrea Burns","Tom Denton"],"pdf_url":"https://arxiv.org/pdf/2508.04665v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.06663v2","updated":"2025-08-06T17:33:10Z","published":"2025-01-11T23:29:51Z","title":"Ultra Memory-Efficient On-FPGA Training of Transformers via\n  Tensor-Compressed Optimization","summary":"  Transformer models have achieved state-of-the-art performance across a wide\nrange of machine learning tasks. There is growing interest in training\ntransformers on resource-constrained edge devices due to considerations such as\nprivacy, domain adaptation, and on-device scientific machine learning. However,\nthe significant computational and memory demands required for transformer\ntraining often exceed the capabilities of an edge device. Leveraging low-rank\ntensor compression, this paper presents the first on-FPGA accelerator for\nend-to-end transformer training. On the algorithm side, we present a\nbi-directional contraction flow for tensorized transformer training,\nsignificantly reducing the computational FLOPS and intra-layer memory costs\ncompared to existing tensor operations. On the hardware side, we store all\nhighly compressed model parameters and gradient information on chip, creating\nan on-chip-memory-only framework for each stage in training. This reduces\noff-chip communication and minimizes latency and energy costs. Additionally, we\nimplement custom computing kernels for each training stage and employ\nintra-layer parallelism and pipe-lining to further enhance run-time and memory\nefficiency. Through experiments on transformer models within $36.7$ to $93.5$\nMB using FP-32 data formats on the ATIS dataset, our tensorized FPGA\naccelerator could conduct single-batch end-to-end training on the AMD Alevo U50\nFPGA, with a memory budget of less than $6$-MB BRAM and $22.5$-MB URAM.\nCompared to uncompressed training on the NVIDIA RTX 3090 GPU, our on-FPGA\ntraining achieves a memory reduction of $30\\times$ to $51\\times$. Our FPGA\naccelerator also achieves up to $3.6\\times$ less energy cost per epoch compared\nwith tensor Transformer training on an NVIDIA RTX 3090 GPU.\n","authors":["Jiayi Tian","Jinming Lu","Hai Li","Xiangwei Wang","Cong Hao","Ian Young","Zheng Zhang"],"pdf_url":"https://arxiv.org/pdf/2501.06663v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04664v1","updated":"2025-08-06T17:32:58Z","published":"2025-08-06T17:32:58Z","title":"Sculptor: Empowering LLMs with Cognitive Agency via Active Context\n  Management","summary":"  Large Language Models (LLMs) suffer from significant performance degradation\nwhen processing long contexts due to proactive interference, where irrelevant\ninformation in earlier parts of the context disrupts reasoning and memory\nrecall. While most research focuses on external memory systems to augment LLMs'\ncapabilities, we propose a complementary approach: empowering LLMs with Active\nContext Management (ACM) tools to actively sculpt their internal working\nmemory. We introduce Sculptor, a framework that equips LLMs with three\ncategories of tools: (1) context fragmentation, (2) summary, hide, and restore,\nand (3) intelligent search. Our approach enables LLMs to proactively manage\ntheir attention and working memory, analogous to how humans selectively focus\non relevant information while filtering out distractions. Experimental\nevaluation on information-sparse benchmarks-PI-LLM (proactive interference) and\nNeedleBench Multi-Needle Reasoning-demonstrates that Sculptor significantly\nimproves performance even without specific training, leveraging LLMs' inherent\ntool calling generalization capabilities. By enabling Active Context\nManagement, Sculptor not only mitigates proactive interference but also\nprovides a cognitive foundation for more reliable reasoning across diverse\nlong-context tasks-highlighting that explicit context-control strategies,\nrather than merely larger token windows, are key to robustness at scale.\n","authors":["Mo Li","L. H. Xu","Qitai Tan","Ting Cao","Yunxin Liu"],"pdf_url":"https://arxiv.org/pdf/2508.04664v1.pdf","comment":"Preprint. Work in progress"},{"id":"http://arxiv.org/abs/2508.03682v2","updated":"2025-08-06T17:23:53Z","published":"2025-08-05T17:51:33Z","title":"Self-Questioning Language Models","summary":"  Can large language models improve without external data -- by generating\ntheir own questions and answers? We hypothesize that a pre-trained language\nmodel can improve its reasoning skills given only a single prompt specifying\nthe topic (e.g., algebra word problems) and asking the model to generate its\nown questions. To do this, we propose Self-Questioning Language Models (SQLM):\nan asymmetric self-play framework where a proposer is given the topic and\ngenerates a question for a solver, who tries to answer it. Both the proposer\nand solver are trained via reinforcement learning. The proposer receives a\nreward if the problem is not too easy or too difficult, and the solver receives\na reward based on majority voting, a proxy for correctness in the absence of\nground-truth answers. For coding, the proposer can instead generate unit tests\nwhich are used for verification. We study this asymmetric self-play framework\non three benchmarks: three-digit multiplication, algebra problems from the\nOMEGA benchmark, and programming problems from Codeforces. By continually\ngenerating more interesting problems and attempting to solve them, language\nmodels can improve on downstream benchmarks without access to any curated\ntraining datasets.\n","authors":["Lili Chen","Mihir Prabhudesai","Katerina Fragkiadaki","Hao Liu","Deepak Pathak"],"pdf_url":"https://arxiv.org/pdf/2508.03682v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04651v1","updated":"2025-08-06T17:18:21Z","published":"2025-08-06T17:18:21Z","title":"Live Music Models","summary":"  We introduce a new class of generative models for music called live music\nmodels that produce a continuous stream of music in real-time with synchronized\nuser control. We release Magenta RealTime, an open-weights live music model\nthat can be steered using text or audio prompts to control acoustic style. On\nautomatic metrics of music quality, Magenta RealTime outperforms other\nopen-weights music generation models, despite using fewer parameters and\noffering first-of-its-kind live generation capabilities. We also release Lyria\nRealTime, an API-based model with extended controls, offering access to our\nmost powerful model with wide prompt coverage. These models demonstrate a new\nparadigm for AI-assisted music creation that emphasizes human-in-the-loop\ninteraction for live music performance.\n","authors":[" Lyria Team","Antoine Caillon","Brian McWilliams","Cassie Tarakajian","Ian Simon","Ilaria Manco","Jesse Engel","Noah Constant","Pen Li","Timo I. Denk","Alberto Lalama","Andrea Agostinelli","Anna Huang","Ethan Manilow","George Brower","Hakan Erdogan","Heidi Lei","Itai Rolnick","Ivan Grishchenko","Manu Orsini","Matej Kastelic","Mauricio Zuluaga","Mauro Verzetti","Michael Dooley","Ondrej Skopek","Rafael Ferrer","Zalán Borsos","Äaron van den Oord","Douglas Eck","Eli Collins","Jason Baldridge","Tom Hume","Chris Donahue","Kehang Han","Adam Roberts"],"pdf_url":"https://arxiv.org/pdf/2508.04651v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04646v1","updated":"2025-08-06T17:13:27Z","published":"2025-08-06T17:13:27Z","title":"Accept-Reject Lasso","summary":"  The Lasso method is known to exhibit instability in the presence of highly\ncorrelated features, often leading to an arbitrary selection of predictors.\nThis issue manifests itself in two primary error types: the erroneous omission\nof features that lack a true substitutable relationship (falsely redundant\nfeatures) and the inclusion of features with a true substitutable relationship\n(truly redundant features). Although most existing methods address only one of\nthese challenges, we introduce the Accept-Reject Lasso (ARL), a novel approach\nthat resolves this dilemma. ARL operationalizes an Accept-Reject framework\nthrough a fine-grained analysis of feature selection across data subsets. This\nframework is designed to partition the output of an ensemble method into\nbeneficial and detrimental components through fine-grained analysis. The\nfundamental challenge for Lasso is that inter-variable correlation obscures the\ntrue sources of information. ARL tackles this by first using clustering to\nidentify distinct subset structures within the data. It then analyzes Lasso's\nbehavior across these subsets to differentiate between true and spurious\ncorrelations. For truly correlated features, which induce multicollinearity,\nARL tends to select a single representative feature and reject the rest to\nensure model stability. Conversely, for features linked by spurious\ncorrelations, which may vanish in certain subsets, ARL accepts those that Lasso\nmight have incorrectly omitted. The distinct patterns arising from true versus\nspurious correlations create a divisible separation. By setting an appropriate\nthreshold, our framework can effectively distinguish between these two\nphenomena, thereby maximizing the inclusion of informative variables while\nminimizing the introduction of detrimental ones. We illustrate the efficacy of\nthe proposed method through extensive simulation and real-data experiments.\n","authors":["Yanxin Liu","Yunqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.04646v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.15110v3","updated":"2025-08-06T17:12:12Z","published":"2025-04-21T14:02:59Z","title":"Approximation Rates in Besov Norms and Sample-Complexity of\n  Kolmogorov-Arnold Networks with Residual Connections","summary":"  Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold\nNetworks (KANs) have recently emerged as an improved backbone for most deep\nlearning frameworks, promising more adaptivity than their multilayer perceptron\n(MLP) predecessor by allowing for trainable spline-based activation functions.\nIn this paper, we probe the theoretical foundations of the KAN architecture by\nshowing that it can optimally approximate any Besov function in\n$B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain\n$\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect\nto any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$.\nWe complement our approximation result with a statistical guarantee by bounding\nthe pseudodimension of the relevant class of Res-KANs. As an application of the\nlatter, we directly deduce a dimension-free estimate on the sample complexity\nof a residual KAN model when learning a function of Besov regularity from $N$\ni.i.d. noiseless samples, showing that KANs can learn the smooth maps which\nthey can approximate.\n","authors":["Anastasis Kratsios","Bum Jun Kim","Takashi Furuya"],"pdf_url":"https://arxiv.org/pdf/2504.15110v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04645v1","updated":"2025-08-06T17:10:31Z","published":"2025-08-06T17:10:31Z","title":"A Scalable Pretraining Framework for Link Prediction with Efficient\n  Adaptation","summary":"  Link Prediction (LP) is a critical task in graph machine learning. While\nGraph Neural Networks (GNNs) have significantly advanced LP performance\nrecently, existing methods face key challenges including limited supervision\nfrom sparse connectivity, sensitivity to initialization, and poor\ngeneralization under distribution shifts. We explore pretraining as a solution\nto address these challenges. Unlike node classification, LP is inherently a\npairwise task, which requires the integration of both node- and edge-level\ninformation. In this work, we present the first systematic study on the\ntransferability of these distinct modules and propose a late fusion strategy to\neffectively combine their outputs for improved performance. To handle the\ndiversity of pretraining data and avoid negative transfer, we introduce a\nMixture-of-Experts (MoE) framework that captures distinct patterns in separate\nexperts, facilitating seamless application of the pretrained model on diverse\ndownstream datasets. For fast adaptation, we develop a parameter-efficient\ntuning strategy that allows the pretrained model to adapt to unseen datasets\nwith minimal computational overhead. Experiments on 16 datasets across two\ndomains demonstrate the effectiveness of our approach, achieving\nstate-of-the-art performance on low-resource link prediction while obtaining\ncompetitive results compared to end-to-end trained methods, with over 10,000x\nlower computational overhead.\n","authors":["Yu Song","Zhigang Hua","Harry Shomer","Yan Xie","Jingzhe Liu","Bo Long","Hui Liu"],"pdf_url":"https://arxiv.org/pdf/2508.04645v1.pdf","comment":"Accepted by KDD 2025 Research Track"},{"id":"http://arxiv.org/abs/2508.01957v3","updated":"2025-08-06T17:06:54Z","published":"2025-08-03T23:48:46Z","title":"Stochastic Encodings for Active Feature Acquisition","summary":"  Active Feature Acquisition is an instance-wise, sequential decision making\nproblem. The aim is to dynamically select which feature to measure based on\ncurrent observations, independently for each test instance. Common approaches\neither use Reinforcement Learning, which experiences training difficulties, or\ngreedily maximize the conditional mutual information of the label and\nunobserved features, which makes myopic acquisitions. To address these\nshortcomings, we introduce a latent variable model, trained in a supervised\nmanner. Acquisitions are made by reasoning about the features across many\npossible unobserved realizations in a stochastic latent space. Extensive\nevaluation on a large range of synthetic and real datasets demonstrates that\nour approach reliably outperforms a diverse set of baselines.\n","authors":["Alexander Norcliffe","Changhee Lee","Fergus Imrie","Mihaela van der Schaar","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2508.01957v3.pdf","comment":"31 pages, 15 figures, 17 tables, published at ICML 2025"},{"id":"http://arxiv.org/abs/2508.04630v1","updated":"2025-08-06T16:57:06Z","published":"2025-08-06T16:57:06Z","title":"CaPulse: Detecting Anomalies by Tuning in to the Causal Rhythms of Time\n  Series","summary":"  Time series anomaly detection has garnered considerable attention across\ndiverse domains. While existing methods often fail to capture the underlying\nmechanisms behind anomaly generation in time series data. In addition, time\nseries anomaly detection often faces several data-related inherent challenges,\ni.e., label scarcity, data imbalance, and complex multi-periodicity. In this\npaper, we leverage causal tools and introduce a new causality-based framework,\nCaPulse, which tunes in to the underlying causal pulse of time series data to\neffectively detect anomalies. Concretely, we begin by building a structural\ncausal model to decipher the generation processes behind anomalies. To tackle\nthe challenges posed by the data, we propose Periodical Normalizing Flows with\na novel mask mechanism and carefully designed periodical learners, creating a\nperiodicity-aware, density-based anomaly detection approach. Extensive\nexperiments on seven real-world datasets demonstrate that CaPulse consistently\noutperforms existing methods, achieving AUROC improvements of 3% to 17%, with\nenhanced interpretability.\n","authors":["Yutong Xia","Yingying Zhang","Yuxuan Liang","Lunting Fan","Qingsong Wen","Roger Zimmermann"],"pdf_url":"https://arxiv.org/pdf/2508.04630v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.00222v3","updated":"2025-08-06T16:36:42Z","published":"2025-07-31T23:55:29Z","title":"RL-PLUS: Countering Capability Boundary Collapse of LLMs in\n  Reinforcement Learning with Hybrid-policy Optimization","summary":"  Reinforcement Learning with Verifiable Reward (RLVR) has significantly\nadvanced the complex reasoning abilities of Large Language Models (LLMs).\nHowever, it struggles to break through the inherent capability boundaries of\nthe base LLM, due to its essentially on-policy strategy coupled with LLM's\nimmense action space and sparse reward. Critically, RLVR can lead to the\ncapability boundary collapse, narrowing the LLM's problem-solving scope. To\naddress this problem, we propose RL-PLUS, a novel hybrid-policy optimization\napproach for LLMs that synergizes internal exploitation with external data to\nachieve stronger reasoning capabilities and surpass the boundaries of base\nmodels. RL-PLUS integrates two core components, i.e., Multiple Importance\nSampling to address distributional mismatch from external data, and\nExploration-Based Advantage Function to guide the model towards high-value,\nunexplored reasoning paths. We provide both theoretical analysis and extensive\nexperiments to demonstrate the superiority and generalizability of our\napproach. Compared with existing RLVR methods, RL-PLUS achieves 1)\nstate-of-the-art performance on six math reasoning benchmarks; 2) superior\nperformance on six out-of-distribution reasoning tasks; 3) consistent and\nsignificant gains across diverse model families, with average relative\nimprovements up to 69.2\\%. Moreover, the analysis of Pass@k curves indicates\nthat RL-PLUS effectively resolves the capability boundary collapse problem.\n","authors":["Yihong Dong","Xue Jiang","Yongding Tao","Huanyu Liu","Kechi Zhang","Lili Mou","Rongyu Cao","Yingwei Ma","Jue Chen","Binhua Li","Zhi Jin","Fei Huang","Yongbin Li","Ge Li"],"pdf_url":"https://arxiv.org/pdf/2508.00222v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04612v1","updated":"2025-08-06T16:33:20Z","published":"2025-08-06T16:33:20Z","title":"A Reproducible, Scalable Pipeline for Synthesizing Autoregressive Model\n  Literature","summary":"  The accelerating pace of research on autoregressive generative models has\nproduced thousands of papers, making manual literature surveys and reproduction\nstudies increasingly impractical. We present a fully open-source, reproducible\npipeline that automatically retrieves candidate documents from public\nrepositories, filters them for relevance, extracts metadata, hyper-parameters\nand reported results, clusters topics, produces retrieval-augmented summaries\nand generates containerised scripts for re-running selected experiments.\nQuantitative evaluation on 50 manually-annotated papers shows F1 scores above\n0.85 for relevance classification, hyper-parameter extraction and citation\nidentification. Experiments on corpora of up to 1000 papers demonstrate\nnear-linear scalability with eight CPU workers. Three case studies -- AWD-LSTM\non WikiText-2, Transformer-XL on WikiText-103 and an autoregressive music model\non the Lakh MIDI dataset -- confirm that the extracted settings support\nfaithful reproduction, achieving test perplexities within 1--3% of the original\nreports.\n","authors":["Faruk Alpay","Bugra Kilictas","Hamdi Alakkad"],"pdf_url":"https://arxiv.org/pdf/2508.04612v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2508.04610v1","updated":"2025-08-06T16:29:59Z","published":"2025-08-06T16:29:59Z","title":"Neuromorphic Cybersecurity with Semi-supervised Lifelong Learning","summary":"  Inspired by the brain's hierarchical processing and energy efficiency, this\npaper presents a Spiking Neural Network (SNN) architecture for lifelong Network\nIntrusion Detection System (NIDS). The proposed system first employs an\nefficient static SNN to identify potential intrusions, which then activates an\nadaptive dynamic SNN responsible for classifying the specific attack type.\nMimicking biological adaptation, the dynamic classifier utilizes Grow When\nRequired (GWR)-inspired structural plasticity and a novel Adaptive\nSpike-Timing-Dependent Plasticity (Ad-STDP) learning rule. These bio-plausible\nmechanisms enable the network to learn new threats incrementally while\npreserving existing knowledge. Tested on the UNSW-NB15 benchmark in a continual\nlearning setting, the architecture demonstrates robust adaptation, reduced\ncatastrophic forgetting, and achieves $85.3$\\% overall accuracy. Furthermore,\nsimulations using the Intel Lava framework confirm high operational sparsity,\nhighlighting the potential for low-power deployment on neuromorphic hardware.\n","authors":["Md Zesun Ahmed Mia","Malyaban Bal","Sen Lu","George M. Nishibuchi","Suhas Chelian","Srini Vasan","Abhronil Sengupta"],"pdf_url":"https://arxiv.org/pdf/2508.04610v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04605v1","updated":"2025-08-06T16:25:19Z","published":"2025-08-06T16:25:19Z","title":"Multitask Learning with Stochastic Interpolants","summary":"  We propose a framework for learning maps between probability distributions\nthat broadly generalizes the time dynamics of flow and diffusion models. To\nenable this, we generalize stochastic interpolants by replacing the scalar time\nvariable with vectors, matrices, or linear operators, allowing us to bridge\nprobability distributions across multiple dimensional spaces. This approach\nenables the construction of versatile generative models capable of fulfilling\nmultiple tasks without task-specific training. Our operator-based interpolants\nnot only provide a unifying theoretical perspective for existing generative\nmodels but also extend their capabilities. Through numerical experiments, we\ndemonstrate the zero-shot efficacy of our method on conditional generation and\ninpainting, fine-tuning and posterior sampling, and multiscale modeling,\nsuggesting its potential as a generic task-agnostic alternative to specialized\nmodels.\n","authors":["Hugo Negrel","Florentin Coeurdoux","Michael S. Albergo","Eric Vanden-Eijnden"],"pdf_url":"https://arxiv.org/pdf/2508.04605v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15877v2","updated":"2025-08-06T16:19:30Z","published":"2024-05-24T18:40:20Z","title":"Basis Selection: Low-Rank Decomposition of Pretrained Large Language\n  Models for Target Applications","summary":"  Large language models (LLMs) significantly enhance the performance of various\napplications, but they are computationally intensive and energy-demanding. This\nmakes it challenging to deploy them on devices with limited resources, such as\npersonal computers and mobile/wearable devices, and results in substantial\ninference costs in resource-rich environments like cloud servers. To extend the\nuse of LLMs, we introduce a low-rank decomposition approach to effectively\ncompress these models, tailored to the requirements of specific applications.\nWe observe that LLMs pretrained on general datasets contain many redundant\ncomponents not needed for particular applications. Our method focuses on\nidentifying and removing these redundant parts, retaining only the necessary\nelements for the target applications. Specifically, we represent the weight\nmatrices of LLMs as a linear combination of base components. We then prune the\nirrelevant bases and enhance the model with new bases beneficial for specific\napplications. Deep compression results on the Llama 2-7b and -13B models,\nconducted on target applications including mathematical reasoning and code\ngeneration, show that our method significantly reduces model size while\nmaintaining comparable accuracy to state-of-the-art low-rank compression\ntechniques.\n","authors":["Yang Li","Daniel Agyei Asante","Changsheng Zhao","Ernie Chang","Yangyang Shi","Vikas Chandra"],"pdf_url":"https://arxiv.org/pdf/2405.15877v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.11304v7","updated":"2025-08-06T16:14:04Z","published":"2024-11-18T05:59:29Z","title":"Personalized One-shot Federated Graph Learning for Heterogeneous Clients","summary":"  Federated Graph Learning (FGL) has emerged as a promising paradigm for\nbreaking data silos among distributed private graphs. In practical scenarios\ninvolving heterogeneous distributed graph data, personalized Federated Graph\nLearning (pFGL) aims to enhance model utility by training personalized models\ntailored to client needs. However, existing pFGL methods often require numerous\ncommunication rounds under heterogeneous graphs, leading to significant\ncommunication overhead and security concerns. While One-shot Federated Learning\n(OFL) enables collaboration in a single round, existing OFL methods are\ndesigned for image-centric tasks and are ineffective for graph data, leaving a\ncritical gap in the field. Additionally, personalized models derived from\nexisting methods suffer from bias, failing to effectively generalize to the\nminority. To address these challenges, we propose the first \\textbf{O}ne-shot\n\\textbf{p}ersonalized \\textbf{F}ederated \\textbf{G}raph \\textbf{L}earning\nmethod (\\textbf{O-pFGL}) for node classification, compatible with Secure\nAggregation protocols for privacy preservation. Specifically, for effective\ngraph learning in one communication round, our method estimates and aggregates\nclass-wise feature distribution statistics to construct a global surrogate\ngraph on the server, facilitating the training of a global graph model. To\nmitigate bias, we introduce a two-stage personalized training approach that\nadaptively balances local personal information and global insights from the\nsurrogate graph, improving both personalization and generalization. Extensive\nexperiments on 14 diverse real-world graph datasets demonstrate that our method\nsignificantly outperforms state-of-the-art baselines across various settings.\n","authors":["Guochen Yan","Xunkai Li","Luyuan Xie","Qingni Shen","Yuejian Fang","Zhonghai Wu"],"pdf_url":"https://arxiv.org/pdf/2411.11304v7.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04595v1","updated":"2025-08-06T16:14:00Z","published":"2025-08-06T16:14:00Z","title":"Improved Training Strategies for Physics-Informed Neural Networks using\n  Real Experimental Data in Aluminum Spot Welding","summary":"  Resistance spot welding is the dominant joining process for the body-in-white\nin the automotive industry, where the weld nugget diameter is the key quality\nmetric. Its measurement requires destructive testing, limiting the potential\nfor efficient quality control. Physics-informed neural networks were\ninvestigated as a promising tool to reconstruct internal process states from\nexperimental data, enabling model-based and non-invasive quality assessment in\naluminum spot welding. A major challenge is the integration of real-world data\ninto the network due to competing optimization objectives. To address this, we\nintroduce two novel training strategies. First, experimental losses for dynamic\ndisplacement and nugget diameter are progressively included using a fading-in\nfunction to prevent excessive optimization conflicts. We also implement a\ncustom learning rate scheduler and early stopping based on a rolling window to\ncounteract premature reduction due to increased loss magnitudes. Second, we\nintroduce a conditional update of temperature-dependent material parameters via\na look-up table, activated only after a loss threshold is reached to ensure\nphysically meaningful temperatures. An axially symmetric two-dimensional model\nwas selected to represent the welding process accurately while maintaining\ncomputational efficiency. To reduce computational burden, the training\nstrategies and model components were first systematically evaluated in one\ndimension, enabling controlled analysis of loss design and contact models. The\ntwo-dimensional network predicts dynamic displacement and nugget growth within\nthe experimental confidence interval, supports transferring welding stages from\nsteel to aluminum, and demonstrates strong potential for fast, model-based\nquality control in industrial applications.\n","authors":["Jan A. Zak","Christian Weißenfels"],"pdf_url":"https://arxiv.org/pdf/2508.04595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04594v1","updated":"2025-08-06T16:12:42Z","published":"2025-08-06T16:12:42Z","title":"GraphProp: Training the Graph Foundation Models using Graph Properties","summary":"  This work focuses on training graph foundation models (GFMs) that have strong\ngeneralization ability in graph-level tasks such as graph classification.\nEffective GFM training requires capturing information consistent across\ndifferent domains. We discover that graph structures provide more consistent\ncross-domain information compared to node features and graph labels. However,\ntraditional GFMs primarily focus on transferring node features from various\ndomains into a unified representation space but often lack structural\ncross-domain generalization. To address this, we introduce GraphProp, which\nemphasizes structural generalization. The training process of GraphProp\nconsists of two main phases. First, we train a structural GFM by predicting\ngraph invariants. Since graph invariants are properties of graphs that depend\nonly on the abstract structure, not on particular labellings or drawings of the\ngraph, this structural GFM has a strong ability to capture the abstract\nstructural information and provide discriminative graph representations\ncomparable across diverse domains. In the second phase, we use the\nrepresentations given by the structural GFM as positional encodings to train a\ncomprehensive GFM. This phase utilizes domain-specific node attributes and\ngraph labels to further improve cross-domain node feature generalization. Our\nexperiments demonstrate that GraphProp significantly outperforms the\ncompetitors in supervised learning and few-shot learning, especially in\nhandling graphs without node attributes.\n","authors":["Ziheng Sun","Qi Feng","Lehao Lin","Chris Ding","Jicong Fan"],"pdf_url":"https://arxiv.org/pdf/2508.04594v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04590v1","updated":"2025-08-06T16:09:11Z","published":"2025-08-06T16:09:11Z","title":"Algebraically Observable Physics-Informed Neural Network and its\n  Application to Epidemiological Modelling","summary":"  Physics-Informed Neural Network (PINN) is a deep learning framework that\nintegrates the governing equations underlying data into a loss function. In\nthis study, we consider the problem of estimating state variables and\nparameters in epidemiological models governed by ordinary differential\nequations using PINNs. In practice, not all trajectory data corresponding to\nthe population described by models can be measured. Learning PINNs to estimate\nthe unmeasured state variables and epidemiological parameters using partial\nmeasurements is challenging.\n  Accordingly, we introduce the concept of algebraic observability of the state\nvariables. Specifically, we propose augmenting the unmeasured data based on\nalgebraic observability analysis. The validity of the proposed method is\ndemonstrated through numerical experiments under three scenarios in the context\nof epidemiological modelling. Specifically, given noisy and partial\nmeasurements, the accuracy of unmeasured states and parameter estimation of the\nproposed method is shown to be higher than that of the conventional methods.\nThe proposed method is also shown to be effective in practical scenarios, such\nas when the data corresponding to certain variables cannot be reconstructed\nfrom the measurements.\n","authors":["Mizuka Komatsu"],"pdf_url":"https://arxiv.org/pdf/2508.04590v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04588v1","updated":"2025-08-06T16:08:55Z","published":"2025-08-06T16:08:55Z","title":"A Comprehensive Framework for Uncertainty Quantification of Voxel-wise\n  Supervised Models in IVIM MRI","summary":"  Accurate estimation of intravoxel incoherent motion (IVIM) parameters from\ndiffusion-weighted MRI remains challenging due to the ill-posed nature of the\ninverse problem and high sensitivity to noise, particularly in the perfusion\ncompartment. In this work, we propose a probabilistic deep learning framework\nbased on Deep Ensembles (DE) of Mixture Density Networks (MDNs), enabling\nestimation of total predictive uncertainty and decomposition into aleatoric\n(AU) and epistemic (EU) components. The method was benchmarked against non\nprobabilistic neural networks, a Bayesian fitting approach and a probabilistic\nnetwork with single Gaussian parametrization. Supervised training was performed\non synthetic data, and evaluation was conducted on both simulated and two in\nvivo datasets. The reliability of the quantified uncertainties was assessed\nusing calibration curves, output distribution sharpness, and the Continuous\nRanked Probability Score (CRPS). MDNs produced more calibrated and sharper\npredictive distributions for the D and f parameters, although slight\noverconfidence was observed in D*. The Robust Coefficient of Variation (RCV)\nindicated smoother in vivo estimates for D* with MDNs compared to Gaussian\nmodel. Despite the training data covering the expected physiological range,\nelevated EU in vivo suggests a mismatch with real acquisition conditions,\nhighlighting the importance of incorporating EU, which was allowed by DE.\nOverall, we present a comprehensive framework for IVIM fitting with uncertainty\nquantification, which enables the identification and interpretation of\nunreliable estimates. The proposed approach can also be adopted for fitting\nother physical models through appropriate architectural and simulation\nadjustments.\n","authors":["Nicola Casali","Alessandro Brusaferri","Giuseppe Baselli","Stefano Fumagalli","Edoardo Micotti","Gianluigi Forloni","Riaz Hussein","Giovanna Rizzo","Alfonso Mastropietro"],"pdf_url":"https://arxiv.org/pdf/2508.04588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04571v1","updated":"2025-08-06T15:53:58Z","published":"2025-08-06T15:53:58Z","title":"Do Recommender Systems Really Leverage Multimodal Content? A\n  Comprehensive Analysis on Multimodal Representations for Recommendation","summary":"  Multimodal Recommender Systems aim to improve recommendation accuracy by\nintegrating heterogeneous content, such as images and textual metadata. While\neffective, it remains unclear whether their gains stem from true multimodal\nunderstanding or increased model complexity. This work investigates the role of\nmultimodal item embeddings, emphasizing the semantic informativeness of the\nrepresentations. Initial experiments reveal that embeddings from standard\nextractors (e.g., ResNet50, Sentence-Bert) enhance performance, but rely on\nmodality-specific encoders and ad hoc fusion strategies that lack control over\ncross-modal alignment. To overcome these limitations, we leverage Large\nVision-Language Models (LVLMs) to generate multimodal-by-design embeddings via\nstructured prompts. This approach yields semantically aligned representations\nwithout requiring any fusion. Experiments across multiple settings show notable\nperformance improvements. Furthermore, LVLMs embeddings offer a distinctive\nadvantage: they can be decoded into structured textual descriptions, enabling\ndirect assessment of their multimodal comprehension. When such descriptions are\nincorporated as side content into recommender systems, they improve\nrecommendation performance, empirically validating the semantic depth and\nalignment encoded within LVLMs outputs. Our study highlights the importance of\nsemantically rich representations and positions LVLMs as a compelling\nfoundation for building robust and meaningful multimodal representations in\nrecommendation tasks.\n","authors":["Claudio Pomo","Matteo Attimonelli","Danilo Danese","Fedelucio Narducci","Tommaso Di Noia"],"pdf_url":"https://arxiv.org/pdf/2508.04571v1.pdf","comment":"Accepted as Full Research Papers at CIKM 2025"},{"id":"http://arxiv.org/abs/2504.07722v6","updated":"2025-08-06T15:51:18Z","published":"2025-04-10T13:15:52Z","title":"A Relative Ignorability Framework for Decision-Relevant Observability in\n  Control Theory and Reinforcement Learning","summary":"  Sequential decision-making systems routinely operate with missing or\nincomplete data. Classical reinforcement learning theory, which is commonly\nused to solve sequential decision problems, assumes Markovian observability,\nwhich may not hold under partial observability. Causal inference paradigms\nformalise ignorability of missingness. We show these views can be unified and\ngeneralized in order to guarantee Q-learning convergence even when the Markov\nproperty fails. To do so, we introduce the concept of relative ignorability.\nRelative ignorability is a graphical-causal criterion which refines the\nrequirements for accurate decision-making based on incomplete data. Theoretical\nresults and simulations both reveal that non-Markovian stochastic processes\nwhose missingness is relatively ignorable with respect to causal estimands can\nstill be optimized using standard Reinforcement Learning algorithms. These\nresults expand the theoretical foundations of safe, data-efficient AI to\nreal-world environments where complete information is unattainable.\n","authors":["MaryLena Bleile","Minh-Nhat Phung","Minh-Binh Tran"],"pdf_url":"https://arxiv.org/pdf/2504.07722v6.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04561v1","updated":"2025-08-06T15:47:19Z","published":"2025-08-06T15:47:19Z","title":"Attack Pattern Mining to Discover Hidden Threats to Industrial Control\n  Systems","summary":"  This work focuses on validation of attack pattern mining in the context of\nIndustrial Control System (ICS) security. A comprehensive security assessment\nof an ICS requires generating a large and variety of attack patterns. For this\npurpose we have proposed a data driven technique to generate attack patterns\nfor an ICS. The proposed technique has been used to generate over 100,000\nattack patterns from data gathered from an operational water treatment plant.\nIn this work we present a detailed case study to validate the attack patterns.\n","authors":["Muhammad Azmi Umer","Chuadhry Mujeeb Ahmed","Aditya Mathur","Muhammad Taha Jilani"],"pdf_url":"https://arxiv.org/pdf/2508.04561v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02879v2","updated":"2025-08-06T15:43:43Z","published":"2025-08-04T20:18:31Z","title":"CauKer: classification time series foundation models can be pretrained\n  on synthetic data only","summary":"  Time series foundation models (TSFMs) have recently gained significant\nattention due to their strong zero-shot capabilities and widespread real-world\napplications. Such models typically require a computationally costly\npretraining on large-scale, carefully curated collections of real-world\nsequences. To allow for a sample-efficient pretraining of TSFMs, we propose\nCauKer, a novel algorithm designed to generate diverse, causally coherent\nsynthetic time series with realistic trends, seasonality, and nonlinear\ninteractions. CauKer combines Gaussian Process (GP) kernel composition with\nStructural Causal Models (SCM) to produce data for sample-efficient pretraining\nof state-of-the-art classification TSFMs having different architectures and\nfollowing different pretraining approaches. Additionally, our experiments\nreveal that CauKer-generated datasets exhibit clear scaling laws for both\ndataset size (10K to 10M samples) and model capacity (1M to 783M parameters),\nunlike real-world datasets, which display irregular scaling behavior.\n","authors":["Shifeng Xie","Vasilii Feofanov","Marius Alonso","Ambroise Odonnat","Jianfeng Zhang","Themis Palpanas","Ievgen Redko"],"pdf_url":"https://arxiv.org/pdf/2508.02879v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04553v1","updated":"2025-08-06T15:37:30Z","published":"2025-08-06T15:37:30Z","title":"LA-CaRe-CNN: Cascading Refinement CNN for Left Atrial Scar Segmentation","summary":"  Atrial fibrillation (AF) represents the most prevalent type of cardiac\narrhythmia for which treatment may require patients to undergo ablation\ntherapy. In this surgery cardiac tissues are locally scarred on purpose to\nprevent electrical signals from causing arrhythmia. Patient-specific cardiac\ndigital twin models show great potential for personalized ablation therapy,\nhowever, they demand accurate semantic segmentation of healthy and scarred\ntissue typically obtained from late gadolinium enhanced (LGE) magnetic\nresonance (MR) scans. In this work we propose the Left Atrial Cascading\nRefinement CNN (LA-CaRe-CNN), which aims to accurately segment the left atrium\nas well as left atrial scar tissue from LGE MR scans. LA-CaRe-CNN is a 2-stage\nCNN cascade that is trained end-to-end in 3D, where Stage 1 generates a\nprediction for the left atrium, which is then refined in Stage 2 in conjunction\nwith the original image information to obtain a prediction for the left atrial\nscar tissue. To account for domain shift towards domains unknown during\ntraining, we employ strong intensity and spatial augmentation to increase the\ndiversity of the training dataset. Our proposed method based on a 5-fold\nensemble achieves great segmentation results, namely, 89.21% DSC and 1.6969 mm\nASSD for the left atrium, as well as 64.59% DSC and 91.80% G-DSC for the more\nchallenging left atrial scar tissue. Thus, segmentations obtained through\nLA-CaRe-CNN show great potential for the generation of patient-specific cardiac\ndigital twin models and downstream tasks like personalized targeted ablation\ntherapy to treat AF.\n","authors":["Franz Thaler","Darko Stern","Gernot Plank","Martin Urschler"],"pdf_url":"https://arxiv.org/pdf/2508.04553v1.pdf","comment":"Accepted for the MICCAI Challenge on Comprehensive Analysis and\n  Computing of Real-World Medical Images 2024, 12 pages"},{"id":"http://arxiv.org/abs/2508.04552v1","updated":"2025-08-06T15:37:22Z","published":"2025-08-06T15:37:22Z","title":"Augmentation-based Domain Generalization and Joint Training from\n  Multiple Source Domains for Whole Heart Segmentation","summary":"  As the leading cause of death worldwide, cardiovascular diseases motivate the\ndevelopment of more sophisticated methods to analyze the heart and its\nsubstructures from medical images like Computed Tomography (CT) and Magnetic\nResonance (MR). Semantic segmentations of important cardiac structures that\nrepresent the whole heart are useful to assess patient-specific cardiac\nmorphology and pathology. Furthermore, accurate semantic segmentations can be\nused to generate cardiac digital twin models which allows e.g.\nelectrophysiological simulation and personalized therapy planning. Even though\ndeep learning-based methods for medical image segmentation achieved great\nadvancements over the last decade, retaining good performance under domain\nshift -- i.e. when training and test data are sampled from different data\ndistributions -- remains challenging. In order to perform well on domains known\nat training-time, we employ a (1) balanced joint training approach that\nutilizes CT and MR data in equal amounts from different source domains.\nFurther, aiming to alleviate domain shift towards domains only encountered at\ntest-time, we rely on (2) strong intensity and spatial augmentation techniques\nto greatly diversify the available training data. Our proposed whole heart\nsegmentation method, a 5-fold ensemble with our contributions, achieves the\nbest performance for MR data overall and a performance similar to the best\nperformance for CT data when compared to a model trained solely on CT. With\n93.33% DSC and 0.8388 mm ASSD for CT and 89.30% DSC and 1.2411 mm ASSD for MR\ndata, our method demonstrates great potential to efficiently obtain accurate\nsemantic segmentations from which patient-specific cardiac twin models can be\ngenerated.\n","authors":["Franz Thaler","Darko Stern","Gernot Plank","Martin Urschler"],"pdf_url":"https://arxiv.org/pdf/2508.04552v1.pdf","comment":"Accepted for the MICCAI Challenge on Comprehensive Analysis and\n  Computing of Real-World Medical Images 2024, 12 pages"},{"id":"http://arxiv.org/abs/2508.04542v1","updated":"2025-08-06T15:30:07Z","published":"2025-08-06T15:30:07Z","title":"Privacy Risk Predictions Based on Fundamental Understanding of Personal\n  Data and an Evolving Threat Landscape","summary":"  It is difficult for individuals and organizations to protect personal\ninformation without a fundamental understanding of relative privacy risks. By\nanalyzing over 5,000 empirical identity theft and fraud cases, this research\nidentifies which types of personal data are exposed, how frequently exposures\noccur, and what the consequences of those exposures are. We construct an\nIdentity Ecosystem graph--a foundational, graph-based model in which nodes\nrepresent personally identifiable information (PII) attributes and edges\nrepresent empirical disclosure relationships between them (e.g., the\nprobability that one PII attribute is exposed due to the exposure of another).\nLeveraging this graph structure, we develop a privacy risk prediction framework\nthat uses graph theory and graph neural networks to estimate the likelihood of\nfurther disclosures when certain PII attributes are compromised. The results\nshow that our approach effectively answers the core question: Can the\ndisclosure of a given identity attribute possibly lead to the disclosure of\nanother attribute?\n","authors":["Haoran Niu","K. Suzanne Barber"],"pdf_url":"https://arxiv.org/pdf/2508.04542v1.pdf","comment":"8 pages, 9 figures, 1 table"},{"id":"http://arxiv.org/abs/2405.09004v3","updated":"2025-08-06T15:25:24Z","published":"2024-05-15T00:04:08Z","title":"Improving Sequential Market Coordination via Value-oriented Renewable\n  Energy Forecasting","summary":"  Large penetration of renewable energy sources (RESs) brings huge uncertainty\ninto the electricity markets. The current deterministic clearing approach in\nthe day-ahead (DA) market, where RESs participate based on expected production,\nhas been criticized for causing a lack of coordination between the DA and\nreal-time (RT) markets, leading to high overall operating costs. Previous works\nindicate that improving day-ahead RES entering quantities can significantly\nmitigate the drawbacks of deterministic clearing. In this work, we propose\nusing a trained forecasting model, referred to as value-oriented forecasting,\nto determine RES Improved Entering Quantities (RIEQ) more efficiently during\nthe operational phase. Unlike traditional models that minimize statistical\nforecasting errors, our approach trains model parameters to minimize the\nexpected overall operating costs across both DA and RT markets. We derive the\nexact form of the loss function used for training, which becomes piecewise\nlinear when market clearing is modeled by linear programs. Additionally, we\nprovide the analytical gradient of the loss function with respect to the\nforecast, enabling an efficient training strategy. Numerical studies\ndemonstrate that our forecasts significantly reduce overall operating costs for\ndeterministic market clearing compared to conventional forecasts based on\nexpected RES production.\n","authors":["Yufan Zhang","Honglin Wen","Yuexin Bian","Yuanyuan Shi"],"pdf_url":"https://arxiv.org/pdf/2405.09004v3.pdf","comment":"Submitted to IEEE Transactions on Energy Markets, Policy, and\n  Regulation"},{"id":"http://arxiv.org/abs/2407.06083v3","updated":"2025-08-06T15:22:29Z","published":"2024-07-04T09:50:50Z","title":"A Survey of Controllable Learning: Methods and Applications in\n  Information Retrieval","summary":"  Controllability has become a crucial aspect of trustworthy machine learning,\nenabling learners to meet predefined targets and adapt dynamically at test time\nwithout requiring retraining as the targets shift. We provide a formal\ndefinition of controllable learning (CL), and discuss its applications in\ninformation retrieval (IR) where information needs are often complex and\ndynamic. The survey categorizes CL according to what is controllable (e.g.,\nmultiple objectives, user portrait, scenario adaptation), who controls (users\nor platforms), how control is implemented (e.g., rule-based method, Pareto\noptimization, hypernetwork and others), and where to implement control (e.g.,\npre-processing, in-processing, post-processing methods). Then, we identify\nchallenges faced by CL across training, evaluation, task setting, and\ndeployment in online environments. Additionally, we outline promising\ndirections for CL in theoretical analysis, efficient computation, empowering\nlarge language models, application scenarios and evaluation frameworks.\n","authors":["Chenglei Shen","Xiao Zhang","Teng Shi","Changshuo Zhang","Guofu Xie","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2407.06083v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.15787v4","updated":"2025-08-06T15:09:52Z","published":"2025-06-18T18:10:30Z","title":"SLR: Automated Synthesis for Scalable Logical Reasoning","summary":"  We introduce SLR, an end-to-end framework for systematic evaluation and\ntraining of Large Language Models (LLMs) via Scalable Logical Reasoning. Given\na user's task specification, SLR automatically synthesizes (i) an instruction\nprompt for an inductive reasoning task, (ii) a validation program, executable\non model outputs to provide verifiable rewards, and (iii) the latent\nground-truth rule. This process is fully automated, scalable, requires no human\nannotations, and offers precise control over task difficulty. Using SLR, we\ncreate SLR-Bench, a benchmark comprising 19k prompts organized into 20\ncurriculum levels that progressively increase in relational, arithmetic, and\nrecursive complexity. Large-scale evaluation reveals that contemporary LLMs\nreadily produce syntactically valid rules, yet often fail at correct logical\ninference. Recent reasoning LLMs demonstrate improved performance but incur\nvery high test-time computation, with costs exceeding $300 for just 1,000\nprompts. Finally, curriculum learning via SLR doubles Llama-3-8B accuracy on\nSLR-Bench, achieving parity with Gemini-Flash-Thinking at a fraction of\ncomputational cost. Moreover, these reasoning capabilities generalize to a wide\nrange of established benchmarks, underscoring the effectiveness of SLR for\ndownstream reasoning.\n","authors":["Lukas Helff","Ahmad Omar","Felix Friedrich","Antonia Wüst","Hikaru Shindo","Rupert Mitchell","Tim Woydt","Patrick Schramowski","Wolfgang Stammer","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2506.15787v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04522v1","updated":"2025-08-06T15:07:39Z","published":"2025-08-06T15:07:39Z","title":"Conditional Fetal Brain Atlas Learning for Automatic Tissue Segmentation","summary":"  Magnetic Resonance Imaging (MRI) of the fetal brain has become a key tool for\nstudying brain development in vivo. Yet, its assessment remains challenging due\nto variability in brain maturation, imaging protocols, and uncertain estimates\nof Gestational Age (GA). To overcome these, brain atlases provide a\nstandardized reference framework that facilitates objective evaluation and\ncomparison across subjects by aligning the atlas and subjects in a common\ncoordinate system. In this work, we introduce a novel deep-learning framework\nfor generating continuous, age-specific fetal brain atlases for real-time fetal\nbrain tissue segmentation. The framework combines a direct registration model\nwith a conditional discriminator. Trained on a curated dataset of 219\nneurotypical fetal MRIs spanning from 21 to 37 weeks of gestation. The method\nachieves high registration accuracy, captures dynamic anatomical changes with\nsharp structural detail, and robust segmentation performance with an average\nDice Similarity Coefficient (DSC) of 86.3% across six brain tissues.\nFurthermore, volumetric analysis of the generated atlases reveals detailed\nneurotypical growth trajectories, providing valuable insights into the\nmaturation of the fetal brain. This approach enables individualized\ndevelopmental assessment with minimal pre-processing and real-time performance,\nsupporting both research and clinical applications. The model code is available\nat https://github.com/cirmuw/fetal-brain-atlas\n","authors":["Johannes Tischer","Patric Kienast","Marlene Stümpflen","Gregor Kasprian","Georg Langs","Roxane Licandro"],"pdf_url":"https://arxiv.org/pdf/2508.04522v1.pdf","comment":"12 pages, 4 figures, MICCAI Workshop on Perinatal Imaging, Placental\n  and Preterm Image analysis"},{"id":"http://arxiv.org/abs/2508.04517v1","updated":"2025-08-06T15:02:28Z","published":"2025-08-06T15:02:28Z","title":"Channel-Independent Federated Traffic Prediction","summary":"  In recent years, traffic prediction has achieved remarkable success and has\nbecome an integral component of intelligent transportation systems. However,\ntraffic data is typically distributed among multiple data owners, and privacy\nconstraints prevent the direct utilization of these isolated datasets for\ntraffic prediction. Most existing federated traffic prediction methods focus on\ndesigning communication mechanisms that allow models to leverage information\nfrom other clients in order to improve prediction accuracy. Unfortunately, such\napproaches often incur substantial communication overhead, and the resulting\ntransmission delays significantly slow down the training process. As the volume\nof traffic data continues to grow, this issue becomes increasingly critical,\nmaking the resource consumption of current methods unsustainable. To address\nthis challenge, we propose a novel variable relationship modeling paradigm for\nfederated traffic prediction, termed the Channel-Independent Paradigm(CIP).\nUnlike traditional approaches, CIP eliminates the need for inter-client\ncommunication by enabling each node to perform efficient and accurate\npredictions using only local information. Based on the CIP, we further develop\nFed-CI, an efficient federated learning framework, allowing each client to\nprocess its own data independently while effectively mitigating the information\nloss caused by the lack of direct data sharing among clients. Fed-CI\nsignificantly reduces communication overhead, accelerates the training process,\nand achieves state-of-the-art performance while complying with privacy\nregulations. Extensive experiments on multiple real-world datasets demonstrate\nthat Fed-CI consistently outperforms existing methods across all datasets and\nfederated settings. It achieves improvements of 8%, 14%, and 16% in RMSE, MAE,\nand MAPE, respectively, while also substantially reducing communication costs.\n","authors":["Mo Zhang","Xiaoyu Li","Bin Xu","Meng Chen","Yongshun Gong"],"pdf_url":"https://arxiv.org/pdf/2508.04517v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08062v6","updated":"2025-08-06T14:58:13Z","published":"2024-02-12T21:12:11Z","title":"Avoiding Catastrophe in Online Learning by Asking for Help","summary":"  Most learning algorithms with formal regret guarantees assume that all\nmistakes are recoverable and essentially rely on trying all possible behaviors.\nThis approach is problematic when some mistakes are \"catastrophic\", i.e.,\nirreparable. We propose an online learning problem where the goal is to\nminimize the chance of catastrophe. Specifically, we assume that the payoff in\neach round represents the chance of avoiding catastrophe in that round and try\nto maximize the product of payoffs (the overall chance of avoiding catastrophe)\nwhile allowing a limited number of queries to a mentor. We also assume that the\nagent can transfer knowledge between similar inputs. We first show that in\ngeneral, any algorithm either queries the mentor at a linear rate or is nearly\nguaranteed to cause catastrophe. However, in settings where the mentor policy\nclass is learnable in the standard online model, we provide an algorithm whose\nregret and rate of querying the mentor both approach 0 as the time horizon\ngrows. Although our focus is the product of payoffs, we provide matching bounds\nfor the typical additive regret. Conceptually, if a policy class is learnable\nin the absence of catastrophic risk, it is learnable in the presence of\ncatastrophic risk if the agent can ask for help.\n","authors":["Benjamin Plaut","Hanlin Zhu","Stuart Russell"],"pdf_url":"https://arxiv.org/pdf/2402.08062v6.pdf","comment":"Accepted to ICML 2025"},{"id":"http://arxiv.org/abs/2503.09781v3","updated":"2025-08-06T14:57:17Z","published":"2025-03-12T19:30:51Z","title":"Learning richness modulates equality reasoning in neural networks","summary":"  Equality reasoning is ubiquitous and purely abstract: sameness or difference\nmay be evaluated no matter the nature of the underlying objects. As a result,\nsame-different (SD) tasks have been extensively studied as a starting point for\nunderstanding abstract reasoning in humans and across animal species. With the\nrise of neural networks that exhibit striking apparent proficiency for\nabstractions, equality reasoning in these models has also gained interest. Yet\ndespite extensive study, conclusions about equality reasoning vary widely and\nwith little consensus. To clarify the underlying principles in learning SD\ntasks, we develop a theory of equality reasoning in multi-layer perceptrons\n(MLP). Following observations in comparative psychology, we propose a spectrum\nof behavior that ranges from conceptual to perceptual outcomes. Conceptual\nbehavior is characterized by task-specific representations, efficient learning,\nand insensitivity to spurious perceptual details. Perceptual behavior is\ncharacterized by strong sensitivity to spurious perceptual details, accompanied\nby the need for exhaustive training to learn the task. We develop a\nmathematical theory to show that an MLP's behavior is driven by learning\nrichness. Rich-regime MLPs exhibit conceptual behavior, whereas lazy-regime\nMLPs exhibit perceptual behavior. We validate our theoretical findings in\nvision SD experiments, showing that rich feature learning promotes success by\nencouraging hallmarks of conceptual behavior. Overall, our work identifies\nfeature learning richness as a key parameter modulating equality reasoning, and\nsuggests that equality reasoning in humans and animals may similarly depend on\nlearning richness in neural circuits.\n","authors":["William L. Tong","Cengiz Pehlevan"],"pdf_url":"https://arxiv.org/pdf/2503.09781v3.pdf","comment":"29 pages, 10 figures, code available at\n  https://github.com/wtong98/equality-reasoning"},{"id":"http://arxiv.org/abs/2505.13241v2","updated":"2025-08-06T14:56:18Z","published":"2025-05-19T15:23:24Z","title":"Reconstructing Physics-Informed Machine Learning for Traffic Flow\n  Modeling: a Multi-Gradient Descent and Pareto Learning Approach","summary":"  Physics-informed machine learning (PIML) is crucial in modern traffic flow\nmodeling because it combines the benefits of both physics-based and data-driven\napproaches. In conventional PIML, physical information is typically\nincorporated by constructing a hybrid loss function that combines data-driven\nloss and physics loss through linear scalarization. The goal is to find a\ntrade-off between these two objectives to improve the accuracy of model\npredictions. However, from a mathematical perspective, linear scalarization is\nlimited to identifying only the convex region of the Pareto front, as it treats\ndata-driven and physics losses as separate objectives. Given that most PIML\nloss functions are non-convex, linear scalarization restricts the achievable\ntrade-off solutions. Moreover, tuning the weighting coefficients for the two\nloss components can be both time-consuming and computationally challenging. To\naddress these limitations, this paper introduces a paradigm shift in PIML by\nreformulating the training process as a multi-objective optimization problem,\ntreating data-driven loss and physics loss independently. We apply several\nmulti-gradient descent algorithms (MGDAs), including traditional multi-gradient\ndescent (TMGD) and dual cone gradient descent (DCGD), to explore the Pareto\nfront in this multi-objective setting. These methods are evaluated on both\nmacroscopic and microscopic traffic flow models. In the macroscopic case, MGDAs\nachieved comparable performance to traditional linear scalarization methods.\nNotably, in the microscopic case, MGDAs significantly outperformed their\nscalarization-based counterparts, demonstrating the advantages of a\nmulti-objective optimization approach in complex PIML scenarios.\n","authors":["Yuan-Zheng Lei","Yaobang Gong","Dianwei Chen","Yao Cheng","Xianfeng Terry Yang"],"pdf_url":"https://arxiv.org/pdf/2505.13241v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04511v1","updated":"2025-08-06T14:56:08Z","published":"2025-08-06T14:56:08Z","title":"Argumentative Debates for Transparent Bias Detection [Technical Report]","summary":"  As the use of AI systems in society grows, addressing potential biases that\nemerge from data or are learned by models is essential to prevent systematic\ndisadvantages against specific groups. Several notions of (un)fairness have\nbeen proposed in the literature, alongside corresponding algorithmic methods\nfor detecting and mitigating unfairness, but, with very few exceptions, these\ntend to ignore transparency. Instead, interpretability and explainability are\ncore requirements for algorithmic fairness, even more so than for other\nalgorithmic solutions, given the human-oriented nature of fairness. In this\npaper, we contribute a novel interpretable, explainable method for bias\ndetection relying on debates about the presence of bias against individuals,\nbased on the values of protected features for the individuals and others in\ntheir neighbourhoods. Our method builds upon techniques from formal and\ncomputational argumentation, whereby debates result from arguing about biases\nwithin and across neighbourhoods. We provide formal, quantitative, and\nqualitative evaluations of our method, highlighting its strengths in\nperformance against baselines, as well as its interpretability and\nexplainability.\n","authors":["Hamed Ayoobi","Nico Potyka","Anna Rapberger","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2508.04511v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04503v1","updated":"2025-08-06T14:50:25Z","published":"2025-08-06T14:50:25Z","title":"PRISM: Lightweight Multivariate Time-Series Classification through\n  Symmetric Multi-Resolution Convolutional Layers","summary":"  Multivariate time-series classification is pivotal in domains ranging from\nwearable sensing to biomedical monitoring. Despite recent advances,\nTransformer- and CNN-based models often remain computationally heavy, offer\nlimited frequency diversity, and require extensive parameter budgets. We\npropose PRISM (Per-channel Resolution-Informed Symmetric Module), a\nconvolutional-based feature extractor that applies symmetric\nfinite-impulse-response (FIR) filters at multiple temporal scales,\nindependently per channel. This multi-resolution, per-channel design yields\nhighly frequency-selective embeddings without any inter-channel convolutions,\ngreatly reducing model size and complexity. Across human-activity, sleep-stage\nand biomedical benchmarks, PRISM, paired with lightweight classification heads,\nmatches or outperforms leading CNN and Transformer baselines, while using\nroughly an order of magnitude fewer parameters and FLOPs. By uniting classical\nsignal processing insights with modern deep learning, PRISM offers an accurate,\nresource-efficient solution for multivariate time-series classification.\n","authors":["Federico Zucchi","Thomas Lampert"],"pdf_url":"https://arxiv.org/pdf/2508.04503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04495v1","updated":"2025-08-06T14:44:23Z","published":"2025-08-06T14:44:23Z","title":"Causal Reflection with Language Models","summary":"  While LLMs exhibit impressive fluency and factual recall, they struggle with\nrobust causal reasoning, often relying on spurious correlations and brittle\npatterns. Similarly, traditional Reinforcement Learning agents also lack causal\nunderstanding, optimizing for rewards without modeling why actions lead to\noutcomes. We introduce Causal Reflection, a framework that explicitly models\ncausality as a dynamic function over state, action, time, and perturbation,\nenabling agents to reason about delayed and nonlinear effects. Additionally, we\ndefine a formal Reflect mechanism that identifies mismatches between predicted\nand observed outcomes and generates causal hypotheses to revise the agent's\ninternal model. In this architecture, LLMs serve not as black-box reasoners,\nbut as structured inference engines translating formal causal outputs into\nnatural language explanations and counterfactuals. Our framework lays the\ntheoretical groundwork for Causal Reflective agents that can adapt,\nself-correct, and communicate causal understanding in evolving environments.\n","authors":["Abi Aryan","Zac Liu"],"pdf_url":"https://arxiv.org/pdf/2508.04495v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.13330v3","updated":"2025-08-06T14:41:42Z","published":"2024-01-24T09:48:12Z","title":"NACHOS: Neural Architecture Search for Hardware Constrained Early Exit\n  Neural Networks","summary":"  Early Exit Neural Networks (EENNs) endow astandard Deep Neural Network (DNN)\nwith Early Exit Classifiers (EECs), to provide predictions at intermediate\npoints of the processing when enough confidence in classification is achieved.\nThis leads to many benefits in terms of effectiveness and efficiency.\nCurrently, the design of EENNs is carried out manually by experts, a complex\nand time-consuming task that requires accounting for many aspects, including\nthe correct placement, the thresholding, and the computational overhead of the\nEECs. For this reason, the research is exploring the use of Neural Architecture\nSearch (NAS) to automatize the design of EENNs. Currently, few comprehensive\nNAS solutions for EENNs have been proposed in the literature, and a fully\nautomated, joint design strategy taking into consideration both the backbone\nand the EECs remains an open problem. To this end, this work presents Neural\nArchitecture Search for Hardware Constrained Early Exit Neural Networks\n(NACHOS), the first NAS framework for the design of optimal EENNs satisfying\nconstraints on the accuracy and the number of Multiply and Accumulate (MAC)\noperations performed by the EENNs at inference time. In particular, this\nprovides the joint design of backbone and EECs to select a set of admissible\n(i.e., respecting the constraints) Pareto Optimal Solutions in terms of best\ntradeoff between the accuracy and number of MACs. The results show that the\nmodels designed by NACHOS are competitive with the state-of-the-art EENNs.\nAdditionally, this work investigates the effectiveness of two novel\nregularization terms designed for the optimization of the auxiliary classifiers\nof the EENN\n","authors":["Matteo Gambella","Jary Pomponi","Simone Scardapane","Manuel Roveri"],"pdf_url":"https://arxiv.org/pdf/2401.13330v3.pdf","comment":"Published in IEEE Transactions on Neural Networks and Learning\n  Systems (TNNLS) 2025"},{"id":"http://arxiv.org/abs/2508.04489v1","updated":"2025-08-06T14:37:18Z","published":"2025-08-06T14:37:18Z","title":"Hierarchical Scoring for Machine Learning Classifier Error Impact\n  Evaluation","summary":"  A common use of machine learning (ML) models is predicting the class of a\nsample. Object detection is an extension of classification that includes\nlocalization of the object via a bounding box within the sample.\nClassification, and by extension object detection, is typically evaluated by\ncounting a prediction as incorrect if the predicted label does not match the\nground truth label. This pass/fail scoring treats all misclassifications as\nequivalent. In many cases, class labels can be organized into a class taxonomy\nwith a hierarchical structure to either reflect relationships among the data or\noperator valuation of misclassifications. When such a hierarchical structure\nexists, hierarchical scoring metrics can return the model performance of a\ngiven prediction related to the distance between the prediction and the ground\ntruth label. Such metrics can be viewed as giving partial credit to predictions\ninstead of pass/fail, enabling a finer-grained understanding of the impact of\nmisclassifications. This work develops hierarchical scoring metrics varying in\ncomplexity that utilize scoring trees to encode relationships between class\nlabels and produce metrics that reflect distance in the scoring tree. The\nscoring metrics are demonstrated on an abstract use case with scoring trees\nthat represent three weighting strategies and evaluated by the kind of errors\ndiscouraged. Results demonstrate that these metrics capture errors with finer\ngranularity and the scoring trees enable tuning. This work demonstrates an\napproach to evaluating ML performance that ranks models not only by how many\nerrors are made but by the kind or impact of errors. Python implementations of\nthe scoring metrics will be available in an open-source repository at time of\npublication.\n","authors":["Erin Lanus","Daniel Wolodkin","Laura J. Freeman"],"pdf_url":"https://arxiv.org/pdf/2508.04489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04486v1","updated":"2025-08-06T14:36:10Z","published":"2025-08-06T14:36:10Z","title":"Quantum circuit complexity and unsupervised machine learning of\n  topological order","summary":"  Inspired by the close relationship between Kolmogorov complexity and\nunsupervised machine learning, we explore quantum circuit complexity, an\nimportant concept in quantum computation and quantum information science, as a\npivot to understand and to build interpretable and efficient unsupervised\nmachine learning for topological order in quantum many-body systems. To span a\nbridge from conceptual power to practical applicability, we present two\ntheorems that connect Nielsen's quantum circuit complexity for the quantum path\nplanning between two arbitrary quantum many-body states with fidelity change\nand entanglement generation, respectively. Leveraging these connections,\nfidelity-based and entanglement-based similarity measures or kernels, which are\nmore practical for implementation, are formulated. Using the two proposed\nkernels, numerical experiments targeting the unsupervised clustering of quantum\nphases of the bond-alternating XXZ spin chain, the ground state of Kitaev's\ntoric code and random product states, are conducted, demonstrating their\nsuperior performance. Relations with classical shadow tomography and shadow\nkernel learning are also discussed, where the latter can be naturally derived\nand understood from our approach. Our results establish connections between key\nconcepts and tools of quantum circuit computation, quantum complexity, and\nmachine learning of topological quantum order.\n","authors":["Yanming Che","Clemens Gneiting","Xiaoguang Wang","Franco Nori"],"pdf_url":"https://arxiv.org/pdf/2508.04486v1.pdf","comment":"17 pages, with appendix; 4 figures. Code is available upon reasonable\n  request, and will be open-sourced along with the publication. Comments are\n  welcome"},{"id":"http://arxiv.org/abs/2508.04482v1","updated":"2025-08-06T14:33:45Z","published":"2025-08-06T14:33:45Z","title":"OS Agents: A Survey on MLLM-based Agents for General Computing Devices\n  Use","summary":"  The dream to create AI assistants as capable and versatile as the fictional\nJ.A.R.V.I.S from Iron Man has long captivated imaginations. With the evolution\nof (multi-modal) large language models ((M)LLMs), this dream is closer to\nreality, as (M)LLM-based Agents using computing devices (e.g., computers and\nmobile phones) by operating within the environments and interfaces (e.g.,\nGraphical User Interface (GUI)) provided by operating systems (OS) to automate\ntasks have significantly advanced. This paper presents a comprehensive survey\nof these advanced agents, designated as OS Agents. We begin by elucidating the\nfundamentals of OS Agents, exploring their key components including the\nenvironment, observation space, and action space, and outlining essential\ncapabilities such as understanding, planning, and grounding. We then examine\nmethodologies for constructing OS Agents, focusing on domain-specific\nfoundation models and agent frameworks. A detailed review of evaluation\nprotocols and benchmarks highlights how OS Agents are assessed across diverse\ntasks. Finally, we discuss current challenges and identify promising directions\nfor future research, including safety and privacy, personalization and\nself-evolution. This survey aims to consolidate the state of OS Agents\nresearch, providing insights to guide both academic inquiry and industrial\ndevelopment. An open-source GitHub repository is maintained as a dynamic\nresource to foster further innovation in this field. We present a 9-page\nversion of our work, accepted by ACL 2025, to provide a concise overview to the\ndomain.\n","authors":["Xueyu Hu","Tao Xiong","Biao Yi","Zishu Wei","Ruixuan Xiao","Yurun Chen","Jiasheng Ye","Meiling Tao","Xiangxin Zhou","Ziyu Zhao","Yuhuai Li","Shengze Xu","Shenzhi Wang","Xinchen Xu","Shuofei Qiao","Zhaokai Wang","Kun Kuang","Tieyong Zeng","Liang Wang","Jiwei Li","Yuchen Eleanor Jiang","Wangchunshu Zhou","Guoyin Wang","Keting Yin","Zhou Zhao","Hongxia Yang","Fan Wu","Shengyu Zhang","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2508.04482v1.pdf","comment":"ACL 2025 (Oral)"},{"id":"http://arxiv.org/abs/2508.04481v1","updated":"2025-08-06T14:32:22Z","published":"2025-08-06T14:32:22Z","title":"Emotion Detection Using Conditional Generative Adversarial Networks\n  (cGAN): A Deep Learning Approach","summary":"  This paper presents a deep learning-based approach to emotion detection using\nConditional Generative Adversarial Networks (cGANs). Unlike traditional\nunimodal techniques that rely on a single data type, we explore a multimodal\nframework integrating text, audio, and facial expressions. The proposed cGAN\narchitecture is trained to generate synthetic emotion-rich data and improve\nclassification accuracy across multiple modalities. Our experimental results\ndemonstrate significant improvements in emotion recognition performance\ncompared to baseline models. This work highlights the potential of cGANs in\nenhancing human-computer interaction systems by enabling more nuanced emotional\nunderstanding.\n","authors":["Anushka Srivastava"],"pdf_url":"https://arxiv.org/pdf/2508.04481v1.pdf","comment":"3 pages, 2 tables, submitted for arXiv preprint"},{"id":"http://arxiv.org/abs/2508.04478v1","updated":"2025-08-06T14:29:38Z","published":"2025-08-06T14:29:38Z","title":"Who cuts emissions, who turns up the heat? causal machine learning\n  estimates of energy efficiency interventions","summary":"  Reducing domestic energy demand is central to climate mitigation and fuel\npoverty strategies, yet the impact of energy efficiency interventions is highly\nheterogeneous. Using a causal machine learning model trained on nationally\nrepresentative data of the English housing stock, we estimate average and\nconditional treatment effects of wall insulation on gas consumption, focusing\non distributional effects across energy burden subgroups. While interventions\nreduce gas demand on average (by as much as 19 percent), low energy burden\ngroups achieve substantial savings, whereas those experiencing high energy\nburdens see little to no reduction. This pattern reflects a\nbehaviourally-driven mechanism: households constrained by high costs-to-income\nratios (e.g. more than 0.1) reallocate savings toward improved thermal comfort\nrather than lowering consumption. Far from wasteful, such responses represent\nrational adjustments in contexts of prior deprivation, with potential\nco-benefits for health and well-being. These findings call for a broader\nevaluation framework that accounts for both climate impacts and the equity\nimplications of domestic energy policy.\n","authors":["Bernardino D'Amico","Francesco Pomponi","Jay H. Arehart","Lina Khaddour"],"pdf_url":"https://arxiv.org/pdf/2508.04478v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04476v1","updated":"2025-08-06T14:29:04Z","published":"2025-08-06T14:29:04Z","title":"Metric Learning in an RKHS","summary":"  Metric learning from a set of triplet comparisons in the form of \"Do you\nthink item h is more similar to item i or item j?\", indicating similarity and\ndifferences between items, plays a key role in various applications including\nimage retrieval, recommendation systems, and cognitive psychology. The goal is\nto learn a metric in the RKHS that reflects the comparisons. Nonlinear metric\nlearning using kernel methods and neural networks have shown great empirical\npromise. While previous works have addressed certain aspects of this problem,\nthere is little or no theoretical understanding of such methods. The exception\nis the special (linear) case in which the RKHS is the standard Euclidean space\n$\\mathbb{R}^d$; there is a comprehensive theory for metric learning in\n$\\mathbb{R}^d$. This paper develops a general RKHS framework for metric\nlearning and provides novel generalization guarantees and sample complexity\nbounds. We validate our findings through a set of simulations and experiments\non real datasets. Our code is publicly available at\nhttps://github.com/RamyaLab/metric-learning-RKHS.\n","authors":["Gokcan Tatli","Yi Chen","Blake Mason","Robert Nowak","Ramya Korlakai Vinayak"],"pdf_url":"https://arxiv.org/pdf/2508.04476v1.pdf","comment":"Appeared in the 41st Conference on Uncertainty in Artificial\n  Intelligence (UAI 2025)"}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2504.15110v3","updated":"2025-08-06T17:12:12Z","published":"2025-04-21T14:02:59Z","title":"Approximation Rates in Besov Norms and Sample-Complexity of\n  Kolmogorov-Arnold Networks with Residual Connections","summary":"  Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold\nNetworks (KANs) have recently emerged as an improved backbone for most deep\nlearning frameworks, promising more adaptivity than their multilayer perceptron\n(MLP) predecessor by allowing for trainable spline-based activation functions.\nIn this paper, we probe the theoretical foundations of the KAN architecture by\nshowing that it can optimally approximate any Besov function in\n$B^{s}_{p,q}(\\mathcal{X})$ on a bounded open, or even fractal, domain\n$\\mathcal{X}$ in $\\mathbb{R}^d$ at the optimal approximation rate with respect\nto any weaker Besov norm $B^{\\alpha}_{p,q}(\\mathcal{X})$; where $\\alpha < s$.\nWe complement our approximation result with a statistical guarantee by bounding\nthe pseudodimension of the relevant class of Res-KANs. As an application of the\nlatter, we directly deduce a dimension-free estimate on the sample complexity\nof a residual KAN model when learning a function of Besov regularity from $N$\ni.i.d. noiseless samples, showing that KANs can learn the smooth maps which\nthey can approximate.\n","authors":["Anastasis Kratsios","Bum Jun Kim","Takashi Furuya"],"pdf_url":"https://arxiv.org/pdf/2504.15110v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01957v3","updated":"2025-08-06T17:06:54Z","published":"2025-08-03T23:48:46Z","title":"Stochastic Encodings for Active Feature Acquisition","summary":"  Active Feature Acquisition is an instance-wise, sequential decision making\nproblem. The aim is to dynamically select which feature to measure based on\ncurrent observations, independently for each test instance. Common approaches\neither use Reinforcement Learning, which experiences training difficulties, or\ngreedily maximize the conditional mutual information of the label and\nunobserved features, which makes myopic acquisitions. To address these\nshortcomings, we introduce a latent variable model, trained in a supervised\nmanner. Acquisitions are made by reasoning about the features across many\npossible unobserved realizations in a stochastic latent space. Extensive\nevaluation on a large range of synthetic and real datasets demonstrates that\nour approach reliably outperforms a diverse set of baselines.\n","authors":["Alexander Norcliffe","Changhee Lee","Fergus Imrie","Mihaela van der Schaar","Pietro Lio"],"pdf_url":"https://arxiv.org/pdf/2508.01957v3.pdf","comment":"31 pages, 15 figures, 17 tables, published at ICML 2025"},{"id":"http://arxiv.org/abs/2505.13241v2","updated":"2025-08-06T14:56:18Z","published":"2025-05-19T15:23:24Z","title":"Reconstructing Physics-Informed Machine Learning for Traffic Flow\n  Modeling: a Multi-Gradient Descent and Pareto Learning Approach","summary":"  Physics-informed machine learning (PIML) is crucial in modern traffic flow\nmodeling because it combines the benefits of both physics-based and data-driven\napproaches. In conventional PIML, physical information is typically\nincorporated by constructing a hybrid loss function that combines data-driven\nloss and physics loss through linear scalarization. The goal is to find a\ntrade-off between these two objectives to improve the accuracy of model\npredictions. However, from a mathematical perspective, linear scalarization is\nlimited to identifying only the convex region of the Pareto front, as it treats\ndata-driven and physics losses as separate objectives. Given that most PIML\nloss functions are non-convex, linear scalarization restricts the achievable\ntrade-off solutions. Moreover, tuning the weighting coefficients for the two\nloss components can be both time-consuming and computationally challenging. To\naddress these limitations, this paper introduces a paradigm shift in PIML by\nreformulating the training process as a multi-objective optimization problem,\ntreating data-driven loss and physics loss independently. We apply several\nmulti-gradient descent algorithms (MGDAs), including traditional multi-gradient\ndescent (TMGD) and dual cone gradient descent (DCGD), to explore the Pareto\nfront in this multi-objective setting. These methods are evaluated on both\nmacroscopic and microscopic traffic flow models. In the macroscopic case, MGDAs\nachieved comparable performance to traditional linear scalarization methods.\nNotably, in the microscopic case, MGDAs significantly outperformed their\nscalarization-based counterparts, demonstrating the advantages of a\nmulti-objective optimization approach in complex PIML scenarios.\n","authors":["Yuan-Zheng Lei","Yaobang Gong","Dianwei Chen","Yao Cheng","Xianfeng Terry Yang"],"pdf_url":"https://arxiv.org/pdf/2505.13241v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2305.14496v4","updated":"2025-08-06T14:31:40Z","published":"2023-05-23T19:57:57Z","title":"Optimal Learning via Moderate Deviations Theory","summary":"  This paper proposes a statistically optimal approach for learning a function\nvalue using a confidence interval in a wide range of models, including general\nnon-parametric estimation of an expected loss described as a stochastic\nprogramming problem or various SDE models. More precisely, we develop a\nsystematic construction of highly accurate confidence intervals by using a\nmoderate deviation principle-based approach. It is shown that the proposed\nconfidence intervals are statistically optimal in the sense that they satisfy\ncriteria regarding exponential accuracy, minimality, consistency,\nmischaracterization probability, and eventual uniformly most accurate (UMA)\nproperty. The confidence intervals suggested by this approach are expressed as\nsolutions to robust optimization problems, where the uncertainty is expressed\nvia the underlying moderate deviation rate function induced by the\ndata-generating process. We demonstrate that for many models these optimization\nproblems admit tractable reformulations as finite convex programs even when\nthey are infinite-dimensional.\n","authors":["Arnab Ganguly","Tobias Sutter"],"pdf_url":"https://arxiv.org/pdf/2305.14496v4.pdf","comment":"35 pages, 3 figures"},{"id":"http://arxiv.org/abs/2508.04476v1","updated":"2025-08-06T14:29:04Z","published":"2025-08-06T14:29:04Z","title":"Metric Learning in an RKHS","summary":"  Metric learning from a set of triplet comparisons in the form of \"Do you\nthink item h is more similar to item i or item j?\", indicating similarity and\ndifferences between items, plays a key role in various applications including\nimage retrieval, recommendation systems, and cognitive psychology. The goal is\nto learn a metric in the RKHS that reflects the comparisons. Nonlinear metric\nlearning using kernel methods and neural networks have shown great empirical\npromise. While previous works have addressed certain aspects of this problem,\nthere is little or no theoretical understanding of such methods. The exception\nis the special (linear) case in which the RKHS is the standard Euclidean space\n$\\mathbb{R}^d$; there is a comprehensive theory for metric learning in\n$\\mathbb{R}^d$. This paper develops a general RKHS framework for metric\nlearning and provides novel generalization guarantees and sample complexity\nbounds. We validate our findings through a set of simulations and experiments\non real datasets. Our code is publicly available at\nhttps://github.com/RamyaLab/metric-learning-RKHS.\n","authors":["Gokcan Tatli","Yi Chen","Blake Mason","Robert Nowak","Ramya Korlakai Vinayak"],"pdf_url":"https://arxiv.org/pdf/2508.04476v1.pdf","comment":"Appeared in the 41st Conference on Uncertainty in Artificial\n  Intelligence (UAI 2025)"},{"id":"http://arxiv.org/abs/2508.04457v1","updated":"2025-08-06T13:58:17Z","published":"2025-08-06T13:58:17Z","title":"Benchmarking Uncertainty and its Disentanglement in multi-label Chest\n  X-Ray Classification","summary":"  Reliable uncertainty quantification is crucial for trustworthy\ndecision-making and the deployment of AI models in medical imaging. While prior\nwork has explored the ability of neural networks to quantify predictive,\nepistemic, and aleatoric uncertainties using an information-theoretical\napproach in synthetic or well defined data settings like natural image\nclassification, its applicability to real life medical diagnosis tasks remains\nunderexplored. In this study, we provide an extensive uncertainty\nquantification benchmark for multi-label chest X-ray classification using the\nMIMIC-CXR-JPG dataset. We evaluate 13 uncertainty quantification methods for\nconvolutional (ResNet) and transformer-based (Vision Transformer) architectures\nacross a wide range of tasks. Additionally, we extend Evidential Deep Learning,\nHetClass NNs, and Deep Deterministic Uncertainty to the multi-label setting.\nOur analysis provides insights into uncertainty estimation effectiveness and\nthe ability to disentangle epistemic and aleatoric uncertainties, revealing\nmethod- and architecture-specific strengths and limitations.\n","authors":["Simon Baur","Wojciech Samek","Jackie Ma"],"pdf_url":"https://arxiv.org/pdf/2508.04457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04444v1","updated":"2025-08-06T13:37:37Z","published":"2025-08-06T13:37:37Z","title":"Matrix-Free Two-to-Infinity and One-to-Two Norms Estimation","summary":"  In this paper, we propose new randomized algorithms for estimating the\ntwo-to-infinity and one-to-two norms in a matrix-free setting, using only\nmatrix-vector multiplications. Our methods are based on appropriate\nmodifications of Hutchinson's diagonal estimator and its Hutch++ version. We\nprovide oracle complexity bounds for both modifications. We further illustrate\nthe practical utility of our algorithms for Jacobian-based regularization in\ndeep neural network training on image classification tasks. We also demonstrate\nthat our methodology can be applied to mitigate the effect of adversarial\nattacks in the domain of recommender systems.\n","authors":["Askar Tsyganov","Evgeny Frolov","Sergey Samsonov","Maxim Rakhuba"],"pdf_url":"https://arxiv.org/pdf/2508.04444v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.00539v2","updated":"2025-08-06T12:59:38Z","published":"2023-10-01T01:37:02Z","title":"Thompson Exploration with Best Challenger Rule in Best Arm\n  Identification","summary":"  This paper studies the fixed-confidence best arm identification (BAI) problem\nin the bandit framework in the canonical single-parameter exponential models.\nFor this problem, many policies have been proposed, but most of them require\nsolving an optimization problem at every round and/or are forced to explore an\narm at least a certain number of times except those restricted to the Gaussian\nmodel. To address these limitations, we propose a novel policy that combines\nThompson sampling with a computationally efficient approach known as the best\nchallenger rule. While Thompson sampling was originally considered for\nmaximizing the cumulative reward, we demonstrate that it can be used to\nnaturally explore arms in BAI without forcing it. We show that our policy is\nasymptotically optimal for any two-armed bandit problems and achieves near\noptimality for general $K$-armed bandit problems for $K\\geq 3$. Nevertheless,\nin numerical experiments, our policy shows competitive performance compared to\nasymptotically optimal policies in terms of sample complexity while requiring\nless computation cost. In addition, we highlight the advantages of our policy\nby comparing it to the concept of $\\beta$-optimality, a relaxed notion of\nasymptotic optimality commonly considered in the analysis of a class of\npolicies including the proposed one.\n","authors":["Jongyeong Lee","Junya Honda","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2310.00539v2.pdf","comment":"Corrigendum to the published version in ACML 2023\n  (https://proceedings.mlr.press/v222/lee24a.html)"},{"id":"http://arxiv.org/abs/2508.04409v1","updated":"2025-08-06T12:54:56Z","published":"2025-08-06T12:54:56Z","title":"The Relative Instability of Model Comparison with Cross-validation","summary":"  Existing work has shown that cross-validation (CV) can be used to provide an\nasymptotic confidence interval for the test error of a stable machine learning\nalgorithm, and existing stability results for many popular algorithms can be\napplied to derive positive instances where such confidence intervals will be\nvalid. However, in the common setting where CV is used to compare two\nalgorithms, it becomes necessary to consider a notion of relative stability\nwhich cannot easily be derived from existing stability results, even for simple\nalgorithms. To better understand relative stability and when CV provides valid\nconfidence intervals for the test error difference of two algorithms, we study\nthe soft-thresholded least squares algorithm, a close cousin of the Lasso. We\nprove that while stability holds when assessing the individual test error of\nthis algorithm, relative stability fails to hold when comparing the test error\nof two such algorithms, even in a sparse low-dimensional linear model setting.\nAdditionally, we empirically confirm the invalidity of CV confidence intervals\nfor the test error difference when either soft-thresholding or the Lasso is\nused. In short, caution is needed when quantifying the uncertainty of CV\nestimates of the performance difference of two machine learning algorithms,\neven when both algorithms are individually stable.\n","authors":["Alexandre Bayle","Lucas Janson","Lester Mackey"],"pdf_url":"https://arxiv.org/pdf/2508.04409v1.pdf","comment":"41 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.04393v1","updated":"2025-08-06T12:37:45Z","published":"2025-08-06T12:37:45Z","title":"Generative Flexible Latent Structure Regression (GFLSR) model","summary":"  Latent structure methods, specifically linear continuous latent structure\nmethods, are a type of fundamental statistical learning strategy. They are\nwidely used for dimension reduction, regression and prediction, in the fields\nof chemometrics, economics, social science and etc. However, due to the lack of\nmodel inference, generative form, and unidentifiable parameters, most of these\nmethods are always used as an algorithm, instead of a model. This paper\nproposed a Generative Flexible Latent Structure Regression (GFLSR) model\nstructure to address this problem. Moreover, we show that most linear\ncontinuous latent variable methods can be represented under the proposed\nframework. The recursive structure allows potential model inference and\nresidual analysis. Then, the traditional Partial Least Squares (PLS) is\nfocused; we show that the PLS can be specialised in the proposed model\nstructure, named Generative-PLS. With a model structure, we analyse the\nconvergence of the parameters and the latent variables. Under additional\ndistribution assumptions, we show that the proposed model structure can lead to\nmodel inference without solving the probabilistic model. Additionally, we\nproposed a novel bootstrap algorithm that enables uncertainty on parameters and\non prediction for new datasets. A simulation study and a Real-world dataset are\nused to verify the proposed Generative-PLS model structure. Although the\ntraditional PLS is a special case, this proposed GFLSRM structure leads to a\npotential inference structure for all the linear continuous latent variable\nmethods.\n","authors":["Clara Grazian","Qian Jin","Pierre Lafaye De Micheaux"],"pdf_url":"https://arxiv.org/pdf/2508.04393v1.pdf","comment":"44 pages in total"},{"id":"http://arxiv.org/abs/2508.03679v2","updated":"2025-08-06T12:22:27Z","published":"2025-08-05T17:50:03Z","title":"Streaming Generated Gaussian Process Experts for Online Learning and\n  Control","summary":"  Gaussian Processes (GPs), as a nonparametric learning method, offer flexible\nmodeling capabilities and calibrated uncertainty quantification for function\napproximations. Additionally, GPs support online learning by efficiently\nincorporating new data with polynomial-time computation, making them\nwell-suited for safety-critical dynamical systems that require rapid\nadaptation. However, the inference and online updates of exact GPs, when\nprocessing streaming data, incur cubic computation time and quadratic storage\nmemory complexity, limiting their scalability to large datasets in real-time\nsettings. In this paper, we propose a streaming kernel-induced progressively\ngenerated expert framework of Gaussian processes (SkyGP) that addresses both\ncomputational and memory constraints by maintaining a bounded set of experts,\nwhile inheriting the learning performance guarantees from exact Gaussian\nprocesses. Furthermore, two SkyGP variants are introduced, each tailored to a\nspecific objective, either maximizing prediction accuracy (SkyGP-Dense) or\nimproving computational efficiency (SkyGP-Fast). The effectiveness of SkyGP is\nvalidated through extensive benchmarks and real-time control experiments\ndemonstrating its superior performance compared to state-of-the-art approaches.\n","authors":["Zewen Yang","Dongfa Zhang","Xiaobing Dai","Fengyi Yu","Chi Zhang","Bingkun Huang","Hamid Sadeghian","Sami Haddadin"],"pdf_url":"https://arxiv.org/pdf/2508.03679v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.06382v4","updated":"2025-08-06T11:34:54Z","published":"2025-06-04T23:28:39Z","title":"On the Fundamental Impossibility of Hallucination Control in Large\n  Language Models","summary":"  This paper establishes a fundamental impossibility theorem: no LLM capable\nperforming non-trivial knowledge aggregation can simultaneously achieve\ntruthful (internally consistent) knowledge representation, semantic information\nconservation, complete revelation of relevant knowledge, and\nknowledge-constrained optimality. This impossibility is not an engineering\nlimitation but arises from the mathematical structure of information\naggregation itself. We establish this result by describing the inference\nprocess as an auction of ideas, where distributed components compete exploiting\ntheir partial knowledge to shape responses. The proof spans three independent\nmathematical domains: mechanism design theory (Green-Laffont), the theory of\nproper scoring rules (Savage), and direct architectural analysis of\ntransformers (Log-Sum-Exp convexity). In particular, we show how in the\nstrictly concave settings the score of an aggregate of diverse beliefs strictly\nexceeds the sum of individual scores. That gap may quantify the creation of\nunattributable certainty or overconfidence -- the mathematical origin of both\nhallucination and creativity, or imagination.\n  To support this analysis, we introduce the complementary concepts of the\nsemantic information measure and the emergence operator to model bounded\nreasoning in a general setting. We prove that while bounded reasoning generates\naccessible information, providing valuable insights and inspirations, idealized\nreasoning strictly preserves semantic content. By demonstrating that\nhallucination and imagination are mathematically identical phenomena-grounded\nin the necessary violation of information conservation-this paper offers a\nprincipled foundation for managing these behaviors in advanced AI systems.\nFinally, we present some speculative ideas to inspire evaluation and\nrefinements of the proposed theory.\n","authors":["Michał P. Karpowicz"],"pdf_url":"https://arxiv.org/pdf/2506.06382v4.pdf","comment":"cleared mathematics, proofs and ideas explained, added missing\n  definitions and axioms, discussion and speculation section added"},{"id":"http://arxiv.org/abs/2306.07886v5","updated":"2025-08-06T11:33:31Z","published":"2023-06-13T16:25:30Z","title":"Symmetry & Critical Points for Symmetric Tensor Decomposition Problems","summary":"  We consider the nonconvex optimization problem associated with the\ndecomposition of a real symmetric tensor into a sum of rank-one terms. Use is\nmade of the rich symmetry structure to construct infinite families of critical\npoints represented by Puiseux series in the problem dimension, and so obtain\nprecise analytic estimates on the objective function value and the Hessian\nspectrum. The results enable an analytic characterization of various\nobstructions to local optimization methods, revealing, in particular, a complex\narray of saddles and minima that differ in their symmetry, structure, and\nanalytic properties. A notable phenomenon, observed for all critical points\nconsidered, concerns the index of the Hessian increasing with the objective\nfunction value.\n","authors":["Yossi Arjevani","Gal Vinograd"],"pdf_url":"https://arxiv.org/pdf/2306.07886v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04258v1","updated":"2025-08-06T09:42:40Z","published":"2025-08-06T09:42:40Z","title":"Deep Neural Network-Driven Adaptive Filtering","summary":"  This paper proposes a deep neural network (DNN)-driven framework to address\nthe longstanding generalization challenge in adaptive filtering (AF). In\ncontrast to traditional AF frameworks that emphasize explicit cost function\ndesign, the proposed framework shifts the paradigm toward direct gradient\nacquisition. The DNN, functioning as a universal nonlinear operator, is\nstructurally embedded into the core architecture of the AF system, establishing\na direct mapping between filtering residuals and learning gradients. The\nmaximum likelihood is adopted as the implicit cost function, rendering the\nderived algorithm inherently data-driven and thus endowed with exemplary\ngeneralization capability, which is validated by extensive numerical\nexperiments across a spectrum of non-Gaussian scenarios. Corresponding mean\nvalue and mean square stability analyses are also conducted in detail.\n","authors":["Qizhen Wang","Gang Wang","Ying-Chang Liang"],"pdf_url":"https://arxiv.org/pdf/2508.04258v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.10945v3","updated":"2025-08-06T06:47:04Z","published":"2025-01-19T04:56:55Z","title":"Gradient-Based Multi-Objective Deep Learning: Algorithms, Theories,\n  Applications, and Beyond","summary":"  Many modern deep learning applications require balancing multiple objectives\nthat are often conflicting. Examples include multi-task learning,\nfairness-aware learning, and the alignment of Large Language Models (LLMs).\nThis leads to multi-objective deep learning, which tries to find optimal\ntrade-offs or Pareto-optimal solutions by adapting mathematical principles from\nthe field of Multi-Objective Optimization (MOO). However, directly applying\ngradient-based MOO techniques to deep neural networks presents unique\nchallenges, including high computational costs, optimization instability, and\nthe difficulty of effectively incorporating user preferences. This paper\nprovides a comprehensive survey of gradient-based techniques for\nmulti-objective deep learning. We systematically categorize existing algorithms\nbased on their outputs: (i) methods that find a single, well-balanced solution,\n(ii) methods that generate a finite set of diverse Pareto-optimal solutions,\nand (iii) methods that learn a continuous Pareto set of solutions. In addition\nto this taxonomy, the survey covers theoretical analyses, key applications,\npractical resources, and highlights open challenges and promising directions\nfor future research. A comprehensive list of multi-objective deep learning\nalgorithms is available at\nhttps://github.com/Baijiong-Lin/Awesome-Multi-Objective-Deep-Learning.\n","authors":["Weiyu Chen","Baijiong Lin","Xiaoyuan Zhang","Xi Lin","Han Zhao","Qingfu Zhang","James T. Kwok"],"pdf_url":"https://arxiv.org/pdf/2501.10945v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.01414v2","updated":"2025-08-06T06:22:51Z","published":"2025-01-02T18:56:23Z","title":"Deep Discrete Encoders: Identifiable Deep Generative Models for Rich\n  Data with Discrete Latent Layers","summary":"  In the era of generative AI, deep generative models (DGMs) with latent\nrepresentations have gained tremendous popularity. Despite their impressive\nempirical performance, the statistical properties of these models remain\nunderexplored. DGMs are often overparametrized, non-identifiable, and\nuninterpretable black boxes, raising serious concerns when deploying them in\nhigh-stakes applications. Motivated by this, we propose interpretable deep\ngenerative models for rich data types with discrete latent layers, called Deep\nDiscrete Encoders (DDEs). A DDE is a directed graphical model with multiple\nbinary latent layers. Theoretically, we propose transparent identifiability\nconditions for DDEs, which imply progressively smaller sizes of the latent\nlayers as they go deeper. Identifiability ensures consistent parameter\nestimation and inspires an interpretable design of the deep architecture.\nComputationally, we propose a scalable estimation pipeline of a layerwise\nnonlinear spectral initialization followed by a penalized stochastic\napproximation EM algorithm. This procedure can efficiently estimate models with\nexponentially many latent components. Extensive simulation studies for\nhigh-dimensional data and deep architectures validate our theoretical results\nand demonstrate the excellent performance of our algorithms. We apply DDEs to\nthree diverse real datasets with different data types to perform hierarchical\ntopic modeling, image representation learning, and response time modeling in\neducational testing.\n","authors":["Seunghyun Lee","Yuqi Gu"],"pdf_url":"https://arxiv.org/pdf/2501.01414v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04111v1","updated":"2025-08-06T06:15:40Z","published":"2025-08-06T06:15:40Z","title":"Negative binomial regression and inference using a pre-trained\n  transformer","summary":"  Negative binomial regression is essential for analyzing over-dispersed count\ndata in in comparative studies, but parameter estimation becomes\ncomputationally challenging in large screens requiring millions of comparisons.\nWe investigate using a pre-trained transformer to produce estimates of negative\nbinomial regression parameters from observed count data, trained through\nsynthetic data generation to learn to invert the process of generating counts\nfrom parameters. The transformer method achieved better parameter accuracy than\nmaximum likelihood optimization while being 20 times faster. However,\ncomparisons unexpectedly revealed that method of moment estimates performed as\nwell as maximum likelihood optimization in accuracy, while being 1,000 times\nfaster and producing better-calibrated and more powerful tests, making it the\nmost efficient solution for this application.\n","authors":["Valentine Svensson"],"pdf_url":"https://arxiv.org/pdf/2508.04111v1.pdf","comment":"6 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.13922v4","updated":"2025-08-06T03:50:08Z","published":"2024-11-21T08:18:04Z","title":"Exponentially Consistent Nonparametric Linkage-Based Clustering of Data\n  Sequences","summary":"  In this paper, we consider nonparametric clustering of $M$ independent and\nidentically distributed (i.i.d.) data sequences generated from {\\em unknown}\ndistributions. The distributions of the $M$ data sequences belong to $K$\nunderlying distribution clusters. Existing results on exponentially consistent\nnonparametric clustering algorithms, like single linkage-based (SLINK)\nclustering and $k$-medoids distribution clustering, assume that the maximum\nintra-cluster distance ($d_L$) is smaller than the minimum inter-cluster\ndistance ($d_H$). First, in the fixed sample size (FSS) setting, we show that\nexponential consistency can be achieved for SLINK clustering under a less\nstrict assumption, $d_I < d_H$, where $d_I$ is the maximum distance between any\ntwo sub-clusters of a cluster that partition the cluster. Note that $d_I < d_L$\nin general. Thus, our results show that SLINK is exponentially consistent for a\nlarger class of problems than previously known. In our simulations, we also\nidentify examples where $k$-medoids clustering is unable to find the true\nclusters, but SLINK is exponentially consistent. Then, we propose a sequential\nclustering algorithm, named SLINK-SEQ, based on SLINK and prove that it is also\nexponentially consistent. Simulation results show that the SLINK-SEQ algorithm\nrequires fewer expected number of samples than the FSS SLINK algorithm for the\nsame probability of error.\n","authors":["Bhupender Singh","Ananth Ram Rajagopalan","Srikrishna Bhashyam"],"pdf_url":"https://arxiv.org/pdf/2411.13922v4.pdf","comment":"Accepted in IEEE Transactions on Signal Processing"},{"id":"http://arxiv.org/abs/2508.03546v2","updated":"2025-08-06T02:41:26Z","published":"2025-08-05T15:15:30Z","title":"Supervised Dynamic Dimension Reduction with Deep Neural Network","summary":"  This paper studies the problem of dimension reduction, tailored to improving\ntime series forecasting with high-dimensional predictors. We propose a novel\nSupervised Deep Dynamic Principal component analysis (SDDP) framework that\nincorporates the target variable and lagged observations into the factor\nextraction process. Assisted by a temporal neural network, we construct\ntarget-aware predictors by scaling the original predictors in a supervised\nmanner, with larger weights assigned to predictors with stronger forecasting\npower. A principal component analysis is then performed on the target-aware\npredictors to extract the estimated SDDP factors. This supervised factor\nextraction not only improves predictive accuracy in the downstream forecasting\ntask but also yields more interpretable and target-specific latent factors.\nBuilding upon SDDP, we propose a factor-augmented nonlinear dynamic forecasting\nmodel that unifies a broad family of factor-model-based forecasting approaches.\nTo further demonstrate the broader applicability of SDDP, we extend our studies\nto a more challenging scenario when the predictors are only partially\nobservable. We validate the empirical performance of the proposed method on\nseveral real-world public datasets. The results show that our algorithm\nachieves notable improvements in forecasting accuracy compared to\nstate-of-the-art methods.\n","authors":["Zhanye Luo","Yuefeng Han","Xiufan Yu"],"pdf_url":"https://arxiv.org/pdf/2508.03546v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.02019v2","updated":"2025-08-06T02:01:15Z","published":"2025-05-04T07:49:56Z","title":"Learning the Simplest Neural ODE","summary":"  Since the advent of the ``Neural Ordinary Differential Equation (Neural\nODE)'' paper, learning ODEs with deep learning has been applied to system\nidentification, time-series forecasting, and related areas. Exploiting the\ndiffeomorphic nature of ODE solution maps, neural ODEs has also enabled their\nuse in generative modeling. Despite the rich potential to incorporate various\nkinds of physical information, training Neural ODEs remains challenging in\npractice. This study demonstrates, through the simplest one-dimensional linear\nmodel, why training Neural ODEs is difficult. We then propose a new\nstabilization method and provide an analytical convergence analysis. The\ninsights and techniques presented here serve as a concise tutorial for\nresearchers beginning work on Neural ODEs.\n","authors":["Yuji Okamoto","Tomoya Takeuchi","Yusuke Sakemi"],"pdf_url":"https://arxiv.org/pdf/2505.02019v2.pdf","comment":"Accepted SICE FES 2025"},{"id":"http://arxiv.org/abs/2507.21155v2","updated":"2025-08-06T00:19:32Z","published":"2025-07-24T19:30:24Z","title":"SPADE-S: A Sparsity-Robust Foundational Forecaster","summary":"  Despite significant advancements in time series forecasting, accurate\nmodeling of time series with strong heterogeneity in magnitude and/or sparsity\npatterns remains challenging for state-of-the-art deep learning architectures.\nWe identify several factors that lead existing models to systematically\nunderperform on low-magnitude and sparse time series, including loss functions\nwith implicit biases toward high-magnitude series, training-time sampling\nmethods, and limitations of time series encoding methods.\n  SPADE-S is a robust forecasting architecture that significantly reduces\nmagnitude- and sparsity-based systematic biases and improves overall prediction\naccuracy. Empirical results demonstrate that SPADE-S outperforms existing\nstate-of-the-art approaches across a diverse set of use cases in demand\nforecasting. In particular, we show that, depending on the quantile forecast\nand magnitude of the series, SPADE-S can improve forecast accuracy by up to\n15%. This results in P90 overall forecast accuracy gains of 2.21%, 6.58%, and\n4.28%, and P50 forecast accuracy gains of 0.92%, 0.77%, and 1.95%,\nrespectively, for each of three distinct datasets, ranging from 3 million to\n700 million series, from a large online retailer.\n","authors":["Malcolm Wolff","Matthew Li","Ravi Kiran Selvam","Hanjing Zhu","Kin G. Olivares","Ruijun Ma","Abhinav Katoch","Shankar Ramasubramanian","Mengfei Cao","Roberto Bandarra","Rahul Gopalsamy","Stefania La Vattiata","Sitan Yang","Michael W. Mahoney"],"pdf_url":"https://arxiv.org/pdf/2507.21155v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10076v2","updated":"2025-08-06T22:41:42Z","published":"2025-04-14T10:21:08Z","title":"Towards Scalable Bayesian Optimization via Gradient-Informed Bayesian\n  Neural Networks","summary":"  Bayesian optimization (BO) is a widely used method for data-driven\noptimization that generally relies on zeroth-order data of objective function\nto construct probabilistic surrogate models. These surrogates guide the\nexploration-exploitation process toward finding global optimum. While Gaussian\nprocesses (GPs) are commonly employed as surrogates of the unknown objective\nfunction, recent studies have highlighted the potential of Bayesian neural\nnetworks (BNNs) as scalable and flexible alternatives. Moreover, incorporating\ngradient observations into GPs, when available, has been shown to improve BO\nperformance. However, the use of gradients within BNN surrogates remains\nunexplored. By leveraging automatic differentiation, gradient information can\nbe seamlessly integrated into BNN training, resulting in more informative\nsurrogates for BO. We propose a gradient-informed loss function for BNN\ntraining, effectively augmenting function observations with local gradient\ninformation. The effectiveness of this approach is demonstrated on well-known\nbenchmarks in terms of improved BNN predictions and faster BO convergence as\nthe number of decision variables increases.\n","authors":["Georgios Makrygiorgos","Joshua Hang Sai Ip","Ali Mesbah"],"pdf_url":"https://arxiv.org/pdf/2504.10076v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04884v1","updated":"2025-08-06T21:19:08Z","published":"2025-08-06T21:19:08Z","title":"The Cosine Schedule is Fisher-Rao-Optimal for Masked Discrete Diffusion\n  Models","summary":"  In this work, we study the problem of choosing the discretisation schedule\nfor sampling from masked discrete diffusion models in terms of the information\ngeometry of the induced probability path. Specifically, we show that the\noptimal schedule under the Fisher-Rao geometry recovers the popularly-used\ncosine schedule.\n","authors":["Leo Zhang"],"pdf_url":"https://arxiv.org/pdf/2508.04884v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2508.04883v1","updated":"2025-08-06T21:16:17Z","published":"2025-08-06T21:16:17Z","title":"Gaussian mixture layers for neural networks","summary":"  The mean-field theory for two-layer neural networks considers infinitely wide\nnetworks that are linearly parameterized by a probability measure over the\nparameter space. This nonparametric perspective has significantly advanced both\nthe theoretical and conceptual understanding of neural networks, with\nsubstantial efforts made to validate its applicability to networks of moderate\nwidth. In this work, we explore the opposite direction, investigating whether\ndynamics can be directly implemented over probability measures. Specifically,\nwe employ Gaussian mixture models as a flexible and expressive parametric\nfamily of distributions together with the theory of Wasserstein gradient flows\nto derive training dynamics for such measures. Our approach introduces a new\ntype of layer -- the Gaussian mixture (GM) layer -- that can be integrated into\nneural network architectures. As a proof of concept, we validate our proposal\nthrough experiments on simple classification tasks, where a GM layer achieves\ntest performance comparable to that of a two-layer fully connected network.\nFurthermore, we examine the behavior of these dynamics and demonstrate\nnumerically that GM layers exhibit markedly different behavior compared to\nclassical fully connected layers, even when the latter are large enough to be\nconsidered in the mean-field regime.\n","authors":["Sinho Chewi","Philippe Rigollet","Yuling Yan"],"pdf_url":"https://arxiv.org/pdf/2508.04883v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04830v1","updated":"2025-08-06T19:17:24Z","published":"2025-08-06T19:17:24Z","title":"Federal Reserve Communication and the COVID-19 Pandemic","summary":"  In this study, we examine the Federal Reserve's communication strategies\nduring the COVID-19 pandemic, comparing them with communication during previous\nperiods of economic stress. Using specialized dictionaries tailored to\nCOVID-19, unconventional monetary policy (UMP), and financial stability,\ncombined with sentiment analysis and topic modeling techniques, we identify a\ndistinct focus in Fed communication during the pandemic on financial stability,\nmarket volatility, social welfare, and UMP, characterized by notable contextual\nuncertainty. Through comparative analysis, we juxtapose the Fed's communication\nduring the COVID-19 crisis with its responses during the dot-com and global\nfinancial crises, examining content, sentiment, and timing dimensions. Our\nfindings reveal that Fed communication and policy actions were more reactive to\nthe COVID-19 crisis than to previous crises. Additionally, declining sentiment\nrelated to financial stability in interest rate announcements and minutes\nanticipated subsequent accommodative monetary policy decisions. We further\ndocument that communicating about UMP has become the \"new normal\" for the Fed's\nFederal Open Market Committee meeting minutes and Chairman's speeches since the\nGlobal Financial Crisis, reflecting an institutional adaptation in\ncommunication strategy following periods of economic distress. These findings\ncontribute to our understanding of how central bank communication evolves\nduring crises and how communication strategies adapt to exceptional economic\ncircumstances.\n","authors":["Jonathan Benchimol","Sophia Kazinnik","Yossi Saadon"],"pdf_url":"https://arxiv.org/pdf/2508.04830v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04818v1","updated":"2025-08-06T18:56:08Z","published":"2025-08-06T18:56:08Z","title":"Single-Step Reconstruction-Free Anomaly Detection and Segmentation via\n  Diffusion Models","summary":"  Generative models have demonstrated significant success in anomaly detection\nand segmentation over the past decade. Recently, diffusion models have emerged\nas a powerful alternative, outperforming previous approaches such as GANs and\nVAEs. In typical diffusion-based anomaly detection, a model is trained on\nnormal data, and during inference, anomalous images are perturbed to a\npredefined intermediate step in the forward diffusion process. The\ncorresponding normal image is then reconstructed through iterative reverse\nsampling.\n  However, reconstruction-based approaches present three major challenges: (1)\nthe reconstruction process is computationally expensive due to multiple\nsampling steps, making real-time applications impractical; (2) for complex or\nsubtle patterns, the reconstructed image may correspond to a different normal\npattern rather than the original input; and (3) Choosing an appropriate\nintermediate noise level is challenging because it is application-dependent and\noften assumes prior knowledge of anomalies, an assumption that does not hold in\nunsupervised settings.\n  We introduce Reconstruction-free Anomaly Detection with Attention-based\ndiffusion models in Real-time (RADAR), which overcomes the limitations of\nreconstruction-based anomaly detection. Unlike current SOTA methods that\nreconstruct the input image, RADAR directly produces anomaly maps from the\ndiffusion model, improving both detection accuracy and computational\nefficiency. We evaluate RADAR on real-world 3D-printed material and the\nMVTec-AD dataset. Our approach surpasses state-of-the-art diffusion-based and\nstatistical machine learning models across all key metrics, including accuracy,\nprecision, recall, and F1 score. Specifically, RADAR improves F1 score by 7% on\nMVTec-AD and 13% on the 3D-printed material dataset compared to the next best\nmodel.\n  Code available at: https://github.com/mehrdadmoradi124/RADAR\n","authors":["Mehrdad Moradi","Marco Grasso","Bianca Maria Colosimo","Kamran Paynabar"],"pdf_url":"https://arxiv.org/pdf/2508.04818v1.pdf","comment":"9 pages, 8 figures, 2 tables. Submitted to an IEEE conference"},{"id":"http://arxiv.org/abs/2508.04800v1","updated":"2025-08-06T18:16:53Z","published":"2025-08-06T18:16:53Z","title":"Differentially Private Model-X Knockoffs via Johnson-Lindenstrauss\n  Transform","summary":"  We introduce a novel privatization framework for high-dimensional controlled\nvariable selection. Our framework enables rigorous False Discovery Rate (FDR)\ncontrol under differential privacy constraints. While the Model-X knockoff\nprocedure provides FDR guarantees by constructing provably exchangeable\n``negative control\" features, existing privacy mechanisms like Laplace or\nGaussian noise injection disrupt its core exchangeability conditions. Our key\ninnovation lies in privatizing the data knockoff matrix through the Gaussian\nJohnson-Lindenstrauss Transformation (JLT), a dimension reduction technique\nthat simultaneously preserves covariate relationships through approximate\nisometry for $(\\epsilon,\\delta)$-differential privacy.\n  We theoretically characterize both FDR and the power of the proposed private\nvariable selection procedure, in an asymptotic regime. Our theoretical analysis\ncharacterizes the role of different factors, such as the JLT's dimension\nreduction ratio, signal-to-noise ratio, differential privacy parameters, sample\nsize and feature dimension, in shaping the privacy-power trade-off. Our\nanalysis is based on a novel `debiasing technique' for high-dimensional private\nknockoff procedure. We further establish sufficient conditions under which the\npower of the proposed procedure converges to one. This work bridges two\ncritical paradigms -- knockoff-based FDR control and private data release --\nenabling reliable variable selection in sensitive domains. Our analysis\ndemonstrates that structural privacy preservation through random projections\noutperforms the classical noise addition mechanism, maintaining statistical\npower even under strict privacy budgets.\n","authors":["Yuxuan Tao","Adel Javanmard"],"pdf_url":"https://arxiv.org/pdf/2508.04800v1.pdf","comment":"68 pages, 6 figures"}],"Computation":[{"id":"http://arxiv.org/abs/2508.04172v1","updated":"2025-08-06T07:55:18Z","published":"2025-08-06T07:55:18Z","title":"Rapid parameter estimation with the full symphony of compact binary\n  mergers using meshfree approximation","summary":"  We present a fast Bayesian inference framework to address the growing\ncomputational cost of gravitational-wave parameter estimation. The increased\ncost is driven by improved broadband detector sensitivity, particularly at low\nfrequencies due to advances in detector commissioning, resulting in longer\nin-band signals and a higher detection rate. Waveform models now incorporate\nfeatures like higher-order modes, further increasing the complexity of standard\ninference methods. Our framework employs meshfree likelihood interpolation with\nradial basis functions to accelerate Bayesian inference using the IMRPhenomXHM\nwaveform model that incorporates higher modes of the gravitational-wave signal.\nIn the initial start-up stage, interpolation nodes are placed within a\nconstant-match metric ellipsoid in the intrinsic parameter space. During\nsampling, likelihood is evaluated directly using the precomputed interpolants,\nbypassing the costly steps of on-the-fly waveform generation and\noverlap-integral computation. We improve efficiency by sampling in a rotated\nparameter space aligned with the eigenbasis of the metric ellipsoid, where\nparameters are uncorrelated by construction. This speeds up sampler\nconvergence. This method yields unbiased parameter recovery when applied to 100\nsimulated neutron-star-black-hole signals (NSBH) in LIGO-Virgo data, while\nreducing computational cost by up to an order of magnitude for the\nlongest-duration signal. The meshfree framework equally applies to symmetric\ncompact binary systems dominated by the quadrupole mode, supporting parameter\nestimation across a broad range of sources. Applied to a simulated NSBH signal\nin Einstein Telescope data, where the effects of Earth's rotation are neglected\nfor simplicity, our method achieves an O(10^4) speed-up, demonstrating its\npotential use in the third-generation (3G) era.\n","authors":["Abhishek Sharma","Lalit Pathak","Soumen Roy","Anand S. Sengupta"],"pdf_url":"https://arxiv.org/pdf/2508.04172v1.pdf","comment":"18 pages, 7 figures"},{"id":"http://arxiv.org/abs/2508.04828v1","updated":"2025-08-06T19:12:44Z","published":"2025-08-06T19:12:44Z","title":"Modelling the emergence of open-ended technological evolution","summary":"  Humans stand alone in terms of their potential to collectively and\ncumulatively improve technologies in an open-ended manner. This open-endedness\nprovides societies with the ability to continually expand their resources and\nto increase their capacity to store, transmit and process information at a\ncollective-level. Here, we propose that the production of resources arises from\nthe interaction between technological systems (a society's repertoire of\ninterdependent skills, techniques and artifacts) and search spaces (the\naggregate collection of needs, problems and goals within a society). Starting\nfrom this premise we develop a macro-level model wherein both technological\nsystems and search spaces are subject to cultural evolutionary dynamics. By\nmanipulating the extent to which these dynamics are characterised by stochastic\nor selection-like processes, we demonstrate that open-ended growth is extremely\nrare, historically contingent and only possible when technological systems and\nsearch spaces co-evolve. Here, stochastic factors must be strong enough to\ncontinually perturb the dynamics into a far-from-equilibrium state, whereas\nselection-like factors help maintain effectiveness and ensure the sustained\nproduction of resources. Only when this co-evolutionary dynamic maintains\neffective technological systems, supports the ongoing expansion of the search\nspace and leads to an increased provision of resources do we observe open-ended\ntechnological evolution.\n","authors":["James Winters","Mathieu Charbonneau"],"pdf_url":"https://arxiv.org/pdf/2508.04828v1.pdf","comment":"25 pages, 4 figures, under review at Philosophical Transactions of\n  the Royal Society B, created in Typst"},{"id":"http://arxiv.org/abs/2507.15893v2","updated":"2025-08-06T18:05:09Z","published":"2025-07-20T13:51:03Z","title":"inrep: A Comprehensive Framework for Adaptive Testing in R","summary":"  The inrep package provides a comprehensive framework for implementing\ncomputerized adaptive testing (CAT) in R. Building upon established\npsychometric foundations from TAM, the package enables researchers to deploy\nproduction-ready adaptive assessments through an integrated shiny interface.\nThe framework supports all major item response theory models (1PL, 2PL, 3PL,\nGRM) with real-time ability estimation, multiple item selection algorithms, and\nsophisticated stopping criteria. Key innovations include dual estimation\nengines for optimal speed-accuracy balance, comprehensive multilingual support,\nGDPR-compliant data management, and seamless integration with external\nplatforms. Empirical validation demonstrates measurement accuracy within\nestablished benchmarks while reducing test length efficiently. The package\naddresses critical barriers to CAT adoption by providing a complete solution\nfrom study configuration through deployment and analysis, making adaptive\ntesting accessible to researchers across educational, psychological, and\nclinical domains.\n","authors":["Clievins Selva"],"pdf_url":"https://arxiv.org/pdf/2507.15893v2.pdf","comment":"I am withdrawing this submission because the paper is still in a\n  preliminary state and does not reflect the final version I intend to publish.\n  I prefer to revise the content offline before any further public release"}]},"2025-08-07T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2508.05628v1","updated":"2025-08-07T17:59:01Z","published":"2025-08-07T17:59:01Z","title":"H-Net++: Hierarchical Dynamic Chunking for Tokenizer-Free Language\n  Modelling in Morphologically-Rich Languages","summary":"  Byte-level language models eliminate fragile tokenizers but face\ncomputational challenges in morphologically-rich languages (MRLs), where words\nspan many bytes. We propose H-NET++, a hierarchical dynamic-chunking model that\nlearns linguistically-informed segmentation through end-to-end training. Key\ninnovations include: (1) a lightweight Transformer context-mixer (1.9M\nparameters) for cross-chunk attention, (2) a two-level latent hyper-prior for\ndocument-level consistency, (3) specialized handling of orthographic artifacts\n(e.g. Persian ZWNJ), and (4) curriculum-based training with staged sequence\nlengths. On a 1.4B-token Persian corpus, H-NET++ achieves state-of-the-art\nresults: 0.159 BPB reduction versus BPE-based GPT-2-fa (12% better\ncompression), 5.4pp gain on ParsGLUE, 53% improved robustness to ZWNJ\ncorruption, and 73.8% F1 on gold morphological boundaries. Our learned chunks\nalign with Persian morphology without explicit supervision, demonstrating that\nhierarchical dynamic chunking provides an effective tokenizer-free solution for\nMRLs while maintaining computational efficiency.\n","authors":["Mehrdad Zakershahrak","Samira Ghodratnama"],"pdf_url":"https://arxiv.org/pdf/2508.05628v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05625v1","updated":"2025-08-07T17:58:41Z","published":"2025-08-07T17:58:41Z","title":"How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in\n  Multi-Turn Conversations","summary":"  Large Language Models (LLMs) have started to demonstrate the ability to\npersuade humans, yet our understanding of how this dynamic transpires is\nlimited. Recent work has used linear probes, lightweight tools for analyzing\nmodel representations, to study various LLM skills such as the ability to model\nuser sentiment and political perspective. Motivated by this, we apply probes to\nstudy persuasion dynamics in natural, multi-turn conversations. We leverage\ninsights from cognitive science to train probes on distinct aspects of\npersuasion: persuasion success, persuadee personality, and persuasion strategy.\nDespite their simplicity, we show that they capture various aspects of\npersuasion at both the sample and dataset levels. For instance, probes can\nidentify the point in a conversation where the persuadee was persuaded or where\npersuasive success generally occurs across the entire dataset. We also show\nthat in addition to being faster than expensive prompting-based approaches,\nprobes can do just as well and even outperform prompting in some settings, such\nas when uncovering persuasion strategy. This suggests probes as a plausible\navenue for studying other complex behaviours such as deception and\nmanipulation, especially in multi-turn settings and large-scale dataset\nanalysis where prompting-based methods would be computationally inefficient.\n","authors":["Brandon Jaipersaud","David Krueger","Ekdeep Singh Lubana"],"pdf_url":"https://arxiv.org/pdf/2508.05625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05618v1","updated":"2025-08-07T17:57:09Z","published":"2025-08-07T17:57:09Z","title":"Learning to Reason for Factuality","summary":"  Reasoning Large Language Models (R-LLMs) have significantly advanced complex\nreasoning tasks but often struggle with factuality, generating substantially\nmore hallucinations than their non-reasoning counterparts on long-form\nfactuality benchmarks. However, extending online Reinforcement Learning (RL), a\nkey component in recent R-LLM advancements, to the long-form factuality setting\nposes several unique challenges due to the lack of reliable verification\nmethods. Previous work has utilized automatic factuality evaluation frameworks\nsuch as FActScore to curate preference data in the offline RL setting, yet we\nfind that directly leveraging such methods as the reward in online RL leads to\nreward hacking in multiple ways, such as producing less detailed or relevant\nresponses. We propose a novel reward function that simultaneously considers the\nfactual precision, response detail level, and answer relevance, and applies\nonline RL to learn high quality factual reasoning. Evaluated on six long-form\nfactuality benchmarks, our factual reasoning model achieves an average\nreduction of 23.1 percentage points in hallucination rate, a 23% increase in\nanswer detail level, and no degradation in the overall response helpfulness.\n","authors":["Xilun Chen","Ilia Kulikov","Vincent-Pierre Berges","Barlas Oğuz","Rulin Shao","Gargi Ghosh","Jason Weston","Wen-tau Yih"],"pdf_url":"https://arxiv.org/pdf/2508.05618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05615v1","updated":"2025-08-07T17:54:27Z","published":"2025-08-07T17:54:27Z","title":"Test-Time Reinforcement Learning for GUI Grounding via Region\n  Consistency","summary":"  Graphical User Interface (GUI) grounding, the task of mapping natural\nlanguage instructions to precise screen coordinates, is fundamental to\nautonomous GUI agents. While existing methods achieve strong performance\nthrough extensive supervised training or reinforcement learning with labeled\nrewards, they remain constrained by the cost and availability of pixel-level\nannotations. We observe that when models generate multiple predictions for the\nsame GUI element, the spatial overlap patterns reveal implicit confidence\nsignals that can guide more accurate localization. Leveraging this insight, we\npropose GUI-RC (Region Consistency), a test-time scaling method that constructs\nspatial voting grids from multiple sampled predictions to identify consensus\nregions where models show highest agreement. Without any training, GUI-RC\nimproves accuracy by 2-3% across various architectures on ScreenSpot\nbenchmarks. We further introduce GUI-RCPO (Region Consistency Policy\nOptimization), which transforms these consistency patterns into rewards for\ntest-time reinforcement learning. By computing how well each prediction aligns\nwith the collective consensus, GUI-RCPO enables models to iteratively refine\ntheir outputs on unlabeled data during inference. Extensive experiments\ndemonstrate the generality of our approach: GUI-RC boosts\nQwen2.5-VL-3B-Instruct from 80.11% to 83.57% on ScreenSpot-v2, while GUI-RCPO\nfurther improves it to 85.14% through self-supervised optimization. Our\napproach reveals the untapped potential of test-time scaling and test-time\nreinforcement learning for GUI grounding, offering a promising path toward more\nrobust and data-efficient GUI agents.\n","authors":["Yong Du","Yuchen Yan","Fei Tang","Zhengxi Lu","Chang Zong","Weiming Lu","Shengpei Jiang","Yongliang Shen"],"pdf_url":"https://arxiv.org/pdf/2508.05615v1.pdf","comment":"Project Page: https://zju-real.github.io/gui-rcpo Code:\n  https://github.com/zju-real/gui-rcpo"},{"id":"http://arxiv.org/abs/2508.05614v1","updated":"2025-08-07T17:54:15Z","published":"2025-08-07T17:54:15Z","title":"OmniEAR: Benchmarking Agent Reasoning in Embodied Tasks","summary":"  Large language models excel at abstract reasoning but their capacity for\nembodied agent reasoning remains largely unexplored. We present OmniEAR, a\ncomprehensive framework for evaluating how language models reason about\nphysical interactions, tool usage, and multi-agent coordination in embodied\ntasks. Unlike existing benchmarks that provide predefined tool sets or explicit\ncollaboration directives, OmniEAR requires agents to dynamically acquire\ncapabilities and autonomously determine coordination strategies based on task\ndemands. Through text-based environment representation, we model continuous\nphysical properties and complex spatial relationships across 1,500 scenarios\nspanning household and industrial domains. Our systematic evaluation reveals\nsevere performance degradation when models must reason from constraints: while\nachieving 85-96% success with explicit instructions, performance drops to\n56-85% for tool reasoning and 63-85% for implicit collaboration, with compound\ntasks showing over 50% failure rates. Surprisingly, complete environmental\ninformation degrades coordination performance, indicating models cannot filter\ntask-relevant constraints. Fine-tuning improves single-agent tasks dramatically\n(0.6% to 76.3%) but yields minimal multi-agent gains (1.5% to 5.5%), exposing\nfundamental architectural limitations. These findings demonstrate that embodied\nreasoning poses fundamentally different challenges than current models can\naddress, establishing OmniEAR as a rigorous benchmark for evaluating and\nadvancing embodied AI systems. Our code and data are included in the\nsupplementary materials and will be open-sourced upon acceptance.\n","authors":["Zixuan Wang","Dingming Li","Hongxing Li","Shuo Chen","Yuchen Yan","Wenqi Zhang","Yongliang Shen","Weiming Lu","Jun Xiao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2508.05614v1.pdf","comment":"Project Page: https://zju-real.github.io/OmniEmbodied Code:\n  https://github.com/ZJU-REAL/OmniEmbodied"},{"id":"http://arxiv.org/abs/2508.05613v1","updated":"2025-08-07T17:53:56Z","published":"2025-08-07T17:53:56Z","title":"Cooper: Co-Optimizing Policy and Reward Models in Reinforcement Learning\n  for Large Language Models","summary":"  Large language models (LLMs) have demonstrated remarkable performance in\nreasoning tasks, where reinforcement learning (RL) serves as a key algorithm\nfor enhancing their reasoning capabilities. Currently, there are two mainstream\nreward paradigms: model-based rewards and rule-based rewards. However, both\napproaches suffer from limitations: rule-based rewards lack robustness, while\nmodel-based rewards are vulnerable to reward hacking. To address these issues,\nwe propose Cooper(Co-optimizing Policy Model and Reward Model), a RL framework\nthat jointly optimizes both the policy model and the reward model. Cooper\nleverages the high precision of rule-based rewards when identifying correct\nresponses, and dynamically constructs and selects positive-negative sample\npairs for continued training the reward model. This design enhances robustness\nand mitigates the risk of reward hacking. To further support Cooper, we\nintroduce a hybrid annotation strategy that efficiently and accurately\ngenerates training data for the reward model. We also propose a reference-based\nreward modeling paradigm, where the reward model takes a reference answer as\ninput. Based on this design, we train a reward model named VerifyRM, which\nachieves higher accuracy on VerifyBench compared to other models of the same\nsize. We conduct reinforcement learning using both VerifyRM and Cooper. Our\nexperiments show that Cooper not only alleviates reward hacking but also\nimproves end-to-end RL performance, for instance, achieving a 0.54% gain in\naverage accuracy on Qwen2.5-1.5B-Instruct. Our findings demonstrate that\ndynamically updating reward model is an effective way to combat reward hacking,\nproviding a reference for better integrating reward models into RL.\n","authors":["Haitao Hong","Yuchen Yan","Xingyu Wu","Guiyang Hou","Wenqi Zhang","Weiming Lu","Yongliang Shen","Jun Xiao"],"pdf_url":"https://arxiv.org/pdf/2508.05613v1.pdf","comment":"Project Page: https://zju-real.github.io/cooper Code:\n  https://github.com/zju-real/cooper"},{"id":"http://arxiv.org/abs/2508.01473v2","updated":"2025-08-07T17:46:00Z","published":"2025-08-02T19:46:09Z","title":"TreeDiff: AST-Guided Code Generation with Diffusion LLMs","summary":"  Recent advances in diffusion-based language models have opened new\npossibilities for controllable and bidirectional sequence generation. These\nmodels provide an alternative to traditional autoregressive approaches by\nframing text generation as an iterative denoising process. However, applying\ndiffusion models to structured domains such as source code remains a\nsignificant challenge. Programming languages differ from natural language in\nthat they follow strict syntactic and semantic rules, with hierarchical\norganization that must be preserved for correctness. Standard token-level\ncorruption techniques used during training often ignore this structure, which\nmay hinder the model's ability to learn meaningful representations of code. To\naddress this limitation, we propose a syntax-aware diffusion framework that\nincorporates structural priors from Abstract Syntax Trees (ASTs) into the\ndenoising process. Instead of masking individual tokens at random, we\nselectively corrupt syntactically meaningful code spans derived from AST\nsubtrees. This enables the model to reconstruct programs in a way that respects\ngrammatical boundaries and captures long-range dependencies. Experimental\nresults demonstrate that syntax-aware corruption significantly improves\nsyntactic correctness, reconstruction accuracy, and generalization to unseen\ncode patterns. These findings highlight the potential of incorporating\nstructural information into diffusion-based training and suggest that\nsyntax-guided denoising is a promising direction for advancing diffusion-based\nlanguage models in code generation tasks.\n","authors":["Yiming Zeng","Jinghan Cao","Zexin Li","Yiming Chen","Tao Ren","Dawei Xiang","Xidong Wu","Shangqian Gao","Tingting Yu"],"pdf_url":"https://arxiv.org/pdf/2508.01473v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05606v1","updated":"2025-08-07T17:45:17Z","published":"2025-08-07T17:45:17Z","title":"Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and\n  Vision","summary":"  Chain-of-Thought (CoT) reasoning has been widely adopted to enhance Large\nLanguage Models (LLMs) by decomposing complex tasks into simpler, sequential\nsubtasks. However, extending CoT to vision-language reasoning tasks remains\nchallenging, as it often requires interpreting transitions of visual states to\nsupport reasoning. Existing methods often struggle with this due to limited\ncapacity of modeling visual state transitions or incoherent visual trajectories\ncaused by fragmented architectures.\n  To overcome these limitations, we propose Uni-CoT, a Unified Chain-of-Thought\nframework that enables coherent and grounded multimodal reasoning within a\nsingle unified model. The key idea is to leverage a model capable of both image\nunderstanding and generation to reason over visual content and model evolving\nvisual states. However, empowering a unified model to achieve that is\nnon-trivial, given the high computational cost and the burden of training. To\naddress this, Uni-CoT introduces a novel two-level reasoning paradigm: A\nMacro-Level CoT for high-level task planning and A Micro-Level CoT for subtask\nexecution. This design significantly reduces the computational overhead.\nFurthermore, we introduce a structured training paradigm that combines\ninterleaved image-text supervision for macro-level CoT with multi-task\nobjectives for micro-level CoT. Together, these innovations allow Uni-CoT to\nperform scalable and coherent multi-modal reasoning. Furthermore, thanks to our\ndesign, all experiments can be efficiently completed using only 8 A100 GPUs\nwith 80GB VRAM each. Experimental results on reasoning-driven image generation\nbenchmark (WISE) and editing benchmarks (RISE and KRIS) indicates that Uni-CoT\ndemonstrates SOTA performance and strong generalization, establishing Uni-CoT\nas a promising solution for multi-modal reasoning. Project Page and Code:\nhttps://sais-fuxi.github.io/projects/uni-cot/\n","authors":["Luozheng Qin","Jia Gong","Yuqing Sun","Tianjiao Li","Mengping Yang","Xiaomeng Yang","Chao Qu","Zhiyu Tan","Hao Li"],"pdf_url":"https://arxiv.org/pdf/2508.05606v1.pdf","comment":"https://sais-fuxi.github.io/projects/uni-cot/"},{"id":"http://arxiv.org/abs/2508.03865v2","updated":"2025-08-07T17:36:04Z","published":"2025-08-05T19:28:43Z","title":"An Entity Linking Agent for Question Answering","summary":"  Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide\naccurate answers. Entity Linking (EL) plays a critical role in linking natural\nlanguage mentions to KB entries. However, most existing EL methods are designed\nfor long contexts and do not perform well on short, ambiguous user questions in\nQA tasks. We propose an entity linking agent for QA, based on a Large Language\nModel that simulates human cognitive workflows. The agent actively identifies\nentity mentions, retrieves candidate entities, and makes decision. To verify\nthe effectiveness of our agent, we conduct two experiments: tool-based entity\nlinking and QA task evaluation. The results confirm the robustness and\neffectiveness of our agent.\n","authors":["Yajie Luo","Yihong Wu","Muzhi Li","Fengran Mo","Jia Ao Sun","Xinyu Wang","Liheng Ma","Yingxue Zhang","Jian-Yun Nie"],"pdf_url":"https://arxiv.org/pdf/2508.03865v2.pdf","comment":"12 pages, 2 figures"},{"id":"http://arxiv.org/abs/2508.05592v1","updated":"2025-08-07T17:32:14Z","published":"2025-08-07T17:32:14Z","title":"MathSmith: Towards Extremely Hard Mathematical Reasoning by Forging\n  Synthetic Problems with a Reinforced Policy","summary":"  Large language models have achieved substantial progress in mathematical\nreasoning, yet their advancement is limited by the scarcity of high-quality,\nhigh-difficulty training data. Existing synthesis methods largely rely on\ntransforming human-written templates, limiting both diversity and scalability.\nWe propose MathSmith, a novel framework for synthesizing challenging\nmathematical problems to enhance LLM reasoning. Rather than modifying existing\nproblems, MathSmith constructs new ones from scratch by randomly sampling\nconcept-explanation pairs from PlanetMath, ensuring data independence and\navoiding contamination. To increase difficulty, we design nine predefined\nstrategies as soft constraints during rationales. We further adopts\nreinforcement learning to jointly optimize structural validity, reasoning\ncomplexity, and answer consistency. The length of the reasoning trace generated\nunder autoregressive prompting is used to reflect cognitive complexity,\nencouraging the creation of more demanding problems aligned with\nlong-chain-of-thought reasoning. Experiments across five benchmarks,\ncategorized as easy & medium (GSM8K, MATH-500) and hard (AIME2024, AIME2025,\nOlympiadBench), show that MathSmith consistently outperforms existing baselines\nunder both short and long CoT settings. Additionally, a weakness-focused\nvariant generation module enables targeted improvement on specific concepts.\nOverall, MathSmith exhibits strong scalability, generalization, and\ntransferability, highlighting the promise of high-difficulty synthetic data in\nadvancing LLM reasoning capabilities.\n","authors":["Shaoxiong Zhan","Yanlin Lai","Ziyu Lu","Dahua Lin","Ziqing Yang","Fei Tang"],"pdf_url":"https://arxiv.org/pdf/2508.05592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05581v1","updated":"2025-08-07T17:15:17Z","published":"2025-08-07T17:15:17Z","title":"Iterative Learning of Computable Phenotypes for Treatment Resistant\n  Hypertension using Large Language Models","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities for\nmedical question answering and programming, but their potential for generating\ninterpretable computable phenotypes (CPs) is under-explored. In this work, we\ninvestigate whether LLMs can generate accurate and concise CPs for six clinical\nphenotypes of varying complexity, which could be leveraged to enable scalable\nclinical decision support to improve care for patients with hypertension. In\naddition to evaluating zero-short performance, we propose and test a\nsynthesize, execute, debug, instruct strategy that uses LLMs to generate and\niteratively refine CPs using data-driven feedback. Our results show that LLMs,\ncoupled with iterative learning, can generate interpretable and reasonably\naccurate programs that approach the performance of state-of-the-art ML methods\nwhile requiring significantly fewer training examples.\n","authors":["Guilherme Seidyo Imai Aldeia","Daniel S. Herman","William G. La Cava"],"pdf_url":"https://arxiv.org/pdf/2508.05581v1.pdf","comment":"To appear in PMLR, Volume 298, Machine Learning for Healthcare, 2025"},{"id":"http://arxiv.org/abs/2508.05571v1","updated":"2025-08-07T17:02:23Z","published":"2025-08-07T17:02:23Z","title":"Fairy$\\pm i$: the First 2-bit Complex LLM with All Parameters in\n  $\\{\\pm1, \\pm i\\}$","summary":"  Quantization-Aware Training (QAT) integrates quantization into the training\nloop, enabling LLMs to learn robust low-bit representations, and is widely\nrecognized as one of the most promising research directions. All current QAT\nresearch focuses on minimizing quantization error on full-precision models,\nwhere the full-precision accuracy acts as an upper bound (accuracy ceiling). No\nexisting method has even attempted to surpass this ceiling. To break this\nceiling, we propose a new paradigm: raising the ceiling (full-precision model),\nand then still quantizing it efficiently into 2 bits. We propose Fairy$\\pm i$,\nthe first 2-bit quantization framework for complex-valued LLMs. Specifically,\nour method leverages the representational advantages of the complex domain to\nboost full-precision accuracy. We map weights to the fourth roots of unity\n$\\{\\pm1, \\pm i\\}$, forming a perfectly symmetric and information-theoretically\noptimal 2-bit representation. Importantly, each quantized weight has either a\nzero real or imaginary part, enabling multiplication-free inference using only\nadditions and element swaps. Experimental results show that Fairy$\\pm i$\noutperforms the ceiling of existing 2-bit quantization approaches in terms of\nboth PPL and downstream tasks, while maintaining strict storage and compute\nefficiency. This work opens a new direction for building highly accurate and\npractical LLMs under extremely low-bit constraints.\n","authors":["Feiyu Wang","Guoan Wang","Yihao Zhang","Shengfan Wang","Weitao Li","Bokai Huang","Shimao Chen","Zihan Jiang","Rui Xu","Tong Yang"],"pdf_url":"https://arxiv.org/pdf/2508.05571v1.pdf","comment":"13 pages, 14 figures"},{"id":"http://arxiv.org/abs/2508.05554v1","updated":"2025-08-07T16:35:29Z","published":"2025-08-07T16:35:29Z","title":"SPGISpeech 2.0: Transcribed multi-speaker financial audio for\n  speaker-tagged transcription","summary":"  We introduce SPGISpeech 2.0, a dataset suitable for speaker-tagged\ntranscription in the financial domain. SPGISpeech 2.0 improves the diversity of\napplicable modeling tasks while maintaining the core characteristic of the\noriginal SPGISpeech dataset: audio snippets and their corresponding fully\nformatted text transcriptions, usable for end-to-end automatic speech\nrecognition (ASR). SPGISpeech 2.0 consists of 3,780 additional hours of\nprofessionally transcribed earnings calls. Furthermore, the dataset contains\ncall and speaker information for each audio snippet facilitating multi-talker\nASR. We validate the utility of SPGISpeech 2.0 through improvements in\nspeaker-tagged ASR performance of popular speech recognition models after\nfine-tuning on SPGISpeech 2.0. Released free for non-commercial use, we expect\nSPGISpeech 2.0 to foster advancements in speech recognition technologies and\ninspire a wide range of research applications.\n","authors":["Raymond Grossman","Taejin Park","Kunal Dhawan","Andrew Titus","Sophia Zhi","Yulia Shchadilova","Weiqing Wang","Jagadeesh Balam","Boris Ginsburg"],"pdf_url":"https://arxiv.org/pdf/2508.05554v1.pdf","comment":"To be presented at Interspeech 2025"},{"id":"http://arxiv.org/abs/2508.05553v1","updated":"2025-08-07T16:33:45Z","published":"2025-08-07T16:33:45Z","title":"Do Political Opinions Transfer Between Western Languages? An Analysis of\n  Unaligned and Aligned Multilingual LLMs","summary":"  Public opinion surveys show cross-cultural differences in political opinions\nbetween socio-cultural contexts. However, there is no clear evidence whether\nthese differences translate to cross-lingual differences in multilingual large\nlanguage models (MLLMs). We analyze whether opinions transfer between languages\nor whether there are separate opinions for each language in MLLMs of various\nsizes across five Western languages. We evaluate MLLMs' opinions by prompting\nthem to report their (dis)agreement with political statements from voting\nadvice applications. To better understand the interaction between languages in\nthe models, we evaluate them both before and after aligning them with more left\nor right views using direct preference optimization and English alignment data\nonly. Our findings reveal that unaligned models show only very few significant\ncross-lingual differences in the political opinions they reflect. The political\nalignment shifts opinions almost uniformly across all five languages. We\nconclude that in Western language contexts, political opinions transfer between\nlanguages, demonstrating the challenges in achieving explicit socio-linguistic,\ncultural, and political alignment of MLLMs.\n","authors":["Franziska Weeber","Tanise Ceron","Sebastian Padó"],"pdf_url":"https://arxiv.org/pdf/2508.05553v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.00255v2","updated":"2025-08-07T16:31:54Z","published":"2025-03-31T22:02:24Z","title":"SciReplicate-Bench: Benchmarking LLMs in Agent-driven Algorithmic\n  Reproduction from Research Papers","summary":"  This study evaluates large language models (LLMs) in generating code from\nalgorithm descriptions in recent NLP papers. The task requires two key\ncompetencies: (1) algorithm comprehension: synthesizing information from papers\nand academic literature to understand implementation logic, and (2) coding\nexpertise: identifying dependencies and correctly implementing necessary APIs.\nTo facilitate rigorous evaluation, we introduce SciReplicate-Bench, a benchmark\nof 100 tasks from 36 NLP papers published in 2024, featuring detailed\nannotations and comprehensive test cases. Building on SciReplicate-Bench, we\npropose Sci-Reproducer, a dual-agent framework consisting of a Paper Agent that\ninterprets algorithmic concepts from literature and a Code Agent that retrieves\ndependencies from repositories and implements solutions. To assess algorithm\nunderstanding, we introduce reasoning graph accuracy, which quantifies\nsimilarity between generated and reference reasoning graphs derived from code\ncomments and structure. For evaluating implementation quality, we employ\nexecution accuracy, CodeBLEU, and repository dependency/API recall metrics. In\nour experiments, we evaluate various powerful non-reasoning and reasoning LLMs\nas foundational models. The best-performing LLM using \\ModelName~achieves only\n39% execution accuracy, highlighting the benchmark's difficulty. Our analysis\nidentifies missing or inconsistent algorithm descriptions as key barriers to\nsuccessful reproduction. We make available our benchmark and code at\nhttps://github.com/xyzCS/SciReplicate-Bench and project homepage at\nhttps://xyzcs.github.io/scireplicate.github.io/.\n","authors":["Yanzheng Xiang","Hanqi Yan","Shuyin Ouyang","Lin Gui","Yulan He"],"pdf_url":"https://arxiv.org/pdf/2504.00255v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2506.12496v2","updated":"2025-08-07T16:23:33Z","published":"2025-06-14T13:17:27Z","title":"Improving Factuality for Dialogue Response Generation via Graph-Based\n  Knowledge Augmentation","summary":"  Large Language Models (LLMs) succeed in many natural language processing\ntasks. However, their tendency to hallucinate - generate plausible but\ninconsistent or factually incorrect text - can cause significant problems in\ncertain tasks, including response generation in dialogue. To mitigate this\nissue, we propose two novel graph knowledge-augmented frameworks, Dialogue\nResponse Generation via Textualised Graphs (TG-DRG) and Graph-Aware Dialogue\nResponse Generation (GA-DRG), which combine reasoning-guided dialogue\nreformulation, dialogue sense knowledge selection, and graph-enhanced response\ngeneration to improve the factuality of dialogue responses. To evaluate the\nfactuality of generated responses, we propose a dialogue fact score that\naddresses the limitations of existing fact-score methods in dialogue settings,\nproviding a more reliable assessment of factual consistency. We evaluate our\nmethods using different baselines on the OpendialKG and HybriDialogue datasets.\nOur methods noticeably improve factuality compared to other graph\nknowledge-augmentation baselines, including the state-of-the-art G-retriever,\nachieving improvements of 3.47% on OpendialKG and 3.12% on HybriDialogue in\nterms of dialogue fact score. The code will be released on GitHub.\n","authors":["Xiangyan Chen","Yujian Gan","Yimeng Gu","Matthew Purver"],"pdf_url":"https://arxiv.org/pdf/2506.12496v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05544v1","updated":"2025-08-07T16:22:49Z","published":"2025-08-07T16:22:49Z","title":"Conformal Sets in Multiple-Choice Question Answering under Black-Box\n  Settings with Provable Coverage Guarantees","summary":"  Large Language Models (LLMs) have shown remarkable progress in\nmultiple-choice question answering (MCQA), but their inherent unreliability,\nsuch as hallucination and overconfidence, limits their application in high-risk\ndomains. To address this, we propose a frequency-based uncertainty\nquantification method under black-box settings, leveraging conformal prediction\n(CP) to ensure provable coverage guarantees. Our approach involves multiple\nindependent samplings of the model's output distribution for each input, with\nthe most frequent sample serving as a reference to calculate predictive entropy\n(PE). Experimental evaluations across six LLMs and four datasets (MedMCQA,\nMedQA, MMLU, MMLU-Pro) demonstrate that frequency-based PE outperforms\nlogit-based PE in distinguishing between correct and incorrect predictions, as\nmeasured by AUROC. Furthermore, the method effectively controls the empirical\nmiscoverage rate under user-specified risk levels, validating that sampling\nfrequency can serve as a viable substitute for logit-based probabilities in\nblack-box scenarios. This work provides a distribution-free model-agnostic\nframework for reliable uncertainty quantification in MCQA with guaranteed\ncoverage, enhancing the trustworthiness of LLMs in practical applications.\n","authors":["Guang Yang","Xinyang Liu"],"pdf_url":"https://arxiv.org/pdf/2508.05544v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2508.05535v1","updated":"2025-08-07T16:09:12Z","published":"2025-08-07T16:09:12Z","title":"Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation","summary":"  Effective robotic systems for long-horizon human-robot collaboration must\nadapt to a wide range of human partners, whose physical behavior, willingness\nto assist, and understanding of the robot's capabilities may change over time.\nThis demands a tightly coupled communication loop that grants both agents the\nflexibility to propose, accept, or decline requests as they coordinate toward\ncompleting the task effectively. We apply a Mixed-Initiative dialog paradigm to\nCollaborative human-roBot teaming and propose MICoBot, a system that handles\nthe common scenario where both agents, using natural language, take initiative\nin formulating, accepting, or rejecting proposals on who can best complete\ndifferent steps of a task. To handle diverse, task-directed dialog, and find\nsuccessful collaborative strategies that minimize human effort, MICoBot makes\ndecisions at three levels: (1) a meta-planner considers human dialog to\nformulate and code a high-level collaboration strategy, (2) a planner optimally\nallocates the remaining steps to either agent based on the robot's capabilities\n(measured by a simulation-pretrained affordance model) and the human's\nestimated availability to help, and (3) an action executor decides the\nlow-level actions to perform or words to say to the human. Our extensive\nevaluations in simulation and real-world -- on a physical robot with 18 unique\nhuman participants over 27 hours -- demonstrate the ability of our method to\neffectively collaborate with diverse human users, yielding significantly\nimproved task success and user experience than a pure LLM baseline and other\nagent allocation models. See additional videos and materials at\nhttps://robin-lab.cs.utexas.edu/MicoBot/.\n","authors":["Albert Yu","Chengshu Li","Luca Macesanu","Arnav Balaji","Ruchira Ray","Raymond Mooney","Roberto Martín-Martín"],"pdf_url":"https://arxiv.org/pdf/2508.05535v1.pdf","comment":"Project website at https://robin-lab.cs.utexas.edu/MicoBot/"},{"id":"http://arxiv.org/abs/2508.05534v1","updated":"2025-08-07T16:06:58Z","published":"2025-08-07T16:06:58Z","title":"CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text\n  Generation","summary":"  Due to their ability to process long and complex contexts, LLMs can offer key\nbenefits to the Legal domain, but their adoption has been hindered by their\ntendency to generate unfaithful, ungrounded, or hallucinatory outputs. While\nRetrieval-Augmented Generation offers a promising solution by grounding\ngenerations in external knowledge, it offers no guarantee that the provided\ncontext will be effectively integrated. To address this, context-aware decoding\nstrategies have been proposed to amplify the influence of relevant context, but\nthey usually do not explicitly enforce faithfulness to the context. In this\nwork, we introduce Confidence-guided Copy-based Decoding for Legal Text\nGeneration (CoCoLex)-a decoding strategy that dynamically interpolates the\nmodel produced vocabulary distribution with a distribution derived based on\ncopying from the context. CoCoLex encourages direct copying based on the\nmodel's confidence, ensuring greater fidelity to the source. Experimental\nresults on five legal benchmarks demonstrate that CoCoLex outperforms existing\ncontext-aware decoding methods, particularly in long-form generation tasks.\n","authors":["Santosh T. Y. S. S","Youssef Tarek Elkhayat","Oana Ichim","Pranav Shetty","Dongsheng Wang","Zhiqiang Ma","Armineh Nourbakhsh","Xiaomo Liu"],"pdf_url":"https://arxiv.org/pdf/2508.05534v1.pdf","comment":"Accepted to ACL 2025-Main Conference"},{"id":"http://arxiv.org/abs/2503.09032v2","updated":"2025-08-07T16:01:43Z","published":"2025-03-12T03:45:53Z","title":"Teaching LLMs How to Learn with Contextual Fine-Tuning","summary":"  Prompting Large Language Models (LLMs), or providing context on the expected\nmodel of operation, is an effective way to steer the outputs of such models to\nsatisfy human desiderata after they have been trained. But in rapidly evolving\ndomains, there is often need to fine-tune LLMs to improve either the kind of\nknowledge in their memory or their abilities to perform open ended reasoning in\nnew domains. When human's learn new concepts, we often do so by linking the new\nmaterial that we are studying to concepts we have already learned before. To\nthat end, we ask, \"can prompting help us teach LLMs how to learn\". In this\nwork, we study a novel generalization of instruction tuning, called contextual\nfine-tuning, to fine-tune LLMs. Our method leverages instructional prompts\ndesigned to mimic human cognitive strategies in learning and problem-solving to\nguide the learning process during training, aiming to improve the model's\ninterpretation and understanding of domain-specific knowledge. We empirically\ndemonstrate that this simple yet effective modification improves the ability of\nLLMs to be fine-tuned rapidly on new datasets both within the medical and\nfinancial domains.\n","authors":["Younwoo Choi","Muhammad Adil Asif","Ziwen Han","John Willes","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2503.09032v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2508.05525v1","updated":"2025-08-07T15:53:30Z","published":"2025-08-07T15:53:30Z","title":"The World According to LLMs: How Geographic Origin Influences LLMs'\n  Entity Deduction Capabilities","summary":"  Large Language Models (LLMs) have been extensively tuned to mitigate explicit\nbiases, yet they often exhibit subtle implicit biases rooted in their\npre-training data. Rather than directly probing LLMs with human-crafted\nquestions that may trigger guardrails, we propose studying how models behave\nwhen they proactively ask questions themselves. The 20 Questions game, a\nmulti-turn deduction task, serves as an ideal testbed for this purpose. We\nsystematically evaluate geographic performance disparities in entity deduction\nusing a new dataset, Geo20Q+, consisting of both notable people and culturally\nsignificant objects (e.g., foods, landmarks, animals) from diverse regions. We\ntest popular LLMs across two gameplay configurations (canonical 20-question and\nunlimited turns) and in seven languages (English, Hindi, Mandarin, Japanese,\nFrench, Spanish, and Turkish). Our results reveal geographic disparities: LLMs\nare substantially more successful at deducing entities from the Global North\nthan the Global South, and the Global West than the Global East. While\nWikipedia pageviews and pre-training corpus frequency correlate mildly with\nperformance, they fail to fully explain these disparities. Notably, the\nlanguage in which the game is played has minimal impact on performance gaps.\nThese findings demonstrate the value of creative, free-form evaluation\nframeworks for uncovering subtle biases in LLMs that remain hidden in standard\nprompting setups. By analyzing how models initiate and pursue reasoning goals\nover multiple turns, we find geographic and cultural disparities embedded in\ntheir reasoning processes. We release the dataset (Geo20Q+) and code at\nhttps://sites.google.com/view/llmbias20q/home.\n","authors":["Harsh Nishant Lalai","Raj Sanjay Shah","Jiaxin Pei","Sashank Varma","Yi-Chia Wang","Ali Emami"],"pdf_url":"https://arxiv.org/pdf/2508.05525v1.pdf","comment":"Conference on Language Modeling 2025"},{"id":"http://arxiv.org/abs/2508.05509v1","updated":"2025-08-07T15:42:00Z","published":"2025-08-07T15:42:00Z","title":"LAG: Logic-Augmented Generation from a Cartesian Perspective","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of tasks, yet exhibit critical limitations in knowledge-intensive\ntasks, often generating hallucinations when faced with questions requiring\nspecialized expertise. While retrieval-augmented generation (RAG) mitigates\nthis by integrating external knowledge, it struggles with complex reasoning\nscenarios due to its reliance on direct semantic retrieval and lack of\nstructured logical organization. Inspired by Cartesian principles from\n\\textit{Discours de la m\\'ethode}, this paper introduces Logic-Augmented\nGeneration (LAG), a novel paradigm that reframes knowledge augmentation through\nsystematic question decomposition and dependency-aware reasoning. Specifically,\nLAG first decomposes complex questions into atomic sub-questions ordered by\nlogical dependencies. It then resolves these sequentially, using prior answers\nto guide context retrieval for subsequent sub-questions, ensuring stepwise\ngrounding in logical chain. To prevent error propagation, LAG incorporates a\nlogical termination mechanism that halts inference upon encountering\nunanswerable sub-questions and reduces wasted computation on excessive\nreasoning. Finally, it synthesizes all sub-resolutions to generate verified\nresponses. Experiments on four benchmark datasets demonstrate that LAG\nsignificantly enhances reasoning robustness, reduces hallucination, and aligns\nLLM problem-solving with human cognition, offering a principled alternative to\nexisting RAG systems.\n","authors":["Yilin Xiao","Chuang Zhou","Qinggang Zhang","Su Dong","Shengyuan Chen","Xiao Huang"],"pdf_url":"https://arxiv.org/pdf/2508.05509v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04094v2","updated":"2025-08-07T15:40:48Z","published":"2024-10-05T09:27:52Z","title":"BloomWise: Enhancing Problem-Solving capabilities of Large Language\n  Models using Bloom's-Taxonomy-Inspired Prompts","summary":"  Despite the remarkable capabilities of large language models (LLMs) across a\nrange of tasks, mathematical reasoning remains a challenging frontier.\nMotivated by the observation that humans learn more effectively when prompted\nnot what to think but how to think, we introduce BloomWise, a\ncognitively-inspired prompting technique designed to enhance LLMs' performance\non mathematical problem solving while making their solutions more explainable.\nBloomWise encourages LLMs to generate solutions - in the form of explanations -\nby progressing through a sequence of cognitive operations-from basic (e.g.,\nremembering) to more advanced reasoning skills (e.g., evaluating) - mirroring\nhow humans build understanding. The process iterates through these levels,\nhalting early if a convergence criterion is met: specifically, if two or more\nconsecutive levels yield the same answer, the solution from the earliest such\nlevel is output; otherwise, the process continues until all levels are\ncompleted. Through extensive experiments across five popular math reasoning\ndatasets, we demonstrate the effectiveness of BloomWise. We also present\ncomprehensive ablation studies to analyze the strengths of each component\nwithin our system.\n","authors":["Maria-Eleni Zoumpoulidi","Georgios Paraskevopoulos","Alexandros Potamianos"],"pdf_url":"https://arxiv.org/pdf/2410.04094v2.pdf","comment":"16 pages, 2 figures"},{"id":"http://arxiv.org/abs/2502.16435v2","updated":"2025-08-07T15:39:27Z","published":"2025-02-23T04:21:32Z","title":"Human Cognitive Benchmarks Reveal Foundational Visual Gaps in MLLMs","summary":"  Despite significant progress on popular multimodal benchmarks,\nstate-of-the-art Multimodal Large Language Models (MLLMs) continue to struggle\nwith basic visual reasoning tasks that are trivially solved by humans, such as\nrecognizing spatial relationships. To systematically investigate this gap, we\nintroduce VisFactor, a benchmark that digitizes 20 vision-centric subtests from\na well-established cognitive psychology assessment. These subtests span four\ncore domains of human visual cognition: (1) Visualization and Spatial\nProcessing, (2) Perceptual and Closure, (3) Memory, and (4) Reasoning. We\nevaluate 20 frontier MLLMs from GPT, Gemini, Claude, LLaMA, Qwen, and SEED\nfamilies. The best-performing model achieves a score of only 25.19 out of 100,\nwith consistent failures on tasks such as mental rotation, spatial relation\ninference, and figure-ground discrimination, regardless of model size or\nprompting strategy. These findings suggest that current MLLM performance gains\non high-level benchmarks do not reflect human-like low-level visual cognition,\nchallenging the assumption that large-scale pretraining naturally induces\ngestalt-like perceptual capabilities. The dataset and evaluation toolkit are\npublicly available at: https://github.com/CUHK-ARISE/VisFactor.\n","authors":["Jen-Tse Huang","Dasen Dai","Jen-Yuan Huang","Youliang Yuan","Xiaoyuan Liu","Wenxuan Wang","Wenxiang Jiao","Pinjia He","Zhaopeng Tu","Haodong Duan"],"pdf_url":"https://arxiv.org/pdf/2502.16435v2.pdf","comment":"Update: Evaluated 20 MLLMs; Added generated test cases"},{"id":"http://arxiv.org/abs/2508.05502v1","updated":"2025-08-07T15:36:24Z","published":"2025-08-07T15:36:24Z","title":"MELLA: Bridging Linguistic Capability and Cultural Groundedness for\n  Low-Resource Language MLLMs","summary":"  Multimodal Large Language Models (MLLMs) have shown remarkable performance in\nhigh-resource languages. However, their effectiveness diminishes significantly\nin the contexts of low-resource languages. Current multilingual enhancement\nmethods are often limited to text modality or rely solely on machine\ntranslation. While such approaches help models acquire basic linguistic\ncapabilities and produce \"thin descriptions\", they neglect the importance of\nmultimodal informativeness and cultural groundedness, both of which are crucial\nfor serving low-resource language users effectively. To bridge this gap, in\nthis study, we identify two significant objectives for a truly effective MLLM\nin low-resource language settings, namely 1) linguistic capability and 2)\ncultural groundedness, placing special emphasis on cultural awareness. To\nachieve these dual objectives, we propose a dual-source strategy that guides\nthe collection of data tailored to each goal, sourcing native web alt-text for\nculture and MLLM-generated captions for linguistics. As a concrete\nimplementation, we introduce MELLA, a multimodal, multilingual dataset.\nExperiment results show that after fine-tuning on MELLA, there is a general\nperformance improvement for the eight languages on various MLLM backbones, with\nmodels producing \"thick descriptions\". We verify that the performance gains are\nfrom both cultural knowledge enhancement and linguistic capability enhancement.\nOur dataset can be found at https://opendatalab.com/applyMultilingualCorpus.\n","authors":["Yufei Gao","Jiaying Fei","Nuo Chen","Ruirui Chen","Guohang Yan","Yunshi Lan","Botian Shi"],"pdf_url":"https://arxiv.org/pdf/2508.05502v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05474v1","updated":"2025-08-07T15:13:55Z","published":"2025-08-07T15:13:55Z","title":"Can Large Language Models Generate Effective Datasets for Emotion\n  Recognition in Conversations?","summary":"  Emotion recognition in conversations (ERC) focuses on identifying emotion\nshifts within interactions, representing a significant step toward advancing\nmachine intelligence. However, ERC data remains scarce, and existing datasets\nface numerous challenges due to their highly biased sources and the inherent\nsubjectivity of soft labels. Even though Large Language Models (LLMs) have\ndemonstrated their quality in many affective tasks, they are typically\nexpensive to train, and their application to ERC tasks--particularly in data\ngeneration--remains limited. To address these challenges, we employ a small,\nresource-efficient, and general-purpose LLM to synthesize ERC datasets with\ndiverse properties, supplementing the three most widely used ERC benchmarks. We\ngenerate six novel datasets, with two tailored to enhance each benchmark. We\nevaluate the utility of these datasets to (1) supplement existing datasets for\nERC classification, and (2) analyze the effects of label imbalance in ERC. Our\nexperimental results indicate that ERC classifier models trained on the\ngenerated datasets exhibit strong robustness and consistently achieve\nstatistically significant performance improvements on existing ERC benchmarks.\n","authors":["Burak Can Kaplan","Hugo Cesar De Castro Carneiro","Stefan Wermter"],"pdf_url":"https://arxiv.org/pdf/2508.05474v1.pdf","comment":"8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.05470v1","updated":"2025-08-07T15:11:48Z","published":"2025-08-07T15:11:48Z","title":"Rethinking Creativity Evaluation: A Critical Analysis of Existing\n  Creativity Evaluations","summary":"  We systematically examine, analyze, and compare representative creativity\nmeasures--creativity index, perplexity, syntactic templates, and\nLLM-as-a-Judge--across diverse creative domains, including creative writing,\nunconventional problem-solving, and research ideation. Our analyses reveal that\nthese metrics exhibit limited consistency, capturing different dimensions of\ncreativity. We highlight key limitations, including the creativity index's\nfocus on lexical diversity, perplexity's sensitivity to model confidence, and\nsyntactic templates' inability to capture conceptual creativity. Additionally,\nLLM-as-a-Judge shows instability and bias. Our findings underscore the need for\nmore robust, generalizable evaluation frameworks that better align with human\njudgments of creativity.\n","authors":["Li-Chun Lu","Miri Liu","Pin-Chun Lu","Yufei Tian","Shao-Hua Sun","Nanyun Peng"],"pdf_url":"https://arxiv.org/pdf/2508.05470v1.pdf","comment":"15 pages, 6 figures"},{"id":"http://arxiv.org/abs/2508.05468v1","updated":"2025-08-07T15:11:17Z","published":"2025-08-07T15:11:17Z","title":"TASE: Token Awareness and Structured Evaluation for Multilingual\n  Language Models","summary":"  While large language models (LLMs) have demonstrated remarkable performance\non high-level semantic tasks, they often struggle with fine-grained,\ntoken-level understanding and structural reasoning--capabilities that are\nessential for applications requiring precision and control. We introduce TASE,\na comprehensive benchmark designed to evaluate LLMs' ability to perceive and\nreason about token-level information across languages. TASE covers 10 tasks\nunder two core categories: token awareness and structural understanding,\nspanning Chinese, English, and Korean, with a 35,927-instance evaluation set\nand a scalable synthetic data generation pipeline for training. Tasks include\ncharacter counting, token alignment, syntactic structure parsing, and length\nconstraint satisfaction. We evaluate over 30 leading commercial and open-source\nLLMs, including O3, Claude 4, Gemini 2.5 Pro, and DeepSeek-R1, and train a\ncustom Qwen2.5-14B model using the GRPO training method. Results show that\nhuman performance significantly outpaces current LLMs, revealing persistent\nweaknesses in token-level reasoning. TASE sheds light on these limitations and\nprovides a new diagnostic lens for future improvements in low-level language\nunderstanding and cross-lingual generalization. Our code and dataset are\npublicly available at https://github.com/cyzcz/Tase .\n","authors":["Chenzhuo Zhao","Xinda Wang","Yue Huang","Junting Lu","Ziqian Liu"],"pdf_url":"https://arxiv.org/pdf/2508.05468v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05464v1","updated":"2025-08-07T15:03:39Z","published":"2025-08-07T15:03:39Z","title":"Bench-2-CoP: Can We Trust Benchmarking for EU AI Compliance?","summary":"  The rapid advancement of General Purpose AI (GPAI) models necessitates robust\nevaluation frameworks, especially with emerging regulations like the EU AI Act\nand its associated Code of Practice (CoP). Current AI evaluation practices\ndepend heavily on established benchmarks, but these tools were not designed to\nmeasure the systemic risks that are the focus of the new regulatory landscape.\nThis research addresses the urgent need to quantify this \"benchmark-regulation\ngap.\" We introduce Bench-2-CoP, a novel, systematic framework that uses\nvalidated LLM-as-judge analysis to map the coverage of 194,955 questions from\nwidely-used benchmarks against the EU AI Act's taxonomy of model capabilities\nand propensities. Our findings reveal a profound misalignment: the evaluation\necosystem is overwhelmingly focused on a narrow set of behavioral propensities,\nsuch as \"Tendency to hallucinate\" (53.7% of the corpus) and \"Discriminatory\nbias\" (28.9%), while critical functional capabilities are dangerously\nneglected. Crucially, capabilities central to loss-of-control scenarios,\nincluding evading human oversight, self-replication, and autonomous AI\ndevelopment, receive zero coverage in the entire benchmark corpus. This\ntranslates to a near-total evaluation gap for systemic risks like \"Loss of\nControl\" (0.4% coverage) and \"Cyber Offence\" (0.8% coverage). This study\nprovides the first comprehensive, quantitative analysis of this gap, offering\ncritical insights for policymakers to refine the CoP and for developers to\nbuild the next generation of evaluation tools, ultimately fostering safer and\nmore compliant AI.\n","authors":["Matteo Prandi","Vincenzo Suriani","Federico Pierucci","Marcello Galisai","Daniele Nardi","Piercosma Bisconti"],"pdf_url":"https://arxiv.org/pdf/2508.05464v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2503.19168v2","updated":"2025-08-07T14:58:09Z","published":"2025-03-24T21:43:47Z","title":"Language Model Uncertainty Quantification with Attention Chain","summary":"  Accurately quantifying a large language model's (LLM) predictive uncertainty\nis crucial for judging the reliability of its answers. While most existing\nresearch focuses on short, directly answerable questions with closed-form\noutputs (e.g., multiple-choice), involving intermediate reasoning steps in LLM\nresponses is increasingly important. This added complexity complicates\nuncertainty quantification (UQ) because the probabilities assigned to answer\ntokens are conditioned on a vast space of preceding reasoning tokens. Direct\nmarginalization is infeasible, and the dependency inflates probability\nestimates, causing overconfidence in UQ. To address this, we propose UQAC, an\nefficient method that narrows the reasoning space to a tractable size for\nmarginalization. UQAC iteratively constructs an \"attention chain\" of tokens\ndeemed \"semantically crucial\" to the final answer via a backtracking procedure.\nStarting from the answer tokens, it uses attention weights to identify the most\ninfluential predecessors, then iterates this process until reaching the input\ntokens. The resulting chain is further refined with similarity filtering and\nprobability thresholding, which reduce the reasoning space, facilitating the\napproximation of the marginal answer token probabilities. We validate UQAC on\nmultiple reasoning benchmarks with advanced open-source LLMs, demonstrating\nthat it consistently delivers reliable UQ estimates with high computational\nefficiency.\n","authors":["Yinghao Li","Rushi Qiang","Lama Moukheiber","Chao Zhang"],"pdf_url":"https://arxiv.org/pdf/2503.19168v2.pdf","comment":"36 pages, 7 figures, 36 tables"},{"id":"http://arxiv.org/abs/2506.11105v3","updated":"2025-08-07T14:57:45Z","published":"2025-06-07T01:37:42Z","title":"Enabling On-Device Medical AI Assistants via Input-Driven Saliency\n  Adaptation","summary":"  Large Language Models (LLMs) have significant impact on the healthcare\nscenarios but remain prohibitively large for deployment in real-time,\nresource-constrained environments such as edge devices. In this work, we\nintroduce a novel medical assistant system, optimized through our\ngeneral-purpose compression framework, which tailors Large Language Models\n(LLMs) for deployment in specialized domains. By measuring neuron saliency on\ndomain-specific data, our method can aggressively prune irrelevant neurons,\nreducing model size while preserving performance. Following pruning, we apply\npost-training quantization to further reduce the memory footprint, and evaluate\nthe compressed model across medical benchmarks including MedMCQA, MedQA, and\nPubMedQA. We also deploy the 50\\% compressed Gemma and the 67\\% compressed\nLLaMA3 models on Jetson Orin Nano (18.7W peak) and Raspberry Pi 5 (6.3W peak),\nachieving real-time, energy-efficient inference under hardware constraints.\n","authors":["Uttej Kallakurik","Edward Humes","Rithvik Jonna","Xiaomin Lin","Tinoosh Mohsenin"],"pdf_url":"https://arxiv.org/pdf/2506.11105v3.pdf","comment":"Accepted for publication in the Proceedings of IEEE BioCAS 2025"},{"id":"http://arxiv.org/abs/2405.00708v2","updated":"2025-08-07T14:48:25Z","published":"2024-04-23T19:57:03Z","title":"Understanding Large Language Model Behaviors through Interactive\n  Counterfactual Generation and Analysis","summary":"  Understanding the behavior of large language models (LLMs) is crucial for\nensuring their safe and reliable use. However, existing explainable AI (XAI)\nmethods for LLMs primarily rely on word-level explanations, which are often\ncomputationally inefficient and misaligned with human reasoning processes.\nMoreover, these methods often treat explanation as a one-time output,\noverlooking its inherently interactive and iterative nature. In this paper, we\npresent LLM Analyzer, an interactive visualization system that addresses these\nlimitations by enabling intuitive and efficient exploration of LLM behaviors\nthrough counterfactual analysis. Our system features a novel algorithm that\ngenerates fluent and semantically meaningful counterfactuals via targeted\nremoval and replacement operations at user-defined levels of granularity. These\ncounterfactuals are used to compute feature attribution scores, which are then\nintegrated with concrete examples in a table-based visualization, supporting\ndynamic analysis of model behavior. A user study with LLM practitioners and\ninterviews with experts demonstrate the system's usability and effectiveness,\nemphasizing the importance of involving humans in the explanation process as\nactive participants rather than passive recipients.\n","authors":["Furui Cheng","Vilém Zouhar","Robin Shing Moon Chan","Daniel Fürst","Hendrik Strobelt","Mennatallah El-Assady"],"pdf_url":"https://arxiv.org/pdf/2405.00708v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05452v1","updated":"2025-08-07T14:46:30Z","published":"2025-08-07T14:46:30Z","title":"LLMEval-3: A Large-Scale Longitudinal Study on Robust and Fair\n  Evaluation of Large Language Models","summary":"  Existing evaluation of Large Language Models (LLMs) on static benchmarks is\nvulnerable to data contamination and leaderboard overfitting, critical issues\nthat obscure true model capabilities. To address this, we introduce LLMEval-3,\na framework for dynamic evaluation of LLMs. LLMEval-3 is built on a proprietary\nbank of 220k graduate-level questions, from which it dynamically samples unseen\ntest sets for each evaluation run. Its automated pipeline ensures integrity via\ncontamination-resistant data curation, a novel anti-cheating architecture, and\na calibrated LLM-as-a-judge process achieving 90% agreement with human experts,\ncomplemented by a relative ranking system for fair comparison. An 20-month\nlongitudinal study of nearly 50 leading models reveals a performance ceiling on\nknowledge memorization and exposes data contamination vulnerabilities\nundetectable by static benchmarks. The framework demonstrates exceptional\nrobustness in ranking stability and consistency, providing strong empirical\nvalidation for the dynamic evaluation paradigm. LLMEval-3 offers a robust and\ncredible methodology for assessing the true capabilities of LLMs beyond\nleaderboard scores, promoting the development of more trustworthy evaluation\nstandards.\n","authors":["Ming Zhang","Yujiong Shen","Jingyi Deng","Yuhui Wang","Yue Zhang","Junzhe Wang","Shichun Liu","Shihan Dou","Huayu Sha","Qiyuan Peng","Changhao Jiang","Jingqi Tong","Yilong Wu","Zhihao Zhang","Mingqi Wu","Zhiheng Xi","Mingxu Chai","Tao Liang","Zhihui Fei","Zhen Wang","Mingyang Wan","Guojun Ma","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2508.05452v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2501.12106v4","updated":"2025-08-07T14:43:09Z","published":"2025-01-21T12:56:47Z","title":"Can open source large language models be used for tumor documentation in\n  Germany? -- An evaluation on urological doctors' notes","summary":"  Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.\n","authors":["Stefan Lenz","Arsenij Ustjanzew","Marco Jeray","Meike Ressing","Torsten Panholzer"],"pdf_url":"https://arxiv.org/pdf/2501.12106v4.pdf","comment":"53 pages, 5 figures"},{"id":"http://arxiv.org/abs/2508.05429v1","updated":"2025-08-07T14:17:43Z","published":"2025-08-07T14:17:43Z","title":"MyCulture: Exploring Malaysia's Diverse Culture under Low-Resource\n  Language Constraints","summary":"  Large Language Models (LLMs) often exhibit cultural biases due to training\ndata dominated by high-resource languages like English and Chinese. This poses\nchallenges for accurately representing and evaluating diverse cultural\ncontexts, particularly in low-resource language settings. To address this, we\nintroduce MyCulture, a benchmark designed to comprehensively evaluate LLMs on\nMalaysian culture across six pillars: arts, attire, customs, entertainment,\nfood, and religion presented in Bahasa Melayu. Unlike conventional benchmarks,\nMyCulture employs a novel open-ended multiple-choice question format without\npredefined options, thereby reducing guessing and mitigating format bias. We\nprovide a theoretical justification for the effectiveness of this open-ended\nstructure in improving both fairness and discriminative power. Furthermore, we\nanalyze structural bias by comparing model performance on structured versus\nfree-form outputs, and assess language bias through multilingual prompt\nvariations. Our evaluation across a range of regional and international LLMs\nreveals significant disparities in cultural comprehension, highlighting the\nurgent need for culturally grounded and linguistically inclusive benchmarks in\nthe development and assessment of LLMs.\n","authors":["Zhong Ken Hew","Jia Xin Low","Sze Jue Yang","Chee Seng chan"],"pdf_url":"https://arxiv.org/pdf/2508.05429v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.15844v3","updated":"2025-08-07T14:12:39Z","published":"2025-07-21T17:52:34Z","title":"Hierarchical Budget Policy Optimization for Adaptive Reasoning","summary":"  Large reasoning models achieve remarkable performance through extensive\nchain-of-thought generation, yet they suffer from a critical inefficiency:\napplying uniformly extensive reasoning regardless of problem complexity. We\npresent Hierarchical Budget Policy Optimization (HBPO), a reinforcement\nlearning framework that enables models to learn problem-specific reasoning\ndepths without sacrificing capability. Unlike existing approaches that impose\nrigid constraints or rely on discrete mode selection, HBPO partitions the\nexploration space into budget-constrained hierarchies (512-2560 tokens), each\nwith differentiated reward structures that preserve both efficiency incentives\nand reasoning capabilities. This design addresses a fundamental challenge in\nefficient reasoning training: traditional length penalties systematically bias\nmodels away from necessary long reasoning paths, causing exploration space\ncollapse. Through hierarchical sampling and budget-aware rewards, HBPO\nmaintains exploration diversity while teaching models to recognize when\nextended deliberation is warranted. Extensive experiments demonstrate that HBPO\nreduces average token usage by up to 60.6% while improving accuracy by 3.14%\nacross four reasoning benchmarks. Most notably, HBPO exhibits emergent adaptive\nbehavior where models automatically adjust reasoning depth based on problem\ncomplexity. Our results suggest that reasoning efficiency and capability are\nnot inherently conflicting, and can be simultaneously optimized through\nappropriately structured hierarchical training that preserves exploration\ndiversity.\n","authors":["Shangke Lyu","Linjuan Wu","Yuchen Yan","Xingyu Wu","Hao Li","Yongliang Shen","Peisheng Jiang","Weiming Lu","Jun Xiao","Yueting Zhuang"],"pdf_url":"https://arxiv.org/pdf/2507.15844v3.pdf","comment":"Code: https://github.com/zju-real/hbpo Project\n  Page:https://zju-real.github.io/hbpo/"},{"id":"http://arxiv.org/abs/2504.04377v2","updated":"2025-08-07T14:05:19Z","published":"2025-04-06T06:09:21Z","title":"PolyGuard: A Multilingual Safety Moderation Tool for 17 Languages","summary":"  Truly multilingual safety moderation efforts for Large Language Models (LLMs)\nhave been hindered by a narrow focus on a small set of languages (e.g.,\nEnglish, Chinese) as well as a limited scope of safety definition, resulting in\nsignificant gaps in moderation capabilities. To bridge these gaps, we release\nPOLYGUARD, a new state-of-the-art multilingual safety model for safeguarding\nLLM generations, and the corresponding training and evaluation datasets.\nPOLYGUARD is trained on POLYGUARDMIX, the largest multilingual safety training\ncorpus to date containing 1.91M samples across 17 languages (e.g., Chinese,\nCzech, English, Hindi). We also introduce POLYGUARDPROMPTS, a high quality\nmultilingual benchmark with 29K samples for the evaluation of safety\nguardrails. Created by combining naturally occurring multilingual human-LLM\ninteractions and human-verified machine translations of an English-only safety\ndataset (WildGuardMix; Han et al., 2024), our datasets contain prompt-output\npairs with labels of prompt harmfulness, response harmfulness, and response\nrefusal. Through extensive evaluations across multiple safety and toxicity\nbenchmarks, we demonstrate that POLYGUARD outperforms existing state-of-the-art\nopen-weight and commercial safety classifiers by 5.5%. Our contributions\nadvance efforts toward safer multilingual LLMs for all global users.\n","authors":["Priyanshu Kumar","Devansh Jain","Akhila Yerukola","Liwei Jiang","Himanshu Beniwal","Thomas Hartvigsen","Maarten Sap"],"pdf_url":"https://arxiv.org/pdf/2504.04377v2.pdf","comment":"Accepted to COLM 2025 Main Conference"},{"id":"http://arxiv.org/abs/2410.03751v4","updated":"2025-08-07T13:29:43Z","published":"2024-10-01T21:48:12Z","title":"Recent Advances in Speech Language Models: A Survey","summary":"  Large Language Models (LLMs) have recently garnered significant attention,\nprimarily for their capabilities in text-based interactions. However, natural\nhuman interaction often relies on speech, necessitating a shift towards\nvoice-based models. A straightforward approach to achieve this involves a\npipeline of ``Automatic Speech Recognition (ASR) + LLM + Text-to-Speech (TTS)\",\nwhere input speech is transcribed to text, processed by an LLM, and then\nconverted back to speech. Despite being straightforward, this method suffers\nfrom inherent limitations, such as information loss during modality conversion,\nsignificant latency due to the complex pipeline, and error accumulation across\nthe three stages. To address these issues, Speech Language Models (SpeechLMs)\n-- end-to-end models that generate speech without converting from text -- have\nemerged as a promising alternative. This survey paper provides the first\ncomprehensive overview of recent methodologies for constructing SpeechLMs,\ndetailing the key components of their architecture and the various training\nrecipes integral to their development. Additionally, we systematically survey\nthe various capabilities of SpeechLMs, categorize their evaluation metrics, and\ndiscuss the challenges and future research directions in this rapidly evolving\nfield. The GitHub repository is available at\nhttps://github.com/dreamtheater123/Awesome-SpeechLM-Survey\n","authors":["Wenqian Cui","Dianzhi Yu","Xiaoqi Jiao","Ziqiao Meng","Guangyan Zhang","Qichao Wang","Yiwen Guo","Irwin King"],"pdf_url":"https://arxiv.org/pdf/2410.03751v4.pdf","comment":"The reduced version of this paper has been accepted at ACL 2025"},{"id":"http://arxiv.org/abs/2508.05374v1","updated":"2025-08-07T13:16:55Z","published":"2025-08-07T13:16:55Z","title":"The TUB Sign Language Corpus Collection","summary":"  We present a collection of parallel corpora of 12 sign languages in video\nformat, together with subtitles in the dominant spoken languages of the\ncorresponding countries. The entire collection includes more than 1,300 hours\nin 4,381 video files, accompanied by 1,3~M subtitles containing 14~M tokens.\nMost notably, it includes the first consistent parallel corpora for 8 Latin\nAmerican sign languages, whereas the size of the German Sign Language corpora\nis ten times the size of the previously available corpora. The collection was\ncreated by collecting and processing videos of multiple sign languages from\nvarious online sources, mainly broadcast material of news shows, governmental\nbodies and educational channels. The preparation involved several stages,\nincluding data collection, informing the content creators and seeking usage\napprovals, scraping, and cropping. The paper provides statistics on the\ncollection and an overview of the methods used to collect the data.\n","authors":["Eleftherios Avramidis","Vera Czehmann","Fabian Deckert","Lorenz Hufe","Aljoscha Lipski","Yuni Amaloa Quintero Villalobos","Tae Kwon Rhee","Mengqian Shi","Lennart Stölting","Fabrizio Nunnari","Sebastian Möller"],"pdf_url":"https://arxiv.org/pdf/2508.05374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05366v1","updated":"2025-08-07T13:13:19Z","published":"2025-08-07T13:13:19Z","title":"Can Language Models Critique Themselves? Investigating Self-Feedback for\n  Retrieval Augmented Generation at BioASQ 2025","summary":"  Agentic Retrieval Augmented Generation (RAG) and 'deep research' systems aim\nto enable autonomous search processes where Large Language Models (LLMs)\niteratively refine outputs. However, applying these systems to domain-specific\nprofessional search, such as biomedical research, presents challenges, as\nautomated systems may reduce user involvement and misalign with expert\ninformation needs. Professional search tasks often demand high levels of user\nexpertise and transparency. The BioASQ CLEF 2025 challenge, using\nexpert-formulated questions, can serve as a platform to study these issues. We\nexplored the performance of current reasoning and nonreasoning LLMs like\nGemini-Flash 2.0, o3-mini, o4-mini and DeepSeek-R1. A key aspect of our\nmethodology was a self-feedback mechanism where LLMs generated, evaluated, and\nthen refined their outputs for query expansion and for multiple answer types\n(yes/no, factoid, list, ideal). We investigated whether this iterative\nself-correction improves performance and if reasoning models are more capable\nof generating useful feedback. Preliminary results indicate varied performance\nfor the self-feedback strategy across models and tasks. This work offers\ninsights into LLM self-correction and informs future work on comparing the\neffectiveness of LLM-generated feedback with direct human expert input in these\nsearch systems.\n","authors":["Samy Ateia","Udo Kruschwitz"],"pdf_url":"https://arxiv.org/pdf/2508.05366v1.pdf","comment":"Version as accepted at the BioASQ Lab at CLEF 2025"},{"id":"http://arxiv.org/abs/2201.08214v4","updated":"2025-08-07T13:11:35Z","published":"2022-01-20T15:01:12Z","title":"A Latent-Variable Model for Intrinsic Probing","summary":"  The success of pre-trained contextualized representations has prompted\nresearchers to analyze them for the presence of linguistic information. Indeed,\nit is natural to assume that these pre-trained representations do encode some\nlevel of linguistic knowledge as they have brought about large empirical\nimprovements on a wide variety of NLP tasks, which suggests they are learning\ntrue linguistic generalization. In this work, we focus on intrinsic probing, an\nanalysis technique where the goal is not only to identify whether a\nrepresentation encodes a linguistic attribute but also to pinpoint where this\nattribute is encoded. We propose a novel latent-variable formulation for\nconstructing intrinsic probes and derive a tractable variational approximation\nto the log-likelihood. Our results show that our model is versatile and yields\ntighter mutual information estimates than two intrinsic probes previously\nproposed in the literature. Finally, we find empirical evidence that\npre-trained representations develop a cross-lingually entangled notion of\nmorphosyntax.\n","authors":["Karolina Stańczak","Lucas Torroba Hennigen","Adina Williams","Ryan Cotterell","Isabelle Augenstein"],"pdf_url":"https://arxiv.org/pdf/2201.08214v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.01215v3","updated":"2025-08-07T13:10:30Z","published":"2024-10-02T03:57:21Z","title":"From Code to Correctness: Closing the Last Mile of Code Generation with\n  Hierarchical Debugging","summary":"  While large language models have made significant strides in code generation,\nthe pass rate of the generated code is bottlenecked on subtle errors, often\nrequiring human intervention to pass tests, especially for complex problems.\nExisting LLM-based debugging systems treat generated programs as monolithic\nunits, failing to address bugs at multiple levels of granularity, from\nlow-level syntax errors to high-level algorithmic flaws. In this paper, we\nintroduce Multi-Granularity Debugger (MGDebugger), a hierarchical code debugger\nby isolating, identifying, and resolving bugs at various levels of granularity.\nMGDebugger decomposes problematic code into a hierarchical tree structure of\nsubfunctions, with each level representing a particular granularity of error.\nDuring debugging, it analyzes each subfunction and iteratively resolves bugs in\na bottom-up manner. To effectively test each subfunction, we propose an\nLLM-simulated Python executor, which traces code execution and tracks important\nvariable states to pinpoint errors accurately. Extensive experiments\ndemonstrate that MGDebugger outperforms existing debugging systems, achieving\nan 18.9% improvement in accuracy over seed generations in HumanEval and a 97.6%\nrepair success rate in HumanEvalFix. Furthermore, MGDebugger effectively fixes\nbugs across different categories and difficulty levels, demonstrating its\nrobustness and effectiveness.\n","authors":["Yuling Shi","Songsong Wang","Chengcheng Wan","Min Wang","Xiaodong Gu"],"pdf_url":"https://arxiv.org/pdf/2410.01215v3.pdf","comment":"Code and data available at https://github.com/YerbaPage/MGDebugger"},{"id":"http://arxiv.org/abs/2508.05358v1","updated":"2025-08-07T13:06:42Z","published":"2025-08-07T13:06:42Z","title":"Evaluation of a Sign Language Avatar on Comprehensibility, User\n  Experience \\& Acceptability","summary":"  This paper presents an investigation into the impact of adding adjustment\nfeatures to an existing sign language (SL) avatar on a Microsoft Hololens 2\ndevice. Through a detailed analysis of interactions of expert German Sign\nLanguage (DGS) users with both adjustable and non-adjustable avatars in a\nspecific use case, this study identifies the key factors influencing the\ncomprehensibility, the user experience (UX), and the acceptability of such a\nsystem. Despite user preference for adjustable settings, no significant\nimprovements in UX or comprehensibility were observed, which remained at low\nlevels, amid missing SL elements (mouthings and facial expressions) and\nimplementation issues (indistinct hand shapes, lack of feedback and menu\npositioning). Hedonic quality was rated higher than pragmatic quality,\nindicating that users found the system more emotionally or aesthetically\npleasing than functionally useful. Stress levels were higher for the adjustable\navatar, reflecting lower performance, greater effort and more frustration.\nAdditionally, concerns were raised about whether the Hololens adjustment\ngestures are intuitive and easy to familiarise oneself with. While\nacceptability of the concept of adjustability was generally positive, it was\nstrongly dependent on usability and animation quality. This study highlights\nthat personalisation alone is insufficient, and that SL avatars must be\ncomprehensible by default. Key recommendations include enhancing mouthing and\nfacial animation, improving interaction interfaces, and applying participatory\ndesign.\n","authors":["Fenya Wasserroth","Eleftherios Avramidis","Vera Czehmann","Tanja Kojic","Fabrizio Nunnari","Sebastian Möller"],"pdf_url":"https://arxiv.org/pdf/2508.05358v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05337v1","updated":"2025-08-07T12:38:22Z","published":"2025-08-07T12:38:22Z","title":"Efficient Reasoning for Large Reasoning Language Models via\n  Certainty-Guided Reflection Suppression","summary":"  Recent Large Reasoning Language Models (LRLMs) employ long chain-of-thought\nreasoning with complex reflection behaviors, typically signaled by specific\ntrigger words (e.g., \"Wait\" and \"Alternatively\") to enhance performance.\nHowever, these reflection behaviors can lead to the overthinking problem where\nthe generation of redundant reasoning steps that unnecessarily increase token\nusage, raise inference costs, and reduce practical utility. In this paper, we\npropose Certainty-Guided Reflection Suppression (CGRS), a novel method that\nmitigates overthinking in LRLMs while maintaining reasoning accuracy. CGRS\noperates by dynamically suppressing the model's generation of reflection\ntriggers when it exhibits high confidence in its current response, thereby\npreventing redundant reflection cycles without compromising output quality. Our\napproach is model-agnostic, requires no retraining or architectural\nmodifications, and can be integrated seamlessly with existing autoregressive\ngeneration pipelines. Extensive experiments across four reasoning benchmarks\n(i.e., AIME24, AMC23, MATH500, and GPQA-D) demonstrate CGRS's effectiveness: it\nreduces token usage by an average of 18.5% to 41.9% while preserving accuracy.\nIt also achieves the optimal balance between length reduction and performance\ncompared to state-of-the-art baselines. These results hold consistently across\nmodel architectures (e.g., DeepSeek-R1-Distill series, QwQ-32B, and Qwen3\nfamily) and scales (4B to 32B parameters), highlighting CGRS's practical value\nfor efficient reasoning.\n","authors":["Jiameng Huang","Baijiong Lin","Guhao Feng","Jierun Chen","Di He","Lu Hou"],"pdf_url":"https://arxiv.org/pdf/2508.05337v1.pdf","comment":"Technical Report"},{"id":"http://arxiv.org/abs/2508.05311v1","updated":"2025-08-07T12:11:53Z","published":"2025-08-07T12:11:53Z","title":"A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM\n  Agents","summary":"  We propose a hybrid architecture that integrates decision tree-based symbolic\nreasoning with the generative capabilities of large language models (LLMs)\nwithin a coordinated multi-agent framework. Unlike prior approaches that\nloosely couple symbolic and neural modules, our design embeds decision trees\nand random forests as callable oracles within a unified reasoning system.\nTree-based modules enable interpretable rule inference and causal logic, while\nLLM agents handle abductive reasoning, generalization, and interactive\nplanning. A central orchestrator maintains belief state consistency and\nmediates communication across agents and external tools, enabling reasoning\nover both structured and unstructured inputs.\n  The system achieves strong performance on reasoning benchmarks. On\n\\textit{ProofWriter}, it improves entailment consistency by +7.2\\% through\nlogic-grounded tree validation. On GSM8k, it achieves +5.3\\% accuracy gains in\nmultistep mathematical problems via symbolic augmentation. On \\textit{ARC}, it\nboosts abstraction accuracy by +6.0\\% through integration of symbolic oracles.\nApplications in clinical decision support and scientific discovery show how the\nsystem encodes domain rules symbolically while leveraging LLMs for contextual\ninference and hypothesis generation. This architecture offers a robust,\ninterpretable, and extensible solution for general-purpose neuro-symbolic\nreasoning.\n","authors":["Andrew Kiruluta"],"pdf_url":"https://arxiv.org/pdf/2508.05311v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.03930v2","updated":"2025-08-07T12:06:29Z","published":"2024-12-05T07:12:53Z","title":"GuARD: Effective Anomaly Detection through a Text-Rich and\n  Graph-Informed Language Model","summary":"  Anomaly detection on text-rich graphs is widely prevalent in real life, such\nas detecting incorrectly assigned academic papers to authors and detecting bots\nin social networks. The remarkable capabilities of large language models (LLMs)\npave a new revenue by utilizing rich-text information for effective anomaly\ndetection. However, simply introducing rich texts into LLMs can obscure\nessential detection cues and introduce high fine-tuning costs. Moreover, LLMs\noften overlook the intrinsic structural bias of graphs which is vital for\ndistinguishing normal from abnormal node patterns. To this end, this paper\nintroduces GuARD, a text-rich and graph-informed language model that combines\nkey structural features from graph-based methods with fine-grained semantic\nattributes extracted via small language models for effective anomaly detection\non text-rich graphs. GuARD is optimized with the progressive multi-modal\nmulti-turn instruction tuning framework in the task-guided instruction tuning\nregime tailed to incorporate both rich-text and structural modalities.\nExtensive experiments on four datasets reveal that GuARD outperforms\ngraph-based and LLM-based anomaly detection methods, while offering up to\n5$\\times$ times speedup in training and 5$\\times$ times speedup in inference\nover vanilla long-context LLMs on the large-scale WhoIsWho dataset.\n","authors":["Yunhe Pang","Bo Chen","Fanjin Zhang","Yanghui Rao","Evgeny Kharlamov","Jie Tang"],"pdf_url":"https://arxiv.org/pdf/2412.03930v2.pdf","comment":"Accepted at KDD 2025"},{"id":"http://arxiv.org/abs/2508.05305v1","updated":"2025-08-07T12:03:44Z","published":"2025-08-07T12:03:44Z","title":"SONAR-LLM: Autoregressive Transformer that Thinks in Sentence Embeddings\n  and Speaks in Tokens","summary":"  The recently proposed Large Concept Model (LCM) generates text by predicting\na sequence of sentence-level embeddings and training with either mean-squared\nerror or diffusion objectives. We present SONAR-LLM, a decoder-only transformer\nthat \"thinks\" in the same continuous SONAR embedding space, yet is supervised\nthrough token-level cross-entropy propagated via the frozen SONAR decoder. This\nhybrid objective retains the semantic abstraction of LCM while eliminating its\ndiffusion sampler and restoring a likelihood-based training signal. Across\nmodel sizes from 39M to 1.3B parameters, SONAR-LLM attains competitive\ngeneration quality. We report scaling trends, ablations, benchmark results, and\nrelease the complete training code and all pretrained checkpoints to foster\nreproducibility and future research.\n","authors":["Nikita Dragunov","Temurbek Rahmatullaev","Elizaveta Goncharova","Andrey Kuznetsov","Anton Razzhigaev"],"pdf_url":"https://arxiv.org/pdf/2508.05305v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04632v2","updated":"2025-08-07T11:30:20Z","published":"2025-08-06T17:00:54Z","title":"IFDECORATOR: Wrapping Instruction Following Reinforcement Learning with\n  Verifiable Rewards","summary":"  Reinforcement Learning with Verifiable Rewards (RLVR) improves instruction\nfollowing capabilities of large language models (LLMs), but suffers from\ntraining inefficiency due to inadequate difficulty assessment. Moreover, RLVR\nis prone to over-optimization, where LLMs exploit verification shortcuts\nwithout aligning to the actual intent of user instructions. We introduce\nInstruction Following Decorator (IFDecorator}, a framework that wraps RLVR\ntraining into a robust and sample-efficient pipeline. It consists of three\ncomponents: (1) a cooperative-adversarial data flywheel that co-evolves\ninstructions and hybrid verifications, generating progressively more\nchallenging instruction-verification pairs; (2) IntentCheck, a bypass module\nenforcing intent alignment; and (3) trip wires, a diagnostic mechanism that\ndetects reward hacking via trap instructions, which trigger and capture\nshortcut exploitation behaviors. Our Qwen2.5-32B-Instruct-IFDecorator achieves\n87.43% accuracy on IFEval, outperforming larger proprietary models such as\nGPT-4o. Additionally, we demonstrate substantial improvements on FollowBench\nwhile preserving general capabilities. Our trip wires show significant\nreductions in reward hacking rates. We will release models, code, and data for\nfuture research.\n","authors":["Xu Guo","Tianyi Liang","Tong Jian","Xiaogui Yang","Ling-I Wu","Chenhui Li","Zhihui Lu","Qipeng Guo","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04632v2.pdf","comment":"7 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.05283v1","updated":"2025-08-07T11:27:43Z","published":"2025-08-07T11:27:43Z","title":"Decision-Making with Deliberation: Meta-reviewing as a Document-grounded\n  Dialogue","summary":"  Meta-reviewing is a pivotal stage in the peer-review process, serving as the\nfinal step in determining whether a paper is recommended for acceptance. Prior\nresearch on meta-reviewing has treated this as a summarization problem over\nreview reports. However, complementary to this perspective, meta-reviewing is a\ndecision-making process that requires weighing reviewer arguments and placing\nthem within a broader context. Prior research has demonstrated that\ndecision-makers can be effectively assisted in such scenarios via dialogue\nagents. In line with this framing, we explore the practical challenges for\nrealizing dialog agents that can effectively assist meta-reviewers. Concretely,\nwe first address the issue of data scarcity for training dialogue agents by\ngenerating synthetic data using Large Language Models (LLMs) based on a\nself-refinement strategy to improve the relevance of these dialogues to expert\ndomains. Our experiments demonstrate that this method produces higher-quality\nsynthetic data and can serve as a valuable resource towards training\nmeta-reviewing assistants. Subsequently, we utilize this data to train dialogue\nagents tailored for meta-reviewing and find that these agents outperform\n\\emph{off-the-shelf} LLM-based assistants for this task. Finally, we apply our\nagents in real-world meta-reviewing scenarios and confirm their effectiveness\nin enhancing the efficiency of meta-reviewing.\\footnote{Code and Data:\nhttps://github.com/UKPLab/arxiv2025-meta-review-as-dialog\n","authors":["Sukannya Purkayastha","Nils Dycke","Anne Lauscher","Iryna Gurevych"],"pdf_url":"https://arxiv.org/pdf/2508.05283v1.pdf","comment":"36 pages, 16 tables, 13 figures"},{"id":"http://arxiv.org/abs/2508.05282v1","updated":"2025-08-07T11:26:40Z","published":"2025-08-07T11:26:40Z","title":"ASCoT: An Adaptive Self-Correction Chain-of-Thought Method for\n  Late-Stage Fragility in LLMs","summary":"  Chain-of-Thought (CoT) prompting has significantly advanced the reasoning\ncapabilities of Large Language Models (LLMs), yet the reliability of these\nreasoning chains remains a critical challenge. A widely held \"cascading\nfailure\" hypothesis suggests that errors are most detrimental when they occur\nearly in the reasoning process. This paper challenges that assumption through\nsystematic error-injection experiments, revealing a counter-intuitive\nphenomenon we term \"Late-Stage Fragility\": errors introduced in the later\nstages of a CoT chain are significantly more likely to corrupt the final answer\nthan identical errors made at the beginning. To address this specific\nvulnerability, we introduce the Adaptive Self-Correction Chain-of-Thought\n(ASCoT) method. ASCoT employs a modular pipeline in which an Adaptive\nVerification Manager (AVM) operates first, followed by the Multi-Perspective\nSelf-Correction Engine (MSCE). The AVM leverages a Positional Impact Score\nfunction I(k) that assigns different weights based on the position within the\nreasoning chains, addressing the Late-Stage Fragility issue by identifying and\nprioritizing high-risk, late-stage steps. Once these critical steps are\nidentified, the MSCE applies robust, dual-path correction specifically to the\nfailure parts. Extensive experiments on benchmarks such as GSM8K and MATH\ndemonstrate that ASCoT achieves outstanding accuracy, outperforming strong\nbaselines, including standard CoT. Our work underscores the importance of\ndiagnosing specific failure modes in LLM reasoning and advocates for a shift\nfrom uniform verification strategies to adaptive, vulnerability-aware\ncorrection mechanisms.\n","authors":["Dongxu Zhang","Ning Yang","Jihua Zhu","Jinnan Yang","Miao Xin","Baoliang Tian"],"pdf_url":"https://arxiv.org/pdf/2508.05282v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2508.05633v1","updated":"2025-08-07T17:59:36Z","published":"2025-08-07T17:59:36Z","title":"KuaiLive: A Real-time Interactive Dataset for Live Streaming\n  Recommendation","summary":"  Live streaming platforms have become a dominant form of online content\nconsumption, offering dynamically evolving content, real-time interactions, and\nhighly engaging user experiences. These unique characteristics introduce new\nchallenges that differentiate live streaming recommendation from traditional\nrecommendation settings and have garnered increasing attention from industry in\nrecent years. However, research progress in academia has been hindered by the\nlack of publicly available datasets that accurately reflect the dynamic nature\nof live streaming environments. To address this gap, we introduce KuaiLive, the\nfirst real-time, interactive dataset collected from Kuaishou, a leading live\nstreaming platform in China with over 400 million daily active users. The\ndataset records the interaction logs of 23,772 users and 452,621 streamers over\na 21-day period. Compared to existing datasets, KuaiLive offers several\nadvantages: it includes precise live room start and end timestamps, multiple\ntypes of real-time user interactions (click, comment, like, gift), and rich\nside information features for both users and streamers. These features enable\nmore realistic simulation of dynamic candidate items and better modeling of\nuser and streamer behaviors. We conduct a thorough analysis of KuaiLive from\nmultiple perspectives and evaluate several representative recommendation\nmethods on it, establishing a strong benchmark for future research. KuaiLive\ncan support a wide range of tasks in the live streaming domain, such as top-K\nrecommendation, click-through rate prediction, watch time prediction, and gift\nprice prediction. Moreover, its fine-grained behavioral data also enables\nresearch on multi-behavior modeling, multi-task learning, and fairness-aware\nrecommendation. The dataset and related resources are publicly available at\nhttps://imgkkk574.github.io/KuaiLive.\n","authors":["Changle Qu","Sunhao Dai","Ke Guo","Liqin Zhao","Yanan Niu","Xiao Zhang","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2508.05633v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05512v1","updated":"2025-08-07T15:46:53Z","published":"2025-08-07T15:46:53Z","title":"RankArena: A Unified Platform for Evaluating Retrieval, Reranking and\n  RAG with Human and LLM Feedback","summary":"  Evaluating the quality of retrieval-augmented generation (RAG) and document\nreranking systems remains challenging due to the lack of scalable,\nuser-centric, and multi-perspective evaluation tools. We introduce RankArena, a\nunified platform for comparing and analysing the performance of retrieval\npipelines, rerankers, and RAG systems using structured human and LLM-based\nfeedback as well as for collecting such feedback. RankArena supports multiple\nevaluation modes: direct reranking visualisation, blind pairwise comparisons\nwith human or LLM voting, supervised manual document annotation, and end-to-end\nRAG answer quality assessment. It captures fine-grained relevance feedback\nthrough both pairwise preferences and full-list annotations, along with\nauxiliary metadata such as movement metrics, annotation time, and quality\nratings. The platform also integrates LLM-as-a-judge evaluation, enabling\ncomparison between model-generated rankings and human ground truth annotations.\nAll interactions are stored as structured evaluation datasets that can be used\nto train rerankers, reward models, judgment agents, or retrieval strategy\nselectors. Our platform is publicly available at https://rankarena.ngrok.io/,\nand the Demo video is provided https://youtu.be/jIYAP4PaSSI.\n","authors":["Abdelrahman Abdallah","Mahmoud Abdalla","Bhawna Piryani","Jamshid Mozafari","Mohammed Ali","Adam Jatowt"],"pdf_url":"https://arxiv.org/pdf/2508.05512v1.pdf","comment":"Accept at CIKM 2025"},{"id":"http://arxiv.org/abs/2504.08754v5","updated":"2025-08-07T15:23:38Z","published":"2025-03-28T15:49:52Z","title":"Towards Personalized Conversational Sales Agents: Contextual User\n  Profiling for Strategic Action","summary":"  Conversational Recommender Systems (CRSs)aim to engage users in dialogue to\nprovide tailored recommendations. While traditional CRSs focus on eliciting\npreferences and retrieving items, real-world e-commerce interactions involve\nmore complex decision-making, where users consider multiple factors beyond\nsimple attributes. To capture this complexity, we introduce Conversational\nSales (CSALES), a novel task that integrates preference elicitation,\nrecommendation, and persuasion within a unified conversational framework. To\nsupport realistic and systematic evaluation, we present CSUSER, an evaluation\nprotocol with LLM-based user simulator grounded in real-world behavioral data\nby modeling fine-grained user profiles for personalized interaction. We also\npropose CSI, a conversational sales agent that proactively infers contextual\nuser profiles and strategically selects actions through conversation.\nComprehensive experiments show that CSI significantly improves both\nrecommendation success and persuasive effectiveness across diverse user\nprofiles.\n","authors":["Tongyoung Kim","Jeongeun Lee","Soojin Yoon","Sunghwan Kim","Dongha Lee"],"pdf_url":"https://arxiv.org/pdf/2504.08754v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.17653v2","updated":"2025-08-07T15:17:29Z","published":"2025-07-23T16:17:43Z","title":"QuMAB: Query-based Multi-Annotator Behavior Modeling with Reliability\n  under Sparse Labels","summary":"  Multi-annotator learning traditionally aggregates diverse annotations to\napproximate a single ground truth, treating disagreements as noise. However,\nthis paradigm faces fundamental challenges: subjective tasks often lack\nabsolute ground truth, and sparse annotation coverage makes aggregation\nstatistically unreliable. We introduce a paradigm shift from sample-wise\naggregation to annotator-wise behavior modeling. By treating annotator\ndisagreements as valuable information rather than noise, modeling\nannotator-specific behavior patterns can reconstruct unlabeled data to reduce\nannotation cost, enhance aggregation reliability, and explain annotator\ndecision behavior. To this end, we propose QuMAB (Query-based Multi-Annotator\nBehavior Pattern Learning), which uses light-weight queries to model individual\nannotators while capturing inter-annotator correlations as implicit\nregularization, preventing overfitting to sparse individual data while\nmaintaining individualization and improving generalization, with a\nvisualization of annotator focus regions offering an explainable analysis of\nbehavior understanding. We contribute two large-scale datasets with dense\nper-annotator labels: STREET (4,300 labels/annotator) and AMER (average 3,118\nlabels/annotator), the first multimodal multi-annotator dataset. Extensive\nexperiments demonstrate the superiority of our QuMAB in modeling individual\nannotators' behavior patterns, their utility for consensus prediction, and\napplicability under sparse annotations.\n","authors":["Liyun Zhang","Zheng Lian","Hong Liu","Takanori Takebe","Yuta Nakashima"],"pdf_url":"https://arxiv.org/pdf/2507.17653v2.pdf","comment":"12 pages. arXiv admin note: substantial text overlap with\n  arXiv:2503.15237"},{"id":"http://arxiv.org/abs/2508.05398v1","updated":"2025-08-07T13:50:05Z","published":"2025-08-07T13:50:05Z","title":"On the Reliability of Sampling Strategies in Offline Recommender\n  Evaluation","summary":"  Offline evaluation plays a central role in benchmarking recommender systems\nwhen online testing is impractical or risky. However, it is susceptible to two\nkey sources of bias: exposure bias, where users only interact with items they\nare shown, and sampling bias, introduced when evaluation is performed on a\nsubset of logged items rather than the full catalog. While prior work has\nproposed methods to mitigate sampling bias, these are typically assessed on\nfixed logged datasets rather than for their ability to support reliable model\ncomparisons under varying exposure conditions or relative to true user\npreferences. In this paper, we investigate how different combinations of\nlogging and sampling choices affect the reliability of offline evaluation.\nUsing a fully observed dataset as ground truth, we systematically simulate\ndiverse exposure biases and assess the reliability of common sampling\nstrategies along four dimensions: sampling resolution (recommender model\nseparability), fidelity (agreement with full evaluation), robustness (stability\nunder exposure bias), and predictive power (alignment with ground truth). Our\nfindings highlight when and how sampling distorts evaluation outcomes and offer\npractical guidance for selecting strategies that yield faithful and robust\noffline comparisons.\n","authors":["Bruno L. Pereira","Alan Said","Rodrygo L. T. Santos"],"pdf_url":"https://arxiv.org/pdf/2508.05398v1.pdf","comment":"Accepted to RecSys 2025"},{"id":"http://arxiv.org/abs/2508.05377v1","updated":"2025-08-07T13:21:00Z","published":"2025-08-07T13:21:00Z","title":"Does Multimodality Improve Recommender Systems as Expected? A Critical\n  Analysis and Future Directions","summary":"  Multimodal recommendation systems are increasingly popular for their\npotential to improve performance by integrating diverse data types. However,\nthe actual benefits of this integration remain unclear, raising questions about\nwhen and how it truly enhances recommendations. In this paper, we propose a\nstructured evaluation framework to systematically assess multimodal\nrecommendations across four dimensions: Comparative Efficiency, Recommendation\nTasks, Recommendation Stages, and Multimodal Data Integration. We benchmark a\nset of reproducible multimodal models against strong traditional baselines and\nevaluate their performance on different platforms. Our findings show that\nmultimodal data is particularly beneficial in sparse interaction scenarios and\nduring the recall stage of recommendation pipelines. We also observe that the\nimportance of each modality is task-specific, where text features are more\nuseful in e-commerce and visual features are more effective in short-video\nrecommendations. Additionally, we explore different integration strategies and\nmodel sizes, finding that Ensemble-Based Learning outperforms Fusion-Based\nLearning, and that larger models do not necessarily deliver better results. To\ndeepen our understanding, we include case studies and review findings from\nother recommendation domains. Our work provides practical insights for building\nefficient and effective multimodal recommendation systems, emphasizing the need\nfor thoughtful modality selection, integration strategies, and model design.\n","authors":["Hongyu Zhou","Yinan Zhang","Aixin Sun","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2508.05377v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05352v1","updated":"2025-08-07T12:58:34Z","published":"2025-08-07T12:58:34Z","title":"Multi-Modal Multi-Behavior Sequential Recommendation with Conditional\n  Diffusion-Based Feature Denoising","summary":"  The sequential recommendation system utilizes historical user interactions to\npredict preferences. Effectively integrating diverse user behavior patterns\nwith rich multimodal information of items to enhance the accuracy of sequential\nrecommendations is an emerging and challenging research direction. This paper\nfocuses on the problem of multi-modal multi-behavior sequential recommendation,\naiming to address the following challenges: (1) the lack of effective\ncharacterization of modal preferences across different behaviors, as user\nattention to different item modalities varies depending on the behavior; (2)\nthe difficulty of effectively mitigating implicit noise in user behavior, such\nas unintended actions like accidental clicks; (3) the inability to handle\nmodality noise in multi-modal representations, which further impacts the\naccurate modeling of user preferences. To tackle these issues, we propose a\nnovel Multi-Modal Multi-Behavior Sequential Recommendation model (M$^3$BSR).\nThis model first removes noise in multi-modal representations using a\nConditional Diffusion Modality Denoising Layer. Subsequently, it utilizes deep\nbehavioral information to guide the denoising of shallow behavioral data,\nthereby alleviating the impact of noise in implicit feedback through\nConditional Diffusion Behavior Denoising. Finally, by introducing a\nMulti-Expert Interest Extraction Layer, M$^3$BSR explicitly models the common\nand specific interests across behaviors and modalities to enhance\nrecommendation performance. Experimental results indicate that M$^3$BSR\nsignificantly outperforms existing state-of-the-art methods on benchmark\ndatasets.\n","authors":["Xiaoxi Cui","Weihai Lu","Yu Tong","Yiheng Li","Zhejun Zhao"],"pdf_url":"https://arxiv.org/pdf/2508.05352v1.pdf","comment":"SIGIR 2025"},{"id":"http://arxiv.org/abs/2508.05314v1","updated":"2025-08-07T12:14:33Z","published":"2025-08-07T12:14:33Z","title":"Difference Views for Visual Graph Query Building","summary":"  Knowledge Graphs (KGs) contain vast amounts of linked resources that encode\nknowledge in various domains, which can be queried and searched for using\nspecialized languages like SPARQL, a query language developed to query KGs.\nExisting visual query builders enable non-expert users to construct SPARQL\nqueries and utilize the knowledge contained in these graphs. Query building is,\nhowever, an iterative and, often, visual process where the question of the user\ncan change and differ throughout the process, especially for explorative\nsearch. Our visual querying interface communicates these change between\niterative steps in the query building process using graph differences to\ncontrast the changes and the evolution in the graph query. We also enable users\nto formulate their evolving information needs using a natural language\ninterface directly integrated into the difference query view. We, furthermore,\ncommunicate the change in results in the result view by contrasting the\ndifferences in both result distribution and individual instances of the\nprototype graph and demonstrate the system's applicability through case studies\non different ontologies and usage scenarios, illustrating how our system\nfosters, both, data exploration and analysis of domain-specific graphs.\n","authors":["Benedikt Kantz","Stefan Lengauer","Peter Waldert","Tobias Schreck"],"pdf_url":"https://arxiv.org/pdf/2508.05314v1.pdf","comment":"5 pages, 6 figures, preparing for submission to Semantic Web\n  Conferences"},{"id":"http://arxiv.org/abs/2508.05225v1","updated":"2025-08-07T10:11:02Z","published":"2025-08-07T10:11:02Z","title":"FIRE: Faithful Interpretable Recommendation Explanations","summary":"  Natural language explanations in recommender systems are often framed as a\nreview generation task, leveraging user reviews as ground-truth supervision.\nWhile convenient, this approach conflates a user's opinion with the system's\nreasoning, leading to explanations that may be fluent but fail to reflect the\ntrue logic behind recommendations. In this work, we revisit the core objective\nof explainable recommendation: to transparently communicate why an item is\nrecommended by linking user needs to relevant item features. Through a\ncomprehensive analysis of existing methods across multiple benchmark datasets,\nwe identify common limitations-explanations that are weakly aligned with model\npredictions, vague or inaccurate in identifying user intents, and overly\nrepetitive or generic. To overcome these challenges, we propose FIRE, a\nlightweight and interpretable framework that combines SHAP-based feature\nattribution with structured, prompt-driven language generation. FIRE produces\nfaithful, diverse, and user-aligned explanations, grounded in the actual\ndecision-making process of the model. Our results demonstrate that FIRE not\nonly achieves competitive recommendation accuracy but also significantly\nimproves explanation quality along critical dimensions such as alignment,\nstructure, and faithfulness. This work highlights the need to move beyond the\nreview-as-explanation paradigm and toward explanation methods that are both\naccountable and interpretable.\n","authors":["S. M. F. Sani","Asal Meskin","Mohammad Amanlou","Hamid R. Rabiee"],"pdf_url":"https://arxiv.org/pdf/2508.05225v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05206v1","updated":"2025-08-07T09:43:34Z","published":"2025-08-07T09:43:34Z","title":"Bidding-Aware Retrieval for Multi-Stage Consistency in Online\n  Advertising","summary":"  Online advertising systems typically use a cascaded architecture to manage\nmassive requests and candidate volumes, where the ranking stages allocate\ntraffic based on eCPM (predicted CTR $\\times$ Bid). With the increasing\npopularity of auto-bidding strategies, the inconsistency between the\ncomputationally sensitive retrieval stage and the ranking stages becomes more\npronounced, as the former cannot access precise, real-time bids for the vast ad\ncorpus. This discrepancy leads to sub-optimal platform revenue and advertiser\noutcomes. To tackle this problem, we propose Bidding-Aware Retrieval (BAR), a\nmodel-based retrieval framework that addresses multi-stage inconsistency by\nincorporating ad bid value into the retrieval scoring function. The core\ninnovation is Bidding-Aware Modeling, incorporating bid signals through\nmonotonicity-constrained learning and multi-task distillation to ensure\neconomically coherent representations, while Asynchronous Near-Line Inference\nenables real-time updates to the embedding for market responsiveness.\nFurthermore, the Task-Attentive Refinement module selectively enhances feature\ninteractions to disentangle user interest and commercial value signals.\nExtensive offline experiments and full-scale deployment across Alibaba's\ndisplay advertising platform validated BAR's efficacy: 4.32% platform revenue\nincrease with 22.2% impression lift for positively-operated advertisements.\n","authors":["Bin Liu","Yunfei Liu","Ziru Xu","Zhaoyu Zhou","Zhi Kou","Yeqiu Yang","Han Zhu","Jian Xu","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2508.05206v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05198v1","updated":"2025-08-07T09:33:32Z","published":"2025-08-07T09:33:32Z","title":"Balancing Accuracy and Novelty with Sub-Item Popularity","summary":"  In the realm of music recommendation, sequential recommenders have shown\npromise in capturing the dynamic nature of music consumption. A key\ncharacteristic of this domain is repetitive listening, where users frequently\nreplay familiar tracks. To capture these repetition patterns, recent research\nhas introduced Personalised Popularity Scores (PPS), which quantify\nuser-specific preferences based on historical frequency. While PPS enhances\nrelevance in recommendation, it often reinforces already-known content,\nlimiting the system's ability to surface novel or serendipitous items - key\nelements for fostering long-term user engagement and satisfaction. To address\nthis limitation, we build upon RecJPQ, a Transformer-based framework initially\ndeveloped to improve scalability in large-item catalogues through sub-item\ndecomposition. We repurpose RecJPQ's sub-item architecture to model\npersonalised popularity at a finer granularity. This allows us to capture\nshared repetition patterns across sub-embeddings - latent structures not\naccessible through item-level popularity alone. We propose a novel integration\nof sub-ID-level personalised popularity within the RecJPQ framework, enabling\nexplicit control over the trade-off between accuracy and personalised novelty.\nOur sub-ID-level PPS method (sPPS) consistently outperforms item-level PPS by\nachieving significantly higher personalised novelty without compromising\nrecommendation accuracy. Code and experiments are publicly available at\nhttps://github.com/sisinflab/Sub-id-Popularity.\n","authors":["Chiara Mallamaci","Aleksandr Vladimirovich Petrov","Alberto Carlo Maria Mancino","Vito Walter Anelli","Tommaso Di Noia","Craig Macdonald"],"pdf_url":"https://arxiv.org/pdf/2508.05198v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.02242v2","updated":"2025-08-07T08:51:15Z","published":"2025-08-04T09:43:21Z","title":"From Generation to Consumption: Personalized List Value Estimation for\n  Re-ranking","summary":"  Re-ranking is critical in recommender systems for optimizing the order of\nrecommendation lists, thus improving user satisfaction and platform revenue.\nMost existing methods follow a generator-evaluator paradigm, where the\nevaluator estimates the overall value of each candidate list. However, they\noften ignore the fact that users may exit before consuming the full list,\nleading to a mismatch between estimated generation value and actual consumption\nvalue. To bridge this gap, we propose CAVE, a personalized Consumption-Aware\nlist Value Estimation framework. CAVE formulates the list value as the\nexpectation over sub-list values, weighted by user-specific exit probabilities\nat each position. The exit probability is decomposed into an interest-driven\ncomponent and a stochastic component, the latter modeled via a Weibull\ndistribution to capture random external factors such as fatigue. By jointly\nmodeling sub-list values and user exit behavior, CAVE yields a more faithful\nestimate of actual list consumption value. We further contribute three\nlarge-scale real-world list-wise benchmarks from the Kuaishou platform, varying\nin size and user activity patterns. Extensive experiments on these benchmarks,\ntwo Amazon datasets, and online A/B testing on Kuaishou show that CAVE\nconsistently outperforms strong baselines, highlighting the benefit of\nexplicitly modeling user exits in re-ranking.\n","authors":["Kaike Zhang","Xiaobei Wang","Xiaoyu Yang","Shuchang Liu","Hailan Yang","Xiang Li","Fei Sun","Qi Cao"],"pdf_url":"https://arxiv.org/pdf/2508.02242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05152v1","updated":"2025-08-07T08:36:26Z","published":"2025-08-07T08:36:26Z","title":"Tool Graph Retriever: Exploring Dependency Graph-based Tool Retrieval\n  for Large Language Models","summary":"  With the remarkable advancement of AI agents, the number of their equipped\ntools is increasing rapidly. However, integrating all tool information into the\nlimited model context becomes impractical, highlighting the need for efficient\ntool retrieval methods. In this regard, dominant methods primarily rely on\nsemantic similarities between tool descriptions and user queries to retrieve\nrelevant tools. However, they often consider each tool independently,\noverlooking dependencies between tools, which may lead to the omission of\nprerequisite tools for successful task execution. To deal with this defect, in\nthis paper, we propose Tool Graph Retriever (TGR), which exploits the\ndependencies among tools to learn better tool representations for retrieval.\nFirst, we construct a dataset termed TDI300K to train a discriminator for\nidentifying tool dependencies. Then, we represent all candidate tools as a tool\ndependency graph and use graph convolution to integrate the dependencies into\ntheir representations. Finally, these updated tool representations are employed\nfor online retrieval. Experimental results on several commonly used datasets\nshow that our TGR can bring a performance improvement to existing dominant\nmethods, achieving SOTA performance. Moreover, in-depth analyses also verify\nthe importance of tool dependencies and the effectiveness of our TGR.\n","authors":["Linfeng Gao","Yaoxiang Wang","Minlong Peng","Jialong Tang","Yuzhe Shang","Mingming Sun","Jinsong Su"],"pdf_url":"https://arxiv.org/pdf/2508.05152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.12871v3","updated":"2025-08-07T08:36:01Z","published":"2025-07-17T07:44:05Z","title":"Generative Multi-Target Cross-Domain Recommendation","summary":"  Recently, there has been a surge of interest in Multi-Target Cross-Domain\nRecommendation (MTCDR), which aims to enhance recommendation performance across\nmultiple domains simultaneously. Existing MTCDR methods primarily rely on\ndomain-shared entities (\\eg users or items) to fuse and transfer cross-domain\nknowledge, which may be unavailable in non-overlapped recommendation scenarios.\nSome studies model user preferences and item features as domain-sharable\nsemantic representations, which can be utilized to tackle the MTCDR task.\nNevertheless, they often require extensive auxiliary data for pre-training.\nDeveloping more effective solutions for MTCDR remains an important area for\nfurther exploration.\n  Inspired by recent advancements in generative recommendation, this paper\nintroduces GMC, a generative paradigm-based approach for multi-target\ncross-domain recommendation. The core idea of GMC is to leverage semantically\nquantized discrete item identifiers as a medium for integrating multi-domain\nknowledge within a unified generative model. GMC first employs an item\ntokenizer to generate domain-shared semantic identifiers for each item, and\nthen formulates item recommendation as a next-token generation task by training\na domain-unified sequence-to-sequence model. To further leverage the domain\ninformation to enhance performance, we incorporate a domain-aware contrastive\nloss into the semantic identifier learning, and perform domain-specific\nfine-tuning on the unified recommender. Extensive experiments on five public\ndatasets demonstrate the effectiveness of GMC compared to a range of baseline\nmethods.\n","authors":["Jinqiu Jin","Yang Zhang","Fuli Feng","Xiangnan He"],"pdf_url":"https://arxiv.org/pdf/2507.12871v3.pdf","comment":"fix some information by request"},{"id":"http://arxiv.org/abs/2504.10496v2","updated":"2025-08-07T08:26:02Z","published":"2025-04-06T05:00:10Z","title":"ArXivBench: When You Should Avoid Using ChatGPT for Academic Writing","summary":"  Large language models (LLMs) demonstrate strong capabilities in reasoning and\nquestion answering, yet their tendency to generate factually incorrect content\nremains a critical challenge. This study evaluates proprietary and open-source\nLLMs on generating relevant research papers with accurate arXiv links. Our\nevaluation reveals critical academic risks: LLMs frequently generate incorrect\narXiv links or references to non-existent papers, fundamentally undermining\ntheir ability to properly attribute research contributions to the actual\nauthors. We introduce arXivBench, a benchmark specifically designed to assess\nLLM performance across eight major subject categories on arXiv and five\nsubfields within computer science, one of the most popular categories among\nthem. Our findings show concerning accuracy variations across subjects, with\nClaude-3.5-Sonnet exhibiting a substantial advantage in generating both\nrelevant and accurate responses. Notably, most LLMs perform significantly\nbetter in Artificial Intelligence than other subfields. This benchmark provides\na standardized tool for evaluating LLM reliability in scientific contexts,\npromoting more dependable academic use in research environments. Our code and\ndataset are available at https://github.com/liningresearch/arXivBench and\nhttps://huggingface.co/datasets/arXivBenchLLM/arXivBench.\n","authors":["Ning Li","Jingran Zhang","Justin Cui"],"pdf_url":"https://arxiv.org/pdf/2504.10496v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05129v1","updated":"2025-08-07T08:08:13Z","published":"2025-08-07T08:08:13Z","title":"Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation\n  through Domain-Aware Retrieval and Latent Reasoning","summary":"  With the rapid and continuous increase in academic publications, identifying\nhigh-quality research has become an increasingly pressing challenge. While\nrecent methods leveraging Large Language Models (LLMs) for automated paper\nevaluation have shown great promise, they are often constrained by outdated\ndomain knowledge and limited reasoning capabilities. In this work, we present\nPaperEval, a novel LLM-based framework for automated paper evaluation that\naddresses these limitations through two key components: 1) a domain-aware paper\nretrieval module that retrieves relevant concurrent work to support\ncontextualized assessments of novelty and contributions, and 2) a latent\nreasoning mechanism that enables deep understanding of complex motivations and\nmethodologies, along with comprehensive comparison against concurrently related\nwork, to support more accurate and reliable evaluation. To guide the reasoning\nprocess, we introduce a progressive ranking optimization strategy that\nencourages the LLM to iteratively refine its predictions with an emphasis on\nrelative comparison. Experiments on two datasets demonstrate that PaperEval\nconsistently outperforms existing methods in both academic impact and paper\nquality evaluation. In addition, we deploy PaperEval in a real-world paper\nrecommendation system for filtering high-quality papers, which has gained\nstrong engagement on social media -- amassing over 8,000 subscribers and\nattracting over 10,000 views for many filtered high-quality papers --\ndemonstrating the practical effectiveness of PaperEval.\n","authors":["Wuqiang Zheng","Yiyan Xu","Xinyu Lin","Chongming Gao","Wenjie Wang","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2508.05129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2505.03407v2","updated":"2025-08-07T07:49:26Z","published":"2025-05-06T10:34:44Z","title":"CB-cPIR: Code-Based Computational Private Information Retrieval","summary":"  A private information retrieval (PIR) scheme is a protocol that allows a user\nto retrieve a file from a database without revealing the identity of the\ndesired file to a curious database. Given a distributed data storage system,\nefficient PIR can be achieved by making assumptions about the colluding\ncapabilities of the storage servers holding the database. If these assumptions\nturn out to be incorrect, privacy is lost. In this work, we focus on the\nworst-case assumption: full collusion or, equivalently, viewing the storage\nsystem virtually as a single honest-but-curious server. We present CB-cPIR, a\nsingle-server code-based computational private information retrieval (cPIR)\nscheme that derives security from code-based cryptography. Specifically, the\nqueries are protected by the hardness of decoding a random linear code. The\nscheme is heavily inspired by the pioneering code-based cPIR scheme proposed by\nHolzbaur, Hollanti, and Wachter-Zeh in [Holzbaur et al., \"Computational\nCode-Based Single-Server Private Information Retrieval\", 2020 IEEE ISIT] and\nfixes the vulnerabilities of the original scheme arising from highly probable\nrank differences in submatrices of the user's query. Recently, a new\nvulnerability was observed in [Lage, Bartz, \"On the Security of a Code-Based\nPIR Scheme\"], a simple modification to the scheme now fixes this vulnerability.\nFor further validation of our scheme, we draw comparisons to the\nstate-of-the-art lattice-based cPIR schemes.\n","authors":["Camilla Hollanti","Neehar Verma"],"pdf_url":"https://arxiv.org/pdf/2505.03407v2.pdf","comment":"This paper builds on the work done in arXiv: 2402.02871v1 (IEEE\n  ISIT24) and arXiv: 2001.07049 (IEEE ISIT20) Remark 6. briefly outlines a fix\n  to a new attack, this paper will soon be updated to reflect the changes to\n  the scheme"},{"id":"http://arxiv.org/abs/2508.05107v1","updated":"2025-08-07T07:42:45Z","published":"2025-08-07T07:42:45Z","title":"Community-Aware Social Community Recommendation","summary":"  Social recommendation, which seeks to leverage social ties among users to\nalleviate the sparsity issue of user-item interactions, has emerged as a\npopular technique for elevating personalized services in recommender systems.\nDespite being effective, existing social recommendation models are mainly\ndevised for recommending regular items such as blogs, images, and products, and\nlargely fail for community recommendations due to overlooking the unique\ncharacteristics of communities. Distinctly, communities are constituted by\nindividuals, who present high dynamicity and relate to rich structural patterns\nin social networks. To our knowledge, limited research has been devoted to\ncomprehensively exploiting this information for recommending communities.\n  To bridge this gap, this paper presents CASO, a novel and effective model\nspecially designed for social community recommendation. Under the hood, CASO\nharnesses three carefully-crafted encoders for user embedding, wherein two of\nthem extract community-related global and local structures from the social\nnetwork via social modularity maximization and social closeness aggregation,\nwhile the third one captures user preferences using collaborative filtering\nwith observed user-community affiliations. To further eliminate feature\nredundancy therein, we introduce a mutual exclusion between social and\ncollaborative signals. Finally, CASO includes a community detection loss in the\nmodel optimization, thereby producing community-aware embeddings for\ncommunities. Our extensive experiments evaluating CASO against nine strong\nbaselines on six real-world social networks demonstrate its consistent and\nremarkable superiority over the state of the art in terms of community\nrecommendation performance.\n","authors":["Runhao Jiang","Renchi Yang","Wenqing Lin"],"pdf_url":"https://arxiv.org/pdf/2508.05107v1.pdf","comment":"This is the technical report of the paper \"Community-Aware Social\n  Community Recommendation\" accepted by CIKM 2025"},{"id":"http://arxiv.org/abs/2508.05093v1","updated":"2025-08-07T07:21:46Z","published":"2025-08-07T07:21:46Z","title":"An End-to-End Multi-objective Ensemble Ranking Framework for Video\n  Recommendation","summary":"  We propose a novel End-to-end Multi-objective Ensemble Ranking framework\n(EMER) for the multi-objective ensemble ranking module, which is the most\ncritical component of the short video recommendation system. EMER enhances\npersonalization by replacing manually-designed heuristic formulas with an\nend-to-end modeling paradigm. EMER introduces a meticulously designed loss\nfunction to address the fundamental challenge of defining effective supervision\nfor ensemble ranking, where no single ground-truth signal can fully capture\nuser satisfaction. Moreover, EMER introduces novel sample organization method\nand transformer-based network architecture to capture the comparative\nrelationships among candidates, which are critical for effective ranking.\nAdditionally, we have proposed an offline-online consistent evaluation system\nto enhance the efficiency of offline model optimization, which is an\nestablished yet persistent challenge within the multi-objective ranking domain\nin industry. Abundant empirical tests are conducted on a real industrial\ndataset, and the results well demonstrate the effectiveness of our proposed\nframework. In addition, our framework has been deployed in the primary\nscenarios of Kuaishou, a short video recommendation platform with hundreds of\nmillions of daily active users, achieving a 1.39% increase in overall App Stay\nTime and a 0.196% increase in 7-day user Lifetime(LT7), which are substantial\nimprovements.\n","authors":["Tiantian He","Minzhi Xie","Runtong Li","Xiaoxiao Xu","Jiaqi Yu","Zixiu Wang","Lantao Hu","Han Li","Kun Gai"],"pdf_url":"https://arxiv.org/pdf/2508.05093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.10512v3","updated":"2025-08-07T07:13:59Z","published":"2025-04-10T01:31:11Z","title":"JEPA4Rec: Learning Effective Language Representations for Sequential\n  Recommendation via Joint Embedding Predictive Architecture","summary":"  Language representation learning has emerged as a promising approach for\nsequential recommendation, thanks to its ability to learn generalizable\nrepresentations. However, despite its advantages, this approach still struggles\nwith data sparsity and a limited understanding of common-sense user\npreferences. To address these limitations, we propose $\\textbf{JEPA4Rec}$, a\nframework that combines $\\textbf{J}$oint $\\textbf{E}$mbedding\n$\\textbf{P}$redictive $\\textbf{A}$rchitecture with language modeling of item\ntextual descriptions. JEPA4Rec captures semantically rich and transferable\nrepresentations, improving recommendation performance and reducing reliance on\nlarge-scale pre-training data. Specifically, JEPA4Rec represents items as text\nsentences by flattening descriptive information such as $\\textit{title,\ncategory}$, and other attributes. To encode these sentences, we employ a\nbidirectional Transformer encoder with modified embedding layers tailored for\ncapturing item information in recommendation datasets. We apply masking to text\nsentences and use them to predict the representations of the unmasked\nsentences, helping the model learn generalizable item embeddings. To further\nimprove recommendation performance and language understanding, we employ a\ntwo-stage training strategy incorporating self-supervised learning losses.\nExperiments on six real-world datasets demonstrate that JEPA4Rec consistently\noutperforms state-of-the-art methods, particularly in cross-domain,\ncross-platform, and low-resource scenarios.\n","authors":["Minh-Anh Nguyen","Dung D. Le"],"pdf_url":"https://arxiv.org/pdf/2504.10512v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05074v1","updated":"2025-08-07T07:00:29Z","published":"2025-08-07T07:00:29Z","title":"Align-for-Fusion: Harmonizing Triple Preferences via Dual-oriented\n  Diffusion for Cross-domain Sequential Recommendation","summary":"  Personalized sequential recommendation aims to predict appropriate items for\nusers based on their behavioral sequences. To alleviate data sparsity and\ninterest drift issues, conventional approaches typically incorporate auxiliary\nbehaviors from other domains via cross-domain transition. However, existing\ncross-domain sequential recommendation (CDSR) methods often follow an\nalign-then-fusion paradigm that performs representation-level alignment across\nmultiple domains and combines them mechanically for recommendation, overlooking\nthe fine-grained fusion of domain-specific preferences. Inspired by recent\nadvances in diffusion models (DMs) for distribution matching, we propose an\nalign-for-fusion framework for CDSR to harmonize triple preferences via\ndual-oriented DMs, termed HorizonRec. Specifically, we investigate the\nuncertainty injection of DMs and identify stochastic noise as a key source of\ninstability in existing DM-based recommenders. To address this, we introduce a\nmixed-conditioned distribution retrieval strategy that leverages distributions\nretrieved from users' authentic behavioral logic as semantic bridges across\ndomains, enabling consistent multi-domain preference modeling. Furthermore, we\npropose a dual-oriented preference diffusion method to suppress potential noise\nand emphasize target-relevant interests during multi-domain user representation\nfusion. Extensive experiments on four CDSR datasets from two distinct platforms\ndemonstrate the effectiveness and robustness of HorizonRec in fine-grained\ntriple-domain preference fusion.\n","authors":["Yongfu Zha","Xinxin Dong","Haokai Ma","Yonghui Yang","Xiaodong Wang"],"pdf_url":"https://arxiv.org/pdf/2508.05074v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05061v1","updated":"2025-08-07T06:28:16Z","published":"2025-08-07T06:28:16Z","title":"Data-Aware Socratic Query Refinement in Database Systems","summary":"  In this paper, we propose Data-Aware Socratic Guidance (DASG), a\ndialogue-based query enhancement framework that embeds \\linebreak interactive\nclarification as a first-class operator within database systems to resolve\nambiguity in natural language queries. DASG treats dialogue as an optimization\ndecision, asking clarifying questions only when the expected execution cost\nreduction exceeds the interaction overhead. The system quantifies ambiguity\nthrough linguistic fuzziness, schema grounding confidence, and projected costs\nacross relational and vector backends. Our algorithm selects the optimal\nclarifications by combining semantic relevance, catalog-based information gain,\nand potential cost reduction. We evaluate our proposed framework on three\ndatasets. The results show that DASG demonstrates improved query precision\nwhile maintaining efficiency, establishing a cooperative analytics paradigm\nwhere systems actively participate in query formulation rather than passively\ntranslating user requests.\n","authors":["Ruiyuan Zhang","Chrysanthi Kosyfaki","Xiaofang Zhou"],"pdf_url":"https://arxiv.org/pdf/2508.05061v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.03016v2","updated":"2025-08-07T03:48:34Z","published":"2025-08-05T02:52:15Z","title":"KBest: Efficient Vector Search on Kunpeng CPU","summary":"  Vector search, which returns the vectors most similar to a given query vector\nfrom a large vector dataset, underlies many important applications such as\nsearch, recommendation, and LLMs. To be economic, vector search needs to be\nefficient to reduce the resources required by a given query workload. However,\nexisting vector search libraries (e.g., Faiss and DiskANN) are optimized for\nx86 CPU architectures (i.e., Intel and AMD CPUs) while Huawei Kunpeng CPUs are\nbased on the ARM architecture and competitive in compute power. In this paper,\nwe present KBest as a vector search library tailored for the latest Kunpeng 920\nCPUs. To be efficient, KBest incorporates extensive hardware-aware and\nalgorithmic optimizations, which include single-instruction-multiple-data\n(SIMD) accelerated distance computation, data prefetch, index refinement, early\ntermination, and vector quantization. Experiment results show that KBest\noutperforms SOTA vector search libraries running on x86 CPUs, and our\noptimizations can improve the query throughput by over 2x. Currently, KBest\nserves applications from both our internal business and external enterprise\nclients with tens of millions of queries on a daily basis.\n","authors":["Kaihao Ma","Meiling Wang","Senkevich Oleg","Zijian Li","Daihao Xue","Dmitriy Malyshev","Yangming Lv","Shihai Xiao","Xiao Yan","Radionov Alexander","Weidi Zeng","Yuanzhan Gao","Zhiyu Zou","Xin Yao","Lin Liu","Junhao Wu","Yiding Liu","Yaoyao Fu","Gongyi Wang","Gong Zhang","Fei Yi","Yingfan Liu"],"pdf_url":"https://arxiv.org/pdf/2508.03016v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04162v2","updated":"2025-08-07T03:27:21Z","published":"2025-08-06T07:39:17Z","title":"SSEmb: A Joint Structural and Semantic Embedding Framework for\n  Mathematical Formula Retrieval","summary":"  Formula retrieval is an important topic in Mathematical Information\nRetrieval. We propose SSEmb, a novel embedding framework capable of capturing\nboth structural and semantic features of mathematical formulas. Structurally,\nwe employ Graph Contrastive Learning to encode formulas represented as Operator\nGraphs. To enhance structural diversity while preserving mathematical validity\nof these formula graphs, we introduce a novel graph data augmentation approach\nthrough a substitution strategy. Semantically, we utilize Sentence-BERT to\nencode the surrounding text of formulas. Finally, for each query and its\ncandidates, structural and semantic similarities are calculated separately and\nthen fused through a weighted scheme. In the ARQMath-3 formula retrieval task,\nSSEmb outperforms existing embedding-based methods by over 5 percentage points\non P'@10 and nDCG'@10. Furthermore, SSEmb enhances the performance of all runs\nof other methods and achieves state-of-the-art results when combined with\nApproach0.\n","authors":["Ruyin Li","Xiaoyu Chen"],"pdf_url":"https://arxiv.org/pdf/2508.04162v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06590v2","updated":"2025-08-07T03:12:19Z","published":"2023-06-11T04:51:29Z","title":"Mean-Variance Efficient Collaborative Filtering for Stock Recommendation","summary":"  The rise of FinTech has transformed financial services onto online platforms,\nyet stock investment recommender systems have received limited attention\ncompared to other industries. Personalized stock recommendations can\nsignificantly impact customer engagement and satisfaction within the industry.\nHowever, traditional investment recommendations focus on high-return stocks or\nhighly diversified portfolios based on the modern portfolio theory, often\nneglecting user preferences. On the other hand, collaborative filtering (CF)\nmethods also may not be directly applicable to stock recommendations, because\nit is inappropriate to just recommend stocks that users like. The key is to\noptimally blend users preference with the portfolio theory. However, research\non stock recommendations within the recommender system domain remains\ncomparatively limited, and no existing model considers both the preference of\nusers and the risk-return characteristics of stocks. In this regard, we propose\na mean-variance efficient collaborative filtering (MVECF) model for stock\nrecommendations that consider both aspects. Our model is specifically designed\nto improve the pareto optimality (mean-variance efficiency) in a trade-off\nbetween the risk (variance of return) and return (mean return) by systemically\nhandling uncertainties in stock prices. Such improvements are incorporated into\nthe MVECF model using regularization, and the model is restructured to fit into\nthe ordinary matrix factorization scheme to boost computational efficiency.\nExperiments on real-world fund holdings data show that our model can increase\nthe mean-variance efficiency of suggested portfolios while sacrificing just a\nsmall amount of mean average precision and recall. Finally, we further show\nMVECF is easily applicable to the state-of-the-art graph-based ranking models.\n","authors":["Munki Chung","Junhyeong Lee","Yongjae Lee","Woo Chang Kim"],"pdf_url":"https://arxiv.org/pdf/2306.06590v2.pdf","comment":"12 pages, 4 figures, preprint, under review"},{"id":"http://arxiv.org/abs/2508.04963v1","updated":"2025-08-07T01:21:51Z","published":"2025-08-07T01:21:51Z","title":"A Metric for MLLM Alignment in Large-scale Recommendation","summary":"  Multimodal recommendation has emerged as a critical technique in modern\nrecommender systems, leveraging content representations from advanced\nmultimodal large language models (MLLMs). To ensure these representations are\nwell-adapted, alignment with the recommender system is essential. However,\nevaluating the alignment of MLLMs for recommendation presents significant\nchallenges due to three key issues: (1) static benchmarks are inaccurate\nbecause of the dynamism in real-world applications, (2) evaluations with online\nsystem, while accurate, are prohibitively expensive at scale, and (3)\nconventional metrics fail to provide actionable insights when learned\nrepresentations underperform. To address these challenges, we propose the\nLeakage Impact Score (LIS), a novel metric for multimodal recommendation.\nRather than directly assessing MLLMs, LIS efficiently measures the upper bound\nof preference data. We also share practical insights on deploying MLLMs with\nLIS in real-world scenarios. Online A/B tests on both Content Feed and Display\nAds of Xiaohongshu's Explore Feed production demonstrate the effectiveness of\nour proposed method, showing significant improvements in user spent time and\nadvertiser value.\n","authors":["Yubin Zhang","Yanhua Huang","Haiming Xu","Mingliang Qi","Chang Wang","Jiarui Jin","Xiangyuan Ren","Xiaodan Wang","Ruiwen Xu"],"pdf_url":"https://arxiv.org/pdf/2508.04963v1.pdf","comment":"Pre-print.Under Review"},{"id":"http://arxiv.org/abs/2504.14147v2","updated":"2025-08-07T00:57:22Z","published":"2025-04-19T02:46:10Z","title":"Explainable Recommendation with Simulated Human Feedback","summary":"  Recent advancements in explainable recommendation have greatly bolstered user\nexperience by elucidating the decision-making rationale. However, the existing\nmethods actually fail to provide effective feedback signals for potentially\nbetter or worse generated explanations due to their reliance on traditional\nsupervised learning paradigms in sparse interaction data. To address these\nissues, we propose a novel human-like feedback-driven optimization framework.\nThis framework employs a dynamic interactive optimization mechanism for\nachieving human-centered explainable requirements without incurring high labor\ncosts. Specifically, we propose to utilize large language models (LLMs) as\nhuman simulators to predict human-like feedback for guiding the learning\nprocess. To enable the LLMs to deeply understand the task essence and meet\nuser's diverse personalized requirements, we introduce a human-induced\ncustomized reward scoring method, which helps stimulate the language\nunderstanding and logical reasoning capabilities of LLMs. Furthermore,\nconsidering the potential conflicts between different perspectives of\nexplanation quality, we introduce a principled Pareto optimization that\ntransforms the multi-perspective quality enhancement task into a\nmulti-objective optimization problem for improving explanation performance. At\nlast, to achieve efficient model training, we design an off-policy optimization\npipeline. By incorporating a replay buffer and addressing the data distribution\nbiases, we can effectively improve data utilization and enhance model\ngenerality. Extensive experiments on four datasets demonstrate the superiority\nof our approach.\n","authors":["Jiakai Tang","Jingsen Zhang","Zihang Tian","Xueyang Feng","Lei Wang","Xu Chen"],"pdf_url":"https://arxiv.org/pdf/2504.14147v2.pdf","comment":null}],"Machine Learning":[{"id":"http://arxiv.org/abs/2508.05634v1","updated":"2025-08-07T17:59:43Z","published":"2025-08-07T17:59:43Z","title":"Towards Generalizable Safety in Crowd Navigation via Conformal\n  Uncertainty Handling","summary":"  Mobile robots navigating in crowds trained using reinforcement learning are\nknown to suffer performance degradation when faced with out-of-distribution\nscenarios. We propose that by properly accounting for the uncertainties of\npedestrians, a robot can learn safe navigation policies that are robust to\ndistribution shifts. Our method augments agent observations with prediction\nuncertainty estimates generated by adaptive conformal inference, and it uses\nthese estimates to guide the agent's behavior through constrained reinforcement\nlearning. The system helps regulate the agent's actions and enables it to adapt\nto distribution shifts. In the in-distribution setting, our approach achieves a\n96.93% success rate, which is over 8.80% higher than the previous\nstate-of-the-art baselines with over 3.72 times fewer collisions and 2.43 times\nfewer intrusions into ground-truth human future trajectories. In three\nout-of-distribution scenarios, our method shows much stronger robustness when\nfacing distribution shifts in velocity variations, policy changes, and\ntransitions from individual to group dynamics. We deploy our method on a real\nrobot, and experiments show that the robot makes safe and robust decisions when\ninteracting with both sparse and dense crowds. Our code and videos are\navailable on https://gen-safe-nav.github.io/.\n","authors":["Jianpeng Yao","Xiaopan Zhang","Yu Xia","Zejin Wang","Amit K. Roy-Chowdhury","Jiachen Li"],"pdf_url":"https://arxiv.org/pdf/2508.05634v1.pdf","comment":"9th Conference on Robot Learning (CoRL 2025); Project website:\n  https://gen-safe-nav.github.io/. arXiv admin note: text overlap with\n  arXiv:2407.17460"},{"id":"http://arxiv.org/abs/2507.15857v5","updated":"2025-08-07T17:59:38Z","published":"2025-07-21T17:59:57Z","title":"Diffusion Beats Autoregressive in Data-Constrained Settings","summary":"  Autoregressive (AR) models have long dominated the landscape of large\nlanguage models, driving progress across a wide range of tasks. Recently,\ndiffusion-based language models have emerged as a promising alternative, though\ntheir advantages over AR models remain underexplored. In this paper, we\nsystematically study masked diffusion models in data-constrained settings-where\ntraining involves repeated passes over limited data-and find that they\nsignificantly outperform AR models when compute is abundant but data is scarce.\nDiffusion models make better use of repeated data, achieving lower validation\nloss and superior downstream performance. We interpret this advantage as\nimplicit data augmentation: masked diffusion exposes the model to a diverse\ndistribution of token orderings and prediction tasks, unlike AR's fixed\nleft-to-right factorization. We find new scaling laws for diffusion models and\nderive a closed-form expression for the critical compute threshold at which\ndiffusion begins to outperform AR. These results suggest that when data, not\ncompute, is the bottleneck, diffusion models offer a compelling alternative to\nthe standard AR paradigm. Our code is available at:\nhttps://diffusion-scaling.github.io.\n","authors":["Mihir Prabhudesai","Mengning Wu","Amir Zadeh","Katerina Fragkiadaki","Deepak Pathak"],"pdf_url":"https://arxiv.org/pdf/2507.15857v5.pdf","comment":"Project Webpage: https://diffusion-scaling.github.io"},{"id":"http://arxiv.org/abs/2508.05629v1","updated":"2025-08-07T17:59:04Z","published":"2025-08-07T17:59:04Z","title":"On the Generalization of SFT: A Reinforcement Learning Perspective with\n  Reward Rectification","summary":"  We present a simple yet theoretically motivated improvement to Supervised\nFine-Tuning (SFT) for the Large Language Model (LLM), addressing its limited\ngeneralization compared to reinforcement learning (RL). Through mathematical\nanalysis, we reveal that standard SFT gradients implicitly encode a problematic\nreward structure that may severely restrict the generalization capabilities of\nmodel. To rectify this, we propose Dynamic Fine-Tuning (DFT), stabilizing\ngradient updates for each token by dynamically rescaling the objective function\nwith the probability of this token. Remarkably, this single-line code change\nsignificantly outperforms standard SFT across multiple challenging benchmarks\nand base models, demonstrating greatly improved generalization. Additionally,\nour approach shows competitive results in offline RL settings, offering an\neffective yet simpler alternative. This work bridges theoretical insight and\npractical solutions, substantially advancing SFT performance. The code will be\navailable at https://github.com/yongliang-wu/DFT.\n","authors":["Yongliang Wu","Yizhou Zhou","Zhou Ziheng","Yingzhe Peng","Xinyu Ye","Xinting Hu","Wenbo Zhu","Lu Qi","Ming-Hsuan Yang","Xu Yang"],"pdf_url":"https://arxiv.org/pdf/2508.05629v1.pdf","comment":"14 pages, 3 figures"},{"id":"http://arxiv.org/abs/2508.05625v1","updated":"2025-08-07T17:58:41Z","published":"2025-08-07T17:58:41Z","title":"How Do LLMs Persuade? Linear Probes Can Uncover Persuasion Dynamics in\n  Multi-Turn Conversations","summary":"  Large Language Models (LLMs) have started to demonstrate the ability to\npersuade humans, yet our understanding of how this dynamic transpires is\nlimited. Recent work has used linear probes, lightweight tools for analyzing\nmodel representations, to study various LLM skills such as the ability to model\nuser sentiment and political perspective. Motivated by this, we apply probes to\nstudy persuasion dynamics in natural, multi-turn conversations. We leverage\ninsights from cognitive science to train probes on distinct aspects of\npersuasion: persuasion success, persuadee personality, and persuasion strategy.\nDespite their simplicity, we show that they capture various aspects of\npersuasion at both the sample and dataset levels. For instance, probes can\nidentify the point in a conversation where the persuadee was persuaded or where\npersuasive success generally occurs across the entire dataset. We also show\nthat in addition to being faster than expensive prompting-based approaches,\nprobes can do just as well and even outperform prompting in some settings, such\nas when uncovering persuasion strategy. This suggests probes as a plausible\navenue for studying other complex behaviours such as deception and\nmanipulation, especially in multi-turn settings and large-scale dataset\nanalysis where prompting-based methods would be computationally inefficient.\n","authors":["Brandon Jaipersaud","David Krueger","Ekdeep Singh Lubana"],"pdf_url":"https://arxiv.org/pdf/2508.05625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05616v1","updated":"2025-08-07T17:55:10Z","published":"2025-08-07T17:55:10Z","title":"TrajEvo: Trajectory Prediction Heuristics Design via LLM-driven\n  Evolution","summary":"  Trajectory prediction is a critical task in modeling human behavior,\nespecially in safety-critical domains such as social robotics and autonomous\nvehicle navigation. Traditional heuristics based on handcrafted rules often\nlack accuracy and generalizability. Although deep learning approaches offer\nimproved performance, they typically suffer from high computational cost,\nlimited explainability, and, importantly, poor generalization to\nout-of-distribution (OOD) scenarios. In this paper, we introduce TrajEvo, a\nframework that leverages Large Language Models (LLMs) to automatically design\ntrajectory prediction heuristics. TrajEvo employs an evolutionary algorithm to\ngenerate and refine prediction heuristics from past trajectory data. We propose\ntwo key innovations: Cross-Generation Elite Sampling to encourage population\ndiversity, and a Statistics Feedback Loop that enables the LLM to analyze and\nimprove alternative predictions. Our evaluations demonstrate that TrajEvo\noutperforms existing heuristic methods across multiple real-world datasets, and\nnotably surpasses both heuristic and deep learning methods in generalizing to\nan unseen OOD real-world dataset. TrajEvo marks a promising step toward the\nautomated design of fast, explainable, and generalizable trajectory prediction\nheuristics. We release our source code to facilitate future research at\nhttps://github.com/ai4co/trajevo.\n","authors":["Zhikai Zhao","Chuanbo Hua","Federico Berto","Kanghoon Lee","Zihan Ma","Jiachen Li","Jinkyoo Park"],"pdf_url":"https://arxiv.org/pdf/2508.05616v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2505.04480"},{"id":"http://arxiv.org/abs/2508.05612v1","updated":"2025-08-07T17:53:47Z","published":"2025-08-07T17:53:47Z","title":"Shuffle-R1: Efficient RL framework for Multimodal Large Language Models\n  via Data-centric Dynamic Shuffle","summary":"  Reinforcement learning (RL) has emerged as an effective post-training\nparadigm for enhancing the reasoning capabilities of multimodal large language\nmodel (MLLM). However, current RL pipelines often suffer from training\ninefficiencies caused by two underexplored issues: Advantage Collapsing, where\nmost advantages in a batch concentrate near zero, and Rollout Silencing, where\nthe proportion of rollouts contributing non-zero gradients diminishes over\ntime. These issues lead to suboptimal gradient updates and hinder long-term\nlearning efficiency. To address these issues, we propose Shuffle-R1, a simple\nyet principled framework that improves RL fine-tuning efficiency by dynamically\nrestructuring trajectory sampling and batch composition. It introduces (1)\nPairwise Trajectory Sampling, which selects high-contrast trajectories with\nlarge advantages to improve gradient signal quality, and (2) Advantage-based\nTrajectory Shuffle, which increases exposure of valuable rollouts through\ninformed batch reshuffling. Experiments across multiple reasoning benchmarks\nshow that our framework consistently outperforms strong RL baselines with\nminimal overhead. These results highlight the importance of data-centric\nadaptations for more efficient RL training in MLLM.\n","authors":["Linghao Zhu","Yiran Guan","Dingkang Liang","Jianzhong Ju","Zhenbo Luo","Bin Qin","Jian Luan","Yuliang Liu","Xiang Bai"],"pdf_url":"https://arxiv.org/pdf/2508.05612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05600v1","updated":"2025-08-07T17:41:33Z","published":"2025-08-07T17:41:33Z","title":"Non-omniscient backdoor injection with a single poison sample: Proving\n  the one-poison hypothesis for linear regression and linear classification","summary":"  Backdoor injection attacks are a threat to machine learning models that are\ntrained on large data collected from untrusted sources; these attacks enable\nattackers to inject malicious behavior into the model that can be triggered by\nspecially crafted inputs. Prior work has established bounds on the success of\nbackdoor attacks and their impact on the benign learning task, however, an open\nquestion is what amount of poison data is needed for a successful backdoor\nattack. Typical attacks either use few samples, but need much information about\nthe data points or need to poison many data points.\n  In this paper, we formulate the one-poison hypothesis: An adversary with one\npoison sample and limited background knowledge can inject a backdoor with zero\nbackdooring-error and without significantly impacting the benign learning task\nperformance. Moreover, we prove the one-poison hypothesis for linear regression\nand linear classification. For adversaries that utilize a direction that is\nunused by the benign data distribution for the poison sample, we show that the\nresulting model is functionally equivalent to a model where the poison was\nexcluded from training. We build on prior work on statistical backdoor learning\nto show that in all other cases, the impact on the benign learning task is\nstill limited. We also validate our theoretical results experimentally with\nrealistic benchmark data sets.\n","authors":["Thorsten Peinemann","Paula Arnold","Sebastian Berndt","Thomas Eisenbarth","Esfandiar Mohammadi"],"pdf_url":"https://arxiv.org/pdf/2508.05600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.17537v2","updated":"2025-08-07T17:33:41Z","published":"2024-06-25T13:21:01Z","title":"SincVAE: A new semi-supervised approach to improve anomaly detection on\n  EEG data using SincNet and variational autoencoder","summary":"  Over the past few decades, electroencephalography (EEG) monitoring has become\na pivotal tool for diagnosing neurological disorders, particularly for\ndetecting seizures. Epilepsy, one of the most prevalent neurological diseases\nworldwide, affects approximately the 1 \\% of the population. These patients\nface significant risks, underscoring the need for reliable, continuous seizure\nmonitoring in daily life. Most of the techniques discussed in the literature\nrely on supervised Machine Learning (ML) methods. However, the challenge of\naccurately labeling variations in epileptic EEG waveforms complicates the use\nof these approaches. Additionally, the rarity of ictal events introduces an\nhigh imbalancing within the data, which could lead to poor prediction\nperformance in supervised learning approaches. Instead, a semi-supervised\napproach allows to train the model only on data not containing seizures, thus\navoiding the issues related to the data imbalancing. This work proposes a\nsemi-supervised approach for detecting epileptic seizures from EEG data,\nutilizing a novel Deep Learning-based method called SincVAE. This proposal\nincorporates the learning of an ad-hoc array of bandpass filter as a first\nlayer of a Variational Autoencoder (VAE), potentially eliminating the\npreprocessing stage where informative band frequencies are identified and\nisolated. Results indicate that SincVAE improves seizure detection in EEG data\nand is capable of identifying early seizures during the preictal stage as well\nas monitoring patients throughout the postictal stage.\n","authors":["Andrea Pollastro","Francesco Isgrò","Roberto Prevete"],"pdf_url":"https://arxiv.org/pdf/2406.17537v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05591v1","updated":"2025-08-07T17:29:10Z","published":"2025-08-07T17:29:10Z","title":"Optimizing IoT Threat Detection with Kolmogorov-Arnold Networks (KANs)","summary":"  The exponential growth of the Internet of Things (IoT) has led to the\nemergence of substantial security concerns, with IoT networks becoming the\nprimary target for cyberattacks. This study examines the potential of\nKolmogorov-Arnold Networks (KANs) as an alternative to conventional machine\nlearning models for intrusion detection in IoT networks. The study demonstrates\nthat KANs, which employ learnable activation functions, outperform traditional\nMLPs and achieve competitive accuracy compared to state-of-the-art models such\nas Random Forest and XGBoost, while offering superior interpretability for\nintrusion detection in IoT networks.\n","authors":["Natalia Emelianova","Carlos Kamienski","Ronaldo C. Prati"],"pdf_url":"https://arxiv.org/pdf/2508.05591v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2508.05587v1","updated":"2025-08-07T17:24:34Z","published":"2025-08-07T17:24:34Z","title":"Enhancing PyKEEN with Multiple Negative Sampling Solutions for Knowledge\n  Graph Embedding Models","summary":"  Embedding methods have become popular due to their scalability on link\nprediction and/or triple classification tasks on Knowledge Graphs. Embedding\nmodels are trained relying on both positive and negative samples of triples.\nHowever, in the absence of negative assertions, these must be usually\nartificially generated using various negative sampling strategies, ranging from\nrandom corruption to more sophisticated techniques which have an impact on the\noverall performance. Most of the popular libraries for knowledge graph\nembedding, support only basic such strategies and lack advanced solutions. To\naddress this gap, we deliver an extension for the popular KGE framework PyKEEN\nthat integrates a suite of several advanced negative samplers (including both\nstatic and dynamic corruption strategies), within a consistent modular\narchitecture, to generate meaningful negative samples, while remaining\ncompatible with existing PyKEEN -based workflows and pipelines. The developed\nextension not only enhancesPyKEEN itself but also allows for easier and\ncomprehensive development of embedding methods and/or for their customization.\nAs a proof of concept, we present a comprehensive empirical study of the\ndeveloped extensions and their impact on the performance (link prediction\ntasks) of different embedding methods, which also provides useful insights for\nthe design of more effective strategies\n","authors":["Claudia d'Amato","Ivan Diliso","Nicola Fanizzi","Zafar Saeed"],"pdf_url":"https://arxiv.org/pdf/2508.05587v1.pdf","comment":"18 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.05106v3","updated":"2025-08-07T17:17:05Z","published":"2024-10-07T15:02:48Z","title":"Nonasymptotic Analysis of Stochastic Gradient Descent with the\n  Richardson-Romberg Extrapolation","summary":"  We address the problem of solving strongly convex and smooth minimization\nproblems using stochastic gradient descent (SGD) algorithm with a constant step\nsize. Previous works suggested to combine the Polyak-Ruppert averaging\nprocedure with the Richardson-Romberg extrapolation to reduce the asymptotic\nbias of SGD at the expense of a mild increase of the variance. We significantly\nextend previous results by providing an expansion of the mean-squared error of\nthe resulting estimator with respect to the number of iterations $n$. We show\nthat the root mean-squared error can be decomposed into the sum of two terms: a\nleading one of order $\\mathcal{O}(n^{-1/2})$ with explicit dependence on a\nminimax-optimal asymptotic covariance matrix, and a second-order term of order\n$\\mathcal{O}(n^{-3/4})$, where the power $3/4$ is best known. We also extend\nthis result to the higher-order moment bounds. Our analysis relies on the\nproperties of the SGD iterates viewed as a time-homogeneous Markov chain. In\nparticular, we establish that this chain is geometrically ergodic with respect\nto a suitably defined weighted Wasserstein semimetric.\n","authors":["Marina Sheshukova","Denis Belomestny","Alain Durmus","Eric Moulines","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2410.05106v3.pdf","comment":"ICLR-2025, camera-ready version. Some typos and definitions of\n  constants have been fixed in the appendix"},{"id":"http://arxiv.org/abs/2508.05581v1","updated":"2025-08-07T17:15:17Z","published":"2025-08-07T17:15:17Z","title":"Iterative Learning of Computable Phenotypes for Treatment Resistant\n  Hypertension using Large Language Models","summary":"  Large language models (LLMs) have demonstrated remarkable capabilities for\nmedical question answering and programming, but their potential for generating\ninterpretable computable phenotypes (CPs) is under-explored. In this work, we\ninvestigate whether LLMs can generate accurate and concise CPs for six clinical\nphenotypes of varying complexity, which could be leveraged to enable scalable\nclinical decision support to improve care for patients with hypertension. In\naddition to evaluating zero-short performance, we propose and test a\nsynthesize, execute, debug, instruct strategy that uses LLMs to generate and\niteratively refine CPs using data-driven feedback. Our results show that LLMs,\ncoupled with iterative learning, can generate interpretable and reasonably\naccurate programs that approach the performance of state-of-the-art ML methods\nwhile requiring significantly fewer training examples.\n","authors":["Guilherme Seidyo Imai Aldeia","Daniel S. Herman","William G. La Cava"],"pdf_url":"https://arxiv.org/pdf/2508.05581v1.pdf","comment":"To appear in PMLR, Volume 298, Machine Learning for Healthcare, 2025"},{"id":"http://arxiv.org/abs/2506.05252v2","updated":"2025-08-07T17:13:46Z","published":"2025-06-05T17:13:59Z","title":"Conservative classifiers do consistently well with improving agents:\n  characterizing statistical and online learning","summary":"  Machine learning is now ubiquitous in societal decision-making, for example\nin evaluating job candidates or loan applications, and it is increasingly\nimportant to take into account how classified agents will react to the learning\nalgorithms. The majority of recent literature on strategic classification has\nfocused on reducing and countering deceptive behaviors by the classified\nagents, but recent work of Attias et al. identifies surprising properties of\nlearnability when the agents genuinely improve in order to attain the desirable\nclassification, such as smaller generalization error than standard\nPAC-learning. In this paper we characterize so-called learnability with\nimprovements across multiple new axes. We introduce an asymmetric variant of\nminimally consistent concept classes and use it to provide an exact\ncharacterization of proper learning with improvements in the realizable\nsetting. While prior work studies learnability only under general, arbitrary\nagent improvement regions, we give positive results for more natural Euclidean\nball improvement sets. In particular, we characterize improper learning under a\nmild generative assumption on the data distribution. We further show how to\nlearn in more challenging settings, achieving lower generalization error under\nwell-studied bounded noise models and obtaining mistake bounds in realizable\nand agnostic online learning. We resolve open questions posed by Attias et al.\nfor both proper and improper learning.\n","authors":["Dravyansh Sharma","Alec Sun"],"pdf_url":"https://arxiv.org/pdf/2506.05252v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2507.20446v2","updated":"2025-08-07T17:12:27Z","published":"2025-07-28T00:30:07Z","title":"BOASF: A Unified Framework for Speeding up Automatic Machine Learning\n  via Adaptive Successive Filtering","summary":"  Machine learning has been making great success in many application areas.\nHowever, for the non-expert practitioners, it is always very challenging to\naddress a machine learning task successfully and efficiently. Finding the\noptimal machine learning model or the hyperparameter combination set from a\nlarge number of possible alternatives usually requires considerable expert\nknowledge and experience. To tackle this problem, we propose a combined\nBayesian Optimization and Adaptive Successive Filtering algorithm (BOASF) under\na unified multi-armed bandit framework to automate the model selection or the\nhyperparameter optimization. Specifically, BOASF consists of multiple\nevaluation rounds in each of which we select promising configurations for each\narm using the Bayesian optimization. Then, ASF can early discard the\npoor-performed arms adaptively using a Gaussian UCB-based probabilistic model.\nFurthermore, a Softmax model is employed to adaptively allocate available\nresources for each promising arm that advances to the next round. The arm with\na higher probability of advancing will be allocated more resources.\nExperimental results show that BOASF is effective for speeding up the model\nselection and hyperparameter optimization processes while achieving robust and\nbetter prediction performance than the existing state-of-the-art automatic\nmachine learning methods. Moreover, BOASF achieves better anytime performance\nunder various time budgets.\n","authors":["Guanghui Zhu","Xin Fang","Feng Cheng","Lei Wang","Wenzhong Chen","Chunfeng Yuan","Yihua Huang"],"pdf_url":"https://arxiv.org/pdf/2507.20446v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10855v3","updated":"2025-08-07T17:04:23Z","published":"2024-12-14T15:03:33Z","title":"Fast and Robust Visuomotor Riemannian Flow Matching Policy","summary":"  Diffusion-based visuomotor policies excel at learning complex robotic tasks\nby effectively combining visual data with high-dimensional, multi-modal action\ndistributions. However, diffusion models often suffer from slow inference due\nto costly denoising processes or require complex sequential training arising\nfrom recent distilling approaches. This paper introduces Riemannian Flow\nMatching Policy (RFMP), a model that inherits the easy training and fast\ninference capabilities of flow matching (FM). Moreover, RFMP inherently\nincorporates geometric constraints commonly found in realistic robotic\napplications, as the robot state resides on a Riemannian manifold. To enhance\nthe robustness of RFMP, we propose Stable RFMP (SRFMP), which leverages\nLaSalle's invariance principle to equip the dynamics of FM with stability to\nthe support of a target Riemannian distribution. Rigorous evaluation on ten\nsimulated and real-world tasks show that RFMP successfully learns and\nsynthesizes complex sensorimotor policies on Euclidean and Riemannian spaces\nwith efficient training and inference phases, outperforming Diffusion Policies\nand Consistency Policies.\n","authors":["Haoran Ding","Noémie Jaquier","Jan Peters","Leonel Rozo"],"pdf_url":"https://arxiv.org/pdf/2412.10855v3.pdf","comment":"Accepted for publication in IEEE T-RO. Project website:\n  https://sites.google.com/view/rfmp 17 pages, 12 figures, 12 tables"},{"id":"http://arxiv.org/abs/2508.05571v1","updated":"2025-08-07T17:02:23Z","published":"2025-08-07T17:02:23Z","title":"Fairy$\\pm i$: the First 2-bit Complex LLM with All Parameters in\n  $\\{\\pm1, \\pm i\\}$","summary":"  Quantization-Aware Training (QAT) integrates quantization into the training\nloop, enabling LLMs to learn robust low-bit representations, and is widely\nrecognized as one of the most promising research directions. All current QAT\nresearch focuses on minimizing quantization error on full-precision models,\nwhere the full-precision accuracy acts as an upper bound (accuracy ceiling). No\nexisting method has even attempted to surpass this ceiling. To break this\nceiling, we propose a new paradigm: raising the ceiling (full-precision model),\nand then still quantizing it efficiently into 2 bits. We propose Fairy$\\pm i$,\nthe first 2-bit quantization framework for complex-valued LLMs. Specifically,\nour method leverages the representational advantages of the complex domain to\nboost full-precision accuracy. We map weights to the fourth roots of unity\n$\\{\\pm1, \\pm i\\}$, forming a perfectly symmetric and information-theoretically\noptimal 2-bit representation. Importantly, each quantized weight has either a\nzero real or imaginary part, enabling multiplication-free inference using only\nadditions and element swaps. Experimental results show that Fairy$\\pm i$\noutperforms the ceiling of existing 2-bit quantization approaches in terms of\nboth PPL and downstream tasks, while maintaining strict storage and compute\nefficiency. This work opens a new direction for building highly accurate and\npractical LLMs under extremely low-bit constraints.\n","authors":["Feiyu Wang","Guoan Wang","Yihao Zhang","Shengfan Wang","Weitao Li","Bokai Huang","Shimao Chen","Zihan Jiang","Rui Xu","Tong Yang"],"pdf_url":"https://arxiv.org/pdf/2508.05571v1.pdf","comment":"13 pages, 14 figures"},{"id":"http://arxiv.org/abs/2508.05570v1","updated":"2025-08-07T17:02:11Z","published":"2025-08-07T17:02:11Z","title":"High-Order Error Bounds for Markovian LSA with Richardson-Romberg\n  Extrapolation","summary":"  In this paper, we study the bias and high-order error bounds of the Linear\nStochastic Approximation (LSA) algorithm with Polyak-Ruppert (PR) averaging\nunder Markovian noise. We focus on the version of the algorithm with constant\nstep size $\\alpha$ and propose a novel decomposition of the bias via a\nlinearization technique. We analyze the structure of the bias and show that the\nleading-order term is linear in $\\alpha$ and cannot be eliminated by PR\naveraging. To address this, we apply the Richardson-Romberg (RR) extrapolation\nprocedure, which effectively cancels the leading bias term. We derive\nhigh-order moment bounds for the RR iterates and show that the leading error\nterm aligns with the asymptotically optimal covariance matrix of the vanilla\naveraged LSA iterates.\n","authors":["Ilya Levin","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2508.05570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05568v1","updated":"2025-08-07T17:00:47Z","published":"2025-08-07T17:00:47Z","title":"X-VFL: A New Vertical Federated Learning Framework with Cross Completion\n  and Decision Subspace Alignment","summary":"  Vertical Federated Learning (VFL) enables collaborative learning by\nintegrating disjoint feature subsets from multiple clients/parties. However,\nVFL typically faces two key challenges: i) the requirement for perfectly\naligned data samples across all clients (missing features are not allowed); ii)\nthe requirement for joint collaborative inference/prediction involving all\nclients (it does not support locally independent inference on a single client).\nTo address these challenges, we propose X-VFL, a new VFL framework designed to\ndeal with the non-aligned data samples with (partially) missing features and to\nsupport locally independent inference of new data samples for each client. In\nparticular, we design two novel modules in X-VFL: Cross Completion (XCom) and\nDecision Subspace Alignment (DS-Align). XCom can complete/reconstruct missing\nfeatures for non-aligned data samples by leveraging information from other\nclients. DS-Align aligns local features with completed and global features\nacross all clients within the decision subspace, thus enabling locally\nindependent inference at each client. Moreover, we provide convergence theorems\nfor different algorithms used in training X-VFL, showing an $O(1/\\sqrt{T})$\nconvergence rate for SGD-type algorithms and an $O(1/T)$ rate for PAGE-type\nalgorithms, where $T$ denotes the number of training update steps. Extensive\nexperiments on real-world datasets demonstrate that X-VFL significantly\noutperforms existing methods, e.g., achieving a 15% improvement in accuracy on\nthe image CIFAR-10 dataset and a 43% improvement on the medical MIMIC-III\ndataset. These results validate the practical effectiveness and superiority of\nX-VFL, particularly in scenarios involving partially missing features and\nlocally independent inference.\n","authors":["Qinghua Yao","Xiangrui Xu","Zhize Li"],"pdf_url":"https://arxiv.org/pdf/2508.05568v1.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2508.05567v1","updated":"2025-08-07T17:00:29Z","published":"2025-08-07T17:00:29Z","title":"L1-Regularized Functional Support Vector Machine","summary":"  In functional data analysis, binary classification with one functional\ncovariate has been extensively studied. We aim to fill in the gap of\nconsidering multivariate functional covariates in classification. In\nparticular, we propose an $L_1$-regularized functional support vector machine\nfor binary classification. An accompanying algorithm is developed to fit the\nclassifier. By imposing an $L_1$ penalty, the algorithm enables us to identify\nrelevant functional covariates of the binary response. Numerical results from\nsimulations and one real-world application demonstrate that the proposed\nclassifier enjoys good performance in both prediction and feature selection.\n","authors":["Bingfan Liu","Peijun Sang"],"pdf_url":"https://arxiv.org/pdf/2508.05567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05559v1","updated":"2025-08-07T16:40:09Z","published":"2025-08-07T16:40:09Z","title":"On the Design of Expressive and Trainable Pulse-based Quantum Machine\n  Learning Models","summary":"  Pulse-based Quantum Machine Learning (QML) has emerged as a novel paradigm in\nquantum artificial intelligence due to its exceptional hardware efficiency. For\npractical applications, pulse-based models must be both expressive and\ntrainable. Previous studies suggest that pulse-based models under dynamic\nsymmetry can be effectively trained, thanks to a favorable loss landscape that\nhas no barren plateaus. However, the resulting uncontrollability may compromise\nexpressivity when the model is inadequately designed. This paper investigates\nthe requirements for pulse-based QML models to be expressive while preserving\ntrainability. We present a necessary condition pertaining to the system's\ninitial state, the measurement observable, and the underlying dynamical\nsymmetry Lie algebra, supported by numerical simulations. Our findings\nestablish a framework for designing practical pulse-based QML models that\nbalance expressivity and trainability.\n","authors":["Han-Xiao Tao","Xin Wang","Re-Bing Wu"],"pdf_url":"https://arxiv.org/pdf/2508.05559v1.pdf","comment":"15 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.01834v2","updated":"2025-08-07T16:33:16Z","published":"2025-08-03T16:44:05Z","title":"Efficient optimization of expensive black-box simulators via marginal\n  means, with application to neutrino detector design","summary":"  With advances in scientific computing, computer experiments are increasingly\nused for optimizing complex systems. However, for modern applications, e.g.,\nthe optimization of nuclear physics detectors, each experiment run can require\nhundreds of CPU hours, making the optimization of its black-box simulator over\na high-dimensional space a challenging task. Given limited runs at inputs\n$\\mathbf{x}_1, \\cdots, \\mathbf{x}_n$, the best solution from these evaluated\ninputs can be far from optimal, particularly as dimensionality increases.\nExisting black-box methods, however, largely employ this ''pick-the-winner''\n(PW) solution, which leads to mediocre optimization performance. To address\nthis, we propose a new Black-box Optimization via Marginal Means (BOMM)\napproach. The key idea is a new estimator of a global optimizer $\\mathbf{x}^*$\nthat leverages the so-called marginal mean functions, which can be efficiently\ninferred with limited runs in high dimensions. Unlike PW, this estimator can\nselect solutions beyond evaluated inputs for improved optimization performance.\nAssuming the objective function follows a generalized additive model with\nunknown link function and under mild conditions, we prove that the BOMM\nestimator not only is consistent for optimization, but also has an optimization\nrate that tempers the ''curse-of-dimensionality'' faced by existing methods,\nthus enabling better performance as dimensionality increases. We present a\npractical framework for implementing BOMM using the transformed additive\nGaussian process surrogate model. Finally, we demonstrate the effectiveness of\nBOMM in numerical experiments and an application on neutrino detector\noptimization in nuclear physics.\n","authors":["Hwanwoo Kim","Simon Mak","Ann-Kathrin Schuetz","Alan Poon"],"pdf_url":"https://arxiv.org/pdf/2508.01834v2.pdf","comment":"updated funding information"},{"id":"http://arxiv.org/abs/2504.13787v3","updated":"2025-08-07T16:32:55Z","published":"2025-04-18T16:39:08Z","title":"Probabilistic Stability Guarantees for Feature Attributions","summary":"  Stability guarantees have emerged as a principled way to evaluate feature\nattributions, but existing certification methods rely on heavily smoothed\nclassifiers and often produce conservative guarantees. To address these\nlimitations, we introduce soft stability and propose a simple, model-agnostic,\nsample-efficient stability certification algorithm (SCA) that yields\nnon-trivial and interpretable guarantees for any attribution method. Moreover,\nwe show that mild smoothing achieves a more favorable trade-off between\naccuracy and stability, avoiding the aggressive compromises made in prior\ncertification methods. To explain this behavior, we use Boolean function\nanalysis to derive a novel characterization of stability under smoothing. We\nevaluate SCA on vision and language tasks and demonstrate the effectiveness of\nsoft stability in measuring the robustness of explanation methods.\n","authors":["Helen Jin","Anton Xue","Weiqiu You","Surbhi Goel","Eric Wong"],"pdf_url":"https://arxiv.org/pdf/2504.13787v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18148v4","updated":"2025-08-07T16:31:15Z","published":"2024-11-27T08:53:19Z","title":"A Runtime-Adaptive Transformer Neural Network Accelerator on FPGAs","summary":"  Transformer neural networks (TNN) excel in natural language processing (NLP),\nmachine translation, and computer vision (CV) without relying on recurrent or\nconvolutional layers. However, they have high computational and memory demands,\nparticularly on resource-constrained devices like FPGAs. Moreover, transformer\nmodels vary in processing time across applications, requiring custom models\nwith specific parameters. Designing custom accelerators for each model is\ncomplex and time-intensive. Some custom accelerators exist with no runtime\nadaptability, and they often rely on sparse matrices to reduce latency.\nHowever, hardware designs become more challenging due to the need for\napplication-specific sparsity patterns. This paper introduces ADAPTOR, a\nruntime-adaptive accelerator for dense matrix computations in transformer\nencoders and decoders on FPGAs. ADAPTOR enhances the utilization of processing\nelements and on-chip memory, enhancing parallelism and reducing latency. It\nincorporates efficient matrix tiling to distribute resources across FPGA\nplatforms and is fully quantized for computational efficiency and portability.\nEvaluations on Xilinx Alveo U55C data center cards and embedded platforms like\nVC707 and ZCU102 show that our design is 1.2$\\times$ and 2.87$\\times$ more\npower efficient than the NVIDIA K80 GPU and the i7-8700K CPU respectively.\nAdditionally, it achieves a speedup of 1.7 to 2.25$\\times$ compared to some\nstate-of-the-art FPGA-based accelerators.\n","authors":["Ehsan Kabir","Jason D. Bakos","David Andrews","Miaoqing Huang"],"pdf_url":"https://arxiv.org/pdf/2411.18148v4.pdf","comment":"arXiv admin note: text overlap with arXiv:2409.14023"},{"id":"http://arxiv.org/abs/2508.05547v1","updated":"2025-08-07T16:27:37Z","published":"2025-08-07T16:27:37Z","title":"Adapting Vision-Language Models Without Labels: A Comprehensive Survey","summary":"  Vision-Language Models (VLMs) have demonstrated remarkable generalization\ncapabilities across a wide range of tasks. However, their performance often\nremains suboptimal when directly applied to specific downstream scenarios\nwithout task-specific adaptation. To enhance their utility while preserving\ndata efficiency, recent research has increasingly focused on unsupervised\nadaptation methods that do not rely on labeled data. Despite the growing\ninterest in this area, there remains a lack of a unified, task-oriented survey\ndedicated to unsupervised VLM adaptation. To bridge this gap, we present a\ncomprehensive and structured overview of the field. We propose a taxonomy based\non the availability and nature of unlabeled visual data, categorizing existing\napproaches into four key paradigms: Data-Free Transfer (no data), Unsupervised\nDomain Transfer (abundant data), Episodic Test-Time Adaptation (batch data),\nand Online Test-Time Adaptation (streaming data). Within this framework, we\nanalyze core methodologies and adaptation strategies associated with each\nparadigm, aiming to establish a systematic understanding of the field.\nAdditionally, we review representative benchmarks across diverse applications\nand highlight open challenges and promising directions for future research. An\nactively maintained repository of relevant literature is available at\nhttps://github.com/tim-learn/Awesome-LabelFree-VLMs.\n","authors":["Hao Dong","Lijun Sheng","Jian Liang","Ran He","Eleni Chatzi","Olga Fink"],"pdf_url":"https://arxiv.org/pdf/2508.05547v1.pdf","comment":"Discussions, comments, and questions are welcome in\n  \\url{https://github.com/tim-learn/Awesome-LabelFree-VLMs}"},{"id":"http://arxiv.org/abs/2507.21886v4","updated":"2025-08-07T16:25:19Z","published":"2025-07-29T14:58:29Z","title":"Efficient Pain Recognition via Respiration Signals: A Single\n  Cross-Attention Transformer Multi-Window Fusion Pipeline","summary":"  Pain is a complex condition affecting a large portion of the population.\nAccurate and consistent evaluation is essential for individuals experiencing\npain, and it supports the development of effective and advanced management\nstrategies. Automatic pain assessment systems provide continuous monitoring and\nsupport clinical decision-making, aiming to reduce distress and prevent\nfunctional decline. This study has been submitted to the \\textit{Second\nMultimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The\nproposed method introduces a pipeline that leverages respiration as the input\nsignal and incorporates a highly efficient cross-attention transformer\nalongside a multi-windowing strategy. Extensive experiments demonstrate that\nrespiration is a valuable physiological modality for pain assessment. Moreover,\nexperiments revealed that compact and efficient models, when properly\noptimized, can achieve strong performance, often surpassing larger\ncounterparts. The proposed multi-window approach effectively captures both\nshort-term and long-term features, as well as global characteristics, thereby\nenhancing the model's representational capacity.\n","authors":["Stefanos Gkikas","Ioannis Kyprakis","Manolis Tsiknakis"],"pdf_url":"https://arxiv.org/pdf/2507.21886v4.pdf","comment":"arXiv admin note: text overlap with arXiv:2507.21881,\n  arXiv:2507.21875"},{"id":"http://arxiv.org/abs/2303.08112v5","updated":"2025-08-07T16:19:06Z","published":"2023-03-14T17:47:09Z","title":"Eliciting Latent Predictions from Transformers with the Tuned Lens","summary":"  We analyze transformers from the perspective of iterative inference, seeking\nto understand how model predictions are refined layer by layer. To do so, we\ntrain an affine probe for each block in a frozen pretrained model, making it\npossible to decode every hidden state into a distribution over the vocabulary.\nOur method, the tuned lens, is a refinement of the earlier \"logit lens\"\ntechnique, which yielded useful insights but is often brittle.\n  We test our method on various autoregressive language models with up to 20B\nparameters, showing it to be more predictive, reliable and unbiased than the\nlogit lens. With causal experiments, we show the tuned lens uses similar\nfeatures to the model itself. We also find the trajectory of latent predictions\ncan be used to detect malicious inputs with high accuracy. All code needed to\nreproduce our results can be found at\nhttps://github.com/AlignmentResearch/tuned-lens.\n","authors":["Nora Belrose","Igor Ostrovsky","Lev McKinney","Zach Furman","Logan Smith","Danny Halawi","Stella Biderman","Jacob Steinhardt"],"pdf_url":"https://arxiv.org/pdf/2303.08112v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05537v1","updated":"2025-08-07T16:13:24Z","published":"2025-08-07T16:13:24Z","title":"Tractable Sharpness-Aware Learning of Probabilistic Circuits","summary":"  Probabilistic Circuits (PCs) are a class of generative models that allow\nexact and tractable inference for a wide range of queries. While recent\ndevelopments have enabled the learning of deep and expressive PCs, this\nincreased capacity can often lead to overfitting, especially when data is\nlimited. We analyze PC overfitting from a log-likelihood-landscape perspective\nand show that it is often caused by convergence to sharp optima that generalize\npoorly. Inspired by sharpness aware minimization in neural networks, we propose\na Hessian-based regularizer for training PCs. As a key contribution, we show\nthat the trace of the Hessian of the log-likelihood-a sharpness proxy that is\ntypically intractable in deep neural networks-can be computed efficiently for\nPCs. Minimizing this Hessian trace induces a gradient-norm-based regularizer\nthat yields simple closed-form parameter updates for EM, and integrates\nseamlessly with gradient based learning methods. Experiments on synthetic and\nreal-world datasets demonstrate that our method consistently guides PCs toward\nflatter minima, improves generalization performance.\n","authors":["Hrithik Suresh","Sahil Sidheekh","Vishnu Shreeram M. P","Sriraam Natarajan","Narayanan C. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2508.05537v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05535v1","updated":"2025-08-07T16:09:12Z","published":"2025-08-07T16:09:12Z","title":"Mixed-Initiative Dialog for Human-Robot Collaborative Manipulation","summary":"  Effective robotic systems for long-horizon human-robot collaboration must\nadapt to a wide range of human partners, whose physical behavior, willingness\nto assist, and understanding of the robot's capabilities may change over time.\nThis demands a tightly coupled communication loop that grants both agents the\nflexibility to propose, accept, or decline requests as they coordinate toward\ncompleting the task effectively. We apply a Mixed-Initiative dialog paradigm to\nCollaborative human-roBot teaming and propose MICoBot, a system that handles\nthe common scenario where both agents, using natural language, take initiative\nin formulating, accepting, or rejecting proposals on who can best complete\ndifferent steps of a task. To handle diverse, task-directed dialog, and find\nsuccessful collaborative strategies that minimize human effort, MICoBot makes\ndecisions at three levels: (1) a meta-planner considers human dialog to\nformulate and code a high-level collaboration strategy, (2) a planner optimally\nallocates the remaining steps to either agent based on the robot's capabilities\n(measured by a simulation-pretrained affordance model) and the human's\nestimated availability to help, and (3) an action executor decides the\nlow-level actions to perform or words to say to the human. Our extensive\nevaluations in simulation and real-world -- on a physical robot with 18 unique\nhuman participants over 27 hours -- demonstrate the ability of our method to\neffectively collaborate with diverse human users, yielding significantly\nimproved task success and user experience than a pure LLM baseline and other\nagent allocation models. See additional videos and materials at\nhttps://robin-lab.cs.utexas.edu/MicoBot/.\n","authors":["Albert Yu","Chengshu Li","Luca Macesanu","Arnav Balaji","Ruchira Ray","Raymond Mooney","Roberto Martín-Martín"],"pdf_url":"https://arxiv.org/pdf/2508.05535v1.pdf","comment":"Project website at https://robin-lab.cs.utexas.edu/MicoBot/"},{"id":"http://arxiv.org/abs/2503.09032v2","updated":"2025-08-07T16:01:43Z","published":"2025-03-12T03:45:53Z","title":"Teaching LLMs How to Learn with Contextual Fine-Tuning","summary":"  Prompting Large Language Models (LLMs), or providing context on the expected\nmodel of operation, is an effective way to steer the outputs of such models to\nsatisfy human desiderata after they have been trained. But in rapidly evolving\ndomains, there is often need to fine-tune LLMs to improve either the kind of\nknowledge in their memory or their abilities to perform open ended reasoning in\nnew domains. When human's learn new concepts, we often do so by linking the new\nmaterial that we are studying to concepts we have already learned before. To\nthat end, we ask, \"can prompting help us teach LLMs how to learn\". In this\nwork, we study a novel generalization of instruction tuning, called contextual\nfine-tuning, to fine-tune LLMs. Our method leverages instructional prompts\ndesigned to mimic human cognitive strategies in learning and problem-solving to\nguide the learning process during training, aiming to improve the model's\ninterpretation and understanding of domain-specific knowledge. We empirically\ndemonstrate that this simple yet effective modification improves the ability of\nLLMs to be fine-tuned rapidly on new datasets both within the medical and\nfinancial domains.\n","authors":["Younwoo Choi","Muhammad Adil Asif","Ziwen Han","John Willes","Rahul G. Krishnan"],"pdf_url":"https://arxiv.org/pdf/2503.09032v2.pdf","comment":"ICLR 2025"},{"id":"http://arxiv.org/abs/2508.02583v2","updated":"2025-08-07T15:57:23Z","published":"2025-08-04T16:39:24Z","title":"CAMA: Enhancing Mathematical Reasoning in Large Language Models with\n  Causal Knowledge","summary":"  Large Language Models (LLMs) have demonstrated strong performance across a\nwide range of tasks, yet they still struggle with complex mathematical\nreasoning, a challenge fundamentally rooted in deep structural dependencies. To\naddress this challenge, we propose \\textbf{CA}usal \\textbf{MA}thematician\n(\\textbf{CAMA}), a two-stage causal framework that equips LLMs with explicit,\nreusable mathematical structure. In the learning stage, CAMA first constructs\nthe \\textbf{M}athematical \\textbf{C}ausal \\textbf{G}raph (\\textbf{MCG}), a\nhigh-level representation of solution strategies, by combining LLM priors with\ncausal discovery algorithms applied to a corpus of question-solution pairs. The\nresulting MCG encodes essential knowledge points and their causal dependencies.\nTo better align the graph with downstream reasoning tasks, CAMA further refines\nthe MCG through iterative feedback derived from a selected subset of the\nquestion-solution pairs. In the reasoning stage, given a new question, CAMA\ndynamically extracts a task-relevant subgraph from the MCG, conditioned on both\nthe question content and the LLM's intermediate reasoning trace. This subgraph,\nwhich encodes the most pertinent knowledge points and their causal\ndependencies, is then injected back into the LLM to guide its reasoning\nprocess. Empirical results on real-world datasets show that CAMA significantly\nimproves LLM performance on challenging mathematical problems. Furthermore, our\nexperiments demonstrate that structured guidance consistently outperforms\nunstructured alternatives, and that incorporating asymmetric causal\nrelationships yields greater improvements than using symmetric associations\nalone.\n","authors":["Lei Zan","Keli Zhang","Ruichu Cai","Lujia Pan"],"pdf_url":"https://arxiv.org/pdf/2508.02583v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05513v1","updated":"2025-08-07T15:46:59Z","published":"2025-08-07T15:46:59Z","title":"Streamlining Admission with LOR Insights: AI-Based Leadership Assessment\n  in Online Master's Program","summary":"  Letters of recommendation (LORs) provide valuable insights into candidates'\ncapabilities and experiences beyond standardized test scores. However,\nreviewing these text-heavy materials is time-consuming and labor-intensive. To\naddress this challenge and support the admission committee in providing\nfeedback for students' professional growth, our study introduces LORI: LOR\nInsights, a novel AI-based detection tool for assessing leadership skills in\nLORs submitted by online master's program applicants. By employing natural\nlanguage processing and leveraging large language models using RoBERTa and\nLLAMA, we seek to identify leadership attributes such as teamwork,\ncommunication, and innovation. Our latest RoBERTa model achieves a weighted F1\nscore of 91.6%, a precision of 92.4%, and a recall of 91.6%, showing a strong\nlevel of consistency in our test data. With the growing importance of\nleadership skills in the STEM sector, integrating LORI into the graduate\nadmissions process is crucial for accurately assessing applicants' leadership\ncapabilities. This approach not only streamlines the admissions process but\nalso automates and ensures a more comprehensive evaluation of candidates'\ncapabilities.\n","authors":["Meryem Yilmaz Soylu","Adrian Gallard","Jeonghyun Lee","Gayane Grigoryan","Rushil Desai","Stephen Harmon"],"pdf_url":"https://arxiv.org/pdf/2508.05513v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05504v1","updated":"2025-08-07T15:36:59Z","published":"2025-08-07T15:36:59Z","title":"Parameter-free entropy-regularized multi-view clustering with\n  hierarchical feature selection","summary":"  Multi-view clustering faces critical challenges in automatically discovering\npatterns across heterogeneous data while managing high-dimensional features and\neliminating irrelevant information. Traditional approaches suffer from manual\nparameter tuning and lack principled cross-view integration mechanisms. This\nwork introduces two complementary algorithms: AMVFCM-U and AAMVFCM-U, providing\na unified parameter-free framework. Our approach replaces fuzzification\nparameters with entropy regularization terms that enforce adaptive cross-view\nconsensus. The core innovation employs signal-to-noise ratio based\nregularization ($\\delta_j^h = \\frac{\\bar{x}_j^h}{(\\sigma_j^h)^2}$) for\nprincipled feature weighting with convergence guarantees, coupled with\ndual-level entropy terms that automatically balance view and feature\ncontributions. AAMVFCM-U extends this with hierarchical dimensionality\nreduction operating at feature and view levels through adaptive thresholding\n($\\theta^{h^{(t)}} = \\frac{d_h^{(t)}}{n}$). Evaluation across five diverse\nbenchmarks demonstrates superiority over 15 state-of-the-art methods. AAMVFCM-U\nachieves up to 97% computational efficiency gains, reduces dimensionality to\n0.45% of original size, and automatically identifies critical view combinations\nfor optimal pattern discovery.\n","authors":["Kristina P. Sinaga","Sara Colantonio","Miin-Shen Yang"],"pdf_url":"https://arxiv.org/pdf/2508.05504v1.pdf","comment":"81 pages, 10 figures, 17 tables"},{"id":"http://arxiv.org/abs/2508.05493v1","updated":"2025-08-07T15:29:22Z","published":"2025-08-07T15:29:22Z","title":"Exact and Heuristic Algorithms for Constrained Biclustering","summary":"  Biclustering, also known as co-clustering or two-way clustering,\nsimultaneously partitions the rows and columns of a data matrix to reveal\nsubmatrices with coherent patterns. Incorporating background knowledge into\nclustering to enhance solution quality and interpretability has attracted\ngrowing interest in mathematical optimization and machine learning research.\nExtending this paradigm to biclustering enables prior information to guide the\njoint grouping of rows and columns. We study constrained biclustering with\npairwise constraints, namely must-link and cannot-link constraints, which\nspecify whether objects should belong to the same or different biclusters. As a\nmodel problem, we address the constrained version of the k-densest disjoint\nbiclique problem, which aims to identify k disjoint complete bipartite\nsubgraphs (called bicliques) in a weighted complete bipartite graph, maximizing\nthe total density while satisfying pairwise constraints. We propose both exact\nand heuristic algorithms. The exact approach is a tailored branch-and-cut\nalgorithm based on a low-dimensional semidefinite programming (SDP) relaxation,\nstrengthened with valid inequalities and solved in a cutting-plane fashion.\nExploiting integer programming tools, a rounding scheme converts SDP solutions\ninto feasible biclusterings at each node. For large-scale instances, we\nintroduce an efficient heuristic based on the low-rank factorization of the\nSDP. The resulting nonlinear optimization problem is tackled with an augmented\nLagrangian method, where the subproblem is solved by decomposition through a\nblock-coordinate projected gradient algorithm. Extensive experiments on\nsynthetic and real-world datasets show that the exact method significantly\noutperforms general-purpose solvers, while the heuristic achieves high-quality\nsolutions efficiently on large instances.\n","authors":["Antonio M. Sudoso"],"pdf_url":"https://arxiv.org/pdf/2508.05493v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05492v1","updated":"2025-08-07T15:28:34Z","published":"2025-08-07T15:28:34Z","title":"MoMA: A Mixture-of-Multimodal-Agents Architecture for Enhancing Clinical\n  Prediction Modelling","summary":"  Multimodal electronic health record (EHR) data provide richer, complementary\ninsights into patient health compared to single-modality data. However,\neffectively integrating diverse data modalities for clinical prediction\nmodeling remains challenging due to the substantial data requirements. We\nintroduce a novel architecture, Mixture-of-Multimodal-Agents (MoMA), designed\nto leverage multiple large language model (LLM) agents for clinical prediction\ntasks using multimodal EHR data. MoMA employs specialized LLM agents\n(\"specialist agents\") to convert non-textual modalities, such as medical images\nand laboratory results, into structured textual summaries. These summaries,\ntogether with clinical notes, are combined by another LLM (\"aggregator agent\")\nto generate a unified multimodal summary, which is then used by a third LLM\n(\"predictor agent\") to produce clinical predictions. Evaluating MoMA on three\nprediction tasks using real-world datasets with different modality combinations\nand prediction settings, MoMA outperforms current state-of-the-art methods,\nhighlighting its enhanced accuracy and flexibility across various tasks.\n","authors":["Jifan Gao","Mahmudur Rahman","John Caskey","Madeline Oguss","Ann O'Rourke","Randy Brown","Anne Stey","Anoop Mayampurath","Matthew M. Churpek","Guanhua Chen","Majid Afshar"],"pdf_url":"https://arxiv.org/pdf/2508.05492v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05489v1","updated":"2025-08-07T15:24:26Z","published":"2025-08-07T15:24:26Z","title":"Keep It Real: Challenges in Attacking Compression-Based Adversarial\n  Purification","summary":"  Previous work has suggested that preprocessing images through lossy\ncompression can defend against adversarial perturbations, but comprehensive\nattack evaluations have been lacking. In this paper, we construct strong\nwhite-box and adaptive attacks against various compression models and identify\na critical challenge for attackers: high realism in reconstructed images\nsignificantly increases attack difficulty. Through rigorous evaluation across\nmultiple attack scenarios, we demonstrate that compression models capable of\nproducing realistic, high-fidelity reconstructions are substantially more\nresistant to our attacks. In contrast, low-realism compression models can be\nbroken. Our analysis reveals that this is not due to gradient masking. Rather,\nrealistic reconstructions maintaining distributional alignment with natural\nimages seem to offer inherent robustness. This work highlights a significant\nobstacle for future adversarial attacks and suggests that developing more\neffective techniques to overcome realism represents an essential challenge for\ncomprehensive security evaluation.\n","authors":["Samuel Räber","Till Aczel","Andreas Plesner","Roger Wattenhofer"],"pdf_url":"https://arxiv.org/pdf/2508.05489v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.04610v2","updated":"2025-08-07T15:23:54Z","published":"2025-08-06T16:29:59Z","title":"Neuromorphic Cybersecurity with Semi-supervised Lifelong Learning","summary":"  Inspired by the brain's hierarchical processing and energy efficiency, this\npaper presents a Spiking Neural Network (SNN) architecture for lifelong Network\nIntrusion Detection System (NIDS). The proposed system first employs an\nefficient static SNN to identify potential intrusions, which then activates an\nadaptive dynamic SNN responsible for classifying the specific attack type.\nMimicking biological adaptation, the dynamic classifier utilizes Grow When\nRequired (GWR)-inspired structural plasticity and a novel Adaptive\nSpike-Timing-Dependent Plasticity (Ad-STDP) learning rule. These bio-plausible\nmechanisms enable the network to learn new threats incrementally while\npreserving existing knowledge. Tested on the UNSW-NB15 benchmark in a continual\nlearning setting, the architecture demonstrates robust adaptation, reduced\ncatastrophic forgetting, and achieves $85.3$\\% overall accuracy. Furthermore,\nsimulations using the Intel Lava framework confirm high operational sparsity,\nhighlighting the potential for low-power deployment on neuromorphic hardware.\n","authors":["Md Zesun Ahmed Mia","Malyaban Bal","Sen Lu","George M. Nishibuchi","Suhas Chelian","Srini Vasan","Abhronil Sengupta"],"pdf_url":"https://arxiv.org/pdf/2508.04610v2.pdf","comment":"Accepted at ACM International Conference on Neuromorphic Systems\n  (ICONS) 2025"},{"id":"http://arxiv.org/abs/2508.05472v1","updated":"2025-08-07T15:12:08Z","published":"2025-08-07T15:12:08Z","title":"Prediction of Survival Outcomes under Clinical Presence Shift: A Joint\n  Neural Network Architecture","summary":"  Electronic health records arise from the complex interaction between patients\nand the healthcare system. This observation process of interactions, referred\nto as clinical presence, often impacts observed outcomes. When using electronic\nhealth records to develop clinical prediction models, it is standard practice\nto overlook clinical presence, impacting performance and limiting the\ntransportability of models when this interaction evolves. We propose a\nmulti-task recurrent neural network that jointly models the inter-observation\ntime and the missingness processes characterising this interaction in parallel\nto the survival outcome of interest. Our work formalises the concept of\nclinical presence shift when the prediction model is deployed in new settings\n(e.g. different hospitals, regions or countries), and we theoretically justify\nwhy the proposed joint modelling can improve transportability under changes in\nclinical presence. We demonstrate, in a real-world mortality prediction task in\nthe MIMIC-III dataset, how the proposed strategy improves performance and\ntransportability compared to state-of-the-art prediction models that do not\nincorporate the observation process. These results emphasise the importance of\nleveraging clinical presence to improve performance and create more\ntransportable clinical prediction models.\n","authors":["Vincent Jeanselme","Glen Martin","Matthew Sperrin","Niels Peek","Brian Tom","Jessica Barrett"],"pdf_url":"https://arxiv.org/pdf/2508.05472v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05469v1","updated":"2025-08-07T15:11:43Z","published":"2025-08-07T15:11:43Z","title":"Let's Measure Information Step-by-Step: LLM-Based Evaluation Beyond\n  Vibes","summary":"  We develop mechanisms for evaluating AI systems without ground truth by\nexploiting a connection between gaming resistance and output quality. The data\nprocessing inequality ensures post-hoc attempts to game a metric degrades both\ninformation content and task performance. We prove that f-mutual information\nmeasures are the unique gaming resistant mechanisms under natural conditions,\nwith the overseer acting as an agent. While Shannon mutual information faces\nexponential sample complexity, bounded measures like total variation distance\nremain tractable. Empirically, across ten domains from translation to peer\nreview, all information-theoretic mechanisms achieve perfect discrimination (d\n> 0.5) between faithful and strategic agents. In contrast, LLM judges exhibit\nsystematic evaluation inversion, preferring fabricated content over accurate\nsummaries. Our mechanisms show 10-100x better robustness to adversarial\nmanipulation than current practices. We also find performance follows an\ninverted-U curve with compression ratio, peaking at 10:1 where agent responses\nexhibit optimal information diversity (3 effective dimensions), giving a\nbias-variance perspective on when our approach is expected to be most\neffective.\n","authors":["Zachary Robertson","Sanmi Koyejo"],"pdf_url":"https://arxiv.org/pdf/2508.05469v1.pdf","comment":"13 pages"},{"id":"http://arxiv.org/abs/2507.00402v2","updated":"2025-08-07T15:06:17Z","published":"2025-07-01T03:39:08Z","title":"GRAND: Graph Release with Assured Node Differential Privacy","summary":"  Differential privacy is a well-established framework for safeguarding\nsensitive information in data. While extensively applied across various\ndomains, its application to network data -- particularly at the node level --\nremains underexplored. Existing methods for node-level privacy either focus\nexclusively on query-based approaches, which restrict output to pre-specified\nnetwork statistics, or fail to preserve key structural properties of the\nnetwork. In this work, we propose GRAND (Graph Release with Assured Node\nDifferential privacy), which is, to the best of our knowledge, the first\nnetwork release mechanism that releases entire networks while ensuring\nnode-level differential privacy and preserving structural properties. Under a\nbroad class of latent space models, we show that the released network\nasymptotically follows the same distribution as the original network. The\neffectiveness of the approach is evaluated through extensive experiments on\nboth synthetic and real-world datasets.\n","authors":["Suqing Liu","Xuan Bi","Tianxi Li"],"pdf_url":"https://arxiv.org/pdf/2507.00402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05463v1","updated":"2025-08-07T15:02:39Z","published":"2025-08-07T15:02:39Z","title":"Task complexity shapes internal representations and robustness in neural\n  networks","summary":"  Neural networks excel across a wide range of tasks, yet remain black boxes.\nIn particular, how their internal representations are shaped by the complexity\nof the input data and the problems they solve remains obscure. In this work, we\nintroduce a suite of five data-agnostic probes-pruning, binarization, noise\ninjection, sign flipping, and bipartite network randomization-to quantify how\ntask difficulty influences the topology and robustness of representations in\nmultilayer perceptrons (MLPs). MLPs are represented as signed, weighted\nbipartite graphs from a network science perspective. We contrast easy and hard\nclassification tasks on the MNIST and Fashion-MNIST datasets. We show that\nbinarizing weights in hard-task models collapses accuracy to chance, whereas\neasy-task models remain robust. We also find that pruning low-magnitude edges\nin binarized hard-task models reveals a sharp phase-transition in performance.\nMoreover, moderate noise injection can enhance accuracy, resembling a\nstochastic-resonance effect linked to optimal sign flips of small-magnitude\nweights. Finally, preserving only the sign structure-instead of precise weight\nmagnitudes-through bipartite network randomizations suffices to maintain high\naccuracy. These phenomena define a model- and modality-agnostic measure of task\ncomplexity: the performance gap between full-precision and binarized or\nshuffled neural network performance. Our findings highlight the crucial role of\nsigned bipartite topology in learned representations and suggest practical\nstrategies for model compression and interpretability that align with task\ncomplexity.\n","authors":["Robert Jankowski","Filippo Radicchi","M. Ángeles Serrano","Marián Boguñá","Santo Fortunato"],"pdf_url":"https://arxiv.org/pdf/2508.05463v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01576v2","updated":"2025-08-07T14:56:46Z","published":"2024-11-03T14:00:20Z","title":"Explainable Clustering Beyond Worst-Case Guarantees","summary":"  We study the explainable clustering problem first posed by Moshkovitz,\nDasgupta, Rashtchian, and Frost (ICML 2020). The goal of explainable clustering\nis to fit an axis-aligned decision tree with $K$ leaves and minimal clustering\ncost (where every leaf is a cluster). The fundamental theoretical question in\nthis line of work is the \\textit{price of explainability}, defined as the ratio\nbetween the clustering cost of the tree and the optimal cost. Numerous papers\nhave provided worst-case guarantees on this quantity. For $K$-medians, it has\nrecently been shown that the worst-case price of explainability is $\\Theta(\\log\nK)$. While this settles the matter from a data-agnostic point of view, two\nimportant questions remain unanswered: Are tighter guarantees possible for\nwell-clustered data? And can we trust decision trees to recover underlying\ncluster structures? In this paper, we place ourselves in a statistical setting\nof mixture models to answer both questions. We prove that better guarantees are\nindeed feasible for well-clustered data. Our algorithm takes as input a mixture\nmodel and constructs a tree in data-independent time. We then extend our\nanalysis to kernel clustering, deriving new guarantees that significantly\nimprove over existing worst-case bounds.\n","authors":["Maximilian Fleissner","Maedeh Zarvandi","Debarghya Ghoshdastidar"],"pdf_url":"https://arxiv.org/pdf/2411.01576v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.07638v2","updated":"2025-08-07T14:51:18Z","published":"2025-04-10T10:38:13Z","title":"Predicting the Lifespan of Industrial Printheads with Survival Analysis","summary":"  Accurately predicting the lifespan of critical device components is essential\nfor maintenance planning and production optimization, making it a topic of\nsignificant interest in both academia and industry. In this work, we\ninvestigate the use of survival analysis for predicting the lifespan of\nproduction printheads developed by Canon Production Printing. Specifically, we\nfocus on the application of five techniques to estimate survival probabilities\nand failure rates: the Kaplan-Meier estimator, Cox proportional hazard model,\nWeibull accelerated failure time model, random survival forest, and gradient\nboosting. The resulting estimates are further refined using isotonic regression\nand subsequently aggregated to determine the expected number of failures. The\npredictions are then validated against real-world ground truth data across\nmultiple time windows to assess model reliability. Our quantitative evaluation\nusing three performance metrics demonstrates that survival analysis outperforms\nindustry-standard baseline methods for printhead lifespan prediction.\n","authors":["Dan Parii","Evelyne Janssen","Guangzhi Tang","Charalampos Kouzinopoulos","Marcin Pietrasik"],"pdf_url":"https://arxiv.org/pdf/2504.07638v2.pdf","comment":"This paper has been published in the 8th IEEE Conference on\n  Industrial Cyber-Physical Systems (ICPS) in Emden, Germany, May 12-15, 2025"},{"id":"http://arxiv.org/abs/2508.05454v1","updated":"2025-08-07T14:48:39Z","published":"2025-08-07T14:48:39Z","title":"EnergyPatchTST: Multi-scale Time Series Transformers with Uncertainty\n  Estimation for Energy Forecasting","summary":"  Accurate and reliable energy time series prediction is of great significance\nfor power generation planning and allocation. At present, deep learning time\nseries prediction has become the mainstream method. However, the multi-scale\ntime dynamics and the irregularity of real data lead to the limitations of the\nexisting methods. Therefore, we propose EnergyPatchTST, which is an extension\nof the Patch Time Series Transformer specially designed for energy forecasting.\nThe main innovations of our method are as follows: (1) multi-scale feature\nextraction mechanism to capture patterns with different time resolutions; (2)\nprobability prediction framework to estimate uncertainty through Monte Carlo\nelimination; (3) integration path of future known variables (such as\ntemperature and wind conditions); And (4) Pre-training and Fine-tuning examples\nto enhance the performance of limited energy data sets. A series of experiments\non common energy data sets show that EnergyPatchTST is superior to other\ncommonly used methods, the prediction error is reduced by 7-12%, and reliable\nuncertainty estimation is provided, which provides an important reference for\ntime series prediction in the energy field.\n","authors":["Wei Li","Zixin Wang","Qizheng Sun","Qixiang Gao","Fenglei Yang"],"pdf_url":"https://arxiv.org/pdf/2508.05454v1.pdf","comment":"Accepted for publication at the International Conference on\n  Intelligent Computing (ICIC 2025). 12 pages. The final authenticated version\n  is published in the Lecture Notes in Computer Science (LNCS) series, vol\n  15860, and is available online. This is the author's version of the work\n  submitted for peer review"},{"id":"http://arxiv.org/abs/2405.00708v2","updated":"2025-08-07T14:48:25Z","published":"2024-04-23T19:57:03Z","title":"Understanding Large Language Model Behaviors through Interactive\n  Counterfactual Generation and Analysis","summary":"  Understanding the behavior of large language models (LLMs) is crucial for\nensuring their safe and reliable use. However, existing explainable AI (XAI)\nmethods for LLMs primarily rely on word-level explanations, which are often\ncomputationally inefficient and misaligned with human reasoning processes.\nMoreover, these methods often treat explanation as a one-time output,\noverlooking its inherently interactive and iterative nature. In this paper, we\npresent LLM Analyzer, an interactive visualization system that addresses these\nlimitations by enabling intuitive and efficient exploration of LLM behaviors\nthrough counterfactual analysis. Our system features a novel algorithm that\ngenerates fluent and semantically meaningful counterfactuals via targeted\nremoval and replacement operations at user-defined levels of granularity. These\ncounterfactuals are used to compute feature attribution scores, which are then\nintegrated with concrete examples in a table-based visualization, supporting\ndynamic analysis of model behavior. A user study with LLM practitioners and\ninterviews with experts demonstrate the system's usability and effectiveness,\nemphasizing the importance of involving humans in the explanation process as\nactive participants rather than passive recipients.\n","authors":["Furui Cheng","Vilém Zouhar","Robin Shing Moon Chan","Daniel Fürst","Hendrik Strobelt","Mennatallah El-Assady"],"pdf_url":"https://arxiv.org/pdf/2405.00708v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1909.00659v2","updated":"2025-08-07T14:46:05Z","published":"2019-09-02T10:50:14Z","title":"Guided Random Forest and its application to data approximation","summary":"  We present a new way of constructing an ensemble classifier, named the Guided\nRandom Forest (GRAF) in the sequel. GRAF extends the idea of building oblique\ndecision trees with localized partitioning to obtain a global partitioning. We\nshow that global partitioning bridges the gap between decision trees and\nboosting algorithms. We empirically demonstrate that global partitioning\nreduces the generalization error bound. Results on 115 benchmark datasets show\nthat GRAF yields comparable or better results on a majority of datasets. We\nalso present a new way of approximating the datasets in the framework of random\nforests.\n","authors":["Prashant Gupta","Aashi Jindal"," Jayadeva","Debarka Sengupta"],"pdf_url":"https://arxiv.org/pdf/1909.00659v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05445v1","updated":"2025-08-07T14:37:23Z","published":"2025-08-07T14:37:23Z","title":"Learning Geometric-Aware Quadrature Rules for Functional Minimization","summary":"  Accurate numerical integration over non-uniform point clouds is a challenge\nfor modern mesh-free machine learning solvers for partial differential\nequations (PDEs) using variational principles. While standard Monte Carlo (MC)\nmethods are not capable of handling a non-uniform point cloud, modern neural\nnetwork architectures can deal with permutation-invariant inputs, creating\nquadrature rules for any point cloud. In this work, we introduce QuadrANN, a\nGraph Neural Network (GNN) architecture designed to learn optimal quadrature\nweights directly from the underlying geometry of point clouds. The design of\nthe model exploits a deep message-passing scheme where the initial layer\nencodes rich local geometric features from absolute and relative positions as\nwell as an explicit local density measure. In contrast, the following layers\nincorporate a global context vector. These architectural choices allow the\nQuadrANN to generate a data-driven quadrature rule that is\npermutation-invariant and adaptive to both local point density and the overall\ndomain shape. We test our methodology on a series of challenging test cases,\nincluding integration on convex and non-convex domains and estimating the\nsolution of the Heat and Fokker-Planck equations. Across all the tests,\nQuadrANN reduces the variance of the integral estimation compared to standard\nQuasi-Monte Carlo methods by warping the point clouds to be more dense in\ncritical areas where the integrands present certain singularities. This\nenhanced stability in critical areas of the domain at hand is critical for the\noptimization of energy functionals, leading to improved deep learning-based\nvariational solvers.\n","authors":["Costas Smaragdakis"],"pdf_url":"https://arxiv.org/pdf/2508.05445v1.pdf","comment":"15 pages, 4 figures"},{"id":"http://arxiv.org/abs/2508.05441v1","updated":"2025-08-07T14:31:22Z","published":"2025-08-07T14:31:22Z","title":"Tail-Risk-Safe Monte Carlo Tree Search under PAC-Level Guarantees","summary":"  Making decisions with respect to just the expected returns in Monte Carlo\nTree Search (MCTS) cannot account for the potential range of high-risk, adverse\noutcomes associated with a decision. To this end, safety-aware MCTS often\nconsider some constrained variants -- by introducing some form of mean risk\nmeasures or hard cost thresholds. These approaches fail to provide rigorous\ntail-safety guarantees with respect to extreme or high-risk outcomes (denoted\nas tail-risk), potentially resulting in serious consequence in high-stake\nscenarios. This paper addresses the problem by developing two novel solutions.\nWe first propose CVaR-MCTS, which embeds a coherent tail risk measure,\nConditional Value-at-Risk (CVaR), into MCTS. Our CVaR-MCTS with parameter\n$\\alpha$ achieves explicit tail-risk control over the expected loss in the\n\"worst $(1-\\alpha)\\%$ scenarios.\" Second, we further address the estimation\nbias of tail-risk due to limited samples. We propose Wasserstein-MCTS (or\nW-MCTS) by introducing a first-order Wasserstein ambiguity set\n$\\mathcal{P}_{\\varepsilon_{s}}(s,a)$ with radius $\\varepsilon_{s}$ to\ncharacterize the uncertainty in tail-risk estimates. We prove PAC tail-safety\nguarantees for both CVaR-MCTS and W-MCTS and establish their regret.\nEvaluations on diverse simulated environments demonstrate that our proposed\nmethods outperform existing baselines, effectively achieving robust tail-risk\nguarantees with improved rewards and stability.\n","authors":["Zuyuan Zhang","Arnob Ghosh","Tian Lan"],"pdf_url":"https://arxiv.org/pdf/2508.05441v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05437v1","updated":"2025-08-07T14:28:44Z","published":"2025-08-07T14:28:44Z","title":"Online Sparsification of Bipartite-Like Clusters in Graphs","summary":"  Graph clustering is an important algorithmic technique for analysing massive\ngraphs, and has been widely applied in many research fields of data science.\nWhile the objective of most graph clustering algorithms is to find a vertex set\nof low conductance, a sequence of recent studies highlights the importance of\nthe inter-connection between vertex sets when analysing real-world datasets.\nFollowing this line of research, in this work we study bipartite-like clusters\nand present efficient and online sparsification algorithms that find such\nclusters in both undirected graphs and directed ones. We conduct experimental\nstudies on both synthetic and real-world datasets, and show that our algorithms\nsignificantly speedup the running time of existing clustering algorithms while\npreserving their effectiveness.\n","authors":["Joyentanuj Das","Suranjan De","He Sun"],"pdf_url":"https://arxiv.org/pdf/2508.05437v1.pdf","comment":"ICML 2025"},{"id":"http://arxiv.org/abs/2508.05435v1","updated":"2025-08-07T14:25:43Z","published":"2025-08-07T14:25:43Z","title":"Competing Risks: Impact on Risk Estimation and Algorithmic Fairness","summary":"  Accurate time-to-event prediction is integral to decision-making, informing\nmedical guidelines, hiring decisions, and resource allocation. Survival\nanalysis, the quantitative framework used to model time-to-event data, accounts\nfor patients who do not experience the event of interest during the study\nperiod, known as censored patients. However, many patients experience events\nthat prevent the observation of the outcome of interest. These competing risks\nare often treated as censoring, a practice frequently overlooked due to a\nlimited understanding of its consequences. Our work theoretically demonstrates\nwhy treating competing risks as censoring introduces substantial bias in\nsurvival estimates, leading to systematic overestimation of risk and,\ncritically, amplifying disparities. First, we formalize the problem of\nmisclassifying competing risks as censoring and quantify the resulting error in\nsurvival estimates. Specifically, we develop a framework to estimate this error\nand demonstrate the associated implications for predictive performance and\nalgorithmic fairness. Furthermore, we examine how differing risk profiles\nacross demographic groups lead to group-specific errors, potentially\nexacerbating existing disparities. Our findings, supported by an empirical\nanalysis of cardiovascular management, demonstrate that ignoring competing\nrisks disproportionately impacts the individuals most at risk of these events,\npotentially accentuating inequity. By quantifying the error and highlighting\nthe fairness implications of the common practice of considering competing risks\nas censoring, our work provides a critical insight into the development of\nsurvival models: practitioners must account for competing risks to improve\naccuracy, reduce disparities in risk assessment, and better inform downstream\ndecisions.\n","authors":["Vincent Jeanselme","Brian Tom","Jessica Barrett"],"pdf_url":"https://arxiv.org/pdf/2508.05435v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2504.08632v2","updated":"2025-08-07T14:25:02Z","published":"2025-04-11T15:35:50Z","title":"Deep Learning Methods for Detecting Thermal Runaway Events in Battery\n  Production Lines","summary":"  One of the key safety considerations of battery manufacturing is thermal\nrunaway, the uncontrolled increase in temperature which can lead to fires,\nexplosions, and emissions of toxic gasses. As such, development of automated\nsystems capable of detecting such events is of considerable importance in both\nacademic and industrial contexts. In this work, we investigate the use of deep\nlearning for detecting thermal runaway in the battery production line of VDL\nNedcar, a Dutch automobile manufacturer. Specifically, we collect data from the\nproduction line to represent both baseline (non thermal runaway) and thermal\nrunaway conditions. Thermal runaway was simulated through the use of external\nheat and smoke sources. The data consisted of both optical and thermal images\nwhich were then preprocessed and fused before serving as input to our models.\nIn this regard, we evaluated three deep-learning models widely used in computer\nvision including shallow convolutional neural networks, residual neural\nnetworks, and vision transformers on two performance metrics. Furthermore, we\nevaluated these models using explainability methods to gain insight into their\nability to capture the relevant feature information from their inputs. The\nobtained results indicate that the use of deep learning is a viable approach to\nthermal runaway detection in battery production lines.\n","authors":["Athanasios Athanasopoulos","Matúš Mihalák","Marcin Pietrasik"],"pdf_url":"https://arxiv.org/pdf/2504.08632v2.pdf","comment":"This paper has been published in the 8th IEEE Conference on\n  Industrial Cyber-Physical Systems (ICPS) in Emden, Germany, May 12-15, 2025"}],"stat Machine Learning":[{"id":"http://arxiv.org/abs/2310.00539v3","updated":"2025-08-07T01:10:49Z","published":"2023-10-01T01:37:02Z","title":"Thompson Exploration with Best Challenger Rule in Best Arm\n  Identification","summary":"  This paper studies the fixed-confidence best arm identification (BAI) problem\nin the bandit framework in the canonical single-parameter exponential models.\nFor this problem, many policies have been proposed, but most of them require\nsolving an optimization problem at every round and/or are forced to explore an\narm at least a certain number of times except those restricted to the Gaussian\nmodel. To address these limitations, we propose a novel policy that combines\nThompson sampling with a computationally efficient approach known as the best\nchallenger rule. While Thompson sampling was originally considered for\nmaximizing the cumulative reward, we demonstrate that it can be used to\nnaturally explore arms in BAI without forcing it. We show that our policy is\nasymptotically optimal for any two-armed bandit problems and achieves near\noptimality for general $K$-armed bandit problems for $K\\geq 3$. Nevertheless,\nin numerical experiments, our policy shows competitive performance compared to\nasymptotically optimal policies in terms of sample complexity while requiring\nless computation cost. In addition, we highlight the advantages of our policy\nby comparing it to the concept of $\\beta$-optimality, a relaxed notion of\nasymptotic optimality commonly considered in the analysis of a class of\npolicies including the proposed one.\n","authors":["Jongyeong Lee","Junya Honda","Masashi Sugiyama"],"pdf_url":"https://arxiv.org/pdf/2310.00539v3.pdf","comment":"Corrigendum to the published version in ACML 2023\n  (https://proceedings.mlr.press/v222/lee24a.html)"},{"id":"http://arxiv.org/abs/2410.05106v3","updated":"2025-08-07T17:17:05Z","published":"2024-10-07T15:02:48Z","title":"Nonasymptotic Analysis of Stochastic Gradient Descent with the\n  Richardson-Romberg Extrapolation","summary":"  We address the problem of solving strongly convex and smooth minimization\nproblems using stochastic gradient descent (SGD) algorithm with a constant step\nsize. Previous works suggested to combine the Polyak-Ruppert averaging\nprocedure with the Richardson-Romberg extrapolation to reduce the asymptotic\nbias of SGD at the expense of a mild increase of the variance. We significantly\nextend previous results by providing an expansion of the mean-squared error of\nthe resulting estimator with respect to the number of iterations $n$. We show\nthat the root mean-squared error can be decomposed into the sum of two terms: a\nleading one of order $\\mathcal{O}(n^{-1/2})$ with explicit dependence on a\nminimax-optimal asymptotic covariance matrix, and a second-order term of order\n$\\mathcal{O}(n^{-3/4})$, where the power $3/4$ is best known. We also extend\nthis result to the higher-order moment bounds. Our analysis relies on the\nproperties of the SGD iterates viewed as a time-homogeneous Markov chain. In\nparticular, we establish that this chain is geometrically ergodic with respect\nto a suitably defined weighted Wasserstein semimetric.\n","authors":["Marina Sheshukova","Denis Belomestny","Alain Durmus","Eric Moulines","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2410.05106v3.pdf","comment":"ICLR-2025, camera-ready version. Some typos and definitions of\n  constants have been fixed in the appendix"},{"id":"http://arxiv.org/abs/2508.05570v1","updated":"2025-08-07T17:02:11Z","published":"2025-08-07T17:02:11Z","title":"High-Order Error Bounds for Markovian LSA with Richardson-Romberg\n  Extrapolation","summary":"  In this paper, we study the bias and high-order error bounds of the Linear\nStochastic Approximation (LSA) algorithm with Polyak-Ruppert (PR) averaging\nunder Markovian noise. We focus on the version of the algorithm with constant\nstep size $\\alpha$ and propose a novel decomposition of the bias via a\nlinearization technique. We analyze the structure of the bias and show that the\nleading-order term is linear in $\\alpha$ and cannot be eliminated by PR\naveraging. To address this, we apply the Richardson-Romberg (RR) extrapolation\nprocedure, which effectively cancels the leading bias term. We derive\nhigh-order moment bounds for the RR iterates and show that the leading error\nterm aligns with the asymptotically optimal covariance matrix of the vanilla\naveraged LSA iterates.\n","authors":["Ilya Levin","Alexey Naumov","Sergey Samsonov"],"pdf_url":"https://arxiv.org/pdf/2508.05570v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05567v1","updated":"2025-08-07T17:00:29Z","published":"2025-08-07T17:00:29Z","title":"L1-Regularized Functional Support Vector Machine","summary":"  In functional data analysis, binary classification with one functional\ncovariate has been extensively studied. We aim to fill in the gap of\nconsidering multivariate functional covariates in classification. In\nparticular, we propose an $L_1$-regularized functional support vector machine\nfor binary classification. An accompanying algorithm is developed to fit the\nclassifier. By imposing an $L_1$ penalty, the algorithm enables us to identify\nrelevant functional covariates of the binary response. Numerical results from\nsimulations and one real-world application demonstrate that the proposed\nclassifier enjoys good performance in both prediction and feature selection.\n","authors":["Bingfan Liu","Peijun Sang"],"pdf_url":"https://arxiv.org/pdf/2508.05567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01834v2","updated":"2025-08-07T16:33:16Z","published":"2025-08-03T16:44:05Z","title":"Efficient optimization of expensive black-box simulators via marginal\n  means, with application to neutrino detector design","summary":"  With advances in scientific computing, computer experiments are increasingly\nused for optimizing complex systems. However, for modern applications, e.g.,\nthe optimization of nuclear physics detectors, each experiment run can require\nhundreds of CPU hours, making the optimization of its black-box simulator over\na high-dimensional space a challenging task. Given limited runs at inputs\n$\\mathbf{x}_1, \\cdots, \\mathbf{x}_n$, the best solution from these evaluated\ninputs can be far from optimal, particularly as dimensionality increases.\nExisting black-box methods, however, largely employ this ''pick-the-winner''\n(PW) solution, which leads to mediocre optimization performance. To address\nthis, we propose a new Black-box Optimization via Marginal Means (BOMM)\napproach. The key idea is a new estimator of a global optimizer $\\mathbf{x}^*$\nthat leverages the so-called marginal mean functions, which can be efficiently\ninferred with limited runs in high dimensions. Unlike PW, this estimator can\nselect solutions beyond evaluated inputs for improved optimization performance.\nAssuming the objective function follows a generalized additive model with\nunknown link function and under mild conditions, we prove that the BOMM\nestimator not only is consistent for optimization, but also has an optimization\nrate that tempers the ''curse-of-dimensionality'' faced by existing methods,\nthus enabling better performance as dimensionality increases. We present a\npractical framework for implementing BOMM using the transformed additive\nGaussian process surrogate model. Finally, we demonstrate the effectiveness of\nBOMM in numerical experiments and an application on neutrino detector\noptimization in nuclear physics.\n","authors":["Hwanwoo Kim","Simon Mak","Ann-Kathrin Schuetz","Alan Poon"],"pdf_url":"https://arxiv.org/pdf/2508.01834v2.pdf","comment":"updated funding information"},{"id":"http://arxiv.org/abs/2410.21021v2","updated":"2025-08-07T15:36:21Z","published":"2024-10-28T13:42:27Z","title":"A Stein Gradient Descent Approach for Doubly Intractable Distributions","summary":"  Bayesian inference for doubly intractable distributions is challenging\nbecause they include intractable terms, which are functions of parameters of\ninterest. Although several alternatives have been developed for such models,\nthey are computationally intensive due to repeated auxiliary variable\nsimulations. We propose a novel Monte Carlo Stein variational gradient descent\n(MC-SVGD) approach for inference for doubly intractable distributions. Through\nan efficient gradient approximation, our MC-SVGD approach rapidly transforms an\narbitrary reference distribution to approximate the posterior distribution of\ninterest, without necessitating any predefined variational distribution class\nfor the posterior. Such a transport map is obtained by minimizing\nKullback-Leibler divergence between the transformed and posterior distributions\nin a reproducing kernel Hilbert space (RKHS). We also investigate the\nconvergence rate of the proposed method. We illustrate the application of the\nmethod to challenging examples, including a Potts model, an exponential random\ngraph model, and a Conway--Maxwell--Poisson regression model. The proposed\nmethod achieves substantial computational gains over existing algorithms, while\nproviding comparable inferential performance for the posterior distributions.\n","authors":["Heesang Lee","Songhee Kim","Bokgyeong Kang","Jaewoo Park"],"pdf_url":"https://arxiv.org/pdf/2410.21021v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.00402v2","updated":"2025-08-07T15:06:17Z","published":"2025-07-01T03:39:08Z","title":"GRAND: Graph Release with Assured Node Differential Privacy","summary":"  Differential privacy is a well-established framework for safeguarding\nsensitive information in data. While extensively applied across various\ndomains, its application to network data -- particularly at the node level --\nremains underexplored. Existing methods for node-level privacy either focus\nexclusively on query-based approaches, which restrict output to pre-specified\nnetwork statistics, or fail to preserve key structural properties of the\nnetwork. In this work, we propose GRAND (Graph Release with Assured Node\nDifferential privacy), which is, to the best of our knowledge, the first\nnetwork release mechanism that releases entire networks while ensuring\nnode-level differential privacy and preserving structural properties. Under a\nbroad class of latent space models, we show that the released network\nasymptotically follows the same distribution as the original network. The\neffectiveness of the approach is evaluated through extensive experiments on\nboth synthetic and real-world datasets.\n","authors":["Suqing Liu","Xuan Bi","Tianxi Li"],"pdf_url":"https://arxiv.org/pdf/2507.00402v2.pdf","comment":null},{"id":"http://arxiv.org/abs/1909.00659v2","updated":"2025-08-07T14:46:05Z","published":"2019-09-02T10:50:14Z","title":"Guided Random Forest and its application to data approximation","summary":"  We present a new way of constructing an ensemble classifier, named the Guided\nRandom Forest (GRAF) in the sequel. GRAF extends the idea of building oblique\ndecision trees with localized partitioning to obtain a global partitioning. We\nshow that global partitioning bridges the gap between decision trees and\nboosting algorithms. We empirically demonstrate that global partitioning\nreduces the generalization error bound. Results on 115 benchmark datasets show\nthat GRAF yields comparable or better results on a majority of datasets. We\nalso present a new way of approximating the datasets in the framework of random\nforests.\n","authors":["Prashant Gupta","Aashi Jindal"," Jayadeva","Debarka Sengupta"],"pdf_url":"https://arxiv.org/pdf/1909.00659v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05423v1","updated":"2025-08-07T14:15:09Z","published":"2025-08-07T14:15:09Z","title":"Negative Binomial Variational Autoencoders for Overdispersed Latent\n  Modeling","summary":"  Biological neurons communicate through spike trains, discrete, irregular\nbursts of activity that exhibit variability far beyond the modeling capacity of\nconventional variational autoencoders (VAEs). Recent work, such as the\nPoisson-VAE, makes a biologically inspired move by modeling spike counts using\nthe Poisson distribution. However, they impose a rigid constraint: equal mean\nand variance, which fails to reflect the true stochastic nature of neural\nactivity. In this work, we challenge this constraint and introduce NegBio-VAE,\na principled extension of the VAE framework that models spike counts using the\nnegative binomial distribution. This shift grants explicit control over\ndispersion, unlocking a broader and more accurate family of neural\nrepresentations. We further develop two ELBO optimization schemes and two\ndifferentiable reparameterization strategies tailored to the negative binomial\nsetting. By introducing one additional dispersion parameter, NegBio-VAE\ngeneralizes the Poisson latent model to a negative binomial formulation.\nEmpirical results demonstrate this minor yet impactful change leads to\nsignificant gains in reconstruction fidelity, highlighting the importance of\nexplicitly modeling overdispersion in spike-like activations.\n","authors":["Yixuan Zhang","Wenxin Zhang","Hua Jiang","Quyu Kong","Feng Zhou"],"pdf_url":"https://arxiv.org/pdf/2508.05423v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01567v2","updated":"2025-08-07T13:28:22Z","published":"2024-11-03T13:43:51Z","title":"Online Graph Topology Learning via Time-Vertex Adaptive Filters: From\n  Theory to Cardiac Fibrillation","summary":"  Graph Signal Processing (GSP) provides a powerful framework for analysing\ncomplex, interconnected systems by modelling data as signals on graphs. While\nrecent advances have enabled graph topology learning from observed signals,\nexisting methods often struggle with time-varying systems and real-time\napplications. To address this gap, we introduce AdaCGP, a sparsity-aware\nadaptive algorithm for dynamic graph topology estimation from multivariate time\nseries. AdaCGP estimates the Graph Shift Operator (GSO) through recursive\nupdate formulae designed to address sparsity, shift-invariance, and bias.\nThrough comprehensive simulations, we demonstrate that AdaCGP consistently\noutperforms multiple baselines across diverse graph topologies, achieving\nimprovements exceeding 83% in GSO estimation compared to state-of-the-art\nmethods while maintaining favourable computational scaling properties. Our\nvariable splitting approach enables reliable identification of causal\nconnections with near-zero false alarm rates and minimal missed edges. Applied\nto cardiac fibrillation recordings, AdaCGP tracks dynamic changes in\npropagation patterns more effectively than established methods like Granger\ncausality, capturing temporal variations in graph topology that static\napproaches miss. The algorithm successfully identifies stability\ncharacteristics in conduction patterns that may maintain arrhythmias,\ndemonstrating potential for clinical applications in diagnosis and treatment of\ncomplex biomedical systems.\n","authors":["Alexander Jenkins","Thiernithi Variddhisai","Ahmed El-Medany","Fu Siong Ng","Danilo Mandic"],"pdf_url":"https://arxiv.org/pdf/2411.01567v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.03775v3","updated":"2025-08-07T13:15:56Z","published":"2023-02-07T22:09:20Z","title":"Optimal Stochastic Non-smooth Non-convex Optimization through\n  Online-to-Non-convex Conversion","summary":"  We present new algorithms for optimizing non-smooth, non-convex stochastic\nobjectives based on a novel analysis technique. This improves the current\nbest-known complexity for finding a $(\\delta,\\epsilon)$-stationary point from\n$O(\\epsilon^{-4}\\delta^{-1})$ stochastic gradient queries to\n$O(\\epsilon^{-3}\\delta^{-1})$, which we also show to be optimal. Our primary\ntechnique is a reduction from non-smooth non-convex optimization to online\nlearning, after which our results follow from standard regret bounds in online\nlearning. For deterministic and second-order smooth objectives, applying more\nadvanced optimistic online learning techniques enables a new complexity of\n$O(\\epsilon^{-1.5}\\delta^{-0.5})$. Our techniques also recover all optimal or\nbest-known results for finding $\\epsilon$ stationary points of smooth or\nsecond-order smooth objectives in both stochastic and deterministic settings.\n","authors":["Ashok Cutkosky","Harsh Mehta","Francesco Orabona"],"pdf_url":"https://arxiv.org/pdf/2302.03775v3.pdf","comment":"v2: fixed error in proof of lower bound identified by Zijian Liu"},{"id":"http://arxiv.org/abs/2507.21807v2","updated":"2025-08-07T12:16:44Z","published":"2025-07-29T13:42:38Z","title":"MIBoost: A Gradient Boosting Algorithm for Variable Selection After\n  Multiple Imputation","summary":"  Statistical learning methods for automated variable selection, such as LASSO,\nelastic nets, or gradient boosting, have become increasingly popular tools for\nbuilding powerful prediction models. Yet, in practice, analyses are often\ncomplicated by missing data. The most widely used approach to address\nmissingness is multiple imputation, which involves creating several completed\ndatasets. However, there is an ongoing debate on how to perform model selection\nin the presence of multiple imputed datasets. Simple strategies, such as\npooling models across datasets, have been shown to have suboptimal properties.\nAlthough more sophisticated methods exist, they are often difficult to\nimplement and therefore not widely applied. In contrast, two recent approaches\nmodify the regularization methods LASSO and elastic nets by defining a single\nloss function, resulting in a unified set of coefficients across imputations.\nOur key contribution is to extend this principle to the framework of\ncomponent-wise gradient boosting by proposing MIBoost, a novel algorithm that\nemploys a uniform variable-selection mechanism across imputed datasets.\nSimulation studies suggest that our approach yields prediction performance\ncomparable to that of these recently proposed methods.\n","authors":["Robert Kuchen"],"pdf_url":"https://arxiv.org/pdf/2507.21807v2.pdf","comment":"21 pages, 2 algorithms, includes a simulation study"},{"id":"http://arxiv.org/abs/2508.05241v1","updated":"2025-08-07T10:31:01Z","published":"2025-08-07T10:31:01Z","title":"Periodic evaluation of defined-contribution pension fund: A dynamic risk\n  measure approach","summary":"  This paper introduces an innovative framework for the periodic evaluation of\ndefined-contribution pension funds. The performance of the pension fund is\nevaluated not only at retirement, but also within the interim periods. In\ncontrast to the traditional literature, we set the dynamic risk measure as the\ncriterion and manage the tail risk of the pension fund dynamically. To\neffectively interact with the stochastic environment, a model-free\nreinforcement learning algorithm is proposed to search for optimal investment\nand insurance strategies. Using U.S. data, we calibrate pension members'\nmortality rates and enhance mortality projections through a Lee-Carter model.\nOur numerical results indicate that periodic evaluations lead to more\nrisk-averse strategies, while mortality improvements encourage more\nrisk-seeking behaviors.\n","authors":["Wanting He","Wenyuan Li","Yunran Wei"],"pdf_url":"https://arxiv.org/pdf/2508.05241v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05212v1","updated":"2025-08-07T09:47:44Z","published":"2025-08-07T09:47:44Z","title":"High-Dimensional Differentially Private Quantile Regression: Distributed\n  Estimation and Statistical Inference","summary":"  With the development of big data and machine learning, privacy concerns have\nbecome increasingly critical, especially when handling heterogeneous datasets\ncontaining sensitive personal information. Differential privacy provides a\nrigorous framework for safeguarding individual privacy while enabling\nmeaningful statistical analysis. In this paper, we propose a differentially\nprivate quantile regression method for high-dimensional data in a distributed\nsetting. Quantile regression is a powerful and robust tool for modeling the\nrelationships between the covariates and responses in the presence of outliers\nor heavy-tailed distributions. To address the computational challenges due to\nthe non-smoothness of the quantile loss function, we introduce a Newton-type\ntransformation that reformulates the quantile regression task into an ordinary\nleast squares problem. Building on this, we develop a differentially private\nestimation algorithm with iterative updates, ensuring both near-optimal\nstatistical accuracy and formal privacy guarantees. For inference, we further\npropose a differentially private debiased estimator, which enables valid\nconfidence interval construction and hypothesis testing. Additionally, we\npropose a communication-efficient and differentially private bootstrap for\nsimultaneous hypothesis testing in high-dimensional quantile regression,\nsuitable for distributed settings with both small and abundant local data.\nExtensive simulations demonstrate the robustness and effectiveness of our\nmethods in practical scenarios.\n","authors":["Ziliang Shen","Caixing Wang","Shaoli Wang","Yibo Yan"],"pdf_url":"https://arxiv.org/pdf/2508.05212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.05173v1","updated":"2025-08-07T09:08:06Z","published":"2025-08-07T09:08:06Z","title":"Near Optimal Inference for the Best-Performing Algorithm","summary":"  Consider a collection of competing machine learning algorithms. Given their\nperformance on a benchmark of datasets, we would like to identify the best\nperforming algorithm. Specifically, which algorithm is most likely to rank\nhighest on a future, unseen dataset. A natural approach is to select the\nalgorithm that demonstrates the best performance on the benchmark. However, in\nmany cases the performance differences are marginal and additional candidates\nmay also be considered. This problem is formulated as subset selection for\nmultinomial distributions. Formally, given a sample from a countable alphabet,\nour goal is to identify a minimal subset of symbols that includes the most\nfrequent symbol in the population with high confidence. In this work, we\nintroduce a novel framework for the subset selection problem. We provide both\nasymptotic and finite-sample schemes that significantly improve upon currently\nknown methods. In addition, we provide matching lower bounds, demonstrating the\nfavorable performance of our proposed schemes.\n","authors":["Amichai Painsky"],"pdf_url":"https://arxiv.org/pdf/2508.05173v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2507.21197v3","updated":"2025-08-07T05:08:12Z","published":"2025-07-28T04:37:03Z","title":"An MLI-Guided Framework for Subgroup-Aware Modeling in Electronic Health\n  Records (AdaptHetero)","summary":"  Machine learning interpretation (MLI) has primarily been leveraged to foster\nclinician trust and extract insights from electronic health records (EHRs),\nrather than to guide subgroup-specific, operationalizable modeling strategies.\nTo bridge this gap, we propose AdaptHetero, a novel MLI-driven framework that\ntransforms interpretability insights into actionable guidance for tailoring\nmodel training and evaluation across subpopulations. Evaluated on three\nlarge-scale EHR datasets -- GOSSIS-1-eICU, WiDS, and MIMIC-IV -- AdaptHetero\nconsistently uncovers heterogeneous model behaviors in predicting ICU\nmortality, in-hospital death, and hidden hypoxemia. Integrating SHAP-based\ninterpretation with unsupervised clustering, AdaptHetero identifies clinically\nmeaningful, subgroup-specific characteristics, improving predictive performance\nacross many subpopulations (with gains up to 174.39 percent) while proactively\nflagging potential risks in others. These results highlight the framework's\npromise for more robust, equitable, and context-aware clinical deployment.\n","authors":["Ling Liao","Eva Aagaard"],"pdf_url":"https://arxiv.org/pdf/2507.21197v3.pdf","comment":"13 pages, 3 figures, 1 table"},{"id":"http://arxiv.org/abs/2407.09738v3","updated":"2025-08-07T03:52:28Z","published":"2024-07-13T01:32:37Z","title":"Sparse Asymptotic PCA: Identifying Sparse Latent Factors Across Time\n  Horizon in High-Dimensional Time Series","summary":"  This paper introduces a novel sparse latent factor modeling framework using\nsparse asymptotic Principal Component Analysis (APCA) to analyze the\nco-movements of high-dimensional panel data over time. Unlike existing methods\nbased on sparse PCA, which assume sparsity in the loading matrices, our\napproach posits sparsity in the factor processes while allowing non-sparse\nloadings. This is motivated by the fact that financial returns typically\nexhibit universal and non-sparse exposure to market factors. Unlike the\ncommonly used $\\ell_1$-relaxation in sparse PCA, the proposed sparse APCA\nemploys a truncated power method to estimate the leading sparse factor and a\nsequential deflation method for multi-factor cases under $\\ell_0$-constraints.\nFurthermore, we develop a data-driven approach to identify the sparsity of risk\nfactors over the time horizon using a novel cross-sectional cross-validation\nmethod. We establish the consistency of our estimators under mild conditions as\nboth the dimension $N$ and the sample size $T$ grow. Monte Carlo simulations\ndemonstrate that the proposed method performs well in finite samples.\nEmpirically, we apply our method to daily S&P 500 stock returns (2004--2016)\nand identify nine risk factors influencing the stock market.\n","authors":["Zhaoxing Gao"],"pdf_url":"https://arxiv.org/pdf/2407.09738v3.pdf","comment":"69 pages, 6 figures"},{"id":"http://arxiv.org/abs/2508.04985v1","updated":"2025-08-07T02:41:43Z","published":"2025-08-07T02:41:43Z","title":"RCUKF: Data-Driven Modeling Meets Bayesian Estimation","summary":"  Accurate modeling is crucial in many engineering and scientific applications,\nyet obtaining a reliable process model for complex systems is often\nchallenging. To address this challenge, we propose a novel framework, reservoir\ncomputing with unscented Kalman filtering (RCUKF), which integrates data-driven\nmodeling via reservoir computing (RC) with Bayesian estimation through the\nunscented Kalman filter (UKF). The RC component learns the nonlinear system\ndynamics directly from data, serving as a surrogate process model in the UKF\nprediction step to generate state estimates in high-dimensional or chaotic\nregimes where nominal mathematical models may fail. Meanwhile, the UKF\nmeasurement update integrates real-time sensor data to correct potential drift\nin the data-driven model. We demonstrate RCUKF effectiveness on well-known\nbenchmark problems and a real-time vehicle trajectory estimation task in a\nhigh-fidelity simulation environment.\n","authors":["Kumar Anurag","Kasra Azizi","Francesco Sorrentino","Wenbin Wan"],"pdf_url":"https://arxiv.org/pdf/2508.04985v1.pdf","comment":"6 pages, 6 figures. Accepted at IFAC MECC 2025 (Modeling, Estimation\n  and Control Conference)"},{"id":"http://arxiv.org/abs/2410.18321v2","updated":"2025-08-07T02:15:03Z","published":"2024-10-23T23:06:50Z","title":"Calibrating Deep Neural Network using Euclidean Distance","summary":"  Uncertainty is a fundamental aspect of real-world scenarios, where perfect\ninformation is rarely available. Humans naturally develop complex internal\nmodels to navigate incomplete data and effectively respond to unforeseen or\npartially observed events. In machine learning, Focal Loss is commonly used to\nreduce misclassification rates by emphasizing hard-to-classify samples.\nHowever, it does not guarantee well-calibrated predicted probabilities and may\nresult in models that are overconfident or underconfident. High calibration\nerror indicates a misalignment between predicted probabilities and actual\noutcomes, affecting model reliability. This research introduces a novel loss\nfunction called Focal Calibration Loss (FCL), designed to improve probability\ncalibration while retaining the advantages of Focal Loss in handling difficult\nsamples. By minimizing the Euclidean norm through a strictly proper loss, FCL\npenalizes the instance-wise calibration error and constrains bounds. We provide\ntheoretical validation for proposed method and apply it to calibrate CheXNet\nfor potential deployment in web-based health-care systems. Extensive\nevaluations on various models and datasets demonstrate that our method achieves\nSOTA performance in both calibration and accuracy metrics.\n","authors":["Wenhao Liang","Chang Dong","Liangwei Zheng","Wei Zhang","Weitong Chen"],"pdf_url":"https://arxiv.org/pdf/2410.18321v2.pdf","comment":"V2"}],"Computation":[{"id":"http://arxiv.org/abs/2508.05567v1","updated":"2025-08-07T17:00:29Z","published":"2025-08-07T17:00:29Z","title":"L1-Regularized Functional Support Vector Machine","summary":"  In functional data analysis, binary classification with one functional\ncovariate has been extensively studied. We aim to fill in the gap of\nconsidering multivariate functional covariates in classification. In\nparticular, we propose an $L_1$-regularized functional support vector machine\nfor binary classification. An accompanying algorithm is developed to fit the\nclassifier. By imposing an $L_1$ penalty, the algorithm enables us to identify\nrelevant functional covariates of the binary response. Numerical results from\nsimulations and one real-world application demonstrate that the proposed\nclassifier enjoys good performance in both prediction and feature selection.\n","authors":["Bingfan Liu","Peijun Sang"],"pdf_url":"https://arxiv.org/pdf/2508.05567v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2508.01834v2","updated":"2025-08-07T16:33:16Z","published":"2025-08-03T16:44:05Z","title":"Efficient optimization of expensive black-box simulators via marginal\n  means, with application to neutrino detector design","summary":"  With advances in scientific computing, computer experiments are increasingly\nused for optimizing complex systems. However, for modern applications, e.g.,\nthe optimization of nuclear physics detectors, each experiment run can require\nhundreds of CPU hours, making the optimization of its black-box simulator over\na high-dimensional space a challenging task. Given limited runs at inputs\n$\\mathbf{x}_1, \\cdots, \\mathbf{x}_n$, the best solution from these evaluated\ninputs can be far from optimal, particularly as dimensionality increases.\nExisting black-box methods, however, largely employ this ''pick-the-winner''\n(PW) solution, which leads to mediocre optimization performance. To address\nthis, we propose a new Black-box Optimization via Marginal Means (BOMM)\napproach. The key idea is a new estimator of a global optimizer $\\mathbf{x}^*$\nthat leverages the so-called marginal mean functions, which can be efficiently\ninferred with limited runs in high dimensions. Unlike PW, this estimator can\nselect solutions beyond evaluated inputs for improved optimization performance.\nAssuming the objective function follows a generalized additive model with\nunknown link function and under mild conditions, we prove that the BOMM\nestimator not only is consistent for optimization, but also has an optimization\nrate that tempers the ''curse-of-dimensionality'' faced by existing methods,\nthus enabling better performance as dimensionality increases. We present a\npractical framework for implementing BOMM using the transformed additive\nGaussian process surrogate model. Finally, we demonstrate the effectiveness of\nBOMM in numerical experiments and an application on neutrino detector\noptimization in nuclear physics.\n","authors":["Hwanwoo Kim","Simon Mak","Ann-Kathrin Schuetz","Alan Poon"],"pdf_url":"https://arxiv.org/pdf/2508.01834v2.pdf","comment":"updated funding information"},{"id":"http://arxiv.org/abs/2506.19230v3","updated":"2025-08-07T15:41:44Z","published":"2025-06-24T01:28:29Z","title":"gcor: A Python Implementation of Categorical Gini Correlation and Its\n  Inference","summary":"  Categorical Gini Correlation (CGC), introduced by Dang et al. (2020), is a\nnovel dependence measure designed to quantify the association between a\nnumerical variable and a categorical variable. It has appealing properties\ncompared to existing dependence measures, such as zero correlation mutually\nimplying independence between the variables. It has also shown superior\nperformance over existing methods when applied to feature screening for\nclassification. This article presents a Python implementation for computing\nCGC, constructing confidence intervals, and performing independence tests based\non it. Efficient algorithms have been implemented for all procedures, and they\nhave been optimized using vectorization and parallelization to enhance\ncomputational efficiency.\n","authors":["Sameera Hewage"],"pdf_url":"https://arxiv.org/pdf/2506.19230v3.pdf","comment":"Corrected typos"},{"id":"http://arxiv.org/abs/2508.05462v1","updated":"2025-08-07T15:02:35Z","published":"2025-08-07T15:02:35Z","title":"Piecewise Deterministic Sampling for Constrained Distributions","summary":"  In this paper, we propose a novel class of Piecewise Deterministic Markov\nProcesses (PDMP) that are designed to sample from constrained probability\ndistributions $\\pi$ supported on a convex set $\\mathcal{M}$. This class of\nPDMPs adapts the concept of a mirror map from convex optimisation to address\nsampling problems. Such samplers provides unbiased algorithms that respect the\nconstraints and, moreover, allow for exact subsampling. We demonstrate the\nadvantages of these algorithms on a range of constrained sampling problems\nwhere the proposed algorithm outperforms state of the art stochastic\ndifferential equation-based methods.\n","authors":["Joël Tatang Demano","Paul Dobson","Konstantinos Zygalakis"],"pdf_url":"https://arxiv.org/pdf/2508.05462v1.pdf","comment":"32 pages, 6 figures"},{"id":"http://arxiv.org/abs/2508.05278v1","updated":"2025-08-07T11:23:05Z","published":"2025-08-07T11:23:05Z","title":"A near-exact linear mixed model for genome-wide association studies","summary":"  Linear mixed models (LMM) are widely adopted in genome-wide association\nstudies (GWAS) to account for population stratification and cryptic\nrelatedness. However, the parameter estimation of LMMs imposes substantial\ncomputational burdens due to large-scale operations on genetic similarity\nmatrices (GSM). We introduced the near-exact linear mixed model (NExt-LMM), a\nnovel LMM framework that overcomes critical computational bottlenecks in GWAS\nthrough the following key innovations. Firstly, we exploit the inherent\nlow-rank structure of the GSM iteratively with the Hierarchical Off-Diagonal\nLow-Rank (HODLR) format, which is much faster than traditional decomposition\nmethods. Secondly, we leverage the HODLR-approximated GSM to dramatically\naccelerate the further maximum likelihood estimation with the shared\nheritability ratios. Moreover, we establish rigorous error bounds for the\nNExt-LMM estimator, proving that Kullback-Leibler divergence between the\napproximated and exact estimators can be arbitrarily small. Consequently, our\nproposed dual approach accelerates inference of LMMs while guaranteeing low\napproximation errors. We use numerical experiments to demonstrate that the\nNExt-LMM significantly improves inference efficiency compared to existing\nmethods. We develop a Python package that is available at\nhttps://github.com/ZhibinPU/NExt-LMM.\n","authors":["Zhibin Pu","Shufei Ge","Shijia Wang"],"pdf_url":"https://arxiv.org/pdf/2508.05278v1.pdf","comment":"36 pages, 13 figures"}]}}